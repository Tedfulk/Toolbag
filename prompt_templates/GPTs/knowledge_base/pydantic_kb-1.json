[
  {
    "title": "Pydantic V2 Plan - Pydantic",
    "url": "https://docs.pydantic.dev/latest/blog/pydantic-v2/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Pydantic V2 Plan Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Blog Pydantic V2 Is Here! Pydantic V2 Pre Release Pydantic V2 Plan Page contents Plan & Timeframe Breaking Changes & Compatibility Motivation & pydantic-core Headlines Performance Strict Mode Formalised Conversion Table Built in JSON support Validation without a Model Required vs. Nullable Cleanup Validator Function Improvements More powerful alias(es) Improvements to Dumping/Serialization/Export Validation Context Model Namespace Cleanup Strict API & API documentation Error descriptions No pure python implementation Pydantic becomes a pure python package is\\\\\\\\\\\\\\_instance like checks I'm dropping the word \"parse\" and just using \"validate\" Changes to custom field types Other Improvements Removed Features & Limitations Features Remaining Questions Implementation Details Conversion Table Pydantic V2 Plan¶ Samuel Colvin •  •  •  Jul 10, 2022 •  25 min read Updated late 10 Jul 2022, see pydantic#4226. I've spoken to quite a few people about pydantic V2, and mention it in passing even more. I owe people a proper explanation of the plan for V2: What we will add What we will remove What we will change How I'm intending to go about completing it and getting it released Some idea of timeframe Here goes... Enormous thanks to Eric Jolibois, Laurence Watson, Sebastián Ramírez, Adrian Garcia Badaracco, Tom Hamilton Stubber, Zac Hatfield-Dodds, Tom & Hasan Ramezani for reviewing this blog post, putting up with (and correcting) my horrible typos and making great suggestions that have made this post and Pydantic V2 materially better. Plan & Timeframe¶ I'm currently taking a kind of sabbatical after leaving my last job to get pydantic V2 released. Why? I ask myself that question quite often. I'm very proud of how much pydantic is used, but I'm less proud of its internals. Since it's something people seem to care about and use quite a lot (26m downloads a month, used by 72k public repos, 10k stars). I want it to be as good as possible. While I'm on the subject of why, how and my odd sabbatical: if you work for a large company who use pydantic a lot, you might encourage the company to sponsor me a meaningful amount, like Salesforce did (if your organisation is not open to donations, I can also offer consulting services). This is not charity, recruitment or marketing - the argument should be about how much the company will save if pydantic is 10x faster, more stable and more powerful - it would be worth paying me 10% of that to make it happen. Before pydantic V2 can be released, we need to release pydantic V1.10 - there are lots of changes in the main branch of pydantic contributed by the community, it's only fair to provide a release including those changes, many of them will remain unchanged for V2, the rest will act as a requirement to make sure pydantic V2 includes the capabilities they implemented. The basic road map for me is as follows: Implement a few more features in pydantic-core, and release a first version, see below Work on getting pydantic V1.10 out - basically merge all open PRs that are finished Release pydantic V1.10 Delete all stale PRs which didn't make it into V1.10, apologise profusely to their authors who put their valuable time into pydantic only to have their PRs closed (and explain when and how they can rebase and recreate the PR) Rename master to main, seems like a good time to do this Change the main branch of pydantic to target V2 Start tearing pydantic code apart and see how many existing tests can be made to pass Rinse, repeat Release pydantic V2 Plan is to have all this done by the end of October, definitely by the end of the year. Breaking Changes & Compatibility ¶ While we'll do our best to avoid breaking changes, some things will break. As per the greatest pun in modern TV history. You can't make a Tomelette without breaking some Greggs. Where possible, if breaking changes are unavoidable, we'll try to provide warnings or errors to make sure those changes are obvious to developers. Motivation & pydantic-core¶ Since pydantic's initial release, with the help of wonderful contributors Eric Jolibois, Sebastián Ramírez, David Montague and many others, the package and its usage have grown enormously. The core logic however has remained mostly unchanged since the initial experiment. It's old, it smells, it needs to be rebuilt. The release of version 2 is an opportunity to rebuild pydantic and correct many things that don't make sense - to make pydantic amazing . The core validation logic of pydantic V2 will be performed by a separate package pydantic-core which I've been building over the last few months. pydantic-core is written in Rust using the excellent pyo3 library which provides rust bindings for python. The motivation for building pydantic-core in Rust is as follows: Performance, see below Recursion and code separation - with no stack and little-to-no overhead for extra function calls, Rust allows pydantic-core to be implemented as a tree of small validators which call each other, making code easier to understand and extend without harming performance Safety and complexity - pydantic-core is a fairly complex piece of code which has to draw distinctions between many different errors, Rust is great in situations like this, it should minimise bugs () and allow the codebase to be extended for a long time to come Note The python interface to pydantic shouldn't change as a result of using pydantic-core, instead pydantic will use type annotations to build a schema for pydantic-core to use. pydantic-core is usable now, albeit with an unintuitive API, if you're interested, please give it a try. pydantic-core provides validators for common data types, see a list here. Other, less commonly used data types will be supported via validator functions implemented in pydantic, in Python. See pydantic-core#153 for a summary of what needs to be completed before its first release. Headlines¶ Here are some of the biggest changes expected in V2. Performance ¶ As a result of the move to Rust for the validation logic (and significant improvements in how validation objects are structured) pydantic V2 will be significantly faster than pydantic V1. Looking at the pydantic-core benchmarks today, pydantic V2 is between 4x and 50x faster than pydantic V1.9.1. In general, pydantic V2 is about 17x faster than V1 when validating a model containing a range of common fields. Strict Mode ¶ People have long complained about pydantic for coercing data instead of throwing an error. E.g. input to an int field could be 123 or the string \"123\" which would be converted to 123 While this is very useful in many scenarios (think: URL parameters, environment variables, user input), there are some situations where it's not desirable. pydantic-core comes with \"strict mode\" built in. With this, only the exact data type is allowed, e.g. passing \"123\" to an int field would result in a validation error. This will allow pydantic V2 to offer a strict switch which can be set on either a model or a field. Formalised Conversion Table ¶ As well as complaints about coercion, another legitimate complaint was inconsistency around data conversion. In pydantic V2, the following principle will govern when data should be converted in \"lax mode\" (strict=False): If the input data has a SINGLE and INTUITIVE representation, in the field's type, AND no data is lost during the conversion, then the data will be converted; otherwise a validation error is raised. There is one exception to this rule: string fields - virtually all data has an intuitive representation as a string (e.g. repr() and str()), therefore a custom rule is required: only str, bytes and bytearray are valid as inputs to string fields. Some examples of what that means in practice: Field Type Input Single & Intuitive R. All Data Preserved Result int \"123\" Convert int 123.0 Convert int 123.1 Error date \"2020-01-01\" Convert date \"2020-01-01T00:00:00\" Convert date \"2020-01-01T12:00:00\" Error int b\"1\" Error (For the last case converting bytes to an int could reasonably mean int(bytes\\\\\\\\\\\\\\_data.decode()) or int.from\\\\\\\\\\\\\\_bytes(b'1', 'big/little'), hence an error) In addition to the general rule, we'll provide a conversion table which defines exactly what data will be allowed to which field types. See the table below for a start on this. Built in JSON support ¶ pydantic-core can parse JSON directly into a model or output type, this both improves performance and avoids issue with strictness - e.g. if you have a strict model with a datetime field, the input must be a datetime object, but clearly that makes no sense when parsing JSON which has no datatime type. Same with bytes and many other types. Pydantic V2 will therefore allow some conversion when validating JSON directly, even in strict mode (e.g. ISO8601 string -> datetime, str -> bytes) even though this would not be allowed when validating a python object. In future direct validation of JSON will also allow: parsing in a separate thread while starting validation in the main thread line numbers from JSON to be included in the validation errors (These features will not be included in V2, but instead will hopefully be added later.) Note Pydantic has always had special support for JSON, that is not going to change. While in theory other formats could be specifically supported, the overheads and development time are significant and I don't think there's another format that's used widely enough to be worth specific logic. Other formats can be parsed to python then validated, similarly when serializing, data can be exported to a python object, then serialized, see below. Validation without a Model ¶ In pydantic V1 the core of all validation was a pydantic model, this led to a significant performance penalty and extra complexity when the output data type was not a model. pydantic-core operates on a tree of validators with no \"model\" type required at the base of that tree. It can therefore validate a single string or datetime value, a TypedDict or a Model equally easily. This feature will provide significant addition performance improvements in scenarios like: Adding validation to dataclasses Validating URL arguments, query strings, headers, etc. in FastAPI Adding validation to TypedDict Function argument validation Adding validation to your custom classes, decorators... In effect - anywhere where you don't care about a traditional model class instance. We'll need to add standalone methods for generating JSON Schema and dumping these objects to JSON, etc. Required vs. Nullable Cleanup ¶ Pydantic previously had a somewhat confused idea about \"required\" vs. \"nullable\". This mostly resulted from my misgivings about marking a field as Optional\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] but requiring a value to be provided but allowing it to be None - I didn't like using the word \"optional\" in relation to a field which was not optional. In pydantic V2, pydantic will move to match dataclasses, thus: Required vs. Nullable from pydantic import BaseModel class Foo(BaseModel): f1: str # required, cannot be None f2: str | None # required, can be None - same as Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] / Union\\\\\\\\\\\\\\[str, None\\\\\\\\\\\\\\] f3: str | None = None # not required, can be None f4: str = 'Foobar' # not required, but cannot be None Validator Function Improvements ¶ This is one of the changes in pydantic V2 that I'm most excited about, I've been talking about something like this for a long time, see pydantic#1984, but couldn't find a way to do this until now. Fields which use a function for validation can be any of the following types: function before mode - where the function is called before the inner validator is called function after mode - where the function is called after the inner validator is called plain mode - where there's no inner validator wrap mode - where the function takes a reference to a function which calls the inner validator, and can therefore modify the input before inner validation, modify the output after inner validation, conditionally not call the inner validator or catch errors from the inner validator and return a default value, or change the error An example how a wrap validator might look: Wrap mode validator function from datetime import datetime from pydantic import BaseModel, ValidationError, validator class MyModel(BaseModel): timestamp: datetime @validator('timestamp', mode='wrap') def validate\\\\\\\\\\\\\\_timestamp(cls, v, handler): if v == 'now': # we don't want to bother with further validation, # just return the new value return datetime.now() try: return handler(v) except ValidationError: # validation failed, in this case we want to # return a default value return datetime(2000, 1, 1) As well as being powerful, this provides a great \"escape hatch\" when pydantic validation doesn't do what you need. More powerful alias(es) ¶ pydantic-core can support alias \"paths\" as well as simple string aliases to flatten data as it's validated. Best demonstrated with an example: Alias paths from pydantic import BaseModel, Field class Foo(BaseModel): bar: str = Field(aliases=\\\\\\\\\\\\\\[\\\\\\\\\\\\\\['baz', 2, 'qux'\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]) data = { 'baz': \\\\\\\\\\\\\\[ {'qux': 'a'}, {'qux': 'b'}, {'qux': 'c'}, {'qux': 'd'}, \\\\\\\\\\\\\\] } foo = Foo(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data) assert foo.bar == 'c' aliases is a list of lists because multiple paths can be provided, if so they're tried in turn until a value is found. Tagged unions will use the same logic as aliases meaning nested attributes can be used to select a schema to validate against. Improvements to Dumping/Serialization/Export ¶ (I haven't worked on this yet, so these ideas are only provisional) There has long been a debate about how to handle converting data when extracting it from a model. One of the features people have long requested is the ability to convert data to JSON compliant types while converting a model to a dict. My plan is to move data export into pydantic-core, with that, one implementation can support all export modes without compromising (and hopefully significantly improving) performance. I see four different export/serialization scenarios: Extracting the field values of a model with no conversion, effectively model.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ but with the current filtering logic provided by .dict() Extracting the field values of a model recursively (effectively what .dict() does now) - sub-models are converted to dicts, but other fields remain unchanged. Extracting data and converting at the same time (e.g. to JSON compliant types) Serializing data straight to JSON I think all 4 modes can be supported in a single implementation, with a kind of \"3.5\" mode where a python function is used to convert the data as the user wishes. The current include and exclude logic is extremely complicated, but hopefully it won't be too hard to translate it to Rust. We should also add support for validate\\\\\\\\\\\\\\_alias and dump\\\\\\\\\\\\\\_alias as well as the standard alias to allow for customising field keys. Validation Context ¶ Pydantic V2 will add a new optional context argument to model\\\\\\\\\\\\\\_validate and model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json which will allow you to pass information not available when creating a model to validators. See pydantic#1549 for motivation. Here's an example of context might be used: Context during Validation from pydantic import BaseModel, EmailStr, validator class User(BaseModel): email: EmailStr home\\\\\\\\\\\\\\_country: str @validator('home\\\\\\\\\\\\\\_country') def check\\\\\\\\\\\\\\_home\\\\\\\\\\\\\\_country(cls, v, context): if v not in context\\\\\\\\\\\\\\['countries'\\\\\\\\\\\\\\]: raise ValueError('invalid country choice') return v async def add\\\\\\\\\\\\\\_user(post\\\\\\\\\\\\\\_data: bytes): countries = set(await db\\\\\\\\\\\\\\_connection.fetch\\\\\\\\\\\\\\_all('select code from country')) user = User.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json(post\\\\\\\\\\\\\\_data, context={'countries': countries}) ... Note We (actually mostly Sebastián ) will have to make some changes to FastAPI to fully leverage context as we'd need some kind of dependency injection to build context before validation so models can still be passed as arguments to views. I'm sure he'll be game. Warning Although this will make it slightly easier to run synchronous IO (HTTP requests, DB. queries, etc.) from within validators, I strongly advise you keep IO separate from validation - do it before and use context, do it afterwards, avoid where possible making queries inside validation. Model Namespace Cleanup ¶ For years I've wanted to clean up the model namespace, see pydantic#1001. This would avoid confusing gotchas when field names clash with methods on a model, it would also make it safer to add more methods to a model without risking new clashes. After much deliberation (and even giving a lightning talk at the python language submit about alternatives, see this discussion). I've decided to go with the simplest and clearest approach, at the expense of a bit more typing: All methods on models will start with model\\\\\\\\\\\\\\_, fields' names will not be allowed to start with \"model\" (aliases can be used if required). This will mean BaseModel will have roughly the following signature. New BaseModel methods class BaseModel: model\\\\\\\\\\\\\\_fields: List\\\\\\\\\\\\\\[FieldInfo\\\\\\\\\\\\\\] \"\"\"previously \\\\\\\\\\\\\\`\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_\\\\\\\\\\\\\\`, although the format will change a lot\"\"\" @classmethod def model\\\\\\\\\\\\\\_validate(cls, data: Any, \\\\\\\\\\\\\\*, context=None) -> Self: # see Validation Context for more information on context \"\"\" previously \\\\\\\\\\\\\\`parse\\\\\\\\\\\\\\_obj()\\\\\\\\\\\\\\`, validate data \"\"\" @classmethod def model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json( cls, data: str | bytes | bytearray, \\\\\\\\\\\\\\*, context=None ) -> Self: \"\"\" previously \\\\\\\\\\\\\\`parse\\\\\\\\\\\\\\_raw(..., content\\\\\\\\\\\\\\_type='application/json')\\\\\\\\\\\\\\` validate data from JSON \"\"\" @classmethod def model\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_instance(cls, data: Any, \\\\\\\\\\\\\\*, context=None) -> bool: # see is\\\\\\\\\\\\\\_instance checks \"\"\" new, check if data is value for the model \"\"\" @classmethod def model\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_json( cls, data: str | bytes | bytearray, \\\\\\\\\\\\\\*, context=None ) -> bool: \"\"\" Same as \\\\\\\\\\\\\\`model\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\`, but from JSON \"\"\" def model\\\\\\\\\\\\\\_dump( self, include: ... = None, exclude: ... = None, by\\\\\\\\\\\\\\_alias: bool = False, exclude\\\\\\\\\\\\\\_unset: bool = False, exclude\\\\\\\\\\\\\\_defaults: bool = False, exclude\\\\\\\\\\\\\\_none: bool = False, mode: Literal\\\\\\\\\\\\\\['unchanged', 'dicts', 'json-compliant'\\\\\\\\\\\\\\] = 'unchanged', converter: Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] | None = None ) -> Any: \"\"\" previously \\\\\\\\\\\\\\`dict()\\\\\\\\\\\\\\`, as before with new \\\\\\\\\\\\\\`mode\\\\\\\\\\\\\\` argument \"\"\" def model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json(self, ...) -> str: \"\"\" previously \\\\\\\\\\\\\\`json()\\\\\\\\\\\\\\`, arguments as above effectively equivalent to \\\\\\\\\\\\\\`json.dump(self.model\\\\\\\\\\\\\\_dump(..., mode='json'))\\\\\\\\\\\\\\`, but more performant \"\"\" def model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema(self, ...) -> dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\]: \"\"\" previously \\\\\\\\\\\\\\`schema()\\\\\\\\\\\\\\`, arguments roughly as before JSON schema as a dict \"\"\" def model\\\\\\\\\\\\\\_update\\\\\\\\\\\\\\_forward\\\\\\\\\\\\\\_refs(self) -> None: \"\"\" previously \\\\\\\\\\\\\\`update\\\\\\\\\\\\\\_forward\\\\\\\\\\\\\\_refs()\\\\\\\\\\\\\\`, update forward references \"\"\" @classmethod def model\\\\\\\\\\\\\\_construct( self, \\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set: set\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] | None = None, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*values: Any ) -> Self: \"\"\" previously \\\\\\\\\\\\\\`construct()\\\\\\\\\\\\\\`, arguments roughly as before construct a model with no validation \"\"\" @classmethod def model\\\\\\\\\\\\\\_customize\\\\\\\\\\\\\\_schema(cls, schema: dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\]) -> dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\]: \"\"\" new, way to customize validation, e.g. if you wanted to alter how the model validates certain types, or add validation for a specific type without custom types or decorated validators \"\"\" class ModelConfig: \"\"\" previously \\\\\\\\\\\\\\`Config\\\\\\\\\\\\\\`, configuration class for models \"\"\" The following methods will be removed: .parse\\\\\\\\\\\\\\_file() - was a mistake, should never have been in pydantic .parse\\\\\\\\\\\\\\_raw() - partially replaced by .model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json(), the other functionality was a mistake .from\\\\\\\\\\\\\\_orm() - the functionality has been moved to config, see other improvements below .schema\\\\\\\\\\\\\\_json() - mostly since it causes confusion between pydantic validation schema and JSON schema, and can be replaced with just json.dumps(m.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema()) .copy() instead we'll implement \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_copy\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and let people use the copy module (this removes some functionality) from copy() but there are bugs and ambiguities with the functionality anyway Strict API & API documentation ¶ When preparing for pydantic V2, we'll make a strict distinction between the public API and private functions & classes. Private objects will be clearly identified as private via a \\\\\\\\\\\\\\_internal sub package to discourage use. The public API will have API documentation. I've recently been working with the wonderful mkdocstrings package for both dirty-equals and watchfiles documentation. I intend to use mkdocstrings to generate complete API documentation for V2. This wouldn't replace the current example-based somewhat informal documentation style but instead will augment it. Error descriptions ¶ The way line errors (the individual errors within a ValidationError) are built has become much more sophisticated in pydantic-core. There's a well-defined set of error codes and messages. More will be added when other types are validated via pure python validators in pydantic. I would like to add a dedicated section to the documentation with extra information for each type of error. This would be another key in a line error: documentation, which would link to the appropriate section in the docs. Thus, errors might look like: Line Errors Example \\\\\\\\\\\\\\[ { 'kind': 'greater\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal', 'loc': \\\\\\\\\\\\\\['age'\\\\\\\\\\\\\\], 'message': 'Value must be greater than or equal to 18', 'input\\\\\\\\\\\\\\_value': 11, 'context': {'ge': 18}, 'documentation': 'https://pydantic.dev/errors/#greater\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal', }, { 'kind': 'bool\\\\\\\\\\\\\\_parsing', 'loc': \\\\\\\\\\\\\\['is\\\\\\\\\\\\\\_developer'\\\\\\\\\\\\\\], 'message': 'Value must be a valid boolean, unable to interpret input', 'input\\\\\\\\\\\\\\_value': 'foobar', 'documentation': 'https://pydantic.dev/errors/#bool\\\\\\\\\\\\\\_parsing', }, \\\\\\\\\\\\\\] I own the pydantic.dev domain and will use it for at least these errors so that even if the docs URL changes, the error will still link to the correct documentation. If developers don't want to show these errors to users, they can always process the errors list and filter out items from each error they don't need or want. No pure python implementation ¶ Since pydantic-core is written in Rust, and I have absolutely no intention of rewriting it in python, pydantic V2 will only work where a binary package can be installed. pydantic-core will provide binaries in PyPI for (at least): Linux: x86\\\\\\\\\\\\\\_64, aarch64, i686, armv7l, musl-x86\\\\\\\\\\\\\\_64 & musl-aarch64 MacOS: x86\\\\\\\\\\\\\\_64 & arm64 (except python 3.7) Windows: amd64 & win32 Web Assembly: wasm32 (pydantic-core is already compiled for wasm32 using emscripten and unit tests pass, except where cpython itself has problems) Binaries for pypy are a work in progress and will be added if possible, see pydantic-core#154. Other binaries can be added provided they can be (cross-)compiled on github actions. If no binary is available from PyPI, pydantic-core can be compiled from source if Rust stable is available. The only place where I know this will cause problems is Raspberry Pi, which is a mess when it comes to packages written in Rust for Python. Effectively, until that's fixed you'll likely have to install pydantic with pip install -i https://pypi.org/simple/ pydantic. Pydantic becomes a pure python package ¶ Pydantic V1.X is a pure python code base but is compiled with cython to provide some performance improvements. Since the \"hot\" code is moved to pydantic-core, pydantic itself can go back to being a pure python package. This should significantly reduce the size of the pydantic package and make unit tests of pydantic much faster. In addition: some constraints on pydantic code can be removed once it no-longer has to be compilable with cython debugging will be easier as you'll be able to drop straight into the pydantic codebase as you can with other, pure python packages Some pieces of edge logic could get a little slower as they're no longer compiled. is\\\\\\\\\\\\\\_instance like checks ¶ Strict mode also means it makes sense to provide an is\\\\\\\\\\\\\\_instance method on models which effectively run validation then throws away the result while avoiding the (admittedly small) overhead of creating and raising an error or returning the validation result. To be clear, this isn't a real isinstance call, rather it is equivalent to is\\\\\\\\\\\\\\_instance class BaseModel: ... @classmethod def model\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_instance(cls, data: Any) -> bool: try: cls(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data) except ValidationError: return False else: return True I'm dropping the word \"parse\" and just using \"validate\" ¶ Partly due to the issues with the lack of strict mode, I've gone back and forth between using the terms \"parse\" and \"validate\" for what pydantic does. While pydantic is not simply a validation library (and I'm sure some would argue validation is not strictly what it does), most people use the word \"validation\". It's time to stop fighting that, and use consistent names. The word \"parse\" will no longer be used except when talking about JSON parsing, see model methods above. Changes to custom field types ¶ Since the core structure of validators has changed from \"a list of validators to call one after another\" to \"a tree of validators which call each other\", the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ way of defining custom field types no longer makes sense. Instead, we'll look for the attribute \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_validation\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ which must be a pydantic-core compliant schema for validating data to this field type (the function item can be a string, if so a function of that name will be taken from the class, see 'validate' below). Here's an example of how a custom field type could be defined: New custom field types from pydantic import ValidationSchema class Foobar: def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, value: str): self.value = value \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_validation\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_: ValidationSchema = { 'type': 'function', 'mode': 'after', 'function': 'validate', 'schema': {'type': 'str'}, } @classmethod def validate(cls, value): if 'foobar' in value: return Foobar(value) else: raise ValueError('expected foobar') What's going on here: \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_validation\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ defines a schema which effectively says: Validate input data as a string, then call the validate function with that string, use the returned value as the final result of validation. ValidationSchema is just an alias to pydantic\\\\\\\\\\\\\\_core.Schema which is a type defining the schema for validation schemas. Note pydantic-core schema has full type definitions although since the type is recursive, mypy can't provide static type analysis, pyright however can. We can probably provide one or more helper functions to make \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_validation\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ easier to generate. Other Improvements ¶ Some other things which will also change, IMHO for the better: Recursive models with cyclic references - although recursive models were supported by pydantic V1, data with cyclic references caused recursion errors, in pydantic-core cyclic references are correctly detected and a validation error is raised The reason I've been so keen to get pydantic-core to compile and run with wasm is that I want all examples in the docs of pydantic V2 to be editable and runnable in the browser Full support for TypedDict, including total=False - e.g. omitted keys, providing validation schema to a TypedDict field/item will use Annotated, e.g. Annotated\\\\\\\\\\\\\\[str, Field(strict=True)\\\\\\\\\\\\\\] from\\\\\\\\\\\\\\_orm has become from\\\\\\\\\\\\\\_attributes and is now defined at schema generation time (either via model config or field config) input\\\\\\\\\\\\\\_value has been added to each line error in a ValidationError, making errors easier to understand, and more comprehensive details of errors to be provided to end users, pydantic#784 on\\\\\\\\\\\\\\_error logic in a schema which allows either a default value to be used in the event of an error, or that value to be omitted (in the case of a total=False TypedDict), pydantic-core#151 datetime, date, time & timedelta validation is improved, see the speedate Rust library I built specifically for this purpose for more details Powerful \"priority\" system for optionally merging or overriding config in sub-models for nested schemas Pydantic will support annotated-types, so you can do stuff like Annotated\\\\\\\\\\\\\\[set\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\], Len(0, 10)\\\\\\\\\\\\\\] or Name = Annotated\\\\\\\\\\\\\\[str, Len(1, 1024)\\\\\\\\\\\\\\] A single decorator for general usage - we should add a validate decorator which can be used: on functions (replacing validate\\\\\\\\\\\\\\_arguments) on dataclasses, pydantic.dataclasses.dataclass will become an alias of this on TypedDicts On any supported type, e.g. Union\\\\\\\\\\\\\\[...\\\\\\\\\\\\\\], Dict\\\\\\\\\\\\\\[str, Thing\\\\\\\\\\\\\\] On Custom field types - e.g. anything with a \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ attribute Easier validation error creation, I've often found myself wanting to raise ValidationErrors outside models, particularly in FastAPI (here is one method I've used), we should provide utilities to generate these errors Improve the performance of \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_eq\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ on models Computed fields, these having been an idea for a long time in pydantic - we should get them right Model validation that avoids instances of subclasses leaking data (particularly important for FastAPI), see pydantic-core#155 We'll now follow semvar properly and avoid breaking changes between minor versions, as a result, major versions will become more common Improve generics to use M(Basemodel, Generic\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\]) instead of M(GenericModel, Generic\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\]) - e.g. GenericModel can be removed; this results from no-longer needing to compile pydantic code with cython Removed Features & Limitations ¶ The emoji here is just for variation, I'm not frowning about any of this, these changes are either good IMHO (will make pydantic cleaner, easier to learn and easier to maintain) or irrelevant to 99.9+% of users. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ custom root models are no longer necessary since validation on any supported data type is allowed without a model .parse\\\\\\\\\\\\\\_file() and .parse\\\\\\\\\\\\\\_raw(), partially replaced with .model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json(), see model methods .schema\\\\\\\\\\\\\\_json() & .copy(), see model methods TypeError are no longer considered as validation errors, but rather as internal errors, this is to better catch errors in argument names in function validators. Subclasses of builtin types like str, bytes and int are coerced to their parent builtin type, this is a limitation of how pydantic-core converts these types to Rust types during validation, if you have a specific need to keep the type, you can use wrap validators or custom type validation as described above integers are represented in rust code as i64, meaning if you want to use ints where abs(v) > 2^63 − 1 (9,223,372,036,854,775,807), you'll need to use a wrap validator and your own logic Settings Management ??? - I definitely don't want to remove the functionality, but it's something of a historical curiosity that it lives within pydantic, perhaps it should move to a separate package, perhaps installable alongside pydantic with pip install pydantic\\\\\\\\\\\\\\[settings\\\\\\\\\\\\\\]? The following Config properties will be removed or deprecated: fields - it's very old (it pre-dates Field), can be removed allow\\\\\\\\\\\\\\_mutation will be removed, instead frozen will be used error\\\\\\\\\\\\\\_msg\\\\\\\\\\\\\\_templates, it's not properly documented anyway, error messages can be customized with external logic if required getter\\\\\\\\\\\\\\_dict - pydantic-core has hardcoded from\\\\\\\\\\\\\\_attributes logic json\\\\\\\\\\\\\\_loads - again this is hard coded in pydantic-core json\\\\\\\\\\\\\\_dumps - possibly json\\\\\\\\\\\\\\_encoders - see the export \"mode\" discussion above underscore\\\\\\\\\\\\\\_attrs\\\\\\\\\\\\\\_are\\\\\\\\\\\\\\_private we should just choose a sensible default smart\\\\\\\\\\\\\\_union - all unions are now \"smart\" dict(model) functionality should be removed, there's a much clearer distinction now that in 2017 when I implemented this between a model and a dict Features Remaining ¶ The following features will remain (mostly) unchanged: JSONSchema, internally this will need to change a lot, but hopefully the external interface will remain unchanged dataclass support, again internals might change, but not the external interface validate\\\\\\\\\\\\\\_arguments, might be renamed, but otherwise remain hypothesis plugin, might be able to improve this as part of the general cleanup Questions ¶ I hope the explanation above is useful. I'm sure people will have questions and feedback; I'm aware I've skipped over some features with limited detail (this post is already fairly long ). To allow feedback without being overwhelmed, I've created a \"Pydantic V2\" category for discussions on github - please feel free to create a discussion if you have any questions or suggestions. We will endeavour to read and respond to everyone. Implementation Details ¶ (This is yet to be built, so these are nascent ideas which might change) At the center of pydantic v2 will be a PydanticValidator class which looks roughly like this (note: this is just pseudo-code, it's not even valid python and is only supposed to be used to demonstrate the idea): PydanticValidator # type identifying data which has been validated, # as per pydantic-core, this can include \"fields\\\\\\\\\\\\\\_set\" data ValidData = ... # any type we can perform validation for AnyOutputType = ... class PydanticValidator: def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, output\\\\\\\\\\\\\\_type: AnyOutputType, config: Config): ... def validate(self, input\\\\\\\\\\\\\\_data: Any) -> ValidData: ... def validate\\\\\\\\\\\\\\_json(self, input\\\\\\\\\\\\\\_data: str | bytes | bytearray) -> ValidData: ... def is\\\\\\\\\\\\\\_instance(self, input\\\\\\\\\\\\\\_data: Any) -> bool: ... def is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_json(self, input\\\\\\\\\\\\\\_data: str | bytes | bytearray) -> bool: ... def json\\\\\\\\\\\\\\_schema(self) -> dict: ... def dump( self, data: ValidData, include: ... = None, exclude: ... = None, by\\\\\\\\\\\\\\_alias: bool = False, exclude\\\\\\\\\\\\\\_unset: bool = False, exclude\\\\\\\\\\\\\\_defaults: bool = False, exclude\\\\\\\\\\\\\\_none: bool = False, mode: Literal\\\\\\\\\\\\\\['unchanged', 'dicts', 'json-compliant'\\\\\\\\\\\\\\] = 'unchanged', converter: Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] | None = None ) -> Any: ... def dump\\\\\\\\\\\\\\_json(self, ...) -> str: ... This could be used directly, but more commonly will be used by the following: BaseModel the validate decorator described above pydantic.dataclasses.dataclass (which might be an alias of validate) generics The aim will be to get pydantic V2 to a place were the vast majority of tests continue to pass unchanged. Thereby guaranteeing (as much as possible) that the external interface to pydantic and its behaviour are unchanged. Conversion Table ¶ The table below provisionally defines what input value types are allowed to which field types. An updated and complete version of this table is available in V2 conversion table. Note Some type conversion shown here is a significant departure from existing behavior, we may have to provide a config flag for backwards compatibility for a few of them, however pydantic V2 cannot be entirely backward compatible, see pydantic-core#152. Field Type Input Mode Input Source Conditions str str both python, JSON - str bytes lax python assumes UTF-8, error on unicode decoding error str bytearray lax python assumes UTF-8, error on unicode decoding error bytes bytes both python - bytes str both JSON - bytes str lax python - bytes bytearray lax python - int int strict python, JSON max abs value 2^64 - i64 is used internally, bool explicitly forbidden int int lax python, JSON i64 int float lax python, JSON i64, must be exact int, e.g. f % 1 == 0, nan, inf raise errors int Decimal lax python, JSON i64, must be exact int, e.g. f % 1 == 0 int bool lax python, JSON - int str lax python, JSON i64, must be numeric only, e.g. \\\\\\\\\\\\\\[0-9\\\\\\\\\\\\\\]+ float float strict python, JSON bool explicitly forbidden float float lax python, JSON - float int lax python, JSON - float str lax python, JSON must match \\\\\\\\\\\\\\[0-9\\\\\\\\\\\\\\]+(\\\\\\\\\\\\\\\\.\\\\\\\\\\\\\\[0-9\\\\\\\\\\\\\\]+)? float Decimal lax python - float bool lax python, JSON - bool bool both python, JSON - bool int lax python, JSON allowed: 0, 1 bool float lax python, JSON allowed: 0, 1 bool Decimal lax python, JSON allowed: 0, 1 bool str lax python, JSON allowed: 'f', 'n', 'no', 'off', 'false', 't', 'y', 'on', 'yes', 'true' None None both python, JSON - date date both python - date datetime lax python must be exact date, eg. no H, M, S, f date str both JSON format YYYY-MM-DD date str lax python format YYYY-MM-DD date bytes lax python format YYYY-MM-DD (UTF-8) date int lax python, JSON interpreted as seconds or ms from epoch, see speedate, must be exact date date float lax python, JSON interpreted as seconds or ms from epoch, see speedate, must be exact date datetime datetime both python - datetime date lax python - datetime str both JSON format YYYY-MM-DDTHH:MM:SS.f etc. see speedate datetime str lax python format YYYY-MM-DDTHH:MM:SS.f etc. see speedate datetime bytes lax python format YYYY-MM-DDTHH:MM:SS.f etc. see speedate, (UTF-8) datetime int lax python, JSON interpreted as seconds or ms from epoch, see speedate datetime float lax python, JSON interpreted as seconds or ms from epoch, see speedate time time both python - time str both JSON format HH:MM:SS.FFFFFF etc. see speedate time str lax python format HH:MM:SS.FFFFFF etc. see speedate time bytes lax python format HH:MM:SS.FFFFFF etc. see speedate, (UTF-8) time int lax python, JSON interpreted as seconds, range 0 - 86399 time float lax python, JSON interpreted as seconds, range 0 - 86399.9\\\\\\\\\\\\\\* time Decimal lax python, JSON interpreted as seconds, range 0 - 86399.9\\\\\\\\\\\\\\* timedelta timedelta both python - timedelta str both JSON format ISO8601 etc. see speedate timedelta str lax python format ISO8601 etc. see speedate timedelta bytes lax python format ISO8601 etc. see speedate, (UTF-8) timedelta int lax python, JSON interpreted as seconds timedelta float lax python, JSON interpreted as seconds timedelta Decimal lax python, JSON interpreted as seconds dict dict both python - dict Object both JSON - dict mapping lax python must implement the mapping interface and have an items() method TypedDict dict both python - TypedDict Object both JSON - TypedDict Any both python builtins not allowed, uses getattr, requires from\\\\\\\\\\\\\\_attributes=True TypedDict mapping lax python must implement the mapping interface and have an items() method list list both python - list Array both JSON - list tuple lax python - list set lax python - list frozenset lax python - list dict\\\\\\\\\\\\\\_keys lax python - tuple tuple both python - tuple Array both JSON - tuple list lax python - tuple set lax python - tuple frozenset lax python - tuple dict\\\\\\\\\\\\\\_keys lax python - set set both python - set Array both JSON - set list lax python - set tuple lax python - set frozenset lax python - set dict\\\\\\\\\\\\\\_keys lax python - frozenset frozenset both python - frozenset Array both JSON - frozenset list lax python - frozenset tuple lax python - frozenset set lax python - frozenset dict\\\\\\\\\\\\\\_keys lax python - is\\\\\\\\\\\\\\_instance Any both python isinstance() check returns True is\\\\\\\\\\\\\\_instance - both JSON never valid callable Any both python callable() check returns True callable - both JSON never valid The ModelClass validator (use to create instances of a class) uses the TypedDict validator, then creates an instance with \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ set, so same rules apply as TypedDict. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Pydantic V2 Pre Release - Pydantic",
    "url": "https://docs.pydantic.dev/latest/blog/pydantic-v2-alpha/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Pydantic V2 Pre Release Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Blog Pydantic V2 Is Here! Pydantic V2 Pre Release Pydantic V2 Plan Page contents Getting started with the Pydantic V2 alpha Headlines Ready for experimentation Still under construction Migration Guide Changes to BaseModel Changes to Pydantic Dataclasses Changes to Config Changes to Validators Changes to Validation of specific types Changes to Generic models Other changes TypeAdapter Pydantic V2 Pre Release¶ Terrence Dorsey & Samuel Colvin •  •  •  April 3, 2023 •  8 min read We're excited to announce the first alpha release of Pydantic V2! This first Pydantic V2 alpha is no April Fool's joke — for a start we missed our April 1st target date . After a year's work, we invite you to explore the improvements we've made and give us your feedback. We look forward to hearing your thoughts and working together to improve the library. For many of you, Pydantic is already a key part of your Python toolkit and needs no introduction — we hope you'll find the improvements and additions in Pydantic V2 useful. If you're new to Pydantic: Pydantic is an open-source Python library that provides powerful data parsing and validation — including type coercion and useful error messages when typing issues arise — and settings management capabilities. See the docs for examples of Pydantic at work. Getting started with the Pydantic V2 alpha¶ Your feedback will be a critical part of ensuring that we have made the right tradeoffs with the API changes in V2. To get started with the Pydantic V2 alpha, install it from PyPI. We recommend using a virtual environment to isolate your testing environment: pip install --pre -U \"pydantic>=2.0a1\" Note that there are still some rough edges and incomplete features, and while trying out the Pydantic V2 alpha releases you may experience errors. We encourage you to try out the alpha releases in a test environment and not in production. Some features are still in development, and we will continue to make changes to the API. If you do encounter any issues, please create an issue in GitHub using the bug V2 label. This will help us to actively monitor and track errors, and to continue to improve the library’s performance. This will be the first of several upcoming alpha releases. As you evaluate our changes and enhancements, we encourage you to share your feedback with us. Please let us know: If you don't like the changes, so we can make sure Pydantic remains a library you enjoy using. If this breaks your usage of Pydantic so we can fix it, or at least describe a migration path. Thank you for your support, and we look forward to your feedback. Headlines¶ Here are some of the most interesting new features in the current Pydantic V2 alpha release. For background on plans behind these features, see the earlier Pydantic V2 Plan blog post. The biggest change to Pydantic V2 is pydantic-core — all validation logic has been rewritten in Rust and moved to a separate package, pydantic-core. This has a number of big advantages: Performance - Pydantic V2 is 5-50x faster than Pydantic V1. Safety & maintainability - We've made changes to the architecture that we think will help us maintain Pydantic V2 with far fewer bugs in the long term. With the use of pydantic-core, the majority of the logic in the Pydantic library is dedicated to generating \"pydantic core schema\" — the schema used define the behaviour of the new, high-performance pydantic-core validators and serializers. Ready for experimentation¶ BaseModel - the core of validation in Pydantic V1 remains, albeit with new method names. Dataclasses - Pydantic dataclasses are improved and ready to test. Serialization - dumping/serialization/marshalling is significantly more flexible, and ready to test. Strict mode - one of the biggest additions in Pydantic V2 is strict mode, which is ready to test. JSON Schema - generation of JSON Schema is much improved and ready to test. Generic Models - are much improved and ready to test. Recursive Models - and validation of recursive data structures is much improved and ready to test. Custom Types - custom types have a new interface and are ready to test. Custom Field Modifiers - used via Annotated\\\\\\\\\\\\\\[\\\\\\\\\\\\\\] are working and in use in Pydantic itself. Validation without a BaseModel - the new TypeAdapter class allows validation without the need for a BaseModel class, and it's ready to test. TypedDict - we now have full support for TypedDict via TypeAdapter, it's ready to test. Still under construction¶ Documentation - we're working hard on full documentation for V2, but it's not ready yet. Conversion Table - a big addition to the documentation will be a conversion table showing how types are coerced, this is a WIP. BaseSettings - BaseSettings will move to a separate pydantic-settings package, it's not yet ready to test. Notice: since pydantic-settings is not yet ready to release, there's no support for BaseSettings in the first alpha release. validate\\\\\\\\\\\\\\_arguments - the validate\\\\\\\\\\\\\\_arguments decorator remains and is working, but hasn't been updated yet. Hypothesis Plugin - the Hypothesis plugin is yet to be updated. computed fields - we know a lot of people are waiting for this, we will include it in Pydantic V2. Error messages - could use some love, and links to docs in error messages are still to be added. Migration Guide - we have some pointers below, but this needs completing. Migration Guide¶ Please note: this is just the beginning of a migration guide. We'll work hard up to the final release to prepare a full migration guide, but for now the following pointers should be some help while experimenting with V2. Changes to BaseModel¶ Various method names have been changed; BaseModel methods all start with model\\\\\\\\\\\\\\_ now. Where possible, we have retained the old method names to help ease migration, but calling them will result in DeprecationWarnings. Some of the built-in data loading functionality has been slated for removal. In particular, parse\\\\\\\\\\\\\\_raw and parse\\\\\\\\\\\\\\_file are now deprecated. You should load the data and then pass it to model\\\\\\\\\\\\\\_validate. The from\\\\\\\\\\\\\\_orm method has been removed; you can now just use model\\\\\\\\\\\\\\_validate (equivalent to parse\\\\\\\\\\\\\\_obj from Pydantic V1) to achieve something similar, as long as you've set from\\\\\\\\\\\\\\_attributes=True in the model config. The \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_eq\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method has changed for models; models are no longer considered equal to the dicts. Custom \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ overrides won't be called. This should be replaced with a @root\\\\\\\\\\\\\\_validator. Due to inconsistency with the rest of the library, we have removed the special behavior of models using the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ field, and have disallowed the use of an attribute with this name to prevent confusion. However, you can achieve equivalent behavior with a \"standard\" field name through the use of @root\\\\\\\\\\\\\\_validator, @model\\\\\\\\\\\\\\_serializer, and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_modify\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. You can see an example of this here. Changes to Pydantic Dataclasses¶ The \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ in Pydantic dataclasses will now be called after validation, rather than before. We no longer support extra='allow' for Pydantic dataclasses, where extra attributes passed to the initializer would be stored as extra fields on the dataclass. extra='ignore' is still supported for the purposes of allowing extra fields while parsing data; they just aren't stored. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_parse\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ has been removed. Nested dataclasses no longer accept tuples as input, only dict. Changes to Config¶ To specify config on a model, it is now deprecated to create a class called Config in the namespace of the parent BaseModel subclass. Instead, you just need to set a class attribute called model\\\\\\\\\\\\\\_config to be a dict with the key/value pairs you want to be used as the config. The following config settings have been removed: allow\\\\\\\\\\\\\\_mutation — this has been removed. You should be able to use frozen equivalently (inverse of current use). error\\\\\\\\\\\\\\_msg\\\\\\\\\\\\\\_templates. fields — this was the source of various bugs, so has been removed. You should be able to use Annotated on fields to modify them as desired. getter\\\\\\\\\\\\\\_dict — orm\\\\\\\\\\\\\\_mode has been removed, and this implementation detail is no longer necessary. schema\\\\\\\\\\\\\\_extra — you should now use the json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra keyword argument to pydantic.Field. smart\\\\\\\\\\\\\\_union. underscore\\\\\\\\\\\\\\_attrs\\\\\\\\\\\\\\_are\\\\\\\\\\\\\\_private — the Pydantic V2 behavior is now the same as if this was always set to True in Pydantic V1. The following config settings have been renamed: allow\\\\\\\\\\\\\\_population\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_name → populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name anystr\\\\\\\\\\\\\\_lower → str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_lower anystr\\\\\\\\\\\\\\_strip\\\\\\\\\\\\\\_whitespace → str\\\\\\\\\\\\\\_strip\\\\\\\\\\\\\\_whitespace anystr\\\\\\\\\\\\\\_upper → str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_upper keep\\\\\\\\\\\\\\_untouched → ignored\\\\\\\\\\\\\\_types max\\\\\\\\\\\\\\_anystr\\\\\\\\\\\\\\_length → str\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_length min\\\\\\\\\\\\\\_anystr\\\\\\\\\\\\\\_length → str\\\\\\\\\\\\\\_min\\\\\\\\\\\\\\_length orm\\\\\\\\\\\\\\_mode → from\\\\\\\\\\\\\\_attributes validate\\\\\\\\\\\\\\_all → validate\\\\\\\\\\\\\\_default Changes to Validators¶ Raising a TypeError inside a validator no longer produces a ValidationError, but just raises the TypeError directly. This was necessary to prevent certain common bugs (such as calling functions with invalid signatures) from being unintentionally converted into ValidationError and displayed to users. If you really want TypeError to be converted to a ValidationError you should use a try: except: block that will catch it and do the conversion. each\\\\\\\\\\\\\\_item validators are deprecated and should be replaced with a type annotation using Annotated to apply a validator or with a validator that operates on all items at the top level. Changes to @validator-decorated function signatures. The stricturl type has been removed. Root validators can no longer be run with skip\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_failure=False. Changes to Validation of specific types¶ Integers outside the valid range of 64 bit integers will cause ValidationErrors during parsing. To work around this, use an IsInstance validator (more details to come). Subclasses of built-ins won't validate into their subclass types; you'll need to use an IsInstance validator to validate these types. Changes to Generic models¶ While it does not raise an error at runtime yet, subclass checks for parametrized generics should no longer be used. These will result in TypeErrors and we can't promise they will work forever. However, it will be okay to do subclass checks against non-parametrized generic models Other changes¶ GetterDict has been removed, as it was just an implementation detail for orm\\\\\\\\\\\\\\_mode, which has been removed. TypeAdapter¶ Pydantic V1 didn't have good support for validation or serializing non-BaseModel. To work with them you had to create a \"root\" model or use the utility functions in pydantic.tools (parse\\\\\\\\\\\\\\_obj\\\\\\\\\\\\\\_as and schema\\\\\\\\\\\\\\_of). In Pydantic V2 this is a lot easier: the TypeAdapter class lets you build an object that behaves almost like a BaseModel class which you can use for a lot of the use cases of root models and as a complete replacement for parse\\\\\\\\\\\\\\_obj\\\\\\\\\\\\\\_as and schema\\\\\\\\\\\\\\_of. from typing import List from pydantic import TypeAdapter validator = TypeAdapter(List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]) assert validator.validate\\\\\\\\\\\\\\_python(\\\\\\\\\\\\\\['1', '2', '3'\\\\\\\\\\\\\\]) == \\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\] print(validator.json\\\\\\\\\\\\\\_schema()) #> {'items': {'type': 'integer'}, 'type': 'array'} Note that this API is provisional and may change before the final release of Pydantic V2. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Rich - Pydantic",
    "url": "https://docs.pydantic.dev/latest/integrations/rich/",
    "html": "Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Rich Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Integrations Mypy PyCharm Hypothesis Visual Studio Code datamodel-code-generator devtools Rich Rich Pydantic models may be printed with the Rich library which will add additional formatting and color to the output. Here's an example: See the Rich documentation on pretty printing for more information. Made with Material for MkDocs Insiders"
  },
  {
    "title": "devtools - Pydantic",
    "url": "https://docs.pydantic.dev/latest/integrations/devtools/",
    "html": "Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 devtools Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Integrations Mypy PyCharm Hypothesis Visual Studio Code datamodel-code-generator devtools Rich devtools Note Admission: I (the primary developer of Pydantic) also develop python-devtools. python-devtools (pip install devtools) provides a number of tools which are useful during Python development, including debug() an alternative to print() which formats output in a way which should be easier to read than print as well as giving information about which file/line the print statement is on and what value was printed. Pydantic integrates with devtools by implementing the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pretty\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method on most public classes. In particular debug() is useful when inspecting models: from datetime import datetime from typing import List from devtools import debug from pydantic import BaseModel class Address(BaseModel): street: str country: str lat: float lng: float class User(BaseModel): id: int name: str signup\\\\\\\\\\\\\\_ts: datetime friends: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] address: Address user = User( id='123', name='John Doe', signup\\\\\\\\\\\\\\_ts='2019-06-01 12:22', friends=\\\\\\\\\\\\\\[1234, 4567, 7890\\\\\\\\\\\\\\], address=dict(street='Testing', country='uk', lat=51.5, lng=0), ) debug(user) print('\\\\\\\\\\\\\\\\nshould be much easier read than:\\\\\\\\\\\\\\\\n') print('user:', user) Will output in your terminal: devtools\\\\\\\\\\\\\\_example.py:31 user: User( id=123, name='John Doe', signup\\\\\\\\\\\\\\_ts=datetime.datetime(2019, 6, 1, 12, 22), friends=\\\\\\\\\\\\\\[ 1234, 4567, 7890, \\\\\\\\\\\\\\], address=Address( street='Testing', country='uk', lat=51.5, lng=0.0, ), ) (User) should be much easier read than: user: id=123 name='John Doe' signup\\\\\\\\\\\\\\_ts=datetime.datetime(2019, 6, 1, 12, 22) friends=\\\\\\\\\\\\\\[1234, 4567, 7890\\\\\\\\\\\\\\] address=Address(street='Testing', country='uk', lat=51.5, lng=0.0) Made with Material for MkDocs Insiders"
  },
  {
    "title": "Visual Studio Code - Pydantic",
    "url": "https://docs.pydantic.dev/latest/integrations/visual_studio_code/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Visual Studio Code Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Integrations Mypy PyCharm Hypothesis Visual Studio Code datamodel-code-generator devtools Rich Page contents Configure VS Code Install Pylance Configure your environment Configure Pylance Configure mypy Tips and tricks Strict errors Disable type checks in a line Override the type of a variable Override the type of a value with cast Config in class arguments Adding a default with Field Technical Details Visual Studio Code Pydantic works well with any editor or IDE out of the box because it's made on top of standard Python type annotations. When using Visual Studio Code (VS Code), there are some additional editor features supported, comparable to the ones provided by the PyCharm plugin. This means that you will have autocompletion (or \"IntelliSense\") and error checks for types and required arguments even while creating new Pydantic model instances. Configure VS Code¶ To take advantage of these features, you need to make sure you configure VS Code correctly, using the recommended settings. In case you have a different configuration, here's a short overview of the steps. Install Pylance¶ You should use the Pylance extension for VS Code. It is the recommended, next-generation, official VS Code plug-in for Python. Pylance is installed as part of the Python Extension for VS Code by default, so it should probably just work. Otherwise, you can double check it's installed and enabled in your editor. Configure your environment¶ Then you need to make sure your editor knows the Python environment (probably a virtual environment) for your Python project. This would be the environment in where you installed Pydantic. Configure Pylance¶ With the default configurations, you will get support for autocompletion, but Pylance might not check for type errors. You can enable type error checks from Pylance with these steps: Open the \"User Settings\" Search for Type Checking Mode You will find an option under Python › Analysis: Type Checking Mode Set it to basic or strict (by default it's off) Now you will not only get autocompletion when creating new Pydantic model instances but also error checks for required arguments. And you will also get error checks for invalid data types. Technical Details Pylance is the VS Code extension, it's closed source, but free to use. Underneath, Pylance uses an open source tool (also from Microsoft) called Pyright that does all the heavy lifting. You can read more about it in the Pylance Frequently Asked Questions. Configure mypy¶ You might also want to configure mypy in VS Code to get mypy error checks inline in your editor (alternatively/additionally to Pylance). This would include the errors detected by the Pydantic mypy plugin, if you configured it. To enable mypy in VS Code, do the following: Open the \"User Settings\" Search for Mypy Enabled You will find an option under Python › Linting: Mypy Enabled Check the box (by default it's unchecked) Tips and tricks¶ Here are some additional tips and tricks to improve your developer experience when using VS Code with Pydantic. Strict errors¶ The way this additional editor support works is that Pylance will treat your Pydantic models as if they were Python's pure dataclasses. And it will show strict type error checks about the data types passed in arguments when creating a new Pydantic model instance. In this example you can see that it shows that a str of '23' is not a valid int for the argument age. It would expect age=23 instead of age='23'. Nevertheless, the design, and one of the main features of Pydantic, is that it is very lenient with data types. It will actually accept the str with value '23' and will convert it to an int with value 23. These strict error checks are very useful most of the time and can help you detect many bugs early. But there are cases, like with age='23', where they could be inconvenient by reporting a \"false positive\" error. This example above with age='23' is intentionally simple, to show the error and the differences in types. But more common cases where these strict errors would be inconvenient would be when using more sophisticated data types, like int values for datetime fields, or dict values for Pydantic sub-models. For example, this is valid for Pydantic: from pydantic import BaseModel class Knight(BaseModel): title: str age: int color: str = 'blue' class Quest(BaseModel): title: str knight: Knight quest = Quest( title='To seek the Holy Grail', knight={'title': 'Sir Lancelot', 'age': 23} ) The type of the field knight is declared with the class Knight (a Pydantic model) and the code is passing a literal dict instead. This is still valid for Pydantic, and the dict would be automatically converted to a Knight instance. Nevertheless, it would be detected as a type error: In those cases, there are several ways to disable or ignore strict errors in very specific places, while still preserving them in the rest of the code. Below are several techniques to achieve it. Disable type checks in a line¶ You can disable the errors for a specific line using a comment of: # type: ignore or (to be specific to pylance/pyright): # pyright: ignore (pyright is the language server used by Pylance.). coming back to the example with age='23', it would be: from pydantic import BaseModel class Knight(BaseModel): title: str age: int color: str = 'blue' lancelot = Knight(title='Sir Lancelot', age='23') # pyright: ignore that way Pylance and mypy will ignore errors in that line. Pros: it's a simple change in that line to remove errors there. Cons: any other error in that line will also be omitted, including type checks, misspelled arguments, required arguments not provided, etc. Override the type of a variable¶ You can also create a variable with the value you want to use and declare its type explicitly with Any. from typing import Any from pydantic import BaseModel class Knight(BaseModel): title: str age: int color: str = 'blue' age\\\\\\\\\\\\\\_str: Any = '23' lancelot = Knight(title='Sir Lancelot', age=age\\\\\\\\\\\\\\_str) that way Pylance and mypy will interpret the variable age\\\\\\\\\\\\\\_str as if they didn't know its type, instead of knowing it has a type of str when an int was expected (and then showing the corresponding error). Pros: errors will be ignored only for a specific value, and you will still see any additional errors for the other arguments. Cons: it requires importing Any and a new variable in a new line for each argument that needs ignoring errors. Override the type of a value with cast¶ The same idea from the previous example can be put on the same line with the help of cast(). This way, the type declaration of the value is overridden inline, without requiring another variable. from typing import Any, cast from pydantic import BaseModel class Knight(BaseModel): title: str age: int color: str = 'blue' lancelot = Knight(title='Sir Lancelot', age=cast(Any, '23')) cast(Any, '23') doesn't affect the value, it's still just '23', but now Pylance and mypy will assume it is of type Any, which means, they will act as if they didn't know the type of the value. So, this is the equivalent of the previous example, without the additional variable. Pros: errors will be ignored only for a specific value, and you will still see any additional errors for the other arguments. There's no need for additional variables. Cons: it requires importing Any and cast, and if you are not used to using cast(), it could seem strange at first. Config in class arguments¶ Pydantic has a rich set of Model Configurations available. These configurations can be set in an internal class Config on each model: from pydantic import BaseModel class Knight(BaseModel): model\\\\\\\\\\\\\\_config = dict(frozen=True) title: str age: int color: str = 'blue' or passed as keyword arguments when defining the model class: from pydantic import BaseModel class Knight(BaseModel, frozen=True): title: str age: int color: str = 'blue' The specific configuration frozen (in beta) has a special meaning. It prevents other code from changing a model instance once it's created, keeping it \"frozen\". When using the second version to declare frozen=True (with keyword arguments in the class definition), Pylance can use it to help you check in your code and detect errors when something is trying to set values in a model that is \"frozen\". Adding a default with Field¶ Pylance/pyright requires default to be a keyword argument to Field in order to infer that the field is optional. from pydantic import BaseModel, Field class Knight(BaseModel): title: str = Field(default='Sir Lancelot') # this is okay age: int = Field( 23 ) # this works fine at runtime but will case an error for pyright lance = Knight() # error: Argument missing for parameter \"age\" This is a limitation of dataclass transforms and cannot be fixed in pydantic. Technical Details¶ Warning As a Pydantic user, you don't need the details below. Feel free to skip the rest of this section. These details are only useful for other library authors, etc. This additional editor support works by implementing the proposed draft standard for Dataclass Transform (PEP 681). The proposed draft standard is written by Eric Traut, from the Microsoft team, the same author of the open source package Pyright (used by Pylance to provide Python support in VS Code). The intention of the standard is to provide a way for libraries like Pydantic and others to tell editors and tools that they (the editors) should treat these libraries (e.g. Pydantic) as if they were dataclasses, providing autocompletion, type checks, etc. The draft standard also includes an Alternate Form for early adopters, like Pydantic, to add support for it right away, even before the new draft standard is finished and approved. This new draft standard, with the Alternate Form, is already supported by Pyright, so it can be used via Pylance in VS Code. As it is being proposed as an official standard for Python, other editors can also easily add support for it. And authors of other libraries similar to Pydantic can also easily adopt the standard right away (using the \"Alternate Form\") and get the benefits of these additional editor features. Made with Material for MkDocs Insiders"
  },
  {
    "title": "datamodel-code-generator - Pydantic",
    "url": "https://docs.pydantic.dev/latest/integrations/datamodel_code_generator/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic datamodel-code-generator Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Integrations Mypy PyCharm Hypothesis Visual Studio Code datamodel-code-generator devtools Rich Page contents Installation Example Code Generation with datamodel-code-generator¶ The datamodel-code-generator project is a library and command-line utility to generate pydantic models from just about any data source, including: OpenAPI 3 (YAML/JSON) JSON Schema JSON/YAML Data (which will converted to JSON Schema) Whenever you find yourself with any data convertible JSON but without pydantic models, this tool will allow you to generate type-safe model hierarchies on demand. Installation¶ pip install datamodel-code-generator Example¶ In this case, datamodel-code-generator creates pydantic models from a JSON Schema file. datamodel-codegen --input person.json --input-file-type jsonschema --output model.py person.json: { \"$id\": \"person.json\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"title\": \"Person\", \"type\": \"object\", \"properties\": { \"first\\\\\\\\\\\\\\_name\": { \"type\": \"string\", \"description\": \"The person's first name.\" }, \"last\\\\\\\\\\\\\\_name\": { \"type\": \"string\", \"description\": \"The person's last name.\" }, \"age\": { \"description\": \"Age in years.\", \"type\": \"integer\", \"minimum\": 0 }, \"pets\": { \"type\": \"array\", \"items\": \\\\\\\\\\\\\\[ { \"$ref\": \"#/definitions/Pet\" } \\\\\\\\\\\\\\] }, \"comment\": { \"type\": \"null\" } }, \"required\": \\\\\\\\\\\\\\[ \"first\\\\\\\\\\\\\\_name\", \"last\\\\\\\\\\\\\\_name\" \\\\\\\\\\\\\\], \"definitions\": { \"Pet\": { \"properties\": { \"name\": { \"type\": \"string\" }, \"age\": { \"type\": \"integer\" } } } } } model.py: # generated by datamodel-codegen: # filename: person.json # timestamp: 2020-05-19T15:07:31+00:00 from \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_future\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ import annotations from typing import Any from pydantic import BaseModel, Field, conint class Pet(BaseModel): name: str | None = None age: int | None = None class Person(BaseModel): first\\\\\\\\\\\\\\_name: str = Field(..., description=\"The person's first name.\") last\\\\\\\\\\\\\\_name: str = Field(..., description=\"The person's last name.\") age: conint(ge=0) | None = Field(None, description='Age in years.') pets: list\\\\\\\\\\\\\\[Pet\\\\\\\\\\\\\\] | None = None comment: Any | None = None More information can be found on the official documentation Made with Material for MkDocs Insiders"
  },
  {
    "title": "Hypothesis - Pydantic",
    "url": "https://docs.pydantic.dev/latest/integrations/hypothesis/",
    "html": "Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Hypothesis Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Integrations Mypy PyCharm Hypothesis Visual Studio Code datamodel-code-generator devtools Rich Hypothesis Hypothesis is the Python library for property-based testing. Hypothesis can infer how to construct type-annotated classes, and supports builtin types, many standard library types, and generic types from the typing and typing\\\\\\\\\\\\\\_extensions modules by default. Pydantic v2.0 drops built-in support for Hypothesis and no more ships with the integrated Hypothesis plugin. Warning We are temporarily removing the Hypothesis plugin in favor of studying a different mechanism. For more information, see the issue annotated-types/annotated-types#37. The Hypothesis plugin may be back in a future release. Subscribe to pydantic/pydantic#4682 for updates. Made with Material for MkDocs Insiders"
  },
  {
    "title": "PyCharm - Pydantic",
    "url": "https://docs.pydantic.dev/latest/integrations/pycharm/",
    "html": "Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic PyCharm Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Integrations Mypy PyCharm Hypothesis Visual Studio Code datamodel-code-generator devtools Rich PyCharm While pydantic will work well with any IDE out of the box, a PyCharm plugin offering improved pydantic integration is available on the JetBrains Plugins Repository for PyCharm. You can install the plugin for free from the plugin marketplace (PyCharm's Preferences -> Plugin -> Marketplace -> search \"pydantic\"). The plugin currently supports the following features: For pydantic.BaseModel.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_: Inspection Autocompletion Type-checking For fields of pydantic.BaseModel: Refactor-renaming fields updates \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ calls, and affects sub- and super-classes Refactor-renaming \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ keyword arguments updates field names, and affects sub- and super-classes More information can be found on the official plugin page and Github repository. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Validation Errors - Pydantic",
    "url": "https://docs.pydantic.dev/latest/errors/validation_errors/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Validation Errors Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Error Messages Error Handling Validation Errors Usage Errors Page contents arguments\\\\\\\\\\\\\\_type assertion\\\\\\\\\\\\\\_error bool\\\\\\\\\\\\\\_parsing bool\\\\\\\\\\\\\\_type bytes\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_long bytes\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_short bytes\\\\\\\\\\\\\\_type callable\\\\\\\\\\\\\\_type dataclass\\\\\\\\\\\\\\_exact\\\\\\\\\\\\\\_type dataclass\\\\\\\\\\\\\\_type date\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_datetime\\\\\\\\\\\\\\_inexact date\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_datetime\\\\\\\\\\\\\\_parsing date\\\\\\\\\\\\\\_future date\\\\\\\\\\\\\\_parsing date\\\\\\\\\\\\\\_past date\\\\\\\\\\\\\\_type datetime\\\\\\\\\\\\\\_future datetime\\\\\\\\\\\\\\_object\\\\\\\\\\\\\\_invalid datetime\\\\\\\\\\\\\\_parsing datetime\\\\\\\\\\\\\\_past datetime\\\\\\\\\\\\\\_type decimal\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_digits decimal\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_places decimal\\\\\\\\\\\\\\_parsing decimal\\\\\\\\\\\\\\_type decimal\\\\\\\\\\\\\\_whole\\\\\\\\\\\\\\_digits dict\\\\\\\\\\\\\\_type enum extra\\\\\\\\\\\\\\_forbidden finite\\\\\\\\\\\\\\_number float\\\\\\\\\\\\\\_parsing float\\\\\\\\\\\\\\_type frozen\\\\\\\\\\\\\\_field frozen\\\\\\\\\\\\\\_instance frozen\\\\\\\\\\\\\\_set\\\\\\\\\\\\\\_type get\\\\\\\\\\\\\\_attribute\\\\\\\\\\\\\\_error greater\\\\\\\\\\\\\\_than greater\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal int\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_float int\\\\\\\\\\\\\\_parsing int\\\\\\\\\\\\\\_parsing\\\\\\\\\\\\\\_size int\\\\\\\\\\\\\\_type invalid\\\\\\\\\\\\\\_key is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_of is\\\\\\\\\\\\\\_subclass\\\\\\\\\\\\\\_of iterable\\\\\\\\\\\\\\_type iteration\\\\\\\\\\\\\\_error json\\\\\\\\\\\\\\_invalid json\\\\\\\\\\\\\\_type less\\\\\\\\\\\\\\_than less\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal list\\\\\\\\\\\\\\_type literal\\\\\\\\\\\\\\_error mapping\\\\\\\\\\\\\\_type missing missing\\\\\\\\\\\\\\_argument missing\\\\\\\\\\\\\\_keyword\\\\\\\\\\\\\\_only\\\\\\\\\\\\\\_argument missing\\\\\\\\\\\\\\_positional\\\\\\\\\\\\\\_only\\\\\\\\\\\\\\_argument model\\\\\\\\\\\\\\_attributes\\\\\\\\\\\\\\_type model\\\\\\\\\\\\\\_type multiple\\\\\\\\\\\\\\_argument\\\\\\\\\\\\\\_values multiple\\\\\\\\\\\\\\_of no\\\\\\\\\\\\\\_such\\\\\\\\\\\\\\_attribute none\\\\\\\\\\\\\\_required recursion\\\\\\\\\\\\\\_loop set\\\\\\\\\\\\\\_type string\\\\\\\\\\\\\\_pattern\\\\\\\\\\\\\\_mismatch string\\\\\\\\\\\\\\_sub\\\\\\\\\\\\\\_type string\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_long string\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_short string\\\\\\\\\\\\\\_type string\\\\\\\\\\\\\\_unicode time\\\\\\\\\\\\\\_delta\\\\\\\\\\\\\\_parsing time\\\\\\\\\\\\\\_delta\\\\\\\\\\\\\\_type time\\\\\\\\\\\\\\_parsing time\\\\\\\\\\\\\\_type timezone\\\\\\\\\\\\\\_aware timezone\\\\\\\\\\\\\\_naive too\\\\\\\\\\\\\\_long too\\\\\\\\\\\\\\_short tuple\\\\\\\\\\\\\\_type unexpected\\\\\\\\\\\\\\_keyword\\\\\\\\\\\\\\_argument unexpected\\\\\\\\\\\\\\_positional\\\\\\\\\\\\\\_argument union\\\\\\\\\\\\\\_tag\\\\\\\\\\\\\\_invalid union\\\\\\\\\\\\\\_tag\\\\\\\\\\\\\\_not\\\\\\\\\\\\\\_found url\\\\\\\\\\\\\\_parsing url\\\\\\\\\\\\\\_scheme url\\\\\\\\\\\\\\_syntax\\\\\\\\\\\\\\_violation url\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_long url\\\\\\\\\\\\\\_type uuid\\\\\\\\\\\\\\_parsing uuid\\\\\\\\\\\\\\_type uuid\\\\\\\\\\\\\\_version value\\\\\\\\\\\\\\_error Validation Errors Pydantic attempts to provide useful validation errors. Below are details on common validation errors users may encounter when working with pydantic, together with some suggestions on how to fix them. arguments\\\\\\\\\\\\\\_type¶ This error is raised when an object that would be passed as arguments to a function during validation is not a tuple, list, or dict. Because NamedTuple uses function calls in its implementation, that is one way to produce this error: from typing import NamedTuple from pydantic import BaseModel, ValidationError class MyNamedTuple(NamedTuple): x: int class MyModel(BaseModel): field: MyNamedTuple try: MyModel.model\\\\\\\\\\\\\\_validate({'field': 'invalid'}) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'arguments\\\\\\\\\\\\\\_type' assertion\\\\\\\\\\\\\\_error¶ This error is raised when a failing assert statement is encountered during validation: from pydantic import BaseModel, ValidationError, field\\\\\\\\\\\\\\_validator class Model(BaseModel): x: int @field\\\\\\\\\\\\\\_validator('x') @classmethod def force\\\\\\\\\\\\\\_x\\\\\\\\\\\\\\_positive(cls, v): assert v > 0 return v try: Model(x=-1) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'assertion\\\\\\\\\\\\\\_error' bool\\\\\\\\\\\\\\_parsing¶ This error is raised when the input value is a string that is not valid for coercion to a boolean: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: bool Model(x='true') # OK try: Model(x='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'bool\\\\\\\\\\\\\\_parsing' bool\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not valid for a bool field: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: bool try: Model(x=None) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'bool\\\\\\\\\\\\\\_type' This error is also raised for strict fields when the input value is not an instance of bool. bytes\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_long¶ This error is raised when the length of a bytes value is greater than the field's max\\\\\\\\\\\\\\_length constraint: from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: bytes = Field(max\\\\\\\\\\\\\\_length=3) try: Model(x=b'test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'bytes\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_long' bytes\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_short¶ This error is raised when the length of a bytes value is less than the field's min\\\\\\\\\\\\\\_length constraint: from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: bytes = Field(min\\\\\\\\\\\\\\_length=3) try: Model(x=b't') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'bytes\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_short' bytes\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not valid for a bytes field: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: bytes try: Model(x=123) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'bytes\\\\\\\\\\\\\\_type' This error is also raised for strict fields when the input value is not an instance of bytes. callable\\\\\\\\\\\\\\_type¶ This error is raised when the input value is not valid as a Callable: from typing import Any, Callable from pydantic import BaseModel, ImportString, ValidationError class Model(BaseModel): x: ImportString\\\\\\\\\\\\\\[Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] Model(x='math:cos') # OK try: Model(x='os.path') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'callable\\\\\\\\\\\\\\_type' dataclass\\\\\\\\\\\\\\_exact\\\\\\\\\\\\\\_type¶ This error is raised when validating a dataclass with strict=True and the input is not an instance of the dataclass: import pydantic.dataclasses from pydantic import TypeAdapter, ValidationError @pydantic.dataclasses.dataclass class MyDataclass: x: str adapter = TypeAdapter(MyDataclass) print(adapter.validate\\\\\\\\\\\\\\_python(MyDataclass(x='test'), strict=True)) #> MyDataclass(x='test') print(adapter.validate\\\\\\\\\\\\\\_python({'x': 'test'})) #> MyDataclass(x='test') try: adapter.validate\\\\\\\\\\\\\\_python({'x': 'test'}, strict=True) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'dataclass\\\\\\\\\\\\\\_exact\\\\\\\\\\\\\\_type' dataclass\\\\\\\\\\\\\\_type¶ This error is raised when the input value is not valid for a dataclass field: from pydantic import ValidationError, dataclasses @dataclasses.dataclass class Inner: x: int @dataclasses.dataclass class Outer: y: Inner Outer(y=Inner(x=1)) # OK try: Outer(y=1) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'dataclass\\\\\\\\\\\\\\_type' date\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_datetime\\\\\\\\\\\\\\_inexact¶ This error is raised when the input datetime value provided for a date field has a nonzero time component. For a timestamp to parse into a field of type date, the time components must all be zero: from datetime import date, datetime from pydantic import BaseModel, ValidationError class Model(BaseModel): x: date Model(x='2023-01-01') # OK Model(x=datetime(2023, 1, 1)) # OK try: Model(x=datetime(2023, 1, 1, 12)) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'date\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_datetime\\\\\\\\\\\\\\_inexact' date\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_datetime\\\\\\\\\\\\\\_parsing¶ This error is raised when the input value is a string that cannot be parsed for a date field: from datetime import date from pydantic import BaseModel, ValidationError class Model(BaseModel): x: date try: Model(x='XX1494012000') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'date\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_datetime\\\\\\\\\\\\\\_parsing' date\\\\\\\\\\\\\\_future¶ This error is raised when the input value provided for a FutureDate field is not in the future: from datetime import date from pydantic import BaseModel, FutureDate, ValidationError class Model(BaseModel): x: FutureDate try: Model(x=date(2000, 1, 1)) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'date\\\\\\\\\\\\\\_future' date\\\\\\\\\\\\\\_parsing¶ This error is raised when validating JSON where the input value is string that cannot be parsed for a date field: import json from datetime import date from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: date = Field(strict=True) try: Model.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json(json.dumps({'x': '1'})) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'date\\\\\\\\\\\\\\_parsing' date\\\\\\\\\\\\\\_past¶ This error is raised when the value provided for a PastDate field is not in the past: from datetime import date, timedelta from pydantic import BaseModel, PastDate, ValidationError class Model(BaseModel): x: PastDate try: Model(x=date.today() + timedelta(1)) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'date\\\\\\\\\\\\\\_past' date\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not valid for a date field: from datetime import date from pydantic import BaseModel, ValidationError class Model(BaseModel): x: date try: Model(x=None) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'date\\\\\\\\\\\\\\_type' This error is also raised for strict fields when the input value is not an instance of date. datetime\\\\\\\\\\\\\\_future¶ This error is raised when the value provided for a FutureDatetime field is not in the future: from datetime import datetime from pydantic import BaseModel, FutureDatetime, ValidationError class Model(BaseModel): x: FutureDatetime try: Model(x=datetime(2000, 1, 1)) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'datetime\\\\\\\\\\\\\\_future' datetime\\\\\\\\\\\\\\_object\\\\\\\\\\\\\\_invalid¶ This error is raised when something about the datetime object is not valid: from datetime import datetime, tzinfo from pydantic import AwareDatetime, BaseModel, ValidationError class CustomTz(tzinfo): # utcoffset is not implemented! def tzname(self, \\\\\\\\\\\\\\_dt): return 'CustomTZ' class Model(BaseModel): x: AwareDatetime try: Model(x=datetime(2023, 1, 1, tzinfo=CustomTz())) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'datetime\\\\\\\\\\\\\\_object\\\\\\\\\\\\\\_invalid' datetime\\\\\\\\\\\\\\_parsing¶ This error is raised when the value is a string that cannot be parsed for a datetime field: from datetime import datetime from pydantic import BaseModel, ValidationError class Model(BaseModel): x: datetime try: Model(x='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'datetime\\\\\\\\\\\\\\_parsing' datetime\\\\\\\\\\\\\\_past¶ This error is raised when the value provided for a PastDatetime field is not in the past: from datetime import datetime, timedelta from pydantic import BaseModel, PastDatetime, ValidationError class Model(BaseModel): x: PastDatetime try: Model(x=datetime.now() + timedelta(100)) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'datetime\\\\\\\\\\\\\\_past' datetime\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not valid for a datetime field: from datetime import datetime from pydantic import BaseModel, ValidationError class Model(BaseModel): x: datetime try: Model(x=None) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'datetime\\\\\\\\\\\\\\_type' This error is also raised for strict fields when the input value is not an instance of datetime. decimal\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_digits¶ This error is raised when the value provided for a Decimal has too many digits: from decimal import Decimal from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: Decimal = Field(max\\\\\\\\\\\\\\_digits=3) try: Model(x='42.1234') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'decimal\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_digits' decimal\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_places¶ This error is raised when the value provided for a Decimal has too many digits after the decimal point: from decimal import Decimal from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: Decimal = Field(decimal\\\\\\\\\\\\\\_places=3) try: Model(x='42.1234') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'decimal\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_places' decimal\\\\\\\\\\\\\\_parsing¶ This error is raised when the value provided for a Decimal could not be parsed as a decimal number: from decimal import Decimal from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: Decimal = Field(decimal\\\\\\\\\\\\\\_places=3) try: Model(x='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'decimal\\\\\\\\\\\\\\_parsing' decimal\\\\\\\\\\\\\\_type¶ This error is raised when the value provided for a Decimal is of the wrong type: from decimal import Decimal from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: Decimal = Field(decimal\\\\\\\\\\\\\\_places=3) try: Model(x=\\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\]) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'decimal\\\\\\\\\\\\\\_type' This error is also raised for strict fields when the input value is not an instance of Decimal. decimal\\\\\\\\\\\\\\_whole\\\\\\\\\\\\\\_digits¶ This error is raised when the value provided for a Decimal has more digits before the decimal point than max\\\\\\\\\\\\\\_digits - decimal\\\\\\\\\\\\\\_places (as long as both are specified): from decimal import Decimal from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: Decimal = Field(max\\\\\\\\\\\\\\_digits=6, decimal\\\\\\\\\\\\\\_places=3) try: Model(x='12345.6') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'decimal\\\\\\\\\\\\\\_whole\\\\\\\\\\\\\\_digits' This error is also raised for strict fields when the input value is not an instance of Decimal. dict\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not dict for a dict field: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: dict try: Model(x=\\\\\\\\\\\\\\['1', '2'\\\\\\\\\\\\\\]) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'dict\\\\\\\\\\\\\\_type' enum¶ This error is raised when the input value does not exist in an enum field members: from enum import Enum from pydantic import BaseModel, ValidationError class MyEnum(str, Enum): option = 'option' class Model(BaseModel): x: MyEnum try: Model(x='other\\\\\\\\\\\\\\_option') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'enum' extra\\\\\\\\\\\\\\_forbidden¶ This error is raised when the input value contains extra fields, but model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['extra'\\\\\\\\\\\\\\] == 'forbid': from pydantic import BaseModel, ConfigDict, ValidationError class Model(BaseModel): x: str model\\\\\\\\\\\\\\_config = ConfigDict(extra='forbid') try: Model(x='test', y='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'extra\\\\\\\\\\\\\\_forbidden' You can read more about the extra configuration in the Extra Attributes section. finite\\\\\\\\\\\\\\_number¶ This error is raised when the value is infinite, or too large to be represented as a 64-bit floating point number during validation: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: int try: Model(x=2.2250738585072011e308) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'finite\\\\\\\\\\\\\\_number' float\\\\\\\\\\\\\\_parsing¶ This error is raised when the value is a string that can't be parsed as a float: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: float try: Model(x='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'float\\\\\\\\\\\\\\_parsing' float\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not valid for a float field: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: float try: Model(x=None) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'float\\\\\\\\\\\\\\_type' frozen\\\\\\\\\\\\\\_field¶ This error is raised when you attempt to assign a value to a field with frozen=True, or to delete such a field: from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: str = Field('test', frozen=True) model = Model() try: model.x = 'test1' except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'frozen\\\\\\\\\\\\\\_field' try: del model.x except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'frozen\\\\\\\\\\\\\\_field' frozen\\\\\\\\\\\\\\_instance¶ This error is raised when model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['frozen\\\\\\\\\\\\\\] == True and you attempt to delete or assign a new value to any of the fields: from pydantic import BaseModel, ConfigDict, ValidationError class Model(BaseModel): x: int model\\\\\\\\\\\\\\_config = ConfigDict(frozen=True) m = Model(x=1) try: m.x = 2 except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'frozen\\\\\\\\\\\\\\_instance' try: del m.x except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'frozen\\\\\\\\\\\\\\_instance' frozen\\\\\\\\\\\\\\_set\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not valid for a frozenset field: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: frozenset try: model = Model(x='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'frozen\\\\\\\\\\\\\\_set\\\\\\\\\\\\\\_type' get\\\\\\\\\\\\\\_attribute\\\\\\\\\\\\\\_error¶ This error is raised when model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['from\\\\\\\\\\\\\\_attributes'\\\\\\\\\\\\\\] == True and an error is raised while reading the attributes: from pydantic import BaseModel, ConfigDict, ValidationError class Foobar: def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self): self.x = 1 @property def y(self): raise RuntimeError('intentional error') class Model(BaseModel): x: int y: str model\\\\\\\\\\\\\\_config = ConfigDict(from\\\\\\\\\\\\\\_attributes=True) try: Model.model\\\\\\\\\\\\\\_validate(Foobar()) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'get\\\\\\\\\\\\\\_attribute\\\\\\\\\\\\\\_error' greater\\\\\\\\\\\\\\_than¶ This error is raised when the value is not greater than the field's gt constraint: from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: int = Field(gt=10) try: Model(x=10) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'greater\\\\\\\\\\\\\\_than' greater\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal¶ This error is raised when the value is not greater than or equal to the field's ge constraint: from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: int = Field(ge=10) try: Model(x=9) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'greater\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal' int\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_float¶ This error is raised when you provide a float value for an int field: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: int try: Model(x=0.5) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'int\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_float' int\\\\\\\\\\\\\\_parsing¶ This error is raised when the value can't be parsed as int: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: int try: Model(x='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'int\\\\\\\\\\\\\\_parsing' int\\\\\\\\\\\\\\_parsing\\\\\\\\\\\\\\_size¶ This error is raised when attempting to parse a python or JSON value from a string outside the maximum range that Python str to int parsing permits: import json from pydantic import BaseModel, ValidationError class Model(BaseModel): x: int # from Python assert Model(x='1' \\\\\\\\\\\\\\* 4\\\\\\\\\\\\\\_300).x == int('1' \\\\\\\\\\\\\\* 4\\\\\\\\\\\\\\_300) # OK too\\\\\\\\\\\\\\_long = '1' \\\\\\\\\\\\\\* 4\\\\\\\\\\\\\\_301 try: Model(x=too\\\\\\\\\\\\\\_long) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'int\\\\\\\\\\\\\\_parsing\\\\\\\\\\\\\\_size' # from JSON try: Model.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json(json.dumps({'x': too\\\\\\\\\\\\\\_long})) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'int\\\\\\\\\\\\\\_parsing\\\\\\\\\\\\\\_size' int\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not valid for an int field: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: int try: Model(x=None) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'int\\\\\\\\\\\\\\_type' invalid\\\\\\\\\\\\\\_key¶ This error is raised when attempting to validate a dict that has a key that is not an instance of str: from pydantic import BaseModel, ConfigDict, ValidationError class Model(BaseModel): x: int model\\\\\\\\\\\\\\_config = ConfigDict(extra='allow') try: Model.model\\\\\\\\\\\\\\_validate({'x': 1, b'y': 2}) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'invalid\\\\\\\\\\\\\\_key' is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_of¶ This error is raised when the input value is not an instance of the expected type: from pydantic import BaseModel, ConfigDict, ValidationError class Nested: x: str class Model(BaseModel): y: Nested model\\\\\\\\\\\\\\_config = ConfigDict(arbitrary\\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_allowed=True) try: Model(y='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_of' is\\\\\\\\\\\\\\_subclass\\\\\\\\\\\\\\_of¶ This error is raised when the input value is not a subclass of the expected type: from typing import Type from pydantic import BaseModel, ValidationError class Nested: x: str class Model(BaseModel): y: Type\\\\\\\\\\\\\\[Nested\\\\\\\\\\\\\\] try: Model(y='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'is\\\\\\\\\\\\\\_subclass\\\\\\\\\\\\\\_of' iterable\\\\\\\\\\\\\\_type¶ This error is raised when the input value is not valid as an Iterable: from typing import Iterable from pydantic import BaseModel, ValidationError class Model(BaseModel): y: Iterable try: Model(y=123) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'iterable\\\\\\\\\\\\\\_type' iteration\\\\\\\\\\\\\\_error¶ This error is raised when an error occurs during iteration: from typing import List from pydantic import BaseModel, ValidationError def gen(): yield 1 raise RuntimeError('error') class Model(BaseModel): x: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] try: Model(x=gen()) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'iteration\\\\\\\\\\\\\\_error' json\\\\\\\\\\\\\\_invalid¶ This error is raised when the input value is not a valid JSON string: from pydantic import BaseModel, Json, ValidationError class Model(BaseModel): x: Json try: Model(x='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'json\\\\\\\\\\\\\\_invalid' json\\\\\\\\\\\\\\_type¶ This error is raised when the input value is of a type that cannot be parsed as JSON: from pydantic import BaseModel, Json, ValidationError class Model(BaseModel): x: Json try: Model(x=None) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'json\\\\\\\\\\\\\\_type' less\\\\\\\\\\\\\\_than¶ This error is raised when the input value is not less than the field's lt constraint: from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: int = Field(lt=10) try: Model(x=10) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'less\\\\\\\\\\\\\\_than' less\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal¶ This error is raised when the input value is not less than or equal to the field's le constraint: from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: int = Field(le=10) try: Model(x=11) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'less\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal' list\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not valid for a list field: from typing import List from pydantic import BaseModel, ValidationError class Model(BaseModel): x: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] try: Model(x=1) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'list\\\\\\\\\\\\\\_type' literal\\\\\\\\\\\\\\_error¶ This error is raised when the input value is not one of the expected literal values: from typing\\\\\\\\\\\\\\_extensions import Literal from pydantic import BaseModel, ValidationError class Model(BaseModel): x: Literal\\\\\\\\\\\\\\['a', 'b'\\\\\\\\\\\\\\] Model(x='a') # OK try: Model(x='c') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'literal\\\\\\\\\\\\\\_error' mapping\\\\\\\\\\\\\\_type¶ This error is raised when a problem occurs during validation due to a failure in a call to the methods from the Mapping protocol, such as .items(): from collections.abc import Mapping from typing import Dict from pydantic import BaseModel, ValidationError class BadMapping(Mapping): def items(self): raise ValueError() def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_iter\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self): raise ValueError() def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_getitem\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, key): raise ValueError() def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_len\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self): return 1 class Model(BaseModel): x: Dict\\\\\\\\\\\\\\[str, str\\\\\\\\\\\\\\] try: Model(x=BadMapping()) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'mapping\\\\\\\\\\\\\\_type' missing¶ This error is raised when there are required fields missing from the input value: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: str try: Model() except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'missing' missing\\\\\\\\\\\\\\_argument¶ This error is raised when a required positional-or-keyword argument is not passed to a function decorated with validate\\\\\\\\\\\\\\_call: from pydantic import ValidationError, validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call def foo(a: int): return a try: foo() except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'missing\\\\\\\\\\\\\\_argument' missing\\\\\\\\\\\\\\_keyword\\\\\\\\\\\\\\_only\\\\\\\\\\\\\\_argument¶ This error is raised when a required keyword-only argument is not passed to a function decorated with validate\\\\\\\\\\\\\\_call: from pydantic import ValidationError, validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call def foo(\\\\\\\\\\\\\\*, a: int): return a try: foo() except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'missing\\\\\\\\\\\\\\_keyword\\\\\\\\\\\\\\_only\\\\\\\\\\\\\\_argument' missing\\\\\\\\\\\\\\_positional\\\\\\\\\\\\\\_only\\\\\\\\\\\\\\_argument¶ This error is raised when a required positional-only argument is not passed to a function decorated with validate\\\\\\\\\\\\\\_call: from pydantic import ValidationError, validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call def foo(a: int, /): return a try: foo() except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'missing\\\\\\\\\\\\\\_positional\\\\\\\\\\\\\\_only\\\\\\\\\\\\\\_argument' model\\\\\\\\\\\\\\_attributes\\\\\\\\\\\\\\_type¶ This error is raised when the input value is not a valid dictionary, model instance, or instance that fields can be extracted from: from pydantic import BaseModel, ValidationError class Model(BaseModel): a: int b: int # simply validating a dict print(Model.model\\\\\\\\\\\\\\_validate({'a': 1, 'b': 2})) #> a=1 b=2 class CustomObj: def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, a, b): self.a = a self.b = b # using from attributes to extract fields from an objects print(Model.model\\\\\\\\\\\\\\_validate(CustomObj(3, 4), from\\\\\\\\\\\\\\_attributes=True)) #> a=3 b=4 try: Model.model\\\\\\\\\\\\\\_validate('not an object', from\\\\\\\\\\\\\\_attributes=True) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'model\\\\\\\\\\\\\\_attributes\\\\\\\\\\\\\\_type' model\\\\\\\\\\\\\\_type¶ This error is raised when the input to a model is not an instance of the model or dict: from pydantic import BaseModel, ValidationError class Model(BaseModel): a: int b: int # simply validating a dict m = Model.model\\\\\\\\\\\\\\_validate({'a': 1, 'b': 2}) print(m) #> a=1 b=2 # validating an existing model instance print(Model.model\\\\\\\\\\\\\\_validate(m)) #> a=1 b=2 try: Model.model\\\\\\\\\\\\\\_validate('not an object') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'model\\\\\\\\\\\\\\_type' multiple\\\\\\\\\\\\\\_argument\\\\\\\\\\\\\\_values¶ This error is raised when you provide multiple values for a single argument while calling a function decorated with validate\\\\\\\\\\\\\\_call: from pydantic import ValidationError, validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call def foo(a: int): return a try: foo(1, a=2) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'multiple\\\\\\\\\\\\\\_argument\\\\\\\\\\\\\\_values' multiple\\\\\\\\\\\\\\_of¶ This error is raised when the input is not a multiple of a field's multiple\\\\\\\\\\\\\\_of constraint: from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: int = Field(multiple\\\\\\\\\\\\\\_of=5) try: Model(x=1) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'multiple\\\\\\\\\\\\\\_of' no\\\\\\\\\\\\\\_such\\\\\\\\\\\\\\_attribute¶ This error is raised when validate\\\\\\\\\\\\\\_assignment=True in the config, and you attempt to assign a value to an attribute that is not an existing field: from pydantic import ConfigDict, ValidationError, dataclasses @dataclasses.dataclass(config=ConfigDict(validate\\\\\\\\\\\\\\_assignment=True)) class MyDataclass: x: int m = MyDataclass(x=1) try: m.y = 10 except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'no\\\\\\\\\\\\\\_such\\\\\\\\\\\\\\_attribute' none\\\\\\\\\\\\\\_required¶ This error is raised when the input value is not None for a field that requires None: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: None try: Model(x=1) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'none\\\\\\\\\\\\\\_required' recursion\\\\\\\\\\\\\\_loop¶ This error is raised when a cyclic reference is detected: from typing import List from pydantic import BaseModel, ValidationError class Model(BaseModel): x: List\\\\\\\\\\\\\\['Model'\\\\\\\\\\\\\\] d = {'x': \\\\\\\\\\\\\\[\\\\\\\\\\\\\\]} d\\\\\\\\\\\\\\['x'\\\\\\\\\\\\\\].append(d) try: Model(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*d) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'recursion\\\\\\\\\\\\\\_loop' set\\\\\\\\\\\\\\_type¶ This error is raised when the value type is not valid for a set field: from typing import Set from pydantic import BaseModel, ValidationError class Model(BaseModel): x: Set\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] try: Model(x='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'set\\\\\\\\\\\\\\_type' string\\\\\\\\\\\\\\_pattern\\\\\\\\\\\\\\_mismatch¶ This error is raised when the input value doesn't match the field's pattern constraint: from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: str = Field(pattern='test') try: Model(x='1') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'string\\\\\\\\\\\\\\_pattern\\\\\\\\\\\\\\_mismatch' string\\\\\\\\\\\\\\_sub\\\\\\\\\\\\\\_type¶ This error is raised when the value is an instance of a strict subtype of str when the field is strict: from enum import Enum from pydantic import BaseModel, Field, ValidationError class MyEnum(str, Enum): foo = 'foo' class Model(BaseModel): x: str = Field(strict=True) try: Model(x=MyEnum.foo) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'string\\\\\\\\\\\\\\_sub\\\\\\\\\\\\\\_type' string\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_long¶ This error is raised when the input value is a string whose length is greater than the field's max\\\\\\\\\\\\\\_length constraint: from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: str = Field(max\\\\\\\\\\\\\\_length=3) try: Model(x='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'string\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_long' string\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_short¶ This error is raised when the input value is a string whose length is less than the field's min\\\\\\\\\\\\\\_length constraint: from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: str = Field(min\\\\\\\\\\\\\\_length=3) try: Model(x='t') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'string\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_short' string\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not valid for a str field: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: str try: Model(x=1) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'string\\\\\\\\\\\\\\_type' This error is also raised for strict fields when the input value is not an instance of str. string\\\\\\\\\\\\\\_unicode¶ This error is raised when the value cannot be parsed as a Unicode string: from pydantic import BaseModel, ValidationError class Model(BaseModel): x: str try: Model(x=b'\\\\\\\\\\\\\\\\x81') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'string\\\\\\\\\\\\\\_unicode' time\\\\\\\\\\\\\\_delta\\\\\\\\\\\\\\_parsing¶ This error is raised when the input value is a string that cannot be parsed for a timedelta field: from datetime import timedelta from pydantic import BaseModel, ValidationError class Model(BaseModel): x: timedelta try: Model(x='t') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'time\\\\\\\\\\\\\\_delta\\\\\\\\\\\\\\_parsing' time\\\\\\\\\\\\\\_delta\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not valid for a timedelta field: from datetime import timedelta from pydantic import BaseModel, ValidationError class Model(BaseModel): x: timedelta try: Model(x=None) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'time\\\\\\\\\\\\\\_delta\\\\\\\\\\\\\\_type' This error is also raised for strict fields when the input value is not an instance of timedelta. time\\\\\\\\\\\\\\_parsing¶ This error is raised when the input value is a string that cannot be parsed for a time field: from datetime import time from pydantic import BaseModel, ValidationError class Model(BaseModel): x: time try: Model(x='25:20:30.400') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'time\\\\\\\\\\\\\\_parsing' time\\\\\\\\\\\\\\_type¶ This error is raised when the value type is not valid for a time field: from datetime import time from pydantic import BaseModel, ValidationError class Model(BaseModel): x: time try: Model(x=None) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'time\\\\\\\\\\\\\\_type' This error is also raised for strict fields when the input value is not an instance of time. timezone\\\\\\\\\\\\\\_aware¶ This error is raised when the datetime value provided for a timezone-aware datetime field doesn't have timezone information: from datetime import datetime from pydantic import AwareDatetime, BaseModel, ValidationError class Model(BaseModel): x: AwareDatetime try: Model(x=datetime.now()) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'timezone\\\\\\\\\\\\\\_aware' timezone\\\\\\\\\\\\\\_naive¶ This error is raised when the datetime value provided for a timezone-naive datetime field has timezone info: from datetime import datetime, timezone from pydantic import BaseModel, NaiveDatetime, ValidationError class Model(BaseModel): x: NaiveDatetime try: Model(x=datetime.now(tz=timezone.utc)) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'timezone\\\\\\\\\\\\\\_naive' too\\\\\\\\\\\\\\_long¶ This error is raised when the input value's length is greater than the field's max\\\\\\\\\\\\\\_length constraint: from typing import List from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] = Field(max\\\\\\\\\\\\\\_length=3) try: Model(x=\\\\\\\\\\\\\\[1, 2, 3, 4\\\\\\\\\\\\\\]) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'too\\\\\\\\\\\\\\_long' too\\\\\\\\\\\\\\_short¶ This error is raised when the value length is less than the field's min\\\\\\\\\\\\\\_length constraint: from typing import List from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] = Field(min\\\\\\\\\\\\\\_length=3) try: Model(x=\\\\\\\\\\\\\\[1, 2\\\\\\\\\\\\\\]) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'too\\\\\\\\\\\\\\_short' tuple\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not valid for a tuple field: from typing import Tuple from pydantic import BaseModel, ValidationError class Model(BaseModel): x: Tuple\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] try: Model(x=None) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'tuple\\\\\\\\\\\\\\_type' This error is also raised for strict fields when the input value is not an instance of tuple. unexpected\\\\\\\\\\\\\\_keyword\\\\\\\\\\\\\\_argument¶ This error is raised when you provide a value by keyword for a positional-only argument while calling a function decorated with validate\\\\\\\\\\\\\\_call: from pydantic import ValidationError, validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call def foo(a: int, /): return a try: foo(a=2) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[1\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'unexpected\\\\\\\\\\\\\\_keyword\\\\\\\\\\\\\\_argument' It is also raised when using pydantic.dataclasses and extra=forbid: from pydantic import TypeAdapter, ValidationError from pydantic.dataclasses import dataclass @dataclass(config={'extra': 'forbid'}) class Foo: bar: int try: TypeAdapter(Foo).validate\\\\\\\\\\\\\\_python({'bar': 1, 'foobar': 2}) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'unexpected\\\\\\\\\\\\\\_keyword\\\\\\\\\\\\\\_argument' unexpected\\\\\\\\\\\\\\_positional\\\\\\\\\\\\\\_argument¶ This error is raised when you provide a positional value for a keyword-only argument while calling a function decorated with validate\\\\\\\\\\\\\\_call: from pydantic import ValidationError, validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call def foo(\\\\\\\\\\\\\\*, a: int): return a try: foo(2) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[1\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'unexpected\\\\\\\\\\\\\\_positional\\\\\\\\\\\\\\_argument' union\\\\\\\\\\\\\\_tag\\\\\\\\\\\\\\_invalid¶ This error is raised when the input's discriminator is not one of the expected values: from typing import Union from typing\\\\\\\\\\\\\\_extensions import Literal from pydantic import BaseModel, Field, ValidationError class BlackCat(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['blackcat'\\\\\\\\\\\\\\] class WhiteCat(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['whitecat'\\\\\\\\\\\\\\] class Model(BaseModel): cat: Union\\\\\\\\\\\\\\[BlackCat, WhiteCat\\\\\\\\\\\\\\] = Field(..., discriminator='pet\\\\\\\\\\\\\\_type') try: Model(cat={'pet\\\\\\\\\\\\\\_type': 'dog'}) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'union\\\\\\\\\\\\\\_tag\\\\\\\\\\\\\\_invalid' union\\\\\\\\\\\\\\_tag\\\\\\\\\\\\\\_not\\\\\\\\\\\\\\_found¶ This error is raised when it is not possible to extract a discriminator value from the input: from typing import Union from typing\\\\\\\\\\\\\\_extensions import Literal from pydantic import BaseModel, Field, ValidationError class BlackCat(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['blackcat'\\\\\\\\\\\\\\] class WhiteCat(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['whitecat'\\\\\\\\\\\\\\] class Model(BaseModel): cat: Union\\\\\\\\\\\\\\[BlackCat, WhiteCat\\\\\\\\\\\\\\] = Field(..., discriminator='pet\\\\\\\\\\\\\\_type') try: Model(cat={'name': 'blackcat'}) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'union\\\\\\\\\\\\\\_tag\\\\\\\\\\\\\\_not\\\\\\\\\\\\\\_found' url\\\\\\\\\\\\\\_parsing¶ This error is raised when the input value cannot be parsed as a URL: from pydantic import AnyUrl, BaseModel, ValidationError class Model(BaseModel): x: AnyUrl try: Model(x='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'url\\\\\\\\\\\\\\_parsing' url\\\\\\\\\\\\\\_scheme¶ This error is raised when the URL scheme is not valid for the URL type of the field: from pydantic import BaseModel, HttpUrl, ValidationError class Model(BaseModel): x: HttpUrl try: Model(x='ftp://example.com') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'url\\\\\\\\\\\\\\_scheme' url\\\\\\\\\\\\\\_syntax\\\\\\\\\\\\\\_violation¶ This error is raised when the URL syntax is not valid: from pydantic import BaseModel, Field, HttpUrl, ValidationError class Model(BaseModel): x: HttpUrl = Field(strict=True) try: Model(x='http:////example.com') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'url\\\\\\\\\\\\\\_syntax\\\\\\\\\\\\\\_violation' url\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_long¶ This error is raised when the URL length is greater than 2083: from pydantic import BaseModel, HttpUrl, ValidationError class Model(BaseModel): x: HttpUrl try: Model(x='x' \\\\\\\\\\\\\\* 2084) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'url\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_long' url\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not valid for a URL field: from pydantic import BaseModel, HttpUrl, ValidationError class Model(BaseModel): x: HttpUrl try: Model(x=None) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'url\\\\\\\\\\\\\\_type' uuid\\\\\\\\\\\\\\_parsing¶ This error is raised when the input value's type is not valid for a UUID field: from uuid import UUID from pydantic import BaseModel, ValidationError class Model(BaseModel): u: UUID try: Model(u='12345678-124-1234-1234-567812345678') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'uuid\\\\\\\\\\\\\\_parsing' uuid\\\\\\\\\\\\\\_type¶ This error is raised when the input value's type is not valid instance for a UUID field (str, bytes or UUID): from uuid import UUID from pydantic import BaseModel, ValidationError class Model(BaseModel): u: UUID try: Model(u=1234567812412341234567812345678) except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'uuid\\\\\\\\\\\\\\_type' uuid\\\\\\\\\\\\\\_version¶ This error is raised when the input value's type is not match UUID version: from pydantic import UUID5, BaseModel, ValidationError class Model(BaseModel): u: UUID5 try: Model(u='a6cc5730-2261-11ee-9c43-2eb5a363657c') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'uuid\\\\\\\\\\\\\\_version' value\\\\\\\\\\\\\\_error¶ This error is raised when a ValueError is raised during validation: from pydantic import BaseModel, ValidationError, field\\\\\\\\\\\\\\_validator class Model(BaseModel): x: str @field\\\\\\\\\\\\\\_validator('x') @classmethod def repeat\\\\\\\\\\\\\\_b(cls, v): raise ValueError() try: Model(x='test') except ValidationError as exc: print(repr(exc.errors()\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\])) #> 'value\\\\\\\\\\\\\\_error' Made with Material for MkDocs Insiders"
  },
  {
    "title": "Usage Errors - Pydantic",
    "url": "https://docs.pydantic.dev/latest/errors/usage_errors/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Usage Errors Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Error Messages Error Handling Validation Errors Usage Errors Page contents Class not fully defined Custom JSON Schema Decorator on missing field Discriminator no field Discriminator alias type Discriminator needs literal Discriminator alias Invalid discriminator validator Callable discriminator case with no tag TypedDict version Model parent field overridden Model field missing annotation Config and model\\\\\\\\\\\\\\_config both defined Keyword arguments removed JSON schema invalid type JSON schema already used BaseModel instantiated Undefined annotation Schema for unknown type Import error create\\\\\\\\\\\\\\_model field definitions create\\\\\\\\\\\\\\_model config base Validator with no fields Invalid validator fields Validator on instance method Root validator, pre, skip\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_failure model\\\\\\\\\\\\\\_serializer instance methods validator, field, config, and info Pydantic V1 validator signature Unrecognized field\\\\\\\\\\\\\\_validator signature Unrecognized field\\\\\\\\\\\\\\_serializer signature Unrecognized model\\\\\\\\\\\\\\_serializer signature Multiple field serializers Invalid annotated type config is unused with TypeAdapter Cannot specify model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['extra'\\\\\\\\\\\\\\] with RootModel Usage Errors Pydantic attempts to provide useful errors. The following sections provide details on common errors developers may encounter when working with Pydantic, along with suggestions for addressing the error condition. Class not fully defined¶ This error is raised when a type referenced in an annotation of a pydantic-validated type (such as a subclass of BaseModel, or a pydantic dataclass) is not defined: from typing import ForwardRef from pydantic import BaseModel, PydanticUserError UndefinedType = ForwardRef('UndefinedType') class Foobar(BaseModel): a: UndefinedType try: Foobar(a=1) except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'class-not-fully-defined' Or when the type has been defined after usage: from typing import Optional from pydantic import BaseModel, PydanticUserError class Foo(BaseModel): a: Optional\\\\\\\\\\\\\\['Bar'\\\\\\\\\\\\\\] = None try: # this doesn't work, see raised error foo = Foo(a={'b': {'a': None}}) except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'class-not-fully-defined' class Bar(BaseModel): b: 'Foo' # this works, though foo = Foo(a={'b': {'a': None}}) For BaseModel subclasses, it can be fixed by defining the type and then calling .model\\\\\\\\\\\\\\_rebuild(): from typing import Optional from pydantic import BaseModel class Foo(BaseModel): a: Optional\\\\\\\\\\\\\\['Bar'\\\\\\\\\\\\\\] = None class Bar(BaseModel): b: 'Foo' Foo.model\\\\\\\\\\\\\\_rebuild() foo = Foo(a={'b': {'a': None}}) In other cases, the error message should indicate how to rebuild the class with the appropriate type defined. Custom JSON Schema¶ The \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_modify\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method is no longer supported in V2. You should use the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method instead. The \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_modify\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ used to receive a single argument representing the JSON schema. See the example below: Old way from pydantic import BaseModel, PydanticUserError try: class Model(BaseModel): @classmethod def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_modify\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(cls, field\\\\\\\\\\\\\\_schema): field\\\\\\\\\\\\\\_schema.update(examples='examples') except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'custom-json-schema' The new method \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ receives two arguments: the first is a dictionary denoted as CoreSchema, and the second a callable handler that receives a CoreSchema as parameter, and returns a JSON schema. See the example below: New way from typing import Any, Dict from pydantic\\\\\\\\\\\\\\_core import CoreSchema from pydantic import BaseModel, GetJsonSchemaHandler class Model(BaseModel): @classmethod def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( cls, core\\\\\\\\\\\\\\_schema: CoreSchema, handler: GetJsonSchemaHandler ) -> Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\]: json\\\\\\\\\\\\\\_schema = super().\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(core\\\\\\\\\\\\\\_schema, handler) json\\\\\\\\\\\\\\_schema = handler.resolve\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema(json\\\\\\\\\\\\\\_schema) json\\\\\\\\\\\\\\_schema.update(examples='examples') return json\\\\\\\\\\\\\\_schema print(Model.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema()) \"\"\" {'examples': 'examples', 'properties': {}, 'title': 'Model', 'type': 'object'} \"\"\" Decorator on missing field¶ This error is raised when you define a decorator with a field that is not valid. from typing import Any from pydantic import BaseModel, PydanticUserError, field\\\\\\\\\\\\\\_validator try: class Model(BaseModel): a: str @field\\\\\\\\\\\\\\_validator('b') def check\\\\\\\\\\\\\\_b(cls, v: Any): return v except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'decorator-missing-field' You can use check\\\\\\\\\\\\\\_fields=False if you're inheriting from the model and intended this. from typing import Any from pydantic import BaseModel, create\\\\\\\\\\\\\\_model, field\\\\\\\\\\\\\\_validator class Model(BaseModel): @field\\\\\\\\\\\\\\_validator('a', check\\\\\\\\\\\\\\_fields=False) def check\\\\\\\\\\\\\\_a(cls, v: Any): return v model = create\\\\\\\\\\\\\\_model('FooModel', a=(str, 'cake'), \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_base\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_=Model) Discriminator no field¶ This error is raised when a model in discriminated unions doesn't define a discriminator field. from typing import Union from typing\\\\\\\\\\\\\\_extensions import Literal from pydantic import BaseModel, Field, PydanticUserError class Cat(BaseModel): c: str class Dog(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['dog'\\\\\\\\\\\\\\] d: str try: class Model(BaseModel): pet: Union\\\\\\\\\\\\\\[Cat, Dog\\\\\\\\\\\\\\] = Field(..., discriminator='pet\\\\\\\\\\\\\\_type') number: int except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'discriminator-no-field' Discriminator alias type¶ This error is raised when you define a non-string alias on a discriminator field. from typing import Union from typing\\\\\\\\\\\\\\_extensions import Literal from pydantic import AliasChoices, BaseModel, Field, PydanticUserError class Cat(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['cat'\\\\\\\\\\\\\\] = Field( validation\\\\\\\\\\\\\\_alias=AliasChoices('Pet', 'PET') ) c: str class Dog(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['dog'\\\\\\\\\\\\\\] d: str try: class Model(BaseModel): pet: Union\\\\\\\\\\\\\\[Cat, Dog\\\\\\\\\\\\\\] = Field(..., discriminator='pet\\\\\\\\\\\\\\_type') number: int except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'discriminator-alias-type' Discriminator needs literal¶ This error is raised when you define a non-Literal type on a discriminator field. from typing import Union from typing\\\\\\\\\\\\\\_extensions import Literal from pydantic import BaseModel, Field, PydanticUserError class Cat(BaseModel): pet\\\\\\\\\\\\\\_type: int c: str class Dog(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['dog'\\\\\\\\\\\\\\] d: str try: class Model(BaseModel): pet: Union\\\\\\\\\\\\\\[Cat, Dog\\\\\\\\\\\\\\] = Field(..., discriminator='pet\\\\\\\\\\\\\\_type') number: int except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'discriminator-needs-literal' Discriminator alias¶ This error is raised when you define different aliases on discriminator fields. from typing import Union from typing\\\\\\\\\\\\\\_extensions import Literal from pydantic import BaseModel, Field, PydanticUserError class Cat(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['cat'\\\\\\\\\\\\\\] = Field(validation\\\\\\\\\\\\\\_alias='PET') c: str class Dog(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['dog'\\\\\\\\\\\\\\] = Field(validation\\\\\\\\\\\\\\_alias='Pet') d: str try: class Model(BaseModel): pet: Union\\\\\\\\\\\\\\[Cat, Dog\\\\\\\\\\\\\\] = Field(..., discriminator='pet\\\\\\\\\\\\\\_type') number: int except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'discriminator-alias' Invalid discriminator validator¶ This error is raised when you use a before, wrap, or plain validator on a discriminator field. This is disallowed because the discriminator field is used to determine the type of the model to use for validation, so you can't use a validator that might change its value. from typing import Union from typing\\\\\\\\\\\\\\_extensions import Literal from pydantic import BaseModel, Field, PydanticUserError, field\\\\\\\\\\\\\\_validator class Cat(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['cat'\\\\\\\\\\\\\\] @field\\\\\\\\\\\\\\_validator('pet\\\\\\\\\\\\\\_type', mode='before') @classmethod def validate\\\\\\\\\\\\\\_pet\\\\\\\\\\\\\\_type(cls, v): if v == 'kitten': return 'cat' return v class Dog(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['dog'\\\\\\\\\\\\\\] try: class Model(BaseModel): pet: Union\\\\\\\\\\\\\\[Cat, Dog\\\\\\\\\\\\\\] = Field(..., discriminator='pet\\\\\\\\\\\\\\_type') number: int except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'discriminator-validator' This can be worked around by using a standard Union, dropping the discriminator: from typing import Union from typing\\\\\\\\\\\\\\_extensions import Literal from pydantic import BaseModel, field\\\\\\\\\\\\\\_validator class Cat(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['cat'\\\\\\\\\\\\\\] @field\\\\\\\\\\\\\\_validator('pet\\\\\\\\\\\\\\_type', mode='before') @classmethod def validate\\\\\\\\\\\\\\_pet\\\\\\\\\\\\\\_type(cls, v): if v == 'kitten': return 'cat' return v class Dog(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['dog'\\\\\\\\\\\\\\] class Model(BaseModel): pet: Union\\\\\\\\\\\\\\[Cat, Dog\\\\\\\\\\\\\\] assert Model(pet={'pet\\\\\\\\\\\\\\_type': 'kitten'}).pet.pet\\\\\\\\\\\\\\_type == 'cat' Callable discriminator case with no tag¶ This error is raised when a Union that uses a callable Discriminator doesn't have Tag annotations for all cases. from typing import Union from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, Discriminator, PydanticUserError, Tag def model\\\\\\\\\\\\\\_x\\\\\\\\\\\\\\_discriminator(v): if isinstance(v, str): return 'str' if isinstance(v, (dict, BaseModel)): return 'model' # tag missing for both union choices try: class DiscriminatedModel(BaseModel): x: Annotated\\\\\\\\\\\\\\[ Union\\\\\\\\\\\\\\[str, 'DiscriminatedModel'\\\\\\\\\\\\\\], Discriminator(model\\\\\\\\\\\\\\_x\\\\\\\\\\\\\\_discriminator), \\\\\\\\\\\\\\] except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'callable-discriminator-no-tag' # tag missing for \\\\\\\\\\\\\\`'DiscriminatedModel'\\\\\\\\\\\\\\` union choice try: class DiscriminatedModel(BaseModel): x: Annotated\\\\\\\\\\\\\\[ Union\\\\\\\\\\\\\\[Annotated\\\\\\\\\\\\\\[str, Tag('str')\\\\\\\\\\\\\\], 'DiscriminatedModel'\\\\\\\\\\\\\\], Discriminator(model\\\\\\\\\\\\\\_x\\\\\\\\\\\\\\_discriminator), \\\\\\\\\\\\\\] except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'callable-discriminator-no-tag' # tag missing for \\\\\\\\\\\\\\`str\\\\\\\\\\\\\\` union choice try: class DiscriminatedModel(BaseModel): x: Annotated\\\\\\\\\\\\\\[ Union\\\\\\\\\\\\\\[str, Annotated\\\\\\\\\\\\\\['DiscriminatedModel', Tag('model')\\\\\\\\\\\\\\]\\\\\\\\\\\\\\], Discriminator(model\\\\\\\\\\\\\\_x\\\\\\\\\\\\\\_discriminator), \\\\\\\\\\\\\\] except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'callable-discriminator-no-tag' TypedDict version¶ This error is raised when you use typing.TypedDict instead of typing\\\\\\\\\\\\\\_extensions.TypedDict on Python < 3.12. Model parent field overridden¶ This error is raised when a field defined on a base class was overridden by a non-annotated attribute. from pydantic import BaseModel, PydanticUserError class Foo(BaseModel): a: float try: class Bar(Foo): x: float = 12.3 a = 123.0 except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'model-field-overridden' Model field missing annotation¶ This error is raised when a field doesn't have an annotation. from pydantic import BaseModel, Field, PydanticUserError try: class Model(BaseModel): a = Field('foobar') b = None except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'model-field-missing-annotation' If the field is not meant to be a field, you may be able to resolve the error by annotating it as a ClassVar: from typing import ClassVar from pydantic import BaseModel class Model(BaseModel): a: ClassVar\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] Or updating model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['ignored\\\\\\\\\\\\\\_types'\\\\\\\\\\\\\\]: from pydantic import BaseModel, ConfigDict class IgnoredType: pass class MyModel(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(ignored\\\\\\\\\\\\\\_types=(IgnoredType,)) \\\\\\\\\\\\\\_a = IgnoredType() \\\\\\\\\\\\\\_b: int = IgnoredType() \\\\\\\\\\\\\\_c: IgnoredType \\\\\\\\\\\\\\_d: IgnoredType = IgnoredType() Config and model\\\\\\\\\\\\\\_config both defined¶ This error is raised when class Config and model\\\\\\\\\\\\\\_config are used together. from pydantic import BaseModel, ConfigDict, PydanticUserError try: class Model(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(from\\\\\\\\\\\\\\_attributes=True) a: str class Config: from\\\\\\\\\\\\\\_attributes = True except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'config-both' Keyword arguments removed¶ This error is raised when the keyword arguments are not available in Pydantic V2. For example, regex is removed from Pydantic V2: from pydantic import BaseModel, Field, PydanticUserError try: class Model(BaseModel): x: str = Field(regex='test') except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'removed-kwargs' JSON schema invalid type¶ This error is raised when Pydantic fails to generate a JSON schema for some CoreSchema. from pydantic import BaseModel, ImportString, PydanticUserError class Model(BaseModel): a: ImportString try: Model.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema() except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'invalid-for-json-schema' JSON schema already used¶ This error is raised when the JSON schema generator has already been used to generate a JSON schema. You must create a new instance to generate a new JSON schema. BaseModel instantiated¶ This error is raised when you instantiate BaseModel directly. Pydantic models should inherit from BaseModel. from pydantic import BaseModel, PydanticUserError try: BaseModel() except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'base-model-instantiated' Undefined annotation¶ This error is raised when handling undefined annotations during CoreSchema generation. from pydantic import BaseModel, PydanticUndefinedAnnotation class Model(BaseModel): a: 'B' # noqa F821 try: Model.model\\\\\\\\\\\\\\_rebuild() except PydanticUndefinedAnnotation as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'undefined-annotation' Schema for unknown type¶ This error is raised when Pydantic fails to generate a CoreSchema for some type. from pydantic import BaseModel, PydanticUserError try: class Model(BaseModel): x: 43 = 123 except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'schema-for-unknown-type' Import error¶ This error is raised when you try to import an object that was available in Pydantic V1, but has been removed in Pydantic V2. See the Migration Guide for more information. create\\\\\\\\\\\\\\_model field definitions¶ This error is raised when you provide field definitions input in create\\\\\\\\\\\\\\_model that is not valid. from pydantic import PydanticUserError, create\\\\\\\\\\\\\\_model try: create\\\\\\\\\\\\\\_model('FooModel', foo=(str, 'default value', 'more')) except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'create-model-field-definitions' create\\\\\\\\\\\\\\_model config base¶ This error is raised when you use both \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_base\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ together in create\\\\\\\\\\\\\\_model. from pydantic import BaseModel, ConfigDict, PydanticUserError, create\\\\\\\\\\\\\\_model try: config = ConfigDict(frozen=True) model = create\\\\\\\\\\\\\\_model( 'FooModel', foo=(int, ...), \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_=config, \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_base\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_=BaseModel ) except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'create-model-config-base' Validator with no fields¶ This error is raised when you use validator bare (with no fields). from pydantic import BaseModel, PydanticUserError, field\\\\\\\\\\\\\\_validator try: class Model(BaseModel): a: str @field\\\\\\\\\\\\\\_validator def checker(cls, v): return v except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'validator-no-fields' Validators should be used with fields and keyword arguments. from pydantic import BaseModel, field\\\\\\\\\\\\\\_validator class Model(BaseModel): a: str @field\\\\\\\\\\\\\\_validator('a') def checker(cls, v): return v Invalid validator fields¶ This error is raised when you use a validator with non-string fields. from pydantic import BaseModel, PydanticUserError, field\\\\\\\\\\\\\\_validator try: class Model(BaseModel): a: str b: str @field\\\\\\\\\\\\\\_validator(\\\\\\\\\\\\\\['a', 'b'\\\\\\\\\\\\\\]) def check\\\\\\\\\\\\\\_fields(cls, v): return v except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'validator-invalid-fields' Fields should be passed as separate string arguments: from pydantic import BaseModel, field\\\\\\\\\\\\\\_validator class Model(BaseModel): a: str b: str @field\\\\\\\\\\\\\\_validator('a', 'b') def check\\\\\\\\\\\\\\_fields(cls, v): return v Validator on instance method¶ This error is raised when you apply a validator on an instance method. from pydantic import BaseModel, PydanticUserError, field\\\\\\\\\\\\\\_validator try: class Model(BaseModel): a: int = 1 @field\\\\\\\\\\\\\\_validator('a') def check\\\\\\\\\\\\\\_a(self, values): return values except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'validator-instance-method' Root validator, pre, skip\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_failure¶ If you use @root\\\\\\\\\\\\\\_validator with pre=False (the default) you MUST specify skip\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_failure=True. The skip\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_failure=False option is no longer available. If you were not trying to set skip\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_failure=False, you can safely set skip\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_failure=True. If you do, this root validator will no longer be called if validation fails for any of the fields. Please see the Migration Guide for more details. model\\\\\\\\\\\\\\_serializer instance methods¶ @model\\\\\\\\\\\\\\_serializer must be applied to instance methods. This error is raised when you apply model\\\\\\\\\\\\\\_serializer on an instance method without self: from pydantic import BaseModel, PydanticUserError, model\\\\\\\\\\\\\\_serializer try: class MyModel(BaseModel): a: int @model\\\\\\\\\\\\\\_serializer def \\\\\\\\\\\\\\_serialize(slf, x, y, z): return slf except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'model-serializer-instance-method' Or on a class method: from pydantic import BaseModel, PydanticUserError, model\\\\\\\\\\\\\\_serializer try: class MyModel(BaseModel): a: int @model\\\\\\\\\\\\\\_serializer @classmethod def \\\\\\\\\\\\\\_serialize(self, x, y, z): return self except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'model-serializer-instance-method' validator, field, config, and info¶ The field and config parameters are not available in Pydantic V2. Please use the info parameter instead. You can access the configuration via info.config, but it is a dictionary instead of an object like it was in Pydantic V1. The field argument is no longer available. Pydantic V1 validator signature¶ This error is raised when you use an unsupported signature for Pydantic V1-style validator. import warnings from pydantic import BaseModel, PydanticUserError, validator warnings.filterwarnings('ignore', category=DeprecationWarning) try: class Model(BaseModel): a: int @validator('a') def check\\\\\\\\\\\\\\_a(cls, value, foo): return value except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'validator-v1-signature' Unrecognized field\\\\\\\\\\\\\\_validator signature¶ This error is raised when a field\\\\\\\\\\\\\\_validator or model\\\\\\\\\\\\\\_validator function has the wrong signature. from pydantic import BaseModel, PydanticUserError, field\\\\\\\\\\\\\\_validator try: class Model(BaseModel): a: str @field\\\\\\\\\\\\\\_validator('a') @classmethod def check\\\\\\\\\\\\\\_a(cls): return 'a' except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'validator-signature' Unrecognized field\\\\\\\\\\\\\\_serializer signature¶ This error is raised when the field\\\\\\\\\\\\\\_serializer function has the wrong signature. from pydantic import BaseModel, PydanticUserError, field\\\\\\\\\\\\\\_serializer try: class Model(BaseModel): x: int @field\\\\\\\\\\\\\\_serializer('x') def no\\\\\\\\\\\\\\_args(): return 'x' except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'field-serializer-signature' Valid serializer signatures are: from pydantic import model\\\\\\\\\\\\\\_serializer # an instance method with the default mode or \\\\\\\\\\\\\\`mode='plain'\\\\\\\\\\\\\\` @model\\\\\\\\\\\\\\_serializer('x') # or @serialize('x', mode='plain') def ser\\\\\\\\\\\\\\_x(self, value: Any, info: pydantic.FieldSerializationInfo): ... # a static method or free-standing function with the default mode or \\\\\\\\\\\\\\`mode='plain'\\\\\\\\\\\\\\` @model\\\\\\\\\\\\\\_serializer('x') # or @serialize('x', mode='plain') @staticmethod def ser\\\\\\\\\\\\\\_x(value: Any, info: pydantic.FieldSerializationInfo): ... # equivalent to def ser\\\\\\\\\\\\\\_x(value: Any, info: pydantic.FieldSerializationInfo): ... serializer('x')(ser\\\\\\\\\\\\\\_x) # an instance method with \\\\\\\\\\\\\\`mode='wrap'\\\\\\\\\\\\\\` @model\\\\\\\\\\\\\\_serializer('x', mode='wrap') def ser\\\\\\\\\\\\\\_x(self, value: Any, nxt: pydantic.SerializerFunctionWrapHandler, info: pydantic.FieldSerializationInfo): ... # a static method or free-standing function with \\\\\\\\\\\\\\`mode='wrap'\\\\\\\\\\\\\\` @model\\\\\\\\\\\\\\_serializer('x', mode='wrap') @staticmethod def ser\\\\\\\\\\\\\\_x(value: Any, nxt: pydantic.SerializerFunctionWrapHandler, info: pydantic.FieldSerializationInfo): ... # equivalent to def ser\\\\\\\\\\\\\\_x(value: Any, nxt: pydantic.SerializerFunctionWrapHandler, info: pydantic.FieldSerializationInfo): ... serializer('x')(ser\\\\\\\\\\\\\\_x) For all of these, you can also choose to omit the \\\\\\\\\\\\\\`info\\\\\\\\\\\\\\` argument, for example: @model\\\\\\\\\\\\\\_serializer('x') def ser\\\\\\\\\\\\\\_x(self, value: Any): ... @model\\\\\\\\\\\\\\_serializer('x', mode='wrap') def ser\\\\\\\\\\\\\\_x(self, value: Any, handler: pydantic.SerializerFunctionWrapHandler): ... Unrecognized model\\\\\\\\\\\\\\_serializer signature¶ This error is raised when the model\\\\\\\\\\\\\\_serializer function has the wrong signature. from pydantic import BaseModel, PydanticUserError, model\\\\\\\\\\\\\\_serializer try: class MyModel(BaseModel): a: int @model\\\\\\\\\\\\\\_serializer def \\\\\\\\\\\\\\_serialize(self, x, y, z): return self except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'model-serializer-signature' Multiple field serializers¶ This error is raised when multiple model\\\\\\\\\\\\\\_serializer functions are defined for a field. from pydantic import BaseModel, PydanticUserError, field\\\\\\\\\\\\\\_serializer try: class MyModel(BaseModel): x: int y: int @field\\\\\\\\\\\\\\_serializer('x', 'y') def serializer1(v): return f'{v:,}' @field\\\\\\\\\\\\\\_serializer('x') def serializer2(v): return v except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'multiple-field-serializers' Invalid annotated type¶ This error is raised when an annotation cannot annotate a type. from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, FutureDate, PydanticUserError try: class Model(BaseModel): foo: Annotated\\\\\\\\\\\\\\[str, FutureDate()\\\\\\\\\\\\\\] except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'invalid\\\\\\\\\\\\\\_annotated\\\\\\\\\\\\\\_type' config is unused with TypeAdapter¶ You will get this error if you try to pass config to TypeAdapter when the type is a type that has its own config that cannot be overridden (currently this is only BaseModel, TypedDict and dataclass): from typing\\\\\\\\\\\\\\_extensions import TypedDict from pydantic import ConfigDict, PydanticUserError, TypeAdapter class MyTypedDict(TypedDict): x: int try: TypeAdapter(MyTypedDict, config=ConfigDict(strict=True)) except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'type-adapter-config-unused' Instead you'll need to subclass the type and override or set the config on it: from typing\\\\\\\\\\\\\\_extensions import TypedDict from pydantic import ConfigDict, TypeAdapter class MyTypedDict(TypedDict): x: int # or \\\\\\\\\\\\\\`model\\\\\\\\\\\\\\_config = ...\\\\\\\\\\\\\\` for BaseModel \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ = ConfigDict(strict=True) TypeAdapter(MyTypedDict) # ok Cannot specify model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['extra'\\\\\\\\\\\\\\] with RootModel¶ Because RootModel is not capable of storing or even accepting extra fields during initialization, we raise an error if you try to specify a value for the config setting 'extra' when creating a subclass of RootModel: from pydantic import PydanticUserError, RootModel try: class MyRootModel(RootModel): model\\\\\\\\\\\\\\_config = {'extra': 'allow'} root: int except PydanticUserError as exc\\\\\\\\\\\\\\_info: assert exc\\\\\\\\\\\\\\_info.code == 'root-model-extra' Made with Material for MkDocs Insiders"
  },
  {
    "title": "Mac Address - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/pydantic_extra_types_mac_address/",
    "html": "Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Mac Address Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic Pydantic Core Pydantic Settings Pydantic Extra Types Color Country Payment Phone Numbers Routing Numbers Coordinate Mac Address Mac Address Made with Material for MkDocs Insiders"
  },
  {
    "title": "Phone Numbers - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/pydantic_extra_types_phone_numbers/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Phone Numbers Initializing search pydantic/pydantic Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic Pydantic Core Pydantic Settings Pydantic Extra Types Color Country Payment Phone Numbers Routing Numbers Coordinate Mac Address Page contents pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.phone\\\\\\\\\\\\\\_numbers PhoneNumber supported\\\\\\\\\\\\\\_regions supported\\\\\\\\\\\\\\_formats default\\\\\\\\\\\\\\_region\\\\\\\\\\\\\\_code phone\\\\\\\\\\\\\\_format min\\\\\\\\\\\\\\_length max\\\\\\\\\\\\\\_length Phone Numbers The pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.phone\\\\\\\\\\\\\\_numbers module provides the PhoneNumber data type. This class depends on the \\\\\\\\\\\\\\[phonenumbers\\\\\\\\\\\\\\] package, which is a Python port of Google's \\\\\\\\\\\\\\[libphonenumber\\\\\\\\\\\\\\]. PhoneNumber ¶ Bases: str A wrapper around phonenumbers package, which is a Python port of Google's libphonenumber. supported\\\\\\\\\\\\\\_regions instance-attribute class-attribute ¶ supported\\\\\\\\\\\\\\_regions: list\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] = sorted( phonenumbers.SUPPORTED\\\\\\\\\\\\\\_REGIONS ) The supported regions. supported\\\\\\\\\\\\\\_formats instance-attribute class-attribute ¶ supported\\\\\\\\\\\\\\_formats: list\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] = sorted( \\\\\\\\\\\\\\[ f for f in phonenumbers.PhoneNumberFormat.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.keys() if f.isupper() \\\\\\\\\\\\\\] ) The supported phone number formats. default\\\\\\\\\\\\\\_region\\\\\\\\\\\\\\_code class-attribute ¶ default\\\\\\\\\\\\\\_region\\\\\\\\\\\\\\_code: str | None = None The default region code to use when parsing phone numbers without an international prefix. phone\\\\\\\\\\\\\\_format instance-attribute class-attribute ¶ phone\\\\\\\\\\\\\\_format: str = 'RFC3966' The format of the phone number. min\\\\\\\\\\\\\\_length instance-attribute class-attribute ¶ min\\\\\\\\\\\\\\_length: int = 7 The minimum length of the phone number. max\\\\\\\\\\\\\\_length instance-attribute class-attribute ¶ max\\\\\\\\\\\\\\_length: int = 64 The maximum length of the phone number. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Coordinate - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/pydantic_extra_types_coordinate/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Coordinate Initializing search pydantic/pydantic Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic Pydantic Core Pydantic Settings Pydantic Extra Types Color Country Payment Phone Numbers Routing Numbers Coordinate Mac Address Page contents pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.coordinate Latitude Longitude Coordinate Coordinate The pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.coordinate module provides the Latitude, Longitude, and Coordinate data types. Latitude ¶ Bases: float Latitude value should be between -90 and 90, inclusive. from pydantic import BaseModel from pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.coordinate import Latitude class Location(BaseModel): latitude: Latitude location = Location(latitude=41.40338) print(location) #> latitude=41.40338 Longitude ¶ Bases: float Longitude value should be between -180 and 180, inclusive. from pydantic import BaseModel from pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.coordinate import Longitude class Location(BaseModel): longitude: Longitude location = Location(longitude=2.17403) print(location) #> longitude=2.17403 Coordinate dataclass ¶ Bases: \\\\\\\\\\\\\\_repr.Representation Coordinate parses Latitude and Longitude. You can use the Coordinate data type for storing coordinates. Coordinates can be defined using one of the following formats: Tuple: (Latitude, Longitude). For example: (41.40338, 2.17403). Coordinate instance: Coordinate(latitude=Latitude, longitude=Longitude). from pydantic import BaseModel from pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.coordinate import Coordinate class Location(BaseModel): coordinate: Coordinate location = Location(coordinate=(41.40338, 2.17403)) #> coordinate=Coordinate(latitude=41.40338, longitude=2.17403) Made with Material for MkDocs Insiders"
  },
  {
    "title": "Routing Numbers - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/pydantic_extra_types_routing_numbers/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Routing Numbers Initializing search pydantic/pydantic Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic Pydantic Core Pydantic Settings Pydantic Extra Types Color Country Payment Phone Numbers Routing Numbers Coordinate Mac Address Page contents pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.routing\\\\\\\\\\\\\\_number ABARoutingNumber Routing Numbers The pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.routing\\\\\\\\\\\\\\_number module provides the ABARoutingNumber data type. ABARoutingNumber ¶ ABARoutingNumber(routing\\\\\\\\\\\\\\_number) Bases: str The ABARoutingNumber data type is a string of 9 digits representing an ABA routing transit number. The algorithm used to validate the routing number is described in the ABA routing transit number Wikipedia article. from pydantic import BaseModel from pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.routing\\\\\\\\\\\\\\_number import ABARoutingNumber class BankAccount(BaseModel): routing\\\\\\\\\\\\\\_number: ABARoutingNumber account = BankAccount(routing\\\\\\\\\\\\\\_number='122105155') print(account) #> routing\\\\\\\\\\\\\\_number='122105155' Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/routing\\\\\\\\\\\\\\_number.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Payment - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/pydantic_extra_types_payment/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Payment Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic Pydantic Core Pydantic Settings Pydantic Extra Types Color Country Payment Phone Numbers Routing Numbers Coordinate Mac Address Page contents pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.payment PaymentCardBrand PaymentCardNumber strip\\\\\\\\\\\\\\_whitespace min\\\\\\\\\\\\\\_length max\\\\\\\\\\\\\\_length bin last4 brand masked validate() validate\\\\\\\\\\\\\\_digits() validate\\\\\\\\\\\\\\_luhn\\\\\\\\\\\\\\_check\\\\\\\\\\\\\\_digit() validate\\\\\\\\\\\\\\_brand() Payment The pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.payment module provides the PaymentCardNumber data type. PaymentCardBrand ¶ Bases: str, Enum Payment card brands supported by the PaymentCardNumber. PaymentCardNumber ¶ PaymentCardNumber(card\\\\\\\\\\\\\\_number) Bases: str A payment card number. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/payment.py strip\\\\\\\\\\\\\\_whitespace class-attribute ¶ strip\\\\\\\\\\\\\\_whitespace: bool = True Whether to strip whitespace from the input value. min\\\\\\\\\\\\\\_length class-attribute ¶ min\\\\\\\\\\\\\\_length: int = 12 The minimum length of the card number. max\\\\\\\\\\\\\\_length class-attribute ¶ max\\\\\\\\\\\\\\_length: int = 19 The maximum length of the card number. bin instance-attribute ¶ bin: str = card\\\\\\\\\\\\\\_number\\\\\\\\\\\\\\[:6\\\\\\\\\\\\\\] The first 6 digits of the card number. last4 instance-attribute ¶ last4: str = card\\\\\\\\\\\\\\_number\\\\\\\\\\\\\\[-4:\\\\\\\\\\\\\\] The last 4 digits of the card number. brand instance-attribute ¶ brand: PaymentCardBrand = self.validate\\\\\\\\\\\\\\_brand(card\\\\\\\\\\\\\\_number) The brand of the card. masked property ¶ masked: str The masked card number. validate classmethod ¶ validate(\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_input\\\\\\\\\\\\\\_value, \\\\\\\\\\\\\\_) Validate the PaymentCardNumber instance. Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_input\\\\\\\\\\\\\\_value str The input value to validate. required \\\\\\\\\\\\\\_ core\\\\\\\\\\\\\\_schema.ValidationInfo The validation info. required Returns: Type Description PaymentCardNumber The validated PaymentCardNumber instance. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/payment.py validate\\\\\\\\\\\\\\_digits classmethod ¶ validate\\\\\\\\\\\\\\_digits(card\\\\\\\\\\\\\\_number) Validate that the card number is all digits. Parameters: Name Type Description Default card\\\\\\\\\\\\\\_number str The card number to validate. required Raises: Type Description PydanticCustomError If the card number is not all digits. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/payment.py validate\\\\\\\\\\\\\\_luhn\\\\\\\\\\\\\\_check\\\\\\\\\\\\\\_digit classmethod ¶ validate\\\\\\\\\\\\\\_luhn\\\\\\\\\\\\\\_check\\\\\\\\\\\\\\_digit(card\\\\\\\\\\\\\\_number) Validate the payment card number. Based on the Luhn algorithm. Parameters: Name Type Description Default card\\\\\\\\\\\\\\_number str The card number to validate. required Returns: Type Description str The validated card number. Raises: Type Description PydanticCustomError If the card number is not valid. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/payment.py validate\\\\\\\\\\\\\\_brand staticmethod ¶ validate\\\\\\\\\\\\\\_brand(card\\\\\\\\\\\\\\_number) Validate length based on BIN for major brands. Parameters: Name Type Description Default card\\\\\\\\\\\\\\_number str The card number to validate. required Returns: Type Description PaymentCardBrand The validated card brand. Raises: Type Description PydanticCustomError If the card number is not valid. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/payment.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "pydantic_core.core_schema - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/pydantic_core_schema/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 pydantic\\\\\\\\\\\\\\_core.core\\\\\\\\\\\\\\_schema Type to start searching pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic Pydantic Core pydantic\\\\\\\\\\\\\\_core pydantic\\\\\\\\\\\\\\_core.core\\\\\\\\\\\\\\_schema Pydantic Settings Pydantic Extra Types Page contents pydantic\\\\\\\\\\\\\\_core.core\\\\\\\\\\\\\\_schema WhenUsed CoreConfig ValidationInfo context config mode data field\\\\\\\\\\\\\\_name simple\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema() plain\\\\\\\\\\\\\\_serializer\\\\\\\\\\\\\\_function\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema() wrap\\\\\\\\\\\\\\_serializer\\\\\\\\\\\\\\_function\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema() format\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema() to\\\\\\\\\\\\\\_string\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema() model\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema() computed\\\\\\\\\\\\\\_field() any\\\\\\\\\\\\\\_schema() none\\\\\\\\\\\\\\_schema() bool\\\\\\\\\\\\\\_schema() int\\\\\\\\\\\\\\_schema() float\\\\\\\\\\\\\\_schema() decimal\\\\\\\\\\\\\\_schema() str\\\\\\\\\\\\\\_schema() bytes\\\\\\\\\\\\\\_schema() date\\\\\\\\\\\\\\_schema() time\\\\\\\\\\\\\\_schema() datetime\\\\\\\\\\\\\\_schema() timedelta\\\\\\\\\\\\\\_schema() literal\\\\\\\\\\\\\\_schema() is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_schema() is\\\\\\\\\\\\\\_subclass\\\\\\\\\\\\\\_schema() callable\\\\\\\\\\\\\\_schema() list\\\\\\\\\\\\\\_schema() tuple\\\\\\\\\\\\\\_positional\\\\\\\\\\\\\\_schema() tuple\\\\\\\\\\\\\\_variable\\\\\\\\\\\\\\_schema() set\\\\\\\\\\\\\\_schema() frozenset\\\\\\\\\\\\\\_schema() generator\\\\\\\\\\\\\\_schema() dict\\\\\\\\\\\\\\_schema() no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_before\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function() with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_before\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function() no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function() with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function() no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function() with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function() no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function() with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function() with\\\\\\\\\\\\\\_default\\\\\\\\\\\\\\_schema() nullable\\\\\\\\\\\\\\_schema() union\\\\\\\\\\\\\\_schema() tagged\\\\\\\\\\\\\\_union\\\\\\\\\\\\\\_schema() chain\\\\\\\\\\\\\\_schema() lax\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_strict\\\\\\\\\\\\\\_schema() json\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_python\\\\\\\\\\\\\\_schema() typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field() typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema() model\\\\\\\\\\\\\\_field() model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_schema() model\\\\\\\\\\\\\\_schema() dataclass\\\\\\\\\\\\\\_field() dataclass\\\\\\\\\\\\\\_args\\\\\\\\\\\\\\_schema() dataclass\\\\\\\\\\\\\\_schema() arguments\\\\\\\\\\\\\\_parameter() arguments\\\\\\\\\\\\\\_schema() call\\\\\\\\\\\\\\_schema() custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_schema() json\\\\\\\\\\\\\\_schema() url\\\\\\\\\\\\\\_schema() multi\\\\\\\\\\\\\\_host\\\\\\\\\\\\\\_url\\\\\\\\\\\\\\_schema() definitions\\\\\\\\\\\\\\_schema() definition\\\\\\\\\\\\\\_reference\\\\\\\\\\\\\\_schema() pydantic\\\\\\\\\\\\\\_core.core\\\\\\\\\\\\\\_schema This module contains definitions to build schemas which pydantic\\\\\\\\\\\\\\_core can validate and serialize. WhenUsed module-attribute ¶ WhenUsed = Literal\\\\\\\\\\\\\\[ \"always\", \"unless-none\", \"json\", \"json-unless-none\" \\\\\\\\\\\\\\] Values have the following meanings: 'always' means always use 'unless-none' means use unless the value is None 'json' means use when serializing to JSON 'json-unless-none' means use when serializing to JSON and the value is not None CoreConfig ¶ Bases: TypedDict Base class for schema configuration options. Attributes: Name Type Description title str The name of the configuration. strict bool Whether the configuration should strictly adhere to specified rules. extra\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_behavior ExtraBehavior The behavior for handling extra fields. typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_total bool Whether the TypedDict should be considered total. Default is True. from\\\\\\\\\\\\\\_attributes bool Whether to use attributes for models, dataclasses, and tagged union keys. loc\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_alias bool Whether to use the used alias (or first alias for \"field required\" errors) instead of field\\\\\\\\\\\\\\_names to construct error locs. Default is True. revalidate\\\\\\\\\\\\\\_instances Literal\\\\\\\\\\\\\\['always', 'never', 'subclass-instances'\\\\\\\\\\\\\\] Whether instances of models and dataclasses should re-validate. Default is 'never'. validate\\\\\\\\\\\\\\_default bool Whether to validate default values during validation. Default is False. populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name bool Whether an aliased field may be populated by its name as given by the model attribute, as well as the alias. (Replaces 'allow\\\\\\\\\\\\\\_population\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_name' in Pydantic v1.) Default is False. str\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_length int The maximum length for string fields. str\\\\\\\\\\\\\\_min\\\\\\\\\\\\\\_length int The minimum length for string fields. str\\\\\\\\\\\\\\_strip\\\\\\\\\\\\\\_whitespace bool Whether to strip whitespace from string fields. str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_lower bool Whether to convert string fields to lowercase. str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_upper bool Whether to convert string fields to uppercase. allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan bool Whether to allow infinity and NaN values for float fields. Default is True. ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_timedelta Literal\\\\\\\\\\\\\\['iso8601', 'float'\\\\\\\\\\\\\\] The serialization option for timedelta values. Default is 'iso8601'. ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_bytes Literal\\\\\\\\\\\\\\['utf8', 'base64', 'hex'\\\\\\\\\\\\\\] The serialization option for bytes values. Default is 'utf8'. ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan Literal\\\\\\\\\\\\\\['null', 'constants'\\\\\\\\\\\\\\] The serialization option for infinity and NaN values in float fields. Default is 'null'. hide\\\\\\\\\\\\\\_input\\\\\\\\\\\\\\_in\\\\\\\\\\\\\\_errors bool Whether to hide input data from ValidationError representation. validation\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_cause bool Whether to add user-python excs to the cause of a ValidationError. Requires exceptiongroup backport pre Python 3.11. coerce\\\\\\\\\\\\\\_numbers\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_str bool Whether to enable coercion of any Number type to str (not applicable in strict mode). regex\\\\\\\\\\\\\\_engine Literal\\\\\\\\\\\\\\['rust-regex', 'python-re'\\\\\\\\\\\\\\] The regex engine to use for regex pattern validation. Default is 'rust-regex'. See StringSchema. ValidationInfo ¶ Bases: Protocol Argument passed to validation functions. context property ¶ context: Any | None Current validation context. config property ¶ config: CoreConfig | None The CoreConfig that applies to this validation. mode property ¶ mode: Literal\\\\\\\\\\\\\\['python', 'json'\\\\\\\\\\\\\\] The type of input data we are currently validating data property ¶ data: Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] The data being validated for this model. field\\\\\\\\\\\\\\_name property ¶ field\\\\\\\\\\\\\\_name: str | None The name of the current field being validated if this validator is attached to a model field. simple\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema ¶ simple\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema(type) Returns a schema for serialization with a custom type. Parameters: Name Type Description Default type ExpectedSerializationTypes The type to use for serialization required Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py plain\\\\\\\\\\\\\\_serializer\\\\\\\\\\\\\\_function\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema ¶ plain\\\\\\\\\\\\\\_serializer\\\\\\\\\\\\\\_function\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema( function, \\\\\\\\\\\\\\*, is\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_serializer=None, info\\\\\\\\\\\\\\_arg=None, return\\\\\\\\\\\\\\_schema=None, when\\\\\\\\\\\\\\_used=\"always\" ) Returns a schema for serialization with a function, can be either a \"general\" or \"field\" function. Parameters: Name Type Description Default function SerializerFunction The function to use for serialization required is\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_serializer bool | None Whether the serializer is for a field, e.g. takes model as the first argument, and info includes field\\\\\\\\\\\\\\_name None info\\\\\\\\\\\\\\_arg bool | None Whether the function takes an \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_info argument None return\\\\\\\\\\\\\\_schema CoreSchema | None Schema to use for serializing return value None when\\\\\\\\\\\\\\_used WhenUsed When the function should be called 'always' Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py wrap\\\\\\\\\\\\\\_serializer\\\\\\\\\\\\\\_function\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema ¶ wrap\\\\\\\\\\\\\\_serializer\\\\\\\\\\\\\\_function\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema( function, \\\\\\\\\\\\\\*, is\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_serializer=None, info\\\\\\\\\\\\\\_arg=None, schema=None, return\\\\\\\\\\\\\\_schema=None, when\\\\\\\\\\\\\\_used=\"always\" ) Returns a schema for serialization with a wrap function, can be either a \"general\" or \"field\" function. Parameters: Name Type Description Default function WrapSerializerFunction The function to use for serialization required is\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_serializer bool | None Whether the serializer is for a field, e.g. takes model as the first argument, and info includes field\\\\\\\\\\\\\\_name None info\\\\\\\\\\\\\\_arg bool | None Whether the function takes an \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_info argument None schema CoreSchema | None The schema to use for the inner serialization None return\\\\\\\\\\\\\\_schema CoreSchema | None Schema to use for serializing return value None when\\\\\\\\\\\\\\_used WhenUsed When the function should be called 'always' Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py format\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema ¶ format\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema( formatting\\\\\\\\\\\\\\_string, \\\\\\\\\\\\\\*, when\\\\\\\\\\\\\\_used=\"json-unless-none\" ) Returns a schema for serialization using python's format method. Parameters: Name Type Description Default formatting\\\\\\\\\\\\\\_string str String defining the format to use required when\\\\\\\\\\\\\\_used WhenUsed Same meaning as for \\\\\\\\\\\\\\[general\\\\\\\\\\\\\\_function\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\], but with a different default 'json-unless-none' Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py to\\\\\\\\\\\\\\_string\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema ¶ to\\\\\\\\\\\\\\_string\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema(\\\\\\\\\\\\\\*, when\\\\\\\\\\\\\\_used='json-unless-none') Returns a schema for serialization using python's str() / \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_str\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method. Parameters: Name Type Description Default when\\\\\\\\\\\\\\_used WhenUsed Same meaning as for \\\\\\\\\\\\\\[general\\\\\\\\\\\\\\_function\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\], but with a different default 'json-unless-none' Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py model\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema ¶ model\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema(cls, schema) Returns a schema for serialization using a model. Parameters: Name Type Description Default cls Type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] The expected class type, used to generate warnings if the wrong type is passed required schema CoreSchema Internal schema to use to serialize the model dict required Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py computed\\\\\\\\\\\\\\_field ¶ computed\\\\\\\\\\\\\\_field( property\\\\\\\\\\\\\\_name, return\\\\\\\\\\\\\\_schema, \\\\\\\\\\\\\\*, alias=None, metadata=None ) ComputedFields are properties of a model or dataclass that are included in serialization. Parameters: Name Type Description Default property\\\\\\\\\\\\\\_name str The name of the property on the model or dataclass required return\\\\\\\\\\\\\\_schema CoreSchema The schema used for the type returned by the computed field required alias str | None The name to use in the serialized output None metadata Any Any other information you want to include with the schema, not used by pydantic-core None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py any\\\\\\\\\\\\\\_schema ¶ any\\\\\\\\\\\\\\_schema(\\\\\\\\\\\\\\*, ref=None, metadata=None, serialization=None) Returns a schema that matches any value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.any\\\\\\\\\\\\\\_schema() v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(1) == 1 Parameters: Name Type Description Default ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py none\\\\\\\\\\\\\\_schema ¶ none\\\\\\\\\\\\\\_schema(\\\\\\\\\\\\\\*, ref=None, metadata=None, serialization=None) Returns a schema that matches a None value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.none\\\\\\\\\\\\\\_schema() v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(None) is None Parameters: Name Type Description Default ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py bool\\\\\\\\\\\\\\_schema ¶ bool\\\\\\\\\\\\\\_schema( strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a bool value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.bool\\\\\\\\\\\\\\_schema() v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python('True') is True Parameters: Name Type Description Default strict bool | None Whether the value should be a bool or a value that can be converted to a bool None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py int\\\\\\\\\\\\\\_schema ¶ int\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\*, multiple\\\\\\\\\\\\\\_of=None, le=None, ge=None, lt=None, gt=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a int value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(multiple\\\\\\\\\\\\\\_of=2, le=6, ge=2) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python('4') == 4 Parameters: Name Type Description Default multiple\\\\\\\\\\\\\\_of int | None The value must be a multiple of this number None le int | None The value must be less than or equal to this number None ge int | None The value must be greater than or equal to this number None lt int | None The value must be strictly less than this number None gt int | None The value must be strictly greater than this number None strict bool | None Whether the value should be a int or a value that can be converted to a int None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py float\\\\\\\\\\\\\\_schema ¶ float\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\*, allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan=None, multiple\\\\\\\\\\\\\\_of=None, le=None, ge=None, lt=None, gt=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a float value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.float\\\\\\\\\\\\\\_schema(le=0.8, ge=0.2) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python('0.5') == 0.5 Parameters: Name Type Description Default allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan bool | None Whether to allow inf and nan values None multiple\\\\\\\\\\\\\\_of float | None The value must be a multiple of this number None le float | None The value must be less than or equal to this number None ge float | None The value must be greater than or equal to this number None lt float | None The value must be strictly less than this number None gt float | None The value must be strictly greater than this number None strict bool | None Whether the value should be a float or a value that can be converted to a float None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py decimal\\\\\\\\\\\\\\_schema ¶ decimal\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\*, allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan=None, multiple\\\\\\\\\\\\\\_of=None, le=None, ge=None, lt=None, gt=None, max\\\\\\\\\\\\\\_digits=None, decimal\\\\\\\\\\\\\\_places=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a decimal value, e.g.: from decimal import Decimal from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.decimal\\\\\\\\\\\\\\_schema(le=0.8, ge=0.2) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python('0.5') == Decimal('0.5') Parameters: Name Type Description Default allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan bool Whether to allow inf and nan values None multiple\\\\\\\\\\\\\\_of Decimal | None The value must be a multiple of this number None le Decimal | None The value must be less than or equal to this number None ge Decimal | None The value must be greater than or equal to this number None lt Decimal | None The value must be strictly less than this number None gt Decimal | None The value must be strictly greater than this number None max\\\\\\\\\\\\\\_digits int | None The maximum number of decimal digits allowed None decimal\\\\\\\\\\\\\\_places int | None The maximum number of decimal places allowed None strict bool | None Whether the value should be a float or a value that can be converted to a float None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py str\\\\\\\\\\\\\\_schema ¶ str\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\*, pattern=None, max\\\\\\\\\\\\\\_length=None, min\\\\\\\\\\\\\\_length=None, strip\\\\\\\\\\\\\\_whitespace=None, to\\\\\\\\\\\\\\_lower=None, to\\\\\\\\\\\\\\_upper=None, regex\\\\\\\\\\\\\\_engine=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a string value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(max\\\\\\\\\\\\\\_length=10, min\\\\\\\\\\\\\\_length=2) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python('hello') == 'hello' Parameters: Name Type Description Default pattern str | None A regex pattern that the value must match None max\\\\\\\\\\\\\\_length int | None The value must be at most this length None min\\\\\\\\\\\\\\_length int | None The value must be at least this length None strip\\\\\\\\\\\\\\_whitespace bool | None Whether to strip whitespace from the value None to\\\\\\\\\\\\\\_lower bool | None Whether to convert the value to lowercase None to\\\\\\\\\\\\\\_upper bool | None Whether to convert the value to uppercase None regex\\\\\\\\\\\\\\_engine Literal\\\\\\\\\\\\\\['rust-regex', 'python-re'\\\\\\\\\\\\\\] | None The regex engine to use for pattern validation. Default is 'rust-regex'. - rust-regex uses the regex Rust crate, which is non-backtracking and therefore more DDoS resistant, but does not support all regex features. - python-re use the re module, which supports all regex features, but may be slower. None strict bool | None Whether the value should be a string or a value that can be converted to a string None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py bytes\\\\\\\\\\\\\\_schema ¶ bytes\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\*, max\\\\\\\\\\\\\\_length=None, min\\\\\\\\\\\\\\_length=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a bytes value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.bytes\\\\\\\\\\\\\\_schema(max\\\\\\\\\\\\\\_length=10, min\\\\\\\\\\\\\\_length=2) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(b'hello') == b'hello' Parameters: Name Type Description Default max\\\\\\\\\\\\\\_length int | None The value must be at most this length None min\\\\\\\\\\\\\\_length int | None The value must be at least this length None strict bool | None Whether the value should be a bytes or a value that can be converted to a bytes None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py date\\\\\\\\\\\\\\_schema ¶ date\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\*, strict=None, le=None, ge=None, lt=None, gt=None, now\\\\\\\\\\\\\\_op=None, now\\\\\\\\\\\\\\_utc\\\\\\\\\\\\\\_offset=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a date value, e.g.: from datetime import date from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.date\\\\\\\\\\\\\\_schema(le=date(2020, 1, 1), ge=date(2019, 1, 1)) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(date(2019, 6, 1)) == date(2019, 6, 1) Parameters: Name Type Description Default strict bool | None Whether the value should be a date or a value that can be converted to a date None le date | None The value must be less than or equal to this date None ge date | None The value must be greater than or equal to this date None lt date | None The value must be strictly less than this date None gt date | None The value must be strictly greater than this date None now\\\\\\\\\\\\\\_op Literal\\\\\\\\\\\\\\['past', 'future'\\\\\\\\\\\\\\] | None The value must be in the past or future relative to the current date None now\\\\\\\\\\\\\\_utc\\\\\\\\\\\\\\_offset int | None The value must be in the past or future relative to the current date with this utc offset None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py time\\\\\\\\\\\\\\_schema ¶ time\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\*, strict=None, le=None, ge=None, lt=None, gt=None, tz\\\\\\\\\\\\\\_constraint=None, microseconds\\\\\\\\\\\\\\_precision=\"truncate\", ref=None, metadata=None, serialization=None ) Returns a schema that matches a time value, e.g.: from datetime import time from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.time\\\\\\\\\\\\\\_schema(le=time(12, 0, 0), ge=time(6, 0, 0)) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(time(9, 0, 0)) == time(9, 0, 0) Parameters: Name Type Description Default strict bool | None Whether the value should be a time or a value that can be converted to a time None le time | None The value must be less than or equal to this time None ge time | None The value must be greater than or equal to this time None lt time | None The value must be strictly less than this time None gt time | None The value must be strictly greater than this time None tz\\\\\\\\\\\\\\_constraint Literal\\\\\\\\\\\\\\['aware', 'naive'\\\\\\\\\\\\\\] | int | None The value must be timezone aware or naive, or an int to indicate required tz offset None microseconds\\\\\\\\\\\\\\_precision Literal\\\\\\\\\\\\\\['truncate', 'error'\\\\\\\\\\\\\\] The behavior when seconds have more than 6 digits or microseconds is too large 'truncate' ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py datetime\\\\\\\\\\\\\\_schema ¶ datetime\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\*, strict=None, le=None, ge=None, lt=None, gt=None, now\\\\\\\\\\\\\\_op=None, tz\\\\\\\\\\\\\\_constraint=None, now\\\\\\\\\\\\\\_utc\\\\\\\\\\\\\\_offset=None, microseconds\\\\\\\\\\\\\\_precision=\"truncate\", ref=None, metadata=None, serialization=None ) Returns a schema that matches a datetime value, e.g.: from datetime import datetime from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.datetime\\\\\\\\\\\\\\_schema() v = SchemaValidator(schema) now = datetime.now() assert v.validate\\\\\\\\\\\\\\_python(str(now)) == now Parameters: Name Type Description Default strict bool | None Whether the value should be a datetime or a value that can be converted to a datetime None le datetime | None The value must be less than or equal to this datetime None ge datetime | None The value must be greater than or equal to this datetime None lt datetime | None The value must be strictly less than this datetime None gt datetime | None The value must be strictly greater than this datetime None now\\\\\\\\\\\\\\_op Literal\\\\\\\\\\\\\\['past', 'future'\\\\\\\\\\\\\\] | None The value must be in the past or future relative to the current datetime None tz\\\\\\\\\\\\\\_constraint Literal\\\\\\\\\\\\\\['aware', 'naive'\\\\\\\\\\\\\\] | int | None The value must be timezone aware or naive, or an int to indicate required tz offset TODO: use of a tzinfo where offset changes based on the datetime is not yet supported None now\\\\\\\\\\\\\\_utc\\\\\\\\\\\\\\_offset int | None The value must be in the past or future relative to the current datetime with this utc offset None microseconds\\\\\\\\\\\\\\_precision Literal\\\\\\\\\\\\\\['truncate', 'error'\\\\\\\\\\\\\\] The behavior when seconds have more than 6 digits or microseconds is too large 'truncate' ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py timedelta\\\\\\\\\\\\\\_schema ¶ timedelta\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\*, strict=None, le=None, ge=None, lt=None, gt=None, microseconds\\\\\\\\\\\\\\_precision=\"truncate\", ref=None, metadata=None, serialization=None ) Returns a schema that matches a timedelta value, e.g.: from datetime import timedelta from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.timedelta\\\\\\\\\\\\\\_schema(le=timedelta(days=1), ge=timedelta(days=0)) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(timedelta(hours=12)) == timedelta(hours=12) Parameters: Name Type Description Default strict bool | None Whether the value should be a timedelta or a value that can be converted to a timedelta None le timedelta | None The value must be less than or equal to this timedelta None ge timedelta | None The value must be greater than or equal to this timedelta None lt timedelta | None The value must be strictly less than this timedelta None gt timedelta | None The value must be strictly greater than this timedelta None microseconds\\\\\\\\\\\\\\_precision Literal\\\\\\\\\\\\\\['truncate', 'error'\\\\\\\\\\\\\\] The behavior when seconds have more than 6 digits or microseconds is too large 'truncate' ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py literal\\\\\\\\\\\\\\_schema ¶ literal\\\\\\\\\\\\\\_schema( expected, \\\\\\\\\\\\\\*, ref=None, metadata=None, serialization=None ) Returns a schema that matches a literal value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.literal\\\\\\\\\\\\\\_schema(\\\\\\\\\\\\\\['hello', 'world'\\\\\\\\\\\\\\]) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python('hello') == 'hello' Parameters: Name Type Description Default expected list\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] The value must be one of these values required ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_schema ¶ is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_schema( cls, \\\\\\\\\\\\\\*, cls\\\\\\\\\\\\\\_repr=None, ref=None, metadata=None, serialization=None ) Returns a schema that checks if a value is an instance of a class, equivalent to python's isinstnace method, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema class A: pass schema = core\\\\\\\\\\\\\\_schema.is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_schema(cls=A) v = SchemaValidator(schema) v.validate\\\\\\\\\\\\\\_python(A()) Parameters: Name Type Description Default cls Any The value must be an instance of this class required cls\\\\\\\\\\\\\\_repr str | None If provided this string is used in the validator name instead of repr(cls) None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py is\\\\\\\\\\\\\\_subclass\\\\\\\\\\\\\\_schema ¶ is\\\\\\\\\\\\\\_subclass\\\\\\\\\\\\\\_schema( cls, \\\\\\\\\\\\\\*, cls\\\\\\\\\\\\\\_repr=None, ref=None, metadata=None, serialization=None ) Returns a schema that checks if a value is a subtype of a class, equivalent to python's issubclass method, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema class A: pass class B(A): pass schema = core\\\\\\\\\\\\\\_schema.is\\\\\\\\\\\\\\_subclass\\\\\\\\\\\\\\_schema(cls=A) v = SchemaValidator(schema) v.validate\\\\\\\\\\\\\\_python(B) Parameters: Name Type Description Default cls Type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] The value must be a subclass of this class required cls\\\\\\\\\\\\\\_repr str | None If provided this string is used in the validator name instead of repr(cls) None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py callable\\\\\\\\\\\\\\_schema ¶ callable\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\*, ref=None, metadata=None, serialization=None ) Returns a schema that checks if a value is callable, equivalent to python's callable method, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.callable\\\\\\\\\\\\\\_schema() v = SchemaValidator(schema) v.validate\\\\\\\\\\\\\\_python(min) Parameters: Name Type Description Default ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py list\\\\\\\\\\\\\\_schema ¶ list\\\\\\\\\\\\\\_schema( items\\\\\\\\\\\\\\_schema=None, \\\\\\\\\\\\\\*, min\\\\\\\\\\\\\\_length=None, max\\\\\\\\\\\\\\_length=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a list value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.list\\\\\\\\\\\\\\_schema(core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(), min\\\\\\\\\\\\\\_length=0, max\\\\\\\\\\\\\\_length=10) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(\\\\\\\\\\\\\\['4'\\\\\\\\\\\\\\]) == \\\\\\\\\\\\\\[4\\\\\\\\\\\\\\] Parameters: Name Type Description Default items\\\\\\\\\\\\\\_schema CoreSchema | None The value must be a list of items that match this schema None min\\\\\\\\\\\\\\_length int | None The value must be a list with at least this many items None max\\\\\\\\\\\\\\_length int | None The value must be a list with at most this many items None strict bool | None The value must be a list with exactly this many items None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization IncExSeqOrElseSerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py tuple\\\\\\\\\\\\\\_positional\\\\\\\\\\\\\\_schema ¶ tuple\\\\\\\\\\\\\\_positional\\\\\\\\\\\\\\_schema( items\\\\\\\\\\\\\\_schema, \\\\\\\\\\\\\\*, extras\\\\\\\\\\\\\\_schema=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a tuple of schemas, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.tuple\\\\\\\\\\\\\\_positional\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\[core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(), core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema()\\\\\\\\\\\\\\] ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python((1, 'hello')) == (1, 'hello') Parameters: Name Type Description Default items\\\\\\\\\\\\\\_schema list\\\\\\\\\\\\\\[CoreSchema\\\\\\\\\\\\\\] The value must be a tuple with items that match these schemas required extras\\\\\\\\\\\\\\_schema CoreSchema | None The value must be a tuple with items that match this schema This was inspired by JSON schema's prefixItems and items fields. In python's typing.Tuple, you can't specify a type for \"extra\" items -- they must all be the same type if the length is variable. So this field won't be set from a typing.Tuple annotation on a pydantic model. None strict bool | None The value must be a tuple with exactly this many items None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization IncExSeqOrElseSerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py tuple\\\\\\\\\\\\\\_variable\\\\\\\\\\\\\\_schema ¶ tuple\\\\\\\\\\\\\\_variable\\\\\\\\\\\\\\_schema( items\\\\\\\\\\\\\\_schema=None, \\\\\\\\\\\\\\*, min\\\\\\\\\\\\\\_length=None, max\\\\\\\\\\\\\\_length=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a tuple of a given schema, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.tuple\\\\\\\\\\\\\\_variable\\\\\\\\\\\\\\_schema( items\\\\\\\\\\\\\\_schema=core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(), min\\\\\\\\\\\\\\_length=0, max\\\\\\\\\\\\\\_length=10 ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(('1', 2, 3)) == (1, 2, 3) Parameters: Name Type Description Default items\\\\\\\\\\\\\\_schema CoreSchema | None The value must be a tuple with items that match this schema None min\\\\\\\\\\\\\\_length int | None The value must be a tuple with at least this many items None max\\\\\\\\\\\\\\_length int | None The value must be a tuple with at most this many items None strict bool | None The value must be a tuple with exactly this many items None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization IncExSeqOrElseSerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py set\\\\\\\\\\\\\\_schema ¶ set\\\\\\\\\\\\\\_schema( items\\\\\\\\\\\\\\_schema=None, \\\\\\\\\\\\\\*, min\\\\\\\\\\\\\\_length=None, max\\\\\\\\\\\\\\_length=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a set of a given schema, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.set\\\\\\\\\\\\\\_schema( items\\\\\\\\\\\\\\_schema=core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(), min\\\\\\\\\\\\\\_length=0, max\\\\\\\\\\\\\\_length=10 ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python({1, '2', 3}) == {1, 2, 3} Parameters: Name Type Description Default items\\\\\\\\\\\\\\_schema CoreSchema | None The value must be a set with items that match this schema None min\\\\\\\\\\\\\\_length int | None The value must be a set with at least this many items None max\\\\\\\\\\\\\\_length int | None The value must be a set with at most this many items None strict bool | None The value must be a set with exactly this many items None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py frozenset\\\\\\\\\\\\\\_schema ¶ frozenset\\\\\\\\\\\\\\_schema( items\\\\\\\\\\\\\\_schema=None, \\\\\\\\\\\\\\*, min\\\\\\\\\\\\\\_length=None, max\\\\\\\\\\\\\\_length=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a frozenset of a given schema, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.frozenset\\\\\\\\\\\\\\_schema( items\\\\\\\\\\\\\\_schema=core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(), min\\\\\\\\\\\\\\_length=0, max\\\\\\\\\\\\\\_length=10 ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(frozenset(range(3))) == frozenset({0, 1, 2}) Parameters: Name Type Description Default items\\\\\\\\\\\\\\_schema CoreSchema | None The value must be a frozenset with items that match this schema None min\\\\\\\\\\\\\\_length int | None The value must be a frozenset with at least this many items None max\\\\\\\\\\\\\\_length int | None The value must be a frozenset with at most this many items None strict bool | None The value must be a frozenset with exactly this many items None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py generator\\\\\\\\\\\\\\_schema ¶ generator\\\\\\\\\\\\\\_schema( items\\\\\\\\\\\\\\_schema=None, \\\\\\\\\\\\\\*, min\\\\\\\\\\\\\\_length=None, max\\\\\\\\\\\\\\_length=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a generator value, e.g.: from typing import Iterator from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema def gen() -> Iterator\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]: yield 1 schema = core\\\\\\\\\\\\\\_schema.generator\\\\\\\\\\\\\\_schema(items\\\\\\\\\\\\\\_schema=core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema()) v = SchemaValidator(schema) v.validate\\\\\\\\\\\\\\_python(gen()) Unlike other types, validated generators do not raise ValidationErrors eagerly, but instead will raise a ValidationError when a violating value is actually read from the generator. This is to ensure that \"validated\" generators retain the benefit of lazy evaluation. Parameters: Name Type Description Default items\\\\\\\\\\\\\\_schema CoreSchema | None The value must be a generator with items that match this schema None min\\\\\\\\\\\\\\_length int | None The value must be a generator that yields at least this many items None max\\\\\\\\\\\\\\_length int | None The value must be a generator that yields at most this many items None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization IncExSeqOrElseSerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py dict\\\\\\\\\\\\\\_schema ¶ dict\\\\\\\\\\\\\\_schema( keys\\\\\\\\\\\\\\_schema=None, values\\\\\\\\\\\\\\_schema=None, \\\\\\\\\\\\\\*, min\\\\\\\\\\\\\\_length=None, max\\\\\\\\\\\\\\_length=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a dict value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.dict\\\\\\\\\\\\\\_schema( keys\\\\\\\\\\\\\\_schema=core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(), values\\\\\\\\\\\\\\_schema=core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema() ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python({'a': '1', 'b': 2}) == {'a': 1, 'b': 2} Parameters: Name Type Description Default keys\\\\\\\\\\\\\\_schema CoreSchema | None The value must be a dict with keys that match this schema None values\\\\\\\\\\\\\\_schema CoreSchema | None The value must be a dict with values that match this schema None min\\\\\\\\\\\\\\_length int | None The value must be a dict with at least this many items None max\\\\\\\\\\\\\\_length int | None The value must be a dict with at most this many items None strict bool | None Whether the keys and values should be validated with strict mode None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_before\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function ¶ no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_before\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( function, schema, \\\\\\\\\\\\\\*, ref=None, metadata=None, serialization=None ) Returns a schema that calls a validator function before validating, no info argument is provided, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema def fn(v: bytes) -> str: return v.decode() + 'world' func\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_before\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( function=fn, schema=core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema() ) schema = core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema({'a': core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field(func\\\\\\\\\\\\\\_schema)}) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python({'a': b'hello '}) == {'a': 'hello world'} Parameters: Name Type Description Default function NoInfoValidatorFunction The validator function to call required schema CoreSchema The schema to validate the output of the validator function required ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_before\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function ¶ with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_before\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( function, schema, \\\\\\\\\\\\\\*, field\\\\\\\\\\\\\\_name=None, ref=None, metadata=None, serialization=None ) Returns a schema that calls a validator function before validation, the function is called with an info argument, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema def fn(v: bytes, info: core\\\\\\\\\\\\\\_schema.ValidationInfo) -> str: assert info.data is not None assert info.field\\\\\\\\\\\\\\_name is not None return v.decode() + 'world' func\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_before\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( function=fn, schema=core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(), field\\\\\\\\\\\\\\_name='a' ) schema = core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema({'a': core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field(func\\\\\\\\\\\\\\_schema)}) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python({'a': b'hello '}) == {'a': 'hello world'} Parameters: Name Type Description Default function WithInfoValidatorFunction The validator function to call required field\\\\\\\\\\\\\\_name str | None The name of the field None schema CoreSchema The schema to validate the output of the validator function required ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function ¶ no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( function, schema, \\\\\\\\\\\\\\*, ref=None, metadata=None, serialization=None ) Returns a schema that calls a validator function after validating, no info argument is provided, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema def fn(v: str) -> str: return v + 'world' func\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function(fn, core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema()) schema = core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema({'a': core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field(func\\\\\\\\\\\\\\_schema)}) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python({'a': b'hello '}) == {'a': 'hello world'} Parameters: Name Type Description Default function NoInfoValidatorFunction The validator function to call after the schema is validated required schema CoreSchema The schema to validate before the validator function required ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function ¶ with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( function, schema, \\\\\\\\\\\\\\*, field\\\\\\\\\\\\\\_name=None, ref=None, metadata=None, serialization=None ) Returns a schema that calls a validator function after validation, the function is called with an info argument, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema def fn(v: str, info: core\\\\\\\\\\\\\\_schema.ValidationInfo) -> str: assert info.data is not None assert info.field\\\\\\\\\\\\\\_name is not None return v + 'world' func\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( function=fn, schema=core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(), field\\\\\\\\\\\\\\_name='a' ) schema = core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema({'a': core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field(func\\\\\\\\\\\\\\_schema)}) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python({'a': b'hello '}) == {'a': 'hello world'} Parameters: Name Type Description Default function WithInfoValidatorFunction The validator function to call after the schema is validated required schema CoreSchema The schema to validate before the validator function required field\\\\\\\\\\\\\\_name str | None The name of the field this validators is applied to, if any None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function ¶ no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( function, schema, \\\\\\\\\\\\\\*, ref=None, metadata=None, serialization=None ) Returns a schema which calls a function with a validator callable argument which can optionally be used to call inner validation with the function logic, this is much like the \"onion\" implementation of middleware in many popular web frameworks, no info argument is passed, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema def fn( v: str, validator: core\\\\\\\\\\\\\\_schema.ValidatorFunctionWrapHandler, ) -> str: return validator(input\\\\\\\\\\\\\\_value=v) + 'world' schema = core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( function=fn, schema=core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema() ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python('hello ') == 'hello world' Parameters: Name Type Description Default function NoInfoWrapValidatorFunction The validator function to call required schema CoreSchema The schema to validate the output of the validator function required ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function ¶ with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( function, schema, \\\\\\\\\\\\\\*, field\\\\\\\\\\\\\\_name=None, ref=None, metadata=None, serialization=None ) Returns a schema which calls a function with a validator callable argument which can optionally be used to call inner validation with the function logic, this is much like the \"onion\" implementation of middleware in many popular web frameworks, an info argument is also passed, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema def fn( v: str, validator: core\\\\\\\\\\\\\\_schema.ValidatorFunctionWrapHandler, info: core\\\\\\\\\\\\\\_schema.ValidationInfo, ) -> str: return validator(input\\\\\\\\\\\\\\_value=v) + 'world' schema = core\\\\\\\\\\\\\\_schema.with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( function=fn, schema=core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema() ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python('hello ') == 'hello world' Parameters: Name Type Description Default function WithInfoWrapValidatorFunction The validator function to call required schema CoreSchema The schema to validate the output of the validator function required field\\\\\\\\\\\\\\_name str | None The name of the field this validators is applied to, if any None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function ¶ no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( function, \\\\\\\\\\\\\\*, ref=None, metadata=None, serialization=None ) Returns a schema that uses the provided function for validation, no info argument is passed, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema def fn(v: str) -> str: assert 'hello' in v return v + 'world' schema = core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function(function=fn) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python('hello ') == 'hello world' Parameters: Name Type Description Default function NoInfoValidatorFunction The validator function to call required ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function ¶ with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( function, \\\\\\\\\\\\\\*, field\\\\\\\\\\\\\\_name=None, ref=None, metadata=None, serialization=None ) Returns a schema that uses the provided function for validation, an info argument is passed, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema def fn(v: str, info: core\\\\\\\\\\\\\\_schema.ValidationInfo) -> str: assert 'hello' in v return v + 'world' schema = core\\\\\\\\\\\\\\_schema.with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function(function=fn) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python('hello ') == 'hello world' Parameters: Name Type Description Default function WithInfoValidatorFunction The validator function to call required field\\\\\\\\\\\\\\_name str | None The name of the field this validators is applied to, if any None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py with\\\\\\\\\\\\\\_default\\\\\\\\\\\\\\_schema ¶ with\\\\\\\\\\\\\\_default\\\\\\\\\\\\\\_schema( schema, \\\\\\\\\\\\\\*, default=PydanticUndefined, default\\\\\\\\\\\\\\_factory=None, on\\\\\\\\\\\\\\_error=None, validate\\\\\\\\\\\\\\_default=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that adds a default value to the given schema, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.with\\\\\\\\\\\\\\_default\\\\\\\\\\\\\\_schema(core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(), default='hello') wrapper\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema( {'a': core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field(schema)} ) v = SchemaValidator(wrapper\\\\\\\\\\\\\\_schema) assert v.validate\\\\\\\\\\\\\\_python({}) == v.validate\\\\\\\\\\\\\\_python({'a': 'hello'}) Parameters: Name Type Description Default schema CoreSchema The schema to add a default value to required default Any The default value to use PydanticUndefined default\\\\\\\\\\\\\\_factory Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] | None A function that returns the default value to use None on\\\\\\\\\\\\\\_error Literal\\\\\\\\\\\\\\['raise', 'omit', 'default'\\\\\\\\\\\\\\] | None What to do if the schema validation fails. One of 'raise', 'omit', 'default' None validate\\\\\\\\\\\\\\_default bool | None Whether the default value should be validated None strict bool | None Whether the underlying schema should be validated with strict mode None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py nullable\\\\\\\\\\\\\\_schema ¶ nullable\\\\\\\\\\\\\\_schema( schema, \\\\\\\\\\\\\\*, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a nullable value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.nullable\\\\\\\\\\\\\\_schema(core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema()) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(None) is None Parameters: Name Type Description Default schema CoreSchema The schema to wrap required strict bool | None Whether the underlying schema should be validated with strict mode None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py union\\\\\\\\\\\\\\_schema ¶ union\\\\\\\\\\\\\\_schema( choices, \\\\\\\\\\\\\\*, auto\\\\\\\\\\\\\\_collapse=None, custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_type=None, custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_message=None, custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_context=None, mode=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a union value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.union\\\\\\\\\\\\\\_schema(\\\\\\\\\\\\\\[core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(), core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema()\\\\\\\\\\\\\\]) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python('hello') == 'hello' assert v.validate\\\\\\\\\\\\\\_python(1) == 1 Parameters: Name Type Description Default choices list\\\\\\\\\\\\\\[CoreSchema | tuple\\\\\\\\\\\\\\[CoreSchema, str\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] The schemas to match. If a tuple, the second item is used as the label for the case. required auto\\\\\\\\\\\\\\_collapse bool | None whether to automatically collapse unions with one element to the inner validator, default true None custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_type str | None The custom error type to use if the validation fails None custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_message str | None The custom error message to use if the validation fails None custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_context dict\\\\\\\\\\\\\\[str, str | int\\\\\\\\\\\\\\] | None The custom error context to use if the validation fails None mode Literal\\\\\\\\\\\\\\['smart', 'left\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_right'\\\\\\\\\\\\\\] | None How to select which choice to return \\\\\\\\\\\\\\* smart (default) will try to return the choice which is the closest match to the input value \\\\\\\\\\\\\\* left\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_right will return the first choice in choices which succeeds validation None strict bool | None Whether the underlying schemas should be validated with strict mode None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py tagged\\\\\\\\\\\\\\_union\\\\\\\\\\\\\\_schema ¶ tagged\\\\\\\\\\\\\\_union\\\\\\\\\\\\\\_schema( choices, discriminator, \\\\\\\\\\\\\\*, custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_type=None, custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_message=None, custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_context=None, strict=None, from\\\\\\\\\\\\\\_attributes=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a tagged union value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema apple\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema( { 'foo': core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field(core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema()), 'bar': core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field(core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema()), } ) banana\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema( { 'foo': core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field(core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema()), 'spam': core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field( core\\\\\\\\\\\\\\_schema.list\\\\\\\\\\\\\\_schema(items\\\\\\\\\\\\\\_schema=core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema()) ), } ) schema = core\\\\\\\\\\\\\\_schema.tagged\\\\\\\\\\\\\\_union\\\\\\\\\\\\\\_schema( choices={ 'apple': apple\\\\\\\\\\\\\\_schema, 'banana': banana\\\\\\\\\\\\\\_schema, }, discriminator='foo', ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python({'foo': 'apple', 'bar': '123'}) == {'foo': 'apple', 'bar': 123} assert v.validate\\\\\\\\\\\\\\_python({'foo': 'banana', 'spam': \\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\]}) == { 'foo': 'banana', 'spam': \\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\], } Parameters: Name Type Description Default choices Dict\\\\\\\\\\\\\\[Hashable, CoreSchema\\\\\\\\\\\\\\] The schemas to match When retrieving a schema from choices using the discriminator value, if the value is a str, it should be fed back into the choices map until a schema is obtained (This approach is to prevent multiple ownership of a single schema in Rust) required discriminator str | list\\\\\\\\\\\\\\[str | int\\\\\\\\\\\\\\] | list\\\\\\\\\\\\\\[list\\\\\\\\\\\\\\[str | int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] | Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Hashable\\\\\\\\\\\\\\] The discriminator to use to determine the schema to use \\\\\\\\\\\\\\* If discriminator is a str, it is the name of the attribute to use as the discriminator \\\\\\\\\\\\\\* If discriminator is a list of int/str, it should be used as a \"path\" to access the discriminator \\\\\\\\\\\\\\* If discriminator is a list of lists, each inner list is a path, and the first path that exists is used \\\\\\\\\\\\\\* If discriminator is a callable, it should return the discriminator when called on the value to validate; the callable can return None to indicate that there is no matching discriminator present on the input required custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_type str | None The custom error type to use if the validation fails None custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_message str | None The custom error message to use if the validation fails None custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_context dict\\\\\\\\\\\\\\[str, int | str | float\\\\\\\\\\\\\\] | None The custom error context to use if the validation fails None strict bool | None Whether the underlying schemas should be validated with strict mode None from\\\\\\\\\\\\\\_attributes bool | None Whether to use the attributes of the object to retrieve the discriminator value None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py chain\\\\\\\\\\\\\\_schema ¶ chain\\\\\\\\\\\\\\_schema( steps, \\\\\\\\\\\\\\*, ref=None, metadata=None, serialization=None ) Returns a schema that chains the provided validation schemas, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema def fn(v: str, info: core\\\\\\\\\\\\\\_schema.ValidationInfo) -> str: assert 'hello' in v return v + ' world' fn\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function(function=fn) schema = core\\\\\\\\\\\\\\_schema.chain\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\[fn\\\\\\\\\\\\\\_schema, fn\\\\\\\\\\\\\\_schema, fn\\\\\\\\\\\\\\_schema, core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema()\\\\\\\\\\\\\\] ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python('hello') == 'hello world world world' Parameters: Name Type Description Default steps list\\\\\\\\\\\\\\[CoreSchema\\\\\\\\\\\\\\] The schemas to chain required ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py lax\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_strict\\\\\\\\\\\\\\_schema ¶ lax\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_strict\\\\\\\\\\\\\\_schema( lax\\\\\\\\\\\\\\_schema, strict\\\\\\\\\\\\\\_schema, \\\\\\\\\\\\\\*, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that uses the lax or strict schema, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema def fn(v: str, info: core\\\\\\\\\\\\\\_schema.ValidationInfo) -> str: assert 'hello' in v return v + ' world' lax\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(strict=False) strict\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(strict=True) schema = core\\\\\\\\\\\\\\_schema.lax\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_strict\\\\\\\\\\\\\\_schema( lax\\\\\\\\\\\\\\_schema=lax\\\\\\\\\\\\\\_schema, strict\\\\\\\\\\\\\\_schema=strict\\\\\\\\\\\\\\_schema, strict=True ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(123) == 123 schema = core\\\\\\\\\\\\\\_schema.lax\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_strict\\\\\\\\\\\\\\_schema( lax\\\\\\\\\\\\\\_schema=lax\\\\\\\\\\\\\\_schema, strict\\\\\\\\\\\\\\_schema=strict\\\\\\\\\\\\\\_schema, strict=False ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python('123') == 123 Parameters: Name Type Description Default lax\\\\\\\\\\\\\\_schema CoreSchema The lax schema to use required strict\\\\\\\\\\\\\\_schema CoreSchema The strict schema to use required strict bool | None Whether the strict schema should be used None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py json\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_python\\\\\\\\\\\\\\_schema ¶ json\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_python\\\\\\\\\\\\\\_schema( json\\\\\\\\\\\\\\_schema, python\\\\\\\\\\\\\\_schema, \\\\\\\\\\\\\\*, ref=None, metadata=None, serialization=None ) Returns a schema that uses the Json or Python schema depending on the input: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, ValidationError, core\\\\\\\\\\\\\\_schema v = SchemaValidator( core\\\\\\\\\\\\\\_schema.json\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_python\\\\\\\\\\\\\\_schema( json\\\\\\\\\\\\\\_schema=core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(), python\\\\\\\\\\\\\\_schema=core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(strict=True), ) ) assert v.validate\\\\\\\\\\\\\\_json('\"123\"') == 123 try: v.validate\\\\\\\\\\\\\\_python('123') except ValidationError: pass else: raise AssertionError('Validation should have failed') Parameters: Name Type Description Default json\\\\\\\\\\\\\\_schema CoreSchema The schema to use for Json inputs required python\\\\\\\\\\\\\\_schema CoreSchema The schema to use for Python inputs required ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field ¶ typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field( schema, \\\\\\\\\\\\\\*, required=None, validation\\\\\\\\\\\\\\_alias=None, serialization\\\\\\\\\\\\\\_alias=None, serialization\\\\\\\\\\\\\\_exclude=None, metadata=None ) Returns a schema that matches a typed dict field, e.g.: from pydantic\\\\\\\\\\\\\\_core import core\\\\\\\\\\\\\\_schema field = core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field(schema=core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(), required=True) Parameters: Name Type Description Default schema CoreSchema The schema to use for the field required required bool | None Whether the field is required None validation\\\\\\\\\\\\\\_alias str | list\\\\\\\\\\\\\\[str | int\\\\\\\\\\\\\\] | list\\\\\\\\\\\\\\[list\\\\\\\\\\\\\\[str | int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] | None The alias(es) to use to find the field in the validation data None serialization\\\\\\\\\\\\\\_alias str | None The alias to use as a key when serializing None serialization\\\\\\\\\\\\\\_exclude bool | None Whether to exclude the field when serializing None metadata Any Any other information you want to include with the schema, not used by pydantic-core None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema ¶ typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema( fields, \\\\\\\\\\\\\\*, computed\\\\\\\\\\\\\\_fields=None, strict=None, extras\\\\\\\\\\\\\\_schema=None, extra\\\\\\\\\\\\\\_behavior=None, total=None, populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name=None, ref=None, metadata=None, serialization=None, config=None ) Returns a schema that matches a typed dict, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema wrapper\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema( {'a': core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field(core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema())} ) v = SchemaValidator(wrapper\\\\\\\\\\\\\\_schema) assert v.validate\\\\\\\\\\\\\\_python({'a': 'hello'}) == {'a': 'hello'} Parameters: Name Type Description Default fields Dict\\\\\\\\\\\\\\[str, TypedDictField\\\\\\\\\\\\\\] The fields to use for the typed dict required computed\\\\\\\\\\\\\\_fields list\\\\\\\\\\\\\\[ComputedField\\\\\\\\\\\\\\] | None Computed fields to use when serializing the model, only applies when directly inside a model None strict bool | None Whether the typed dict is strict None extras\\\\\\\\\\\\\\_schema CoreSchema | None The extra validator to use for the typed dict None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None extra\\\\\\\\\\\\\\_behavior ExtraBehavior | None The extra behavior to use for the typed dict None total bool | None Whether the typed dict is total None populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name bool | None Whether the typed dict should populate by name None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py model\\\\\\\\\\\\\\_field ¶ model\\\\\\\\\\\\\\_field( schema, \\\\\\\\\\\\\\*, validation\\\\\\\\\\\\\\_alias=None, serialization\\\\\\\\\\\\\\_alias=None, serialization\\\\\\\\\\\\\\_exclude=None, frozen=None, metadata=None ) Returns a schema for a model field, e.g.: from pydantic\\\\\\\\\\\\\\_core import core\\\\\\\\\\\\\\_schema field = core\\\\\\\\\\\\\\_schema.model\\\\\\\\\\\\\\_field(schema=core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema()) Parameters: Name Type Description Default schema CoreSchema The schema to use for the field required validation\\\\\\\\\\\\\\_alias str | list\\\\\\\\\\\\\\[str | int\\\\\\\\\\\\\\] | list\\\\\\\\\\\\\\[list\\\\\\\\\\\\\\[str | int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] | None The alias(es) to use to find the field in the validation data None serialization\\\\\\\\\\\\\\_alias str | None The alias to use as a key when serializing None serialization\\\\\\\\\\\\\\_exclude bool | None Whether to exclude the field when serializing None frozen bool | None Whether the field is frozen None metadata Any Any other information you want to include with the schema, not used by pydantic-core None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_schema ¶ model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_schema( fields, \\\\\\\\\\\\\\*, model\\\\\\\\\\\\\\_name=None, computed\\\\\\\\\\\\\\_fields=None, strict=None, extras\\\\\\\\\\\\\\_schema=None, extra\\\\\\\\\\\\\\_behavior=None, populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name=None, from\\\\\\\\\\\\\\_attributes=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a typed dict, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema wrapper\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_schema( {'a': core\\\\\\\\\\\\\\_schema.model\\\\\\\\\\\\\\_field(core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema())} ) v = SchemaValidator(wrapper\\\\\\\\\\\\\\_schema) print(v.validate\\\\\\\\\\\\\\_python({'a': 'hello'})) #> ({'a': 'hello'}, None, {'a'}) Parameters: Name Type Description Default fields Dict\\\\\\\\\\\\\\[str, ModelField\\\\\\\\\\\\\\] The fields to use for the typed dict required model\\\\\\\\\\\\\\_name str | None The name of the model, used for error messages, defaults to \"Model\" None computed\\\\\\\\\\\\\\_fields list\\\\\\\\\\\\\\[ComputedField\\\\\\\\\\\\\\] | None Computed fields to use when serializing the model, only applies when directly inside a model None strict bool | None Whether the typed dict is strict None extras\\\\\\\\\\\\\\_schema CoreSchema | None The extra validator to use for the typed dict None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None extra\\\\\\\\\\\\\\_behavior ExtraBehavior | None The extra behavior to use for the typed dict None populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name bool | None Whether the typed dict should populate by name None from\\\\\\\\\\\\\\_attributes bool | None Whether the typed dict should be populated from attributes None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py model\\\\\\\\\\\\\\_schema ¶ model\\\\\\\\\\\\\\_schema( cls, schema, \\\\\\\\\\\\\\*, custom\\\\\\\\\\\\\\_init=None, root\\\\\\\\\\\\\\_model=None, post\\\\\\\\\\\\\\_init=None, revalidate\\\\\\\\\\\\\\_instances=None, strict=None, frozen=None, extra\\\\\\\\\\\\\\_behavior=None, config=None, ref=None, metadata=None, serialization=None ) A model schema generally contains a typed-dict schema. It will run the typed dict validator, then create a new class and set the dict and fields set returned from the typed dict validator to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ respectively. Example: from pydantic\\\\\\\\\\\\\\_core import CoreConfig, SchemaValidator, core\\\\\\\\\\\\\\_schema class MyModel: \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_slots\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ = ( '\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_', '\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_', '\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_', '\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_private\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_', ) schema = core\\\\\\\\\\\\\\_schema.model\\\\\\\\\\\\\\_schema( cls=MyModel, config=CoreConfig(str\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_length=5), schema=core\\\\\\\\\\\\\\_schema.model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_schema( fields={'a': core\\\\\\\\\\\\\\_schema.model\\\\\\\\\\\\\\_field(core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema())}, ), ) v = SchemaValidator(schema) assert v.isinstance\\\\\\\\\\\\\\_python({'a': 'hello'}) is True assert v.isinstance\\\\\\\\\\\\\\_python({'a': 'too long'}) is False Parameters: Name Type Description Default cls Type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] The class to use for the model required schema CoreSchema The schema to use for the model required custom\\\\\\\\\\\\\\_init bool | None Whether the model has a custom init method None root\\\\\\\\\\\\\\_model bool | None Whether the model is a RootModel None post\\\\\\\\\\\\\\_init str | None The call after init to use for the model None revalidate\\\\\\\\\\\\\\_instances Literal\\\\\\\\\\\\\\['always', 'never', 'subclass-instances'\\\\\\\\\\\\\\] | None whether instances of models and dataclasses (including subclass instances) should re-validate defaults to config.revalidate\\\\\\\\\\\\\\_instances, else 'never' None strict bool | None Whether the model is strict None frozen bool | None Whether the model is frozen None extra\\\\\\\\\\\\\\_behavior ExtraBehavior | None The extra behavior to use for the model, used in serialization None config CoreConfig | None The config to use for the model None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py dataclass\\\\\\\\\\\\\\_field ¶ dataclass\\\\\\\\\\\\\\_field( name, schema, \\\\\\\\\\\\\\*, kw\\\\\\\\\\\\\\_only=None, init\\\\\\\\\\\\\\_only=None, validation\\\\\\\\\\\\\\_alias=None, serialization\\\\\\\\\\\\\\_alias=None, serialization\\\\\\\\\\\\\\_exclude=None, metadata=None, frozen=None ) Returns a schema for a dataclass field, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema field = core\\\\\\\\\\\\\\_schema.dataclass\\\\\\\\\\\\\\_field( name='a', schema=core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(), kw\\\\\\\\\\\\\\_only=False ) schema = core\\\\\\\\\\\\\\_schema.dataclass\\\\\\\\\\\\\\_args\\\\\\\\\\\\\\_schema('Foobar', \\\\\\\\\\\\\\[field\\\\\\\\\\\\\\]) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python({'a': 'hello'}) == ({'a': 'hello'}, None) Parameters: Name Type Description Default name str The name to use for the argument parameter required schema CoreSchema The schema to use for the argument parameter required kw\\\\\\\\\\\\\\_only bool | None Whether the field can be set with a positional argument as well as a keyword argument None init\\\\\\\\\\\\\\_only bool | None Whether the field should be omitted from \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and passed to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ None validation\\\\\\\\\\\\\\_alias str | list\\\\\\\\\\\\\\[str | int\\\\\\\\\\\\\\] | list\\\\\\\\\\\\\\[list\\\\\\\\\\\\\\[str | int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] | None The alias(es) to use to find the field in the validation data None serialization\\\\\\\\\\\\\\_alias str | None The alias to use as a key when serializing None serialization\\\\\\\\\\\\\\_exclude bool | None Whether to exclude the field when serializing None metadata Any Any other information you want to include with the schema, not used by pydantic-core None frozen bool | None Whether the field is frozen None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py dataclass\\\\\\\\\\\\\\_args\\\\\\\\\\\\\\_schema ¶ dataclass\\\\\\\\\\\\\\_args\\\\\\\\\\\\\\_schema( dataclass\\\\\\\\\\\\\\_name, fields, \\\\\\\\\\\\\\*, computed\\\\\\\\\\\\\\_fields=None, populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name=None, collect\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_only=None, ref=None, metadata=None, serialization=None, extra\\\\\\\\\\\\\\_behavior=None ) Returns a schema for validating dataclass arguments, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema field\\\\\\\\\\\\\\_a = core\\\\\\\\\\\\\\_schema.dataclass\\\\\\\\\\\\\\_field( name='a', schema=core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(), kw\\\\\\\\\\\\\\_only=False ) field\\\\\\\\\\\\\\_b = core\\\\\\\\\\\\\\_schema.dataclass\\\\\\\\\\\\\\_field( name='b', schema=core\\\\\\\\\\\\\\_schema.bool\\\\\\\\\\\\\\_schema(), kw\\\\\\\\\\\\\\_only=False ) schema = core\\\\\\\\\\\\\\_schema.dataclass\\\\\\\\\\\\\\_args\\\\\\\\\\\\\\_schema('Foobar', \\\\\\\\\\\\\\[field\\\\\\\\\\\\\\_a, field\\\\\\\\\\\\\\_b\\\\\\\\\\\\\\]) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python({'a': 'hello', 'b': True}) == ({'a': 'hello', 'b': True}, None) Parameters: Name Type Description Default dataclass\\\\\\\\\\\\\\_name str The name of the dataclass being validated required fields list\\\\\\\\\\\\\\[DataclassField\\\\\\\\\\\\\\] The fields to use for the dataclass required computed\\\\\\\\\\\\\\_fields List\\\\\\\\\\\\\\[ComputedField\\\\\\\\\\\\\\] | None Computed fields to use when serializing the dataclass None populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name bool | None Whether to populate by name None collect\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_only bool | None Whether to collect init only fields into a dict to pass to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None extra\\\\\\\\\\\\\\_behavior ExtraBehavior | None How to handle extra fields None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py dataclass\\\\\\\\\\\\\\_schema ¶ dataclass\\\\\\\\\\\\\\_schema( cls, schema, fields, \\\\\\\\\\\\\\*, cls\\\\\\\\\\\\\\_name=None, post\\\\\\\\\\\\\\_init=None, revalidate\\\\\\\\\\\\\\_instances=None, strict=None, ref=None, metadata=None, serialization=None, frozen=None, slots=None, config=None ) Returns a schema for a dataclass. As with ModelSchema, this schema can only be used as a field within another schema, not as the root type. Parameters: Name Type Description Default cls Type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] The dataclass type, used to perform subclass checks required schema CoreSchema The schema to use for the dataclass fields required fields List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] Fields of the dataclass, this is used in serialization and in validation during re-validation and while validating assignment required cls\\\\\\\\\\\\\\_name str | None The name to use in error locs, etc; this is useful for generics (default: cls.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_) None post\\\\\\\\\\\\\\_init bool | None Whether to call \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ after validation None revalidate\\\\\\\\\\\\\\_instances Literal\\\\\\\\\\\\\\['always', 'never', 'subclass-instances'\\\\\\\\\\\\\\] | None whether instances of models and dataclasses (including subclass instances) should re-validate defaults to config.revalidate\\\\\\\\\\\\\\_instances, else 'never' None strict bool | None Whether to require an exact instance of cls None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None frozen bool | None Whether the dataclass is frozen None slots bool | None Whether slots=True on the dataclass, means each field is assigned independently, rather than simply setting \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, default false None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py arguments\\\\\\\\\\\\\\_parameter ¶ arguments\\\\\\\\\\\\\\_parameter(name, schema, \\\\\\\\\\\\\\*, mode=None, alias=None) Returns a schema that matches an argument parameter, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema param = core\\\\\\\\\\\\\\_schema.arguments\\\\\\\\\\\\\\_parameter( name='a', schema=core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(), mode='positional\\\\\\\\\\\\\\_only' ) schema = core\\\\\\\\\\\\\\_schema.arguments\\\\\\\\\\\\\\_schema(\\\\\\\\\\\\\\[param\\\\\\\\\\\\\\]) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(('hello',)) == (('hello',), {}) Parameters: Name Type Description Default name str The name to use for the argument parameter required schema CoreSchema The schema to use for the argument parameter required mode Literal\\\\\\\\\\\\\\['positional\\\\\\\\\\\\\\_only', 'positional\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_keyword', 'keyword\\\\\\\\\\\\\\_only'\\\\\\\\\\\\\\] | None The mode to use for the argument parameter None alias str | list\\\\\\\\\\\\\\[str | int\\\\\\\\\\\\\\] | list\\\\\\\\\\\\\\[list\\\\\\\\\\\\\\[str | int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] | None The alias to use for the argument parameter None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py arguments\\\\\\\\\\\\\\_schema ¶ arguments\\\\\\\\\\\\\\_schema( arguments, \\\\\\\\\\\\\\*, populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name=None, var\\\\\\\\\\\\\\_args\\\\\\\\\\\\\\_schema=None, var\\\\\\\\\\\\\\_kwargs\\\\\\\\\\\\\\_schema=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches an arguments schema, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema param\\\\\\\\\\\\\\_a = core\\\\\\\\\\\\\\_schema.arguments\\\\\\\\\\\\\\_parameter( name='a', schema=core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(), mode='positional\\\\\\\\\\\\\\_only' ) param\\\\\\\\\\\\\\_b = core\\\\\\\\\\\\\\_schema.arguments\\\\\\\\\\\\\\_parameter( name='b', schema=core\\\\\\\\\\\\\\_schema.bool\\\\\\\\\\\\\\_schema(), mode='positional\\\\\\\\\\\\\\_only' ) schema = core\\\\\\\\\\\\\\_schema.arguments\\\\\\\\\\\\\\_schema(\\\\\\\\\\\\\\[param\\\\\\\\\\\\\\_a, param\\\\\\\\\\\\\\_b\\\\\\\\\\\\\\]) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(('hello', True)) == (('hello', True), {}) Parameters: Name Type Description Default arguments list\\\\\\\\\\\\\\[ArgumentsParameter\\\\\\\\\\\\\\] The arguments to use for the arguments schema required populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name bool | None Whether to populate by name None var\\\\\\\\\\\\\\_args\\\\\\\\\\\\\\_schema CoreSchema | None The variable args schema to use for the arguments schema None var\\\\\\\\\\\\\\_kwargs\\\\\\\\\\\\\\_schema CoreSchema | None The variable kwargs schema to use for the arguments schema None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py call\\\\\\\\\\\\\\_schema ¶ call\\\\\\\\\\\\\\_schema( arguments, function, \\\\\\\\\\\\\\*, function\\\\\\\\\\\\\\_name=None, return\\\\\\\\\\\\\\_schema=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches an arguments schema, then calls a function, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema param\\\\\\\\\\\\\\_a = core\\\\\\\\\\\\\\_schema.arguments\\\\\\\\\\\\\\_parameter( name='a', schema=core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(), mode='positional\\\\\\\\\\\\\\_only' ) param\\\\\\\\\\\\\\_b = core\\\\\\\\\\\\\\_schema.arguments\\\\\\\\\\\\\\_parameter( name='b', schema=core\\\\\\\\\\\\\\_schema.bool\\\\\\\\\\\\\\_schema(), mode='positional\\\\\\\\\\\\\\_only' ) args\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.arguments\\\\\\\\\\\\\\_schema(\\\\\\\\\\\\\\[param\\\\\\\\\\\\\\_a, param\\\\\\\\\\\\\\_b\\\\\\\\\\\\\\]) schema = core\\\\\\\\\\\\\\_schema.call\\\\\\\\\\\\\\_schema( arguments=args\\\\\\\\\\\\\\_schema, function=lambda a, b: a + str(not b), return\\\\\\\\\\\\\\_schema=core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(), ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python((('hello', True))) == 'helloFalse' Parameters: Name Type Description Default arguments CoreSchema The arguments to use for the arguments schema required function Callable\\\\\\\\\\\\\\[..., Any\\\\\\\\\\\\\\] The function to use for the call schema required function\\\\\\\\\\\\\\_name str | None The function name to use for the call schema, if not provided function.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ is used None return\\\\\\\\\\\\\\_schema CoreSchema | None The return schema to use for the call schema None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_schema ¶ custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_schema( schema, custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_type, \\\\\\\\\\\\\\*, custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_message=None, custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_context=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a custom error value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_schema( schema=core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(), custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_type='MyError', custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_message='Error msg', ) v = SchemaValidator(schema) v.validate\\\\\\\\\\\\\\_python(1) Parameters: Name Type Description Default schema CoreSchema The schema to use for the custom error schema required custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_type str The custom error type to use for the custom error schema required custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_message str | None The custom error message to use for the custom error schema None custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_context dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None The custom error context to use for the custom error schema None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py json\\\\\\\\\\\\\\_schema ¶ json\\\\\\\\\\\\\\_schema( schema=None, \\\\\\\\\\\\\\*, ref=None, metadata=None, serialization=None ) Returns a schema that matches a JSON value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema dict\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_schema( { 'field\\\\\\\\\\\\\\_a': core\\\\\\\\\\\\\\_schema.model\\\\\\\\\\\\\\_field(core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema()), 'field\\\\\\\\\\\\\\_b': core\\\\\\\\\\\\\\_schema.model\\\\\\\\\\\\\\_field(core\\\\\\\\\\\\\\_schema.bool\\\\\\\\\\\\\\_schema()), }, ) class MyModel: \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_slots\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ = ( '\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_', '\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_', '\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_', '\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_private\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_', ) field\\\\\\\\\\\\\\_a: str field\\\\\\\\\\\\\\_b: bool json\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.json\\\\\\\\\\\\\\_schema(schema=dict\\\\\\\\\\\\\\_schema) schema = core\\\\\\\\\\\\\\_schema.model\\\\\\\\\\\\\\_schema(cls=MyModel, schema=json\\\\\\\\\\\\\\_schema) v = SchemaValidator(schema) m = v.validate\\\\\\\\\\\\\\_python('{\"field\\\\\\\\\\\\\\_a\": \"hello\", \"field\\\\\\\\\\\\\\_b\": true}') assert isinstance(m, MyModel) Parameters: Name Type Description Default schema CoreSchema | None The schema to use for the JSON schema None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py url\\\\\\\\\\\\\\_schema ¶ url\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\*, max\\\\\\\\\\\\\\_length=None, allowed\\\\\\\\\\\\\\_schemes=None, host\\\\\\\\\\\\\\_required=None, default\\\\\\\\\\\\\\_host=None, default\\\\\\\\\\\\\\_port=None, default\\\\\\\\\\\\\\_path=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a URL value, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.url\\\\\\\\\\\\\\_schema() v = SchemaValidator(schema) print(v.validate\\\\\\\\\\\\\\_python('https://example.com')) #> https://example.com/ Parameters: Name Type Description Default max\\\\\\\\\\\\\\_length int | None The maximum length of the URL None allowed\\\\\\\\\\\\\\_schemes list\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] | None The allowed URL schemes None host\\\\\\\\\\\\\\_required bool | None Whether the URL must have a host None default\\\\\\\\\\\\\\_host str | None The default host to use if the URL does not have a host None default\\\\\\\\\\\\\\_port int | None The default port to use if the URL does not have a port None default\\\\\\\\\\\\\\_path str | None The default path to use if the URL does not have a path None strict bool | None Whether to use strict URL parsing None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py multi\\\\\\\\\\\\\\_host\\\\\\\\\\\\\\_url\\\\\\\\\\\\\\_schema ¶ multi\\\\\\\\\\\\\\_host\\\\\\\\\\\\\\_url\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\*, max\\\\\\\\\\\\\\_length=None, allowed\\\\\\\\\\\\\\_schemes=None, host\\\\\\\\\\\\\\_required=None, default\\\\\\\\\\\\\\_host=None, default\\\\\\\\\\\\\\_port=None, default\\\\\\\\\\\\\\_path=None, strict=None, ref=None, metadata=None, serialization=None ) Returns a schema that matches a URL value with possibly multiple hosts, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.multi\\\\\\\\\\\\\\_host\\\\\\\\\\\\\\_url\\\\\\\\\\\\\\_schema() v = SchemaValidator(schema) print(v.validate\\\\\\\\\\\\\\_python('redis://localhost,0.0.0.0,127.0.0.1')) #> redis://localhost,0.0.0.0,127.0.0.1 Parameters: Name Type Description Default max\\\\\\\\\\\\\\_length int | None The maximum length of the URL None allowed\\\\\\\\\\\\\\_schemes list\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] | None The allowed URL schemes None host\\\\\\\\\\\\\\_required bool | None Whether the URL must have a host None default\\\\\\\\\\\\\\_host str | None The default host to use if the URL does not have a host None default\\\\\\\\\\\\\\_port int | None The default port to use if the URL does not have a port None default\\\\\\\\\\\\\\_path str | None The default path to use if the URL does not have a path None strict bool | None Whether to use strict URL parsing None ref str | None optional unique identifier of the schema, used to reference the schema in other places None metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py definitions\\\\\\\\\\\\\\_schema ¶ definitions\\\\\\\\\\\\\\_schema(schema, definitions) Build a schema that contains both an inner schema and a list of definitions which can be used within the inner schema. from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema = core\\\\\\\\\\\\\\_schema.definitions\\\\\\\\\\\\\\_schema( core\\\\\\\\\\\\\\_schema.list\\\\\\\\\\\\\\_schema(core\\\\\\\\\\\\\\_schema.definition\\\\\\\\\\\\\\_reference\\\\\\\\\\\\\\_schema('foobar')), \\\\\\\\\\\\\\[core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(ref='foobar')\\\\\\\\\\\\\\], ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(\\\\\\\\\\\\\\[1, 2, '3'\\\\\\\\\\\\\\]) == \\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\] Parameters: Name Type Description Default schema CoreSchema The inner schema required definitions list\\\\\\\\\\\\\\[CoreSchema\\\\\\\\\\\\\\] List of definitions which can be referenced within inner schema required Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py definition\\\\\\\\\\\\\\_reference\\\\\\\\\\\\\\_schema ¶ definition\\\\\\\\\\\\\\_reference\\\\\\\\\\\\\\_schema( schema\\\\\\\\\\\\\\_ref, metadata=None, serialization=None ) Returns a schema that points to a schema stored in \"definitions\", this is useful for nested recursive models and also when you want to define validators separately from the main schema, e.g.: from pydantic\\\\\\\\\\\\\\_core import SchemaValidator, core\\\\\\\\\\\\\\_schema schema\\\\\\\\\\\\\\_definition = core\\\\\\\\\\\\\\_schema.definition\\\\\\\\\\\\\\_reference\\\\\\\\\\\\\\_schema('list-schema') schema = core\\\\\\\\\\\\\\_schema.definitions\\\\\\\\\\\\\\_schema( schema=schema\\\\\\\\\\\\\\_definition, definitions=\\\\\\\\\\\\\\[ core\\\\\\\\\\\\\\_schema.list\\\\\\\\\\\\\\_schema(items\\\\\\\\\\\\\\_schema=schema\\\\\\\\\\\\\\_definition, ref='list-schema'), \\\\\\\\\\\\\\], ) v = SchemaValidator(schema) assert v.validate\\\\\\\\\\\\\\_python(\\\\\\\\\\\\\\[()\\\\\\\\\\\\\\]) == \\\\\\\\\\\\\\[\\\\\\\\\\\\\\[\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] Parameters: Name Type Description Default schema\\\\\\\\\\\\\\_ref str The schema ref to use for the definition reference schema required metadata Any Any other information you want to include with the schema, not used by pydantic-core None serialization SerSchema | None Custom serialization schema None Source code in pydantic\\\\\\\\\\\\\\_core/core\\\\\\\\\\\\\\_schema.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Country - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/pydantic_extra_types_country/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Country Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic Pydantic Core Pydantic Settings Pydantic Extra Types Color Country Payment Phone Numbers Routing Numbers Coordinate Mac Address Page contents pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.country CountryAlpha2 alpha3 numeric\\\\\\\\\\\\\\_code short\\\\\\\\\\\\\\_name official\\\\\\\\\\\\\\_name CountryAlpha3 alpha2 numeric\\\\\\\\\\\\\\_code short\\\\\\\\\\\\\\_name official\\\\\\\\\\\\\\_name CountryNumericCode alpha2 alpha3 short\\\\\\\\\\\\\\_name official\\\\\\\\\\\\\\_name CountryShortName alpha2 alpha3 numeric\\\\\\\\\\\\\\_code official\\\\\\\\\\\\\\_name CountryOfficialName alpha2 alpha3 numeric\\\\\\\\\\\\\\_code short\\\\\\\\\\\\\\_name Country Country definitions that are based on the ISO 3166. CountryAlpha2 ¶ Bases: str CountryAlpha2 parses country codes in the ISO 3166-1 alpha-2 format. from pydantic import BaseModel from pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.country import CountryAlpha2 class Product(BaseModel): made\\\\\\\\\\\\\\_in: CountryAlpha2 product = Product(made\\\\\\\\\\\\\\_in='ES') print(product) #> made\\\\\\\\\\\\\\_in='ES' alpha3 property ¶ alpha3: str The country code in the ISO 3166-1 alpha-3 format. numeric\\\\\\\\\\\\\\_code property ¶ numeric\\\\\\\\\\\\\\_code: str The country code in the ISO 3166-1 numeric format. short\\\\\\\\\\\\\\_name property ¶ short\\\\\\\\\\\\\\_name: str The country short name. official\\\\\\\\\\\\\\_name property ¶ official\\\\\\\\\\\\\\_name: str The country official name. CountryAlpha3 ¶ Bases: str CountryAlpha3 parses country codes in the ISO 3166-1 alpha-3 format. from pydantic import BaseModel from pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.country import CountryAlpha3 class Product(BaseModel): made\\\\\\\\\\\\\\_in: CountryAlpha3 product = Product(made\\\\\\\\\\\\\\_in=\"USA\") print(product) #> made\\\\\\\\\\\\\\_in='USA' alpha2 property ¶ alpha2: str The country code in the ISO 3166-1 alpha-2 format. numeric\\\\\\\\\\\\\\_code property ¶ numeric\\\\\\\\\\\\\\_code: str The country code in the ISO 3166-1 numeric format. short\\\\\\\\\\\\\\_name property ¶ short\\\\\\\\\\\\\\_name: str The country short name. official\\\\\\\\\\\\\\_name property ¶ official\\\\\\\\\\\\\\_name: str The country official name. CountryNumericCode ¶ Bases: str CountryNumericCode parses country codes in the ISO 3166-1 numeric format. from pydantic import BaseModel from pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.country import CountryNumericCode class Product(BaseModel): made\\\\\\\\\\\\\\_in: CountryNumericCode product = Product(made\\\\\\\\\\\\\\_in=\"840\") print(product) #> made\\\\\\\\\\\\\\_in='840' alpha2 property ¶ alpha2: str The country code in the ISO 3166-1 alpha-2 format. alpha3 property ¶ alpha3: str The country code in the ISO 3166-1 alpha-3 format. short\\\\\\\\\\\\\\_name property ¶ short\\\\\\\\\\\\\\_name: str The country short name. official\\\\\\\\\\\\\\_name property ¶ official\\\\\\\\\\\\\\_name: str The country official name. CountryShortName ¶ Bases: str CountryShortName parses country codes in the short name format. from pydantic import BaseModel from pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.country import CountryShortName class Product(BaseModel): made\\\\\\\\\\\\\\_in: CountryShortName product = Product(made\\\\\\\\\\\\\\_in=\"United States\") print(product) #> made\\\\\\\\\\\\\\_in='United States' alpha2 property ¶ alpha2: str The country code in the ISO 3166-1 alpha-2 format. alpha3 property ¶ alpha3: str The country code in the ISO 3166-1 alpha-3 format. numeric\\\\\\\\\\\\\\_code property ¶ numeric\\\\\\\\\\\\\\_code: str The country code in the ISO 3166-1 numeric format. official\\\\\\\\\\\\\\_name property ¶ official\\\\\\\\\\\\\\_name: str The country official name. CountryOfficialName ¶ Bases: str CountryOfficialName parses country codes in the official name format. from pydantic import BaseModel from pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.country import CountryOfficialName class Product(BaseModel): made\\\\\\\\\\\\\\_in: CountryOfficialName product = Product(made\\\\\\\\\\\\\\_in=\"United States of America\") print(product) #> made\\\\\\\\\\\\\\_in='United States of America' alpha2 property ¶ alpha2: str The country code in the ISO 3166-1 alpha-2 format. alpha3 property ¶ alpha3: str The country code in the ISO 3166-1 alpha-3 format. numeric\\\\\\\\\\\\\\_code property ¶ numeric\\\\\\\\\\\\\\_code: str The country code in the ISO 3166-1 numeric format. short\\\\\\\\\\\\\\_name property ¶ short\\\\\\\\\\\\\\_name: str The country short name. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Color - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/pydantic_extra_types_color/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Color Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic Pydantic Core Pydantic Settings Pydantic Extra Types Color Country Payment Phone Numbers Routing Numbers Coordinate Mac Address Page contents pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.color RGBA Color original() as\\\\\\\\\\\\\\_named() as\\\\\\\\\\\\\\_hex() as\\\\\\\\\\\\\\_rgb() as\\\\\\\\\\\\\\_rgb\\\\\\\\\\\\\\_tuple() as\\\\\\\\\\\\\\_hsl() as\\\\\\\\\\\\\\_hsl\\\\\\\\\\\\\\_tuple() parse\\\\\\\\\\\\\\_tuple() parse\\\\\\\\\\\\\\_str() ints\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_rgba() parse\\\\\\\\\\\\\\_color\\\\\\\\\\\\\\_value() parse\\\\\\\\\\\\\\_float\\\\\\\\\\\\\\_alpha() parse\\\\\\\\\\\\\\_hsl() float\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_255() Color Color definitions are used as per the CSS3 CSS Color Module Level 3 specification. A few colors have multiple names referring to the sames colors, eg. grey and gray or aqua and cyan. In these cases the last color when sorted alphabetically takes preferences, eg. Color((0, 255, 255)).as\\\\\\\\\\\\\\_named() == 'cyan' because \"cyan\" comes after \"aqua\". RGBA ¶ RGBA(r, g, b, alpha) Internal use only as a representation of a color. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py Color ¶ Color(value) Bases: \\\\\\\\\\\\\\_repr.Representation Represents a color. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py original ¶ original() Original value passed to Color. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py as\\\\\\\\\\\\\\_named ¶ as\\\\\\\\\\\\\\_named(\\\\\\\\\\\\\\*, fallback=False) Returns the name of the color if it can be found in COLORS\\\\\\\\\\\\\\_BY\\\\\\\\\\\\\\_VALUE dictionary, otherwise returns the hexadecimal representation of the color or raises ValueError. Parameters: Name Type Description Default fallback bool If True, falls back to returning the hexadecimal representation of the color instead of raising a ValueError when no named color is found. False Returns: Type Description str The name of the color, or the hexadecimal representation of the color. Raises: Type Description ValueError When no named color is found and fallback is False. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py as\\\\\\\\\\\\\\_hex ¶ as\\\\\\\\\\\\\\_hex(format='short') Returns the hexadecimal representation of the color. Hex string representing the color can be 3, 4, 6, or 8 characters depending on whether the string a \"short\" representation of the color is possible and whether there's an alpha channel. Returns: Type Description str The hexadecimal representation of the color. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py as\\\\\\\\\\\\\\_rgb ¶ as\\\\\\\\\\\\\\_rgb() Color as an rgb(, , \\\\\\*\\\\\\*) or rgba(, , \\\\\\*\\\\\\*, ) string. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py as\\\\\\\\\\\\\\_rgb\\\\\\\\\\\\\\_tuple ¶ as\\\\\\\\\\\\\\_rgb\\\\\\\\\\\\\\_tuple(\\\\\\\\\\\\\\*, alpha=None) Returns the color as an RGB or RGBA tuple. Parameters: Name Type Description Default alpha bool | None Whether to include the alpha channel. There are three options for this input: None (default): Include alpha only if it's set. (e.g. not None) True: Always include alpha. False: Always omit alpha. None Returns: Type Description ColorTuple A tuple that contains the values of the red, green, and blue channels in the range 0 to 255. If alpha is included, it is in the range 0 to 1. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py as\\\\\\\\\\\\\\_hsl ¶ as\\\\\\\\\\\\\\_hsl() Color as an hsl(, , ) or hsl(, , , ) string. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py as\\\\\\\\\\\\\\_hsl\\\\\\\\\\\\\\_tuple ¶ as\\\\\\\\\\\\\\_hsl\\\\\\\\\\\\\\_tuple(\\\\\\\\\\\\\\*, alpha=None) Returns the color as an HSL or HSLA tuple. Parameters: Name Type Description Default alpha bool | None Whether to include the alpha channel. None (default): Include the alpha channel only if it's set (e.g. not None). True: Always include alpha. False: Always omit alpha. None Returns: Type Description HslColorTuple The color as a tuple of hue, saturation, lightness, and alpha (if included). All elements are in the range 0 to 1. Note This is HSL as used in HTML and most other places, not HLS as used in Python's colorsys. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py parse\\\\\\\\\\\\\\_tuple ¶ parse\\\\\\\\\\\\\\_tuple(value) Parse a tuple or list to get RGBA values. Parameters: Name Type Description Default value tuple\\\\\\\\\\\\\\[Any, ...\\\\\\\\\\\\\\] A tuple or list. required Returns: Type Description RGBA An RGBA tuple parsed from the input tuple. Raises: Type Description PydanticCustomError If tuple is not valid. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py parse\\\\\\\\\\\\\\_str ¶ parse\\\\\\\\\\\\\\_str(value) Parse a string representing a color to an RGBA tuple. Possible formats for the input string include: named color, see COLORS\\\\\\\\\\\\\\_BY\\\\\\\\\\\\\\_NAME hex short eg. fff (prefix can be #, 0x or nothing) hex long eg. ffffff (prefix can be #, 0x or nothing) rgb(, , \\\\\\*\\\\\\*) rgba(, , \\\\\\*\\\\\\*,\\\\\\*\\\\\\*\\\\\\*\\\\\\* \\\\\\*\\\\\\*\\\\\\*\\\\\\*) transparent Parameters: Name Type Description Default value str A string representing a color. required Returns: Type Description RGBA An RGBA tuple parsed from the input string. Raises: Type Description ValueError If the input string cannot be parsed to an RGBA tuple. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py ints\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_rgba ¶ ints\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_rgba(r, g, b, alpha=None) Converts integer or string values for RGB color and an optional alpha value to an RGBA object. Parameters: Name Type Description Default r int | str An integer or string representing the red color value. required g int | str An integer or string representing the green color value. required b int | str An integer or string representing the blue color value. required alpha float | None A float representing the alpha value. Defaults to None. None Returns: Type Description RGBA An instance of the RGBA class with the corresponding color and alpha values. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py parse\\\\\\\\\\\\\\_color\\\\\\\\\\\\\\_value ¶ parse\\\\\\\\\\\\\\_color\\\\\\\\\\\\\\_value(value, max\\\\\\\\\\\\\\_val=255) Parse the color value provided and return a number between 0 and 1. Parameters: Name Type Description Default value int | str An integer or string color value. required max\\\\\\\\\\\\\\_val int Maximum range value. Defaults to 255. 255 Raises: Type Description PydanticCustomError If the value is not a valid color. Returns: Type Description float A number between 0 and 1. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py parse\\\\\\\\\\\\\\_float\\\\\\\\\\\\\\_alpha ¶ parse\\\\\\\\\\\\\\_float\\\\\\\\\\\\\\_alpha(value) Parse an alpha value checking it's a valid float in the range 0 to 1. Parameters: Name Type Description Default value None | str | float | int The input value to parse. required Returns: Type Description float | None The parsed value as a float, or None if the value was None or equal 1. Raises: Type Description PydanticCustomError If the input value cannot be successfully parsed as a float in the expected range. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py parse\\\\\\\\\\\\\\_hsl ¶ parse\\\\\\\\\\\\\\_hsl(h, h\\\\\\\\\\\\\\_units, sat, light, alpha=None) Parse raw hue, saturation, lightness, and alpha values and convert to RGBA. Parameters: Name Type Description Default h str The hue value. required h\\\\\\\\\\\\\\_units str The unit for hue value. required sat str The saturation value. required light str The lightness value. required alpha float | None Alpha value. None Returns: Type Description RGBA An instance of RGBA. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py float\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_255 ¶ float\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_255(c) Converts a float value between 0 and 1 (inclusive) to an integer between 0 and 255 (inclusive). Parameters: Name Type Description Default c float The float value to be converted. Must be between 0 and 1 (inclusive). required Returns: Type Description int The integer equivalent of the given float value rounded to the nearest whole number. Source code in pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types/color.py Made with Material for MkDocs Insiders\\\\\\*\\\\\\*\\\\\\*\\\\\\*\\\\\\*\\\\\\*\\\\\\*\\\\\\*"
  },
  {
    "title": "Pydantic Settings - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/pydantic_settings/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Pydantic Settings Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic\\\\\\\\\\\\\\_settings PydanticBaseSettingsSource get\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value() field\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_complex() prepare\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value() decode\\\\\\\\\\\\\\_complex\\\\\\\\\\\\\\_value() BaseSettings settings\\\\\\\\\\\\\\_customise\\\\\\\\\\\\\\_sources() InitSettingsSource SecretsSettingsSource find\\\\\\\\\\\\\\_case\\\\\\\\\\\\\\_path() get\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value() EnvSettingsSource get\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value() prepare\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value() next\\\\\\\\\\\\\\_field() explode\\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_vars() DotEnvSettingsSource Pydantic Settings PydanticBaseSettingsSource ¶ PydanticBaseSettingsSource(settings\\\\\\\\\\\\\\_cls) Bases: ABC Abstract base class for settings sources, every settings source classes should inherit from it. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py get\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value abstractmethod ¶ get\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value(field, field\\\\\\\\\\\\\\_name) Gets the value, the key for model creation, and a flag to determine whether value is complex. This is an abstract method that should be overridden in every settings source classes. Parameters: Name Type Description Default field FieldInfo The field. required field\\\\\\\\\\\\\\_name str The field name. required Returns: Type Description tuple\\\\\\\\\\\\\\[Any, str, bool\\\\\\\\\\\\\\] A tuple contains the key, value and a flag to determine whether value is complex. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py field\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_complex ¶ field\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_complex(field) Checks whether a field is complex, in which case it will attempt to be parsed as JSON. Parameters: Name Type Description Default field FieldInfo The field. required Returns: Type Description bool Whether the field is complex. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py prepare\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value ¶ prepare\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value( field\\\\\\\\\\\\\\_name, field, value, value\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_complex ) Prepares the value of a field. Parameters: Name Type Description Default field\\\\\\\\\\\\\\_name str The field name. required field FieldInfo The field. required value Any The value of the field that has to be prepared. required value\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_complex bool A flag to determine whether value is complex. required Returns: Type Description Any The prepared value. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py decode\\\\\\\\\\\\\\_complex\\\\\\\\\\\\\\_value ¶ decode\\\\\\\\\\\\\\_complex\\\\\\\\\\\\\\_value(field\\\\\\\\\\\\\\_name, field, value) Decode the value for a complex field Parameters: Name Type Description Default field\\\\\\\\\\\\\\_name str The field name. required field FieldInfo The field. required value Any The value of the field that has to be prepared. required Returns: Type Description Any The decoded value for further preparation Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py BaseSettings ¶ BaseSettings( \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_self\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, \\\\\\\\\\\\\\_case\\\\\\\\\\\\\\_sensitive=None, \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_prefix=None, \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_file=ENV\\\\\\\\\\\\\\_FILE\\\\\\\\\\\\\\_SENTINEL, \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_encoding=None, \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_nested\\\\\\\\\\\\\\_delimiter=None, \\\\\\\\\\\\\\_secrets\\\\\\\\\\\\\\_dir=None, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*values ) Bases: BaseModel Base class for settings, allowing values to be overridden by environment variables. This is useful in production for secrets you do not wish to save in code, it plays nicely with docker(-compose), Heroku and any 12 factor app design. All the below attributes can be set via model\\\\\\\\\\\\\\_config. Parameters: Name Type Description Default \\\\\\\\\\\\\\_case\\\\\\\\\\\\\\_sensitive bool | None Whether environment variables names should be read with case-sensitivity. Defaults to None. None \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_prefix str | None Prefix for all environment variables. Defaults to None. None \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_file DotenvType | None The env file(s) to load settings values from. Defaults to Path(''), which means that the value from model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['env\\\\\\\\\\\\\\_file'\\\\\\\\\\\\\\] should be used. You can also pass None to indicate that environment variables should not be loaded from an env file. ENV\\\\\\\\\\\\\\_FILE\\\\\\\\\\\\\\_SENTINEL \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_encoding str | None The env file encoding, e.g. 'latin-1'. Defaults to None. None \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_nested\\\\\\\\\\\\\\_delimiter str | None The nested env values delimiter. Defaults to None. None \\\\\\\\\\\\\\_secrets\\\\\\\\\\\\\\_dir str | Path | None The secret files directory. Defaults to None. None Source code in pydantic\\\\\\\\\\\\\\_settings/main.py settings\\\\\\\\\\\\\\_customise\\\\\\\\\\\\\\_sources classmethod ¶ settings\\\\\\\\\\\\\\_customise\\\\\\\\\\\\\\_sources( settings\\\\\\\\\\\\\\_cls, init\\\\\\\\\\\\\\_settings, env\\\\\\\\\\\\\\_settings, dotenv\\\\\\\\\\\\\\_settings, file\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_settings, ) Define the sources and their order for loading the settings values. Parameters: Name Type Description Default settings\\\\\\\\\\\\\\_cls type\\\\\\\\\\\\\\[BaseSettings\\\\\\\\\\\\\\] The Settings class. required init\\\\\\\\\\\\\\_settings PydanticBaseSettingsSource The InitSettingsSource instance. required env\\\\\\\\\\\\\\_settings PydanticBaseSettingsSource The EnvSettingsSource instance. required dotenv\\\\\\\\\\\\\\_settings PydanticBaseSettingsSource The DotEnvSettingsSource instance. required file\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_settings PydanticBaseSettingsSource The SecretsSettingsSource instance. required Returns: Type Description tuple\\\\\\\\\\\\\\[PydanticBaseSettingsSource, ...\\\\\\\\\\\\\\] A tuple containing the sources and their order for loading the settings values. Source code in pydantic\\\\\\\\\\\\\\_settings/main.py InitSettingsSource ¶ InitSettingsSource(settings\\\\\\\\\\\\\\_cls, init\\\\\\\\\\\\\\_kwargs) Bases: PydanticBaseSettingsSource Source class for loading values provided during settings class initialization. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py SecretsSettingsSource ¶ SecretsSettingsSource( settings\\\\\\\\\\\\\\_cls, secrets\\\\\\\\\\\\\\_dir=None, case\\\\\\\\\\\\\\_sensitive=None, env\\\\\\\\\\\\\\_prefix=None, ) Bases: PydanticBaseEnvSettingsSource Source class for loading settings values from secret files. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py find\\\\\\\\\\\\\\_case\\\\\\\\\\\\\\_path classmethod ¶ find\\\\\\\\\\\\\\_case\\\\\\\\\\\\\\_path(dir\\\\\\\\\\\\\\_path, file\\\\\\\\\\\\\\_name, case\\\\\\\\\\\\\\_sensitive) Find a file within path's directory matching filename, optionally ignoring case. Parameters: Name Type Description Default dir\\\\\\\\\\\\\\_path Path Directory path. required file\\\\\\\\\\\\\\_name str File name. required case\\\\\\\\\\\\\\_sensitive bool Whether to search for file name case sensitively. required Returns: Type Description Path | None Whether file path or None if file does not exist in directory. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py get\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value ¶ get\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value(field, field\\\\\\\\\\\\\\_name) Gets the value for field from secret file and a flag to determine whether value is complex. Parameters: Name Type Description Default field FieldInfo The field. required field\\\\\\\\\\\\\\_name str The field name. required Returns: Type Description tuple\\\\\\\\\\\\\\[Any, str, bool\\\\\\\\\\\\\\] A tuple contains the key, value if the file exists otherwise None, and a flag to determine whether value is complex. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py EnvSettingsSource ¶ EnvSettingsSource( settings\\\\\\\\\\\\\\_cls, case\\\\\\\\\\\\\\_sensitive=None, env\\\\\\\\\\\\\\_prefix=None, env\\\\\\\\\\\\\\_nested\\\\\\\\\\\\\\_delimiter=None, ) Bases: PydanticBaseEnvSettingsSource Source class for loading settings values from environment variables. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py get\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value ¶ get\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value(field, field\\\\\\\\\\\\\\_name) Gets the value for field from environment variables and a flag to determine whether value is complex. Parameters: Name Type Description Default field FieldInfo The field. required field\\\\\\\\\\\\\\_name str The field name. required Returns: Type Description tuple\\\\\\\\\\\\\\[Any, str, bool\\\\\\\\\\\\\\] A tuple contains the key, value if the file exists otherwise None, and a flag to determine whether value is complex. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py prepare\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value ¶ prepare\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value( field\\\\\\\\\\\\\\_name, field, value, value\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_complex ) Prepare value for the field. Extract value for nested field. Deserialize value to python object for complex field. Parameters: Name Type Description Default field FieldInfo The field. required field\\\\\\\\\\\\\\_name str The field name. required Returns: Type Description Any A tuple contains prepared value for the field. Raises: Type Description ValuesError When There is an error in deserializing value for complex field. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py next\\\\\\\\\\\\\\_field staticmethod ¶ next\\\\\\\\\\\\\\_field(field, key) Find the field in a sub model by key(env name) By having the following models class SubSubModel(BaseSettings): dvals: Dict class SubModel(BaseSettings): vals: list\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] sub\\\\\\\\\\\\\\_sub\\\\\\\\\\\\\\_model: SubSubModel class Cfg(BaseSettings): sub\\\\\\\\\\\\\\_model: SubModel Then next\\\\\\\\\\\\\\_field(sub\\\\\\\\\\\\\\_model, 'vals') Returns the vals field of SubModel class next\\\\\\\\\\\\\\_field(sub\\\\\\\\\\\\\\_model, 'sub\\\\\\\\\\\\\\_sub\\\\\\\\\\\\\\_model') Returns sub\\\\\\\\\\\\\\_sub\\\\\\\\\\\\\\_model field of SubModel class Parameters: Name Type Description Default field FieldInfo | None The field. required key str The key (env name). required Returns: Type Description FieldInfo | None Field if it finds the next field otherwise None. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py explode\\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_vars ¶ explode\\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_vars(field\\\\\\\\\\\\\\_name, field, env\\\\\\\\\\\\\\_vars) Process env\\\\\\\\\\\\\\_vars and extract the values of keys containing env\\\\\\\\\\\\\\_nested\\\\\\\\\\\\\\_delimiter into nested dictionaries. This is applied to a single field, hence filtering by env\\\\\\\\\\\\\\_var prefix. Parameters: Name Type Description Default field\\\\\\\\\\\\\\_name str The field name. required field FieldInfo The field. required env\\\\\\\\\\\\\\_vars Mapping\\\\\\\\\\\\\\[str, str | None\\\\\\\\\\\\\\] Environment variables. required Returns: Type Description dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] A dictionaty contains extracted values from nested env values. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py DotEnvSettingsSource ¶ DotEnvSettingsSource( settings\\\\\\\\\\\\\\_cls, env\\\\\\\\\\\\\\_file=ENV\\\\\\\\\\\\\\_FILE\\\\\\\\\\\\\\_SENTINEL, env\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_encoding=None, case\\\\\\\\\\\\\\_sensitive=None, env\\\\\\\\\\\\\\_prefix=None, env\\\\\\\\\\\\\\_nested\\\\\\\\\\\\\\_delimiter=None, ) Bases: EnvSettingsSource Source class for loading settings values from env files. Source code in pydantic\\\\\\\\\\\\\\_settings/sources.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "pydantic_core - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/pydantic_core/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 pydantic\\\\\\\\\\\\\\_core Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic Pydantic Core pydantic\\\\\\\\\\\\\\_core pydantic\\\\\\\\\\\\\\_core.core\\\\\\\\\\\\\\_schema Pydantic Settings Pydantic Extra Types Page contents pydantic\\\\\\\\\\\\\\_core \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_version\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ SchemaValidator title validate\\\\\\\\\\\\\\_python() isinstance\\\\\\\\\\\\\\_python() validate\\\\\\\\\\\\\\_json() validate\\\\\\\\\\\\\\_strings() validate\\\\\\\\\\\\\\_assignment() get\\\\\\\\\\\\\\_default\\\\\\\\\\\\\\_value() SchemaSerializer to\\\\\\\\\\\\\\_python() to\\\\\\\\\\\\\\_json() ValidationError title from\\\\\\\\\\\\\\_exception\\\\\\\\\\\\\\_data() error\\\\\\\\\\\\\\_count() errors() json() ErrorDetails type loc msg input ctx InitErrorDetails type loc input ctx SchemaError error\\\\\\\\\\\\\\_count() errors() PydanticCustomError PydanticKnownError PydanticOmit PydanticSerializationError PydanticSerializationUnexpectedValue Url scheme username password host port path query fragment unicode\\\\\\\\\\\\\\_host() query\\\\\\\\\\\\\\_params() unicode\\\\\\\\\\\\\\_string() build() MultiHostUrl scheme path query fragment query\\\\\\\\\\\\\\_params() hosts() unicode\\\\\\\\\\\\\\_string() build() MultiHostHost username password host port ArgsKwargs Some value TzInfo ErrorTypeInfo type message\\\\\\\\\\\\\\_template\\\\\\\\\\\\\\_python example\\\\\\\\\\\\\\_message\\\\\\\\\\\\\\_python message\\\\\\\\\\\\\\_template\\\\\\\\\\\\\\_json example\\\\\\\\\\\\\\_message\\\\\\\\\\\\\\_json example\\\\\\\\\\\\\\_context to\\\\\\\\\\\\\\_json() from\\\\\\\\\\\\\\_json() to\\\\\\\\\\\\\\_jsonable\\\\\\\\\\\\\\_python() pydantic\\\\\\\\\\\\\\_core \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_version\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ module-attribute ¶ \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_version\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_: str SchemaValidator ¶ SchemaValidator is the Python wrapper for pydantic-core's Rust validation logic, internally it owns one CombinedValidator which may in turn own more CombinedValidators which make up the full schema validator. title property ¶ title: str The title of the schema, as used in the heading of ValidationError.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_str\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(). validate\\\\\\\\\\\\\\_python ¶ validate\\\\\\\\\\\\\\_python( input, \\\\\\\\\\\\\\*, strict=None, from\\\\\\\\\\\\\\_attributes=None, context=None, self\\\\\\\\\\\\\\_instance=None ) Validate a Python object against the schema and return the validated object. Parameters: Name Type Description Default input Any The Python object to validate. required strict bool | None Whether to validate the object in strict mode. If None, the value of CoreConfig.strict is used. None from\\\\\\\\\\\\\\_attributes bool | None Whether to validate objects as inputs to models by extracting attributes. If None, the value of CoreConfig.from\\\\\\\\\\\\\\_attributes is used. None context 'dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None' The context to use for validation, this is passed to functional validators as info.context. None self\\\\\\\\\\\\\\_instance Any | None An instance of a model set attributes on from validation, this is used when running validation from the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method of a model. None Raises: Type Description ValidationError If validation fails. Exception Other error types maybe raised if internal errors occur. Returns: Type Description Any The validated object. isinstance\\\\\\\\\\\\\\_python ¶ isinstance\\\\\\\\\\\\\\_python( input, \\\\\\\\\\\\\\*, strict=None, from\\\\\\\\\\\\\\_attributes=None, context=None, self\\\\\\\\\\\\\\_instance=None ) Similar to validate\\\\\\\\\\\\\\_python() but returns a boolean. Arguments match validate\\\\\\\\\\\\\\_python(). This method will not raise ValidationErrors but will raise internal errors. Returns: Type Description bool True if validation succeeds, False if validation fails. validate\\\\\\\\\\\\\\_json ¶ validate\\\\\\\\\\\\\\_json( input, \\\\\\\\\\\\\\*, strict=None, context=None, self\\\\\\\\\\\\\\_instance=None ) Validate JSON data directly against the schema and return the validated Python object. This method should be significantly faster than validate\\\\\\\\\\\\\\_python(json.loads(json\\\\\\\\\\\\\\_data)) as it avoids the need to create intermediate Python objects It also handles constructing the correct Python type even in strict mode, where validate\\\\\\\\\\\\\\_python(json.loads(json\\\\\\\\\\\\\\_data)) would fail validation. Parameters: Name Type Description Default input str | bytes | bytearray The JSON data to validate. required strict bool | None Whether to validate the object in strict mode. If None, the value of CoreConfig.strict is used. None context 'dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None' The context to use for validation, this is passed to functional validators as info.context. None self\\\\\\\\\\\\\\_instance Any | None An instance of a model set attributes on from validation. None Raises: Type Description ValidationError If validation fails or if the JSON data is invalid. Exception Other error types maybe raised if internal errors occur. Returns: Type Description Any The validated Python object. validate\\\\\\\\\\\\\\_strings ¶ validate\\\\\\\\\\\\\\_strings(input, \\\\\\\\\\\\\\*, strict=None, context=None) Validate a string against the schema and return the validated Python object. This is similar to validate\\\\\\\\\\\\\\_json but applies to scenarios where the input will be a string but not JSON data, e.g. URL fragments, query parameters, etc. Parameters: Name Type Description Default input \\\\\\\\\\\\\\_StringInput The input as a string, or bytes/bytearray if strict=False. required strict bool | None Whether to validate the object in strict mode. If None, the value of CoreConfig.strict is used. None context 'dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None' The context to use for validation, this is passed to functional validators as info.context. None Raises: Type Description ValidationError If validation fails or if the JSON data is invalid. Exception Other error types maybe raised if internal errors occur. Returns: Type Description Any The validated Python object. validate\\\\\\\\\\\\\\_assignment ¶ validate\\\\\\\\\\\\\\_assignment( obj, field\\\\\\\\\\\\\\_name, field\\\\\\\\\\\\\\_value, \\\\\\\\\\\\\\*, strict=None, from\\\\\\\\\\\\\\_attributes=None, context=None ) Validate an assignment to a field on a model. Parameters: Name Type Description Default obj Any The model instance being assigned to. required field\\\\\\\\\\\\\\_name str The name of the field to validate assignment for. required field\\\\\\\\\\\\\\_value Any The value to assign to the field. required strict bool | None Whether to validate the object in strict mode. If None, the value of CoreConfig.strict is used. None from\\\\\\\\\\\\\\_attributes bool | None Whether to validate objects as inputs to models by extracting attributes. If None, the value of CoreConfig.from\\\\\\\\\\\\\\_attributes is used. None context 'dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None' The context to use for validation, this is passed to functional validators as info.context. None Raises: Type Description ValidationError If validation fails. Exception Other error types maybe raised if internal errors occur. Returns: Type Description dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | tuple\\\\\\\\\\\\\\[dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\], dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None, set\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] Either the model dict or a tuple of (model\\\\\\\\\\\\\\_data, model\\\\\\\\\\\\\\_extra, fields\\\\\\\\\\\\\\_set) get\\\\\\\\\\\\\\_default\\\\\\\\\\\\\\_value ¶ get\\\\\\\\\\\\\\_default\\\\\\\\\\\\\\_value(\\\\\\\\\\\\\\*, strict=None, context=None) Get the default value for the schema, including running default value validation. Parameters: Name Type Description Default strict bool | None Whether to validate the default value in strict mode. If None, the value of CoreConfig.strict is used. None context Any The context to use for validation, this is passed to functional validators as info.context. None Raises: Type Description ValidationError If validation fails. Exception Other error types maybe raised if internal errors occur. Returns: Type Description Some | None None if the schema has no default value, otherwise a Some containing the default. SchemaSerializer ¶ SchemaSerializer is the Python wrapper for pydantic-core's Rust serialization logic, internally it owns one CombinedSerializer which may in turn own more CombinedSerializers which make up the full schema serializer. to\\\\\\\\\\\\\\_python ¶ to\\\\\\\\\\\\\\_python( value, \\\\\\\\\\\\\\*, mode=None, include=None, exclude=None, by\\\\\\\\\\\\\\_alias=True, exclude\\\\\\\\\\\\\\_unset=False, exclude\\\\\\\\\\\\\\_defaults=False, exclude\\\\\\\\\\\\\\_none=False, round\\\\\\\\\\\\\\_trip=False, warnings=True, fallback=None ) Serialize/marshal a Python object to a Python object including transforming and filtering data. Parameters: Name Type Description Default value Any The Python object to serialize. required mode str | None The serialization mode to use, either 'python' or 'json', defaults to 'python'. In JSON mode, all values are converted to JSON compatible types, e.g. None, int, float, str, list, dict. None include \\\\\\\\\\\\\\_IncEx A set of fields to include, if None all fields are included. None exclude \\\\\\\\\\\\\\_IncEx A set of fields to exclude, if None no fields are excluded. None by\\\\\\\\\\\\\\_alias bool Whether to use the alias names of fields. True exclude\\\\\\\\\\\\\\_unset bool Whether to exclude fields that are not set, e.g. are not included in \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. False exclude\\\\\\\\\\\\\\_defaults bool Whether to exclude fields that are equal to their default value. False exclude\\\\\\\\\\\\\\_none bool Whether to exclude fields that have a value of None. False round\\\\\\\\\\\\\\_trip bool Whether to enable serialization and validation round-trip support. False warnings bool Whether to log warnings when invalid fields are encountered. True fallback Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] | None A function to call when an unknown value is encountered, if None a PydanticSerializationError error is raised. None Raises: Type Description PydanticSerializationError If serialization fails and no fallback function is provided. Returns: Type Description Any The serialized Python object. to\\\\\\\\\\\\\\_json ¶ to\\\\\\\\\\\\\\_json( value, \\\\\\\\\\\\\\*, indent=None, include=None, exclude=None, by\\\\\\\\\\\\\\_alias=True, exclude\\\\\\\\\\\\\\_unset=False, exclude\\\\\\\\\\\\\\_defaults=False, exclude\\\\\\\\\\\\\\_none=False, round\\\\\\\\\\\\\\_trip=False, warnings=True, fallback=None ) Serialize a Python object to JSON including transforming and filtering data. Parameters: Name Type Description Default value Any The Python object to serialize. required indent int | None If None, the JSON will be compact, otherwise it will be pretty-printed with the indent provided. None include \\\\\\\\\\\\\\_IncEx A set of fields to include, if None all fields are included. None exclude \\\\\\\\\\\\\\_IncEx A set of fields to exclude, if None no fields are excluded. None by\\\\\\\\\\\\\\_alias bool Whether to use the alias names of fields. True exclude\\\\\\\\\\\\\\_unset bool Whether to exclude fields that are not set, e.g. are not included in \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. False exclude\\\\\\\\\\\\\\_defaults bool Whether to exclude fields that are equal to their default value. False exclude\\\\\\\\\\\\\\_none bool Whether to exclude fields that have a value of None. False round\\\\\\\\\\\\\\_trip bool Whether to enable serialization and validation round-trip support. False warnings bool Whether to log warnings when invalid fields are encountered. True fallback Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] | None A function to call when an unknown value is encountered, if None a PydanticSerializationError error is raised. None Raises: Type Description PydanticSerializationError If serialization fails and no fallback function is provided. Returns: Type Description bytes JSON bytes. ValidationError ¶ Bases: ValueError ValidationError is the exception raised by pydantic-core when validation fails, it contains a list of errors which detail why validation failed. title property ¶ title: str The title of the error, as used in the heading of str(validation\\\\\\\\\\\\\\_error). from\\\\\\\\\\\\\\_exception\\\\\\\\\\\\\\_data staticmethod ¶ from\\\\\\\\\\\\\\_exception\\\\\\\\\\\\\\_data( title, line\\\\\\\\\\\\\\_errors, input\\\\\\\\\\\\\\_type=\"python\", hide\\\\\\\\\\\\\\_input=False, ) Python constructor for a Validation Error. The API for constructing validation errors will probably change in the future, hence the static method rather than \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. Parameters: Name Type Description Default title str The title of the error, as used in the heading of str(validation\\\\\\\\\\\\\\_error) required line\\\\\\\\\\\\\\_errors list\\\\\\\\\\\\\\[InitErrorDetails\\\\\\\\\\\\\\] A list of InitErrorDetails which contain information about errors that occurred during validation. required input\\\\\\\\\\\\\\_type Literal\\\\\\\\\\\\\\['python', 'json'\\\\\\\\\\\\\\] Whether the error is for a Python object or JSON. 'python' hide\\\\\\\\\\\\\\_input bool Whether to hide the input value in the error message. False error\\\\\\\\\\\\\\_count ¶ error\\\\\\\\\\\\\\_count() Returns: Type Description int The number of errors in the validation error. errors ¶ errors( \\\\\\\\\\\\\\*, include\\\\\\\\\\\\\\_url=True, include\\\\\\\\\\\\\\_context=True, include\\\\\\\\\\\\\\_input=True ) Details about each error in the validation error. Parameters: Name Type Description Default include\\\\\\\\\\\\\\_url bool Whether to include a URL to documentation on the error each error. True include\\\\\\\\\\\\\\_context bool Whether to include the context of each error. True include\\\\\\\\\\\\\\_input bool Whether to include the input value of each error. True Returns: Type Description list\\\\\\\\\\\\\\[ErrorDetails\\\\\\\\\\\\\\] A list of ErrorDetails for each error in the validation error. json ¶ json( \\\\\\\\\\\\\\*, indent=None, include\\\\\\\\\\\\\\_url=True, include\\\\\\\\\\\\\\_context=True, include\\\\\\\\\\\\\\_input=True ) Same as errors() but returns a JSON string. Parameters: Name Type Description Default indent int | None The number of spaces to indent the JSON by, or None for no indentation - compact JSON. None include\\\\\\\\\\\\\\_url bool Whether to include a URL to documentation on the error each error. True include\\\\\\\\\\\\\\_context bool Whether to include the context of each error. True include\\\\\\\\\\\\\\_input bool Whether to include the input value of each error. True Returns: Type Description str a JSON string. ErrorDetails ¶ Bases: \\\\\\\\\\\\\\_TypedDict type instance-attribute ¶ type: str The type of error that occurred, this is an identifier designed for programmatic use that will change rarely or never. type is unique for each error message, and can hence be used as an identifier to build custom error messages. loc instance-attribute ¶ loc: tuple\\\\\\\\\\\\\\[int | str, ...\\\\\\\\\\\\\\] Tuple of strings and ints identifying where in the schema the error occurred. msg instance-attribute ¶ msg: str A human readable error message. input instance-attribute ¶ input: \\\\\\\\\\\\\\_Any The input data at this loc that caused the error. ctx instance-attribute ¶ ctx: \\\\\\\\\\\\\\_NotRequired\\\\\\\\\\\\\\[dict\\\\\\\\\\\\\\[str, \\\\\\\\\\\\\\_Any\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] Values which are required to render the error message, and could hence be useful in rendering custom error messages. Also useful for passing custom error data forward. InitErrorDetails ¶ Bases: \\\\\\\\\\\\\\_TypedDict type instance-attribute ¶ type: str | PydanticCustomError The type of error that occurred, this should a \"slug\" identifier that changes rarely or never. loc instance-attribute ¶ loc: \\\\\\\\\\\\\\_NotRequired\\\\\\\\\\\\\\[tuple\\\\\\\\\\\\\\[int | str, ...\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] Tuple of strings and ints identifying where in the schema the error occurred. input instance-attribute ¶ input: \\\\\\\\\\\\\\_Any The input data at this loc that caused the error. ctx instance-attribute ¶ ctx: \\\\\\\\\\\\\\_NotRequired\\\\\\\\\\\\\\[dict\\\\\\\\\\\\\\[str, \\\\\\\\\\\\\\_Any\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] Values which are required to render the error message, and could hence be useful in rendering custom error messages. Also useful for passing custom error data forward. SchemaError ¶ Bases: Exception Information about errors that occur while building a SchemaValidator or SchemaSerializer. error\\\\\\\\\\\\\\_count ¶ error\\\\\\\\\\\\\\_count() Returns: Type Description int The number of errors in the schema. errors ¶ errors() Returns: Type Description list\\\\\\\\\\\\\\[ErrorDetails\\\\\\\\\\\\\\] A list of ErrorDetails for each error in the schema. PydanticCustomError ¶ Bases: ValueError PydanticKnownError ¶ Bases: ValueError PydanticOmit ¶ Bases: Exception PydanticSerializationError ¶ Bases: ValueError PydanticSerializationUnexpectedValue ¶ Bases: ValueError Url ¶ Bases: SupportsAllComparisons A URL type, internal logic uses the url rust crate originally developed by Mozilla. scheme property ¶ scheme: str The scheme part of the URL. e.g. https in https://user:pass@host:port/path?query#fragment username property ¶ username: str | None The username part of the URL, or None. e.g. user in https://user:pass@host:port/path?query#fragment password property ¶ password: str | None The password part of the URL, or None. e.g. pass in https://user:pass@host:port/path?query#fragment host property ¶ host: str | None The host part of the URL, or None. If the URL must be punycode encoded, this is the encoded host, e.g if the input URL is https://£££.com, host will be xn--9aaa.com port property ¶ port: int | None The port part of the URL, or None. e.g. port in https://user:pass@host:port/path?query#fragment path property ¶ path: str | None The path part of the URL, or None. e.g. /path in https://user:pass@host:port/path?query#fragment query property ¶ query: str | None The query part of the URL, or None. e.g. query in https://user:pass@host:port/path?query#fragment fragment property ¶ fragment: str | None The fragment part of the URL, or None. e.g. fragment in https://user:pass@host:port/path?query#fragment unicode\\\\\\\\\\\\\\_host ¶ unicode\\\\\\\\\\\\\\_host() The host part of the URL as a unicode string, or None. e.g. host in https://user:pass@host:port/path?query#fragment If the URL must be punycode encoded, this is the decoded host, e.g if the input URL is https://£££.com, unicode\\\\\\\\\\\\\\_host() will be £££.com query\\\\\\\\\\\\\\_params ¶ query\\\\\\\\\\\\\\_params() The query part of the URL as a list of key-value pairs. e.g. \\\\\\\\\\\\\\[('foo', 'bar')\\\\\\\\\\\\\\] in https://user:pass@host:port/path?foo=bar#fragment unicode\\\\\\\\\\\\\\_string ¶ unicode\\\\\\\\\\\\\\_string() The URL as a unicode string, unlike \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_str\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_() this will not punycode encode the host. If the URL must be punycode encoded, this is the decoded string, e.g if the input URL is https://£££.com, unicode\\\\\\\\\\\\\\_string() will be https://£££.com build classmethod ¶ build( \\\\\\\\\\\\\\*, scheme, username=None, password=None, host, port=None, path=None, query=None, fragment=None ) Build a new Url instance from its component parts. Parameters: Name Type Description Default scheme str The scheme part of the URL. required username Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] The username part of the URL, or omit for no username. None password Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] The password part of the URL, or omit for no password. None host str The host part of the URL. required port Optional\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] The port part of the URL, or omit for no port. None path Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] The path part of the URL, or omit for no path. None query Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] The query part of the URL, or omit for no query. None fragment Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] The fragment part of the URL, or omit for no fragment. None Returns: Type Description Self An instance of URL MultiHostUrl ¶ Bases: SupportsAllComparisons A URL type with support for multiple hosts, as used by some databases for DSNs, e.g. https://foo.com,bar.com/path. Internal URL logic uses the url rust crate originally developed by Mozilla. scheme property ¶ scheme: str The scheme part of the URL. e.g. https in https://foo.com,bar.com/path?query#fragment path property ¶ path: str | None The path part of the URL, or None. e.g. /path in https://foo.com,bar.com/path?query#fragment query property ¶ query: str | None The query part of the URL, or None. e.g. query in https://foo.com,bar.com/path?query#fragment fragment property ¶ fragment: str | None The fragment part of the URL, or None. e.g. fragment in https://foo.com,bar.com/path?query#fragment query\\\\\\\\\\\\\\_params ¶ query\\\\\\\\\\\\\\_params() The query part of the URL as a list of key-value pairs. e.g. \\\\\\\\\\\\\\[('foo', 'bar')\\\\\\\\\\\\\\] in https://foo.com,bar.com/path?query#fragment hosts ¶ hosts() The hosts of the MultiHostUrl as MultiHostHost typed dicts. from pydantic\\\\\\\\\\\\\\_core import MultiHostUrl mhu = MultiHostUrl('https://foo.com:123,foo:bar@bar.com/path') print(mhu.hosts()) \"\"\" \\\\\\\\\\\\\\[ {'username': None, 'password': None, 'host': 'foo.com', 'port': 123}, {'username': 'foo', 'password': 'bar', 'host': 'bar.com', 'port': 443} \\\\\\\\\\\\\\] Returns: Type Description list\\\\\\\\\\\\\\[MultiHostHost\\\\\\\\\\\\\\] A list of dicts, each representing a host. unicode\\\\\\\\\\\\\\_string ¶ unicode\\\\\\\\\\\\\\_string() The URL as a unicode string, unlike \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_str\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_() this will not punycode encode the hosts. build classmethod ¶ build( \\\\\\\\\\\\\\*, scheme, hosts=None, username=None, password=None, host=None, port=None, path=None, query=None, fragment=None ) Build a new MultiHostUrl instance from its component parts. This method takes either hosts - a list of MultiHostHost typed dicts, or the individual components username, password, host and port. Parameters: Name Type Description Default scheme str The scheme part of the URL. required hosts Optional\\\\\\\\\\\\\\[list\\\\\\\\\\\\\\[MultiHostHost\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] Multiple hosts to build the URL from. None username Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] The username part of the URL. None password Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] The password part of the URL. None host Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] The host part of the URL. None port Optional\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] The port part of the URL. None path Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] The path part of the URL. None query Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] The query part of the URL, or omit for no query. None fragment Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] The fragment part of the URL, or omit for no fragment. None Returns: Type Description Self An instance of MultiHostUrl MultiHostHost ¶ Bases: \\\\\\\\\\\\\\_TypedDict A host part of a multi-host URL. username instance-attribute ¶ username: str | None The username part of this host, or None. password instance-attribute ¶ password: str | None The password part of this host, or None. host instance-attribute ¶ host: str | None The host part of this host, or None. port instance-attribute ¶ port: int | None The port part of this host, or None. ArgsKwargs ¶ Some ¶ Bases: Generic\\\\\\\\\\\\\\[\\\\\\\\\\\\\\_T\\\\\\\\\\\\\\] Similar to Rust's Option::Some type, this identifies a value as being present, and provides a way to access it. Generally used in a union with None to different between \"some value which could be None\" and no value. value property ¶ value: \\\\\\\\\\\\\\_T Returns the value wrapped by Some. TzInfo ¶ Bases: datetime.tzinfo ErrorTypeInfo ¶ Bases: \\\\\\\\\\\\\\_TypedDict Gives information about errors. type instance-attribute ¶ type: ErrorType The type of error that occurred, this should a \"slug\" identifier that changes rarely or never. message\\\\\\\\\\\\\\_template\\\\\\\\\\\\\\_python instance-attribute ¶ message\\\\\\\\\\\\\\_template\\\\\\\\\\\\\\_python: str String template to render a human readable error message from using context, when the input is Python. example\\\\\\\\\\\\\\_message\\\\\\\\\\\\\\_python instance-attribute ¶ example\\\\\\\\\\\\\\_message\\\\\\\\\\\\\\_python: str Example of a human readable error message, when the input is Python. message\\\\\\\\\\\\\\_template\\\\\\\\\\\\\\_json instance-attribute ¶ message\\\\\\\\\\\\\\_template\\\\\\\\\\\\\\_json: \\\\\\\\\\\\\\_NotRequired\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] String template to render a human readable error message from using context, when the input is JSON data. example\\\\\\\\\\\\\\_message\\\\\\\\\\\\\\_json instance-attribute ¶ example\\\\\\\\\\\\\\_message\\\\\\\\\\\\\\_json: \\\\\\\\\\\\\\_NotRequired\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] Example of a human readable error message, when the input is JSON data. example\\\\\\\\\\\\\\_context instance-attribute ¶ example\\\\\\\\\\\\\\_context: dict\\\\\\\\\\\\\\[str, \\\\\\\\\\\\\\_Any\\\\\\\\\\\\\\] | None Example of context values. to\\\\\\\\\\\\\\_json ¶ to\\\\\\\\\\\\\\_json( value, \\\\\\\\\\\\\\*, indent=None, include=None, exclude=None, by\\\\\\\\\\\\\\_alias=True, exclude\\\\\\\\\\\\\\_none=False, round\\\\\\\\\\\\\\_trip=False, timedelta\\\\\\\\\\\\\\_mode=\"iso8601\", bytes\\\\\\\\\\\\\\_mode=\"utf8\", serialize\\\\\\\\\\\\\\_unknown=False, fallback=None ) Serialize a Python object to JSON including transforming and filtering data. This is effectively a standalone version of SchemaSerializer.to\\\\\\\\\\\\\\_json. Parameters: Name Type Description Default value Any The Python object to serialize. required indent int | None If None, the JSON will be compact, otherwise it will be pretty-printed with the indent provided. None include \\\\\\\\\\\\\\_IncEx A set of fields to include, if None all fields are included. None exclude \\\\\\\\\\\\\\_IncEx A set of fields to exclude, if None no fields are excluded. None by\\\\\\\\\\\\\\_alias bool Whether to use the alias names of fields. True exclude\\\\\\\\\\\\\\_none bool Whether to exclude fields that have a value of None. False round\\\\\\\\\\\\\\_trip bool Whether to enable serialization and validation round-trip support. False timedelta\\\\\\\\\\\\\\_mode Literal\\\\\\\\\\\\\\['iso8601', 'float'\\\\\\\\\\\\\\] How to serialize timedelta objects, either 'iso8601' or 'float'. 'iso8601' bytes\\\\\\\\\\\\\\_mode Literal\\\\\\\\\\\\\\['utf8', 'base64'\\\\\\\\\\\\\\] How to serialize bytes objects, either 'utf8' or 'base64'. 'utf8' serialize\\\\\\\\\\\\\\_unknown bool Attempt to serialize unknown types, str(value) will be used, if that fails \"\" will be used. False fallback Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] | None A function to call when an unknown value is encountered, if None a PydanticSerializationError error is raised. None Raises: Type Description PydanticSerializationError If serialization fails and no fallback function is provided. Returns: Type Description bytes JSON bytes. from\\\\\\\\\\\\\\_json ¶ from\\\\\\\\\\\\\\_json(data, \\\\\\\\\\\\\\*, allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan=True) Deserialize JSON data to a Python object. This is effectively a faster version of json.loads(). Parameters: Name Type Description Default data str | bytes | bytearray The JSON data to deserialize. required allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan bool Whether to allow Infinity, -Infinity and NaN values as json.loads() does by default. True Raises: Type Description ValueError If deserialization fails. Returns: Type Description Any The deserialized Python object. to\\\\\\\\\\\\\\_jsonable\\\\\\\\\\\\\\_python ¶ to\\\\\\\\\\\\\\_jsonable\\\\\\\\\\\\\\_python( value, \\\\\\\\\\\\\\*, include=None, exclude=None, by\\\\\\\\\\\\\\_alias=True, exclude\\\\\\\\\\\\\\_none=False, round\\\\\\\\\\\\\\_trip=False, timedelta\\\\\\\\\\\\\\_mode=\"iso8601\", bytes\\\\\\\\\\\\\\_mode=\"utf8\", serialize\\\\\\\\\\\\\\_unknown=False, fallback=None ) Serialize/marshal a Python object to a JSON-serializable Python object including transforming and filtering data. This is effectively a standalone version of SchemaSerializer.to\\\\\\\\\\\\\\_python(mode='json'). Parameters: Name Type Description Default value Any The Python object to serialize. required include \\\\\\\\\\\\\\_IncEx A set of fields to include, if None all fields are included. None exclude \\\\\\\\\\\\\\_IncEx A set of fields to exclude, if None no fields are excluded. None by\\\\\\\\\\\\\\_alias bool Whether to use the alias names of fields. True exclude\\\\\\\\\\\\\\_none bool Whether to exclude fields that have a value of None. False round\\\\\\\\\\\\\\_trip bool Whether to enable serialization and validation round-trip support. False timedelta\\\\\\\\\\\\\\_mode Literal\\\\\\\\\\\\\\['iso8601', 'float'\\\\\\\\\\\\\\] How to serialize timedelta objects, either 'iso8601' or 'float'. 'iso8601' bytes\\\\\\\\\\\\\\_mode Literal\\\\\\\\\\\\\\['utf8', 'base64'\\\\\\\\\\\\\\] How to serialize bytes objects, either 'utf8' or 'base64'. 'utf8' serialize\\\\\\\\\\\\\\_unknown bool Attempt to serialize unknown types, str(value) will be used, if that fails \"\" will be used. False fallback Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] | None A function to call when an unknown value is encountered, if None a PydanticSerializationError error is raised. None Raises: Type Description PydanticSerializationError If serialization fails and no fallback function is provided. Returns: Type Description Any The serialized Python object. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Annotated Handlers - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/annotated_handlers/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Annotated Handlers Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.annotated\\\\\\\\\\\\\\_handlers GetJsonSchemaHandler resolve\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema() GetCoreSchemaHandler field\\\\\\\\\\\\\\_name generate\\\\\\\\\\\\\\_schema() resolve\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema() Annotated Handlers Type annotations to use with \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. GetJsonSchemaHandler ¶ Handler to call into the next JSON schema generation function. Attributes: Name Type Description mode JsonSchemaMode Json schema mode, can be validation or serialization. resolve\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema ¶ resolve\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema(\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_maybe\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema) Get the real schema for a {\"$ref\": ...} schema. If the schema given is not a $ref schema, it will be returned as is. This means you don't have to check before calling this function. Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_maybe\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema JsonSchemaValue A JsonSchemaValue, ref based or not. required Raises: Type Description LookupError If the ref is not found. Returns: Name Type Description JsonSchemaValue JsonSchemaValue A JsonSchemaValue that has no $ref. Source code in pydantic/annotated\\\\\\\\\\\\\\_handlers.py GetCoreSchemaHandler ¶ Handler to call into the next CoreSchema schema generation function. field\\\\\\\\\\\\\\_name property ¶ field\\\\\\\\\\\\\\_name: str | None Get the name of the closest field to this validator. generate\\\\\\\\\\\\\\_schema ¶ generate\\\\\\\\\\\\\\_schema(\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_source\\\\\\\\\\\\\\_type) Generate a schema unrelated to the current context. Use this function if e.g. you are handling schema generation for a sequence and want to generate a schema for its items. Otherwise, you may end up doing something like applying a min\\\\\\\\\\\\\\_length constraint that was intended for the sequence itself to its items! Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_source\\\\\\\\\\\\\\_type Any The input type. required Returns: Name Type Description CoreSchema core\\\\\\\\\\\\\\_schema.CoreSchema The pydantic-core CoreSchema generated. Source code in pydantic/annotated\\\\\\\\\\\\\\_handlers.py resolve\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema ¶ resolve\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema(\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_maybe\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema) Get the real schema for a definition-ref schema. If the schema given is not a definition-ref schema, it will be returned as is. This means you don't have to check before calling this function. Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_maybe\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema core\\\\\\\\\\\\\\_schema.CoreSchema A CoreSchema, ref-based or not. required Raises: Type Description LookupError If the ref is not found. Returns: Type Description core\\\\\\\\\\\\\\_schema.CoreSchema A concrete CoreSchema. Source code in pydantic/annotated\\\\\\\\\\\\\\_handlers.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Pydantic Plugins - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/plugin/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Pydantic Plugins Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.plugin SchemaTypePath PydanticPluginProtocol new\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_validator() BaseValidateHandlerProtocol on\\\\\\\\\\\\\\_enter on\\\\\\\\\\\\\\_success() on\\\\\\\\\\\\\\_error() on\\\\\\\\\\\\\\_exception() ValidatePythonHandlerProtocol on\\\\\\\\\\\\\\_enter() ValidateJsonHandlerProtocol on\\\\\\\\\\\\\\_enter() ValidateStringsHandlerProtocol on\\\\\\\\\\\\\\_enter() Pydantic Plugins Experimental feature Plugins support is experimental and is subject to change in minor releases. Developing plugins is not recommended until the feature becomes stable. Usage Documentation Build a plugin Plugin interface for Pydantic plugins, and related types. SchemaTypePath ¶ Bases: NamedTuple Path defining where schema\\\\\\\\\\\\\\_type was defined, or where TypeAdapter was called. PydanticPluginProtocol ¶ Bases: Protocol Protocol defining the interface for Pydantic plugins. new\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_validator ¶ new\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_validator( schema, schema\\\\\\\\\\\\\\_type, schema\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_path, schema\\\\\\\\\\\\\\_kind, config, plugin\\\\\\\\\\\\\\_settings, ) This method is called for each plugin every time a new SchemaValidator is created. It should return an event handler for each of the three validation methods, or None if the plugin does not implement that method. Parameters: Name Type Description Default schema CoreSchema The schema to validate against. required schema\\\\\\\\\\\\\\_type Any The original type which the schema was created from, e.g. the model class. required schema\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_path SchemaTypePath Path defining where schema\\\\\\\\\\\\\\_type was defined, or where TypeAdapter was called. required schema\\\\\\\\\\\\\\_kind SchemaKind The kind of schema to validate against. required config CoreConfig | None The config to use for validation. required plugin\\\\\\\\\\\\\\_settings dict\\\\\\\\\\\\\\[str, object\\\\\\\\\\\\\\] Any plugin settings. required Returns: Type Description tuple\\\\\\\\\\\\\\[ValidatePythonHandlerProtocol | None, ValidateJsonHandlerProtocol | None, ValidateStringsHandlerProtocol | None\\\\\\\\\\\\\\] A tuple of optional event handlers for each of the three validation methods - validate\\\\\\\\\\\\\\_python, validate\\\\\\\\\\\\\\_json, validate\\\\\\\\\\\\\\_strings. Source code in pydantic/plugin/\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.py BaseValidateHandlerProtocol ¶ Bases: Protocol Base class for plugin callbacks protocols. You shouldn't implement this protocol directly, instead use one of the subclasses with adds the correctly typed on\\\\\\\\\\\\\\_error method. on\\\\\\\\\\\\\\_enter instance-attribute ¶ on\\\\\\\\\\\\\\_enter: Callable\\\\\\\\\\\\\\[..., None\\\\\\\\\\\\\\] on\\\\\\\\\\\\\\_enter is changed to be more specific on all subclasses on\\\\\\\\\\\\\\_success ¶ on\\\\\\\\\\\\\\_success(result) Callback to be notified of successful validation. Parameters: Name Type Description Default result Any The result of the validation. required Source code in pydantic/plugin/\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.py on\\\\\\\\\\\\\\_error ¶ on\\\\\\\\\\\\\\_error(error) Callback to be notified of validation errors. Parameters: Name Type Description Default error ValidationError The validation error. required Source code in pydantic/plugin/\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.py on\\\\\\\\\\\\\\_exception ¶ on\\\\\\\\\\\\\\_exception(exception) Callback to be notified of validation exceptions. Parameters: Name Type Description Default exception Exception The exception raised during validation. required Source code in pydantic/plugin/\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.py ValidatePythonHandlerProtocol ¶ Bases: BaseValidateHandlerProtocol, Protocol Event handler for SchemaValidator.validate\\\\\\\\\\\\\\_python. on\\\\\\\\\\\\\\_enter ¶ on\\\\\\\\\\\\\\_enter( input, \\\\\\\\\\\\\\*, strict=None, from\\\\\\\\\\\\\\_attributes=None, context=None, self\\\\\\\\\\\\\\_instance=None ) Callback to be notified of validation start, and create an instance of the event handler. Parameters: Name Type Description Default input Any The input to be validated. required strict bool | None Whether to validate the object in strict mode. None from\\\\\\\\\\\\\\_attributes bool | None Whether to validate objects as inputs by extracting attributes. None context dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None The context to use for validation, this is passed to functional validators. None self\\\\\\\\\\\\\\_instance Any | None An instance of a model to set attributes on from validation, this is used when running validation from the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method of a model. None Source code in pydantic/plugin/\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.py ValidateJsonHandlerProtocol ¶ Bases: BaseValidateHandlerProtocol, Protocol Event handler for SchemaValidator.validate\\\\\\\\\\\\\\_json. on\\\\\\\\\\\\\\_enter ¶ on\\\\\\\\\\\\\\_enter( input, \\\\\\\\\\\\\\*, strict=None, context=None, self\\\\\\\\\\\\\\_instance=None ) Callback to be notified of validation start, and create an instance of the event handler. Parameters: Name Type Description Default input str | bytes | bytearray The JSON data to be validated. required strict bool | None Whether to validate the object in strict mode. None context dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None The context to use for validation, this is passed to functional validators. None self\\\\\\\\\\\\\\_instance Any | None An instance of a model to set attributes on from validation, this is used when running validation from the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method of a model. None Source code in pydantic/plugin/\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.py ValidateStringsHandlerProtocol ¶ Bases: BaseValidateHandlerProtocol, Protocol Event handler for SchemaValidator.validate\\\\\\\\\\\\\\_strings. on\\\\\\\\\\\\\\_enter ¶ on\\\\\\\\\\\\\\_enter(input, \\\\\\\\\\\\\\*, strict=None, context=None) Callback to be notified of validation start, and create an instance of the event handler. Parameters: Name Type Description Default input StringInput The string data to be validated. required strict bool | None Whether to validate the object in strict mode. None context dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None The context to use for validation, this is passed to functional validators. None Source code in pydantic/plugin/\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Network Types - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/networks/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Network Types Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.networks AnyUrl AnyHttpUrl HttpUrl FileUrl PostgresDsn CockroachDsn AmqpDsn RedisDsn MongoDsn KafkaDsn MySQLDsn MariaDBDsn MAX\\\\\\\\\\\\\\_EMAIL\\\\\\\\\\\\\\_LENGTH UrlConstraints EmailStr NameEmail IPvAnyAddress IPvAnyInterface IPvAnyNetwork validate\\\\\\\\\\\\\\_email() Network Types The networks module contains types for common network-related fields. AnyUrl module-attribute ¶ AnyUrl = Url Base type for all URLs. Any scheme allowed Top-level domain (TLD) not required Host required Assuming an input URL of http://samuel:pass@example.com:8000/the/path/?query=here#fragment=is;this=bit, the types export the following properties: scheme: the URL scheme (http), always set. host: the URL host (example.com), always set. username: optional username if included (samuel). password: optional password if included (pass). port: optional port (8000). path: optional path (/the/path/). query: optional URL query (for example, GET arguments or \"search string\", such as query=here). fragment: optional fragment (fragment=is;this=bit). AnyHttpUrl module-attribute ¶ AnyHttpUrl = Annotated\\\\\\\\\\\\\\[ Url, UrlConstraints(allowed\\\\\\\\\\\\\\_schemes=\\\\\\\\\\\\\\[\"http\", \"https\"\\\\\\\\\\\\\\]) \\\\\\\\\\\\\\] A type that will accept any http or https URL. TLD not required Host required HttpUrl module-attribute ¶ HttpUrl = Annotated\\\\\\\\\\\\\\[ Url, UrlConstraints( max\\\\\\\\\\\\\\_length=2083, allowed\\\\\\\\\\\\\\_schemes=\\\\\\\\\\\\\\[\"http\", \"https\"\\\\\\\\\\\\\\] ), \\\\\\\\\\\\\\] A type that will accept any http or https URL. TLD required Host required Max length 2083 from pydantic import BaseModel, HttpUrl, ValidationError class MyModel(BaseModel): url: HttpUrl m = MyModel(url='http://www.example.com') print(m.url) #> http://www.example.com/ try: MyModel(url='ftp://invalid.url') except ValidationError as e: print(e) ''' 1 validation error for MyModel url URL scheme should be 'http' or 'https' \\\\\\\\\\\\\\[type=url\\\\\\\\\\\\\\_scheme, input\\\\\\\\\\\\\\_value='ftp://invalid.url', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' try: MyModel(url='not a url') except ValidationError as e: print(e) ''' 1 validation error for MyModel url Input should be a valid URL, relative URL without a base \\\\\\\\\\\\\\[type=url\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='not a url', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' \"International domains\" (e.g. a URL where the host or TLD includes non-ascii characters) will be encoded via punycode (see this article for a good description of why this is important): from pydantic import BaseModel, HttpUrl class MyModel(BaseModel): url: HttpUrl m1 = MyModel(url='http://puny£code.com') print(m1.url) #> http://xn--punycode-eja.com/ m2 = MyModel(url='https://www.аррӏе.com/') print(m2.url) #> https://www.xn--80ak6aa92e.com/ m3 = MyModel(url='https://www.example.珠宝/') print(m3.url) #> https://www.example.xn--pbt977c/ Underscores in Hostnames In Pydantic, underscores are allowed in all parts of a domain except the TLD. Technically this might be wrong - in theory the hostname cannot have underscores, but subdomains can. To explain this; consider the following two cases: exam\\\\\\\\\\\\\\_ple.co.uk: the hostname is exam\\\\\\\\\\\\\\_ple, which should not be allowed since it contains an underscore. foo\\\\\\\\\\\\\\_bar.example.com the hostname is example, which should be allowed since the underscore is in the subdomain. Without having an exhaustive list of TLDs, it would be impossible to differentiate between these two. Therefore underscores are allowed, but you can always do further validation in a validator if desired. Also, Chrome, Firefox, and Safari all currently accept http://exam\\\\\\\\\\\\\\_ple.com as a URL, so we're in good (or at least big) company. FileUrl module-attribute ¶ FileUrl = Annotated\\\\\\\\\\\\\\[ Url, UrlConstraints(allowed\\\\\\\\\\\\\\_schemes=\\\\\\\\\\\\\\[\"file\"\\\\\\\\\\\\\\]) \\\\\\\\\\\\\\] A type that will accept any file URL. Host not required PostgresDsn module-attribute ¶ PostgresDsn = Annotated\\\\\\\\\\\\\\[ MultiHostUrl, UrlConstraints( host\\\\\\\\\\\\\\_required=True, allowed\\\\\\\\\\\\\\_schemes=\\\\\\\\\\\\\\[ \"postgres\", \"postgresql\", \"postgresql+asyncpg\", \"postgresql+pg8000\", \"postgresql+psycopg\", \"postgresql+psycopg2\", \"postgresql+psycopg2cffi\", \"postgresql+py-postgresql\", \"postgresql+pygresql\", \\\\\\\\\\\\\\], ), \\\\\\\\\\\\\\] A type that will accept any Postgres DSN. User info required TLD not required Host required Supports multiple hosts If further validation is required, these properties can be used by validators to enforce specific behaviour: from pydantic import ( BaseModel, HttpUrl, PostgresDsn, ValidationError, field\\\\\\\\\\\\\\_validator, ) class MyModel(BaseModel): url: HttpUrl m = MyModel(url='http://www.example.com') # the repr() method for a url will display all properties of the url print(repr(m.url)) #> Url('http://www.example.com/') print(m.url.scheme) #> http print(m.url.host) #> www.example.com print(m.url.port) #> 80 class MyDatabaseModel(BaseModel): db: PostgresDsn @field\\\\\\\\\\\\\\_validator('db') def check\\\\\\\\\\\\\\_db\\\\\\\\\\\\\\_name(cls, v): assert v.path and len(v.path) > 1, 'database must be provided' return v m = MyDatabaseModel(db='postgres://user:pass@localhost:5432/foobar') print(m.db) #> postgres://user:pass@localhost:5432/foobar try: MyDatabaseModel(db='postgres://user:pass@localhost:5432') except ValidationError as e: print(e) ''' 1 validation error for MyDatabaseModel db Assertion failed, database must be provided assert (None) + where None = MultiHostUrl('postgres://user:pass@localhost:5432').path \\\\\\\\\\\\\\[type=assertion\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='postgres://user:pass@localhost:5432', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' CockroachDsn module-attribute ¶ CockroachDsn = Annotated\\\\\\\\\\\\\\[ Url, UrlConstraints( host\\\\\\\\\\\\\\_required=True, allowed\\\\\\\\\\\\\\_schemes=\\\\\\\\\\\\\\[ \"cockroachdb\", \"cockroachdb+psycopg2\", \"cockroachdb+asyncpg\", \\\\\\\\\\\\\\], ), \\\\\\\\\\\\\\] A type that will accept any Cockroach DSN. User info required TLD not required Host required AmqpDsn module-attribute ¶ AmqpDsn = Annotated\\\\\\\\\\\\\\[ Url, UrlConstraints(allowed\\\\\\\\\\\\\\_schemes=\\\\\\\\\\\\\\[\"amqp\", \"amqps\"\\\\\\\\\\\\\\]) \\\\\\\\\\\\\\] A type that will accept any AMQP DSN. User info required TLD not required Host required RedisDsn module-attribute ¶ RedisDsn = Annotated\\\\\\\\\\\\\\[ Url, UrlConstraints( allowed\\\\\\\\\\\\\\_schemes=\\\\\\\\\\\\\\[\"redis\", \"rediss\"\\\\\\\\\\\\\\], default\\\\\\\\\\\\\\_host=\"localhost\", default\\\\\\\\\\\\\\_port=6379, default\\\\\\\\\\\\\\_path=\"/0\", ), \\\\\\\\\\\\\\] A type that will accept any Redis DSN. User info required TLD not required Host required (e.g., rediss://:pass@localhost) MongoDsn module-attribute ¶ MongoDsn = Annotated\\\\\\\\\\\\\\[ MultiHostUrl, UrlConstraints( allowed\\\\\\\\\\\\\\_schemes=\\\\\\\\\\\\\\[\"mongodb\", \"mongodb+srv\"\\\\\\\\\\\\\\], default\\\\\\\\\\\\\\_port=27017, ), \\\\\\\\\\\\\\] A type that will accept any MongoDB DSN. User info not required Database name not required Port not required User info may be passed without user part (e.g., mongodb://mongodb0.example.com:27017). KafkaDsn module-attribute ¶ KafkaDsn = Annotated\\\\\\\\\\\\\\[ Url, UrlConstraints( allowed\\\\\\\\\\\\\\_schemes=\\\\\\\\\\\\\\[\"kafka\"\\\\\\\\\\\\\\], default\\\\\\\\\\\\\\_host=\"localhost\", default\\\\\\\\\\\\\\_port=9092, ), \\\\\\\\\\\\\\] A type that will accept any Kafka DSN. User info required TLD not required Host required MySQLDsn module-attribute ¶ MySQLDsn = Annotated\\\\\\\\\\\\\\[ Url, UrlConstraints( allowed\\\\\\\\\\\\\\_schemes=\\\\\\\\\\\\\\[ \"mysql\", \"mysql+mysqlconnector\", \"mysql+aiomysql\", \"mysql+asyncmy\", \"mysql+mysqldb\", \"mysql+pymysql\", \"mysql+cymysql\", \"mysql+pyodbc\", \\\\\\\\\\\\\\], default\\\\\\\\\\\\\\_port=3306, ), \\\\\\\\\\\\\\] A type that will accept any MySQL DSN. User info required TLD not required Host required MariaDBDsn module-attribute ¶ MariaDBDsn = Annotated\\\\\\\\\\\\\\[ Url, UrlConstraints( allowed\\\\\\\\\\\\\\_schemes=\\\\\\\\\\\\\\[ \"mariadb\", \"mariadb+mariadbconnector\", \"mariadb+pymysql\", \\\\\\\\\\\\\\], default\\\\\\\\\\\\\\_port=3306, ), \\\\\\\\\\\\\\] A type that will accept any MariaDB DSN. User info required TLD not required Host required MAX\\\\\\\\\\\\\\_EMAIL\\\\\\\\\\\\\\_LENGTH module-attribute ¶ MAX\\\\\\\\\\\\\\_EMAIL\\\\\\\\\\\\\\_LENGTH = 2048 Maximum length for an email. A somewhat arbitrary but very generous number compared to what is allowed by most implementations. UrlConstraints dataclass ¶ Bases: \\\\\\\\\\\\\\_fields.PydanticMetadata Url constraints. Attributes: Name Type Description max\\\\\\\\\\\\\\_length int | None The maximum length of the url. Defaults to None. allowed\\\\\\\\\\\\\\_schemes list\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] | None The allowed schemes. Defaults to None. host\\\\\\\\\\\\\\_required bool | None Whether the host is required. Defaults to None. default\\\\\\\\\\\\\\_host str | None The default host. Defaults to None. default\\\\\\\\\\\\\\_port int | None The default port. Defaults to None. default\\\\\\\\\\\\\\_path str | None The default path. Defaults to None. EmailStr ¶ Info To use this type, you need to install the optional email-validator package: pip install email-validator Validate email addresses. from pydantic import BaseModel, EmailStr class Model(BaseModel): email: EmailStr print(Model(email='contact@mail.com')) #> email='contact@mail.com' NameEmail ¶ NameEmail(name, email) Bases: \\\\\\\\\\\\\\_repr.Representation Info To use this type, you need to install the optional email-validator package: pip install email-validator Validate a name and email address combination, as specified by RFC 5322. The NameEmail has two properties: name and email. In case the name is not provided, it's inferred from the email address. from pydantic import BaseModel, NameEmail class User(BaseModel): email: NameEmail user = User(email='Fred Bloggs ') print(user.email) #> Fred Bloggs print(user.email.name) #> Fred Bloggs user = User(email='fred.bloggs@example.com') print(user.email) #> fred.bloggs print(user.email.name) #> fred.bloggs Source code in pydantic/networks.py IPvAnyAddress ¶ Validate an IPv4 or IPv6 address. from pydantic import BaseModel from pydantic.networks import IPvAnyAddress class IpModel(BaseModel): ip: IPvAnyAddress print(IpModel(ip='127.0.0.1')) #> ip=IPv4Address('127.0.0.1') try: IpModel(ip='http://www.example.com') except ValueError as e: print(e.errors()) ''' \\\\\\\\\\\\\\[ { 'type': 'ip\\\\\\\\\\\\\\_any\\\\\\\\\\\\\\_address', 'loc': ('ip',), 'msg': 'value is not a valid IPv4 or IPv6 address', 'input': 'http://www.example.com', } \\\\\\\\\\\\\\] ''' IPvAnyInterface ¶ Validate an IPv4 or IPv6 interface. IPvAnyNetwork ¶ Validate an IPv4 or IPv6 network. validate\\\\\\\\\\\\\\_email ¶ validate\\\\\\\\\\\\\\_email(value) Email address validation using email-validator. Note Note that: Raw IP address (literal) domain parts are not allowed. \"John Doe \" style \"pretty\" email addresses are processed. Spaces are striped from the beginning and end of addresses, but no error is raised. Source code in pydantic/networks.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Pydantic Types - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/types/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Pydantic Types Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.types StrictBool PositiveInt NegativeInt NonPositiveInt NonNegativeInt StrictInt PositiveFloat NegativeFloat NonPositiveFloat NonNegativeFloat StrictFloat FiniteFloat StrictBytes StrictStr UUID1 UUID3 UUID4 UUID5 FilePath DirectoryPath NewPath Base64Bytes Base64Str Base64UrlBytes Base64UrlStr JsonValue Strict AllowInfNan StringConstraints ImportString UuidVersion Json SecretStr SecretBytes PaymentCardNumber masked validate() validate\\\\\\\\\\\\\\_digits() validate\\\\\\\\\\\\\\_luhn\\\\\\\\\\\\\\_check\\\\\\\\\\\\\\_digit() validate\\\\\\\\\\\\\\_brand() ByteSize human\\\\\\\\\\\\\\_readable() to() PastDate FutureDate AwareDatetime NaiveDatetime PastDatetime FutureDatetime EncoderProtocol decode() encode() get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_format() Base64Encoder decode() encode() get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_format() Base64UrlEncoder decode() encode() get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_format() EncodedBytes decode() encode() EncodedStr decode\\\\\\\\\\\\\\_str() encode\\\\\\\\\\\\\\_str() GetPydanticSchema Tag Discriminator discriminator custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_type custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_message custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_context conint() confloat() conbytes() constr() conset() confrozenset() conlist() condecimal() condate() Pydantic Types The types module contains custom types used by pydantic. StrictBool module-attribute ¶ StrictBool = Annotated\\\\\\\\\\\\\\[bool, Strict()\\\\\\\\\\\\\\] A boolean that must be either True or False. PositiveInt module-attribute ¶ PositiveInt = Annotated\\\\\\\\\\\\\\[int, annotated\\\\\\\\\\\\\\_types.Gt(0)\\\\\\\\\\\\\\] An integer that must be greater than zero. from pydantic import BaseModel, PositiveInt, ValidationError class Model(BaseModel): positive\\\\\\\\\\\\\\_int: PositiveInt m = Model(positive\\\\\\\\\\\\\\_int=1) print(repr(m)) #> Model(positive\\\\\\\\\\\\\\_int=1) try: Model(positive\\\\\\\\\\\\\\_int=-1) except ValidationError as e: print(e.errors()) ''' \\\\\\\\\\\\\\[ { 'type': 'greater\\\\\\\\\\\\\\_than', 'loc': ('positive\\\\\\\\\\\\\\_int',), 'msg': 'Input should be greater than 0', 'input': -1, 'ctx': {'gt': 0}, 'url': 'https://errors.pydantic.dev/2/v/greater\\\\\\\\\\\\\\_than', } \\\\\\\\\\\\\\] ''' NegativeInt module-attribute ¶ NegativeInt = Annotated\\\\\\\\\\\\\\[int, annotated\\\\\\\\\\\\\\_types.Lt(0)\\\\\\\\\\\\\\] An integer that must be less than zero. from pydantic import BaseModel, NegativeInt, ValidationError class Model(BaseModel): negative\\\\\\\\\\\\\\_int: NegativeInt m = Model(negative\\\\\\\\\\\\\\_int=-1) print(repr(m)) #> Model(negative\\\\\\\\\\\\\\_int=-1) try: Model(negative\\\\\\\\\\\\\\_int=1) except ValidationError as e: print(e.errors()) ''' \\\\\\\\\\\\\\[ { 'type': 'less\\\\\\\\\\\\\\_than', 'loc': ('negative\\\\\\\\\\\\\\_int',), 'msg': 'Input should be less than 0', 'input': 1, 'ctx': {'lt': 0}, 'url': 'https://errors.pydantic.dev/2/v/less\\\\\\\\\\\\\\_than', } \\\\\\\\\\\\\\] ''' NonPositiveInt module-attribute ¶ NonPositiveInt = Annotated\\\\\\\\\\\\\\[int, annotated\\\\\\\\\\\\\\_types.Le(0)\\\\\\\\\\\\\\] An integer that must be less than or equal to zero. from pydantic import BaseModel, NonPositiveInt, ValidationError class Model(BaseModel): non\\\\\\\\\\\\\\_positive\\\\\\\\\\\\\\_int: NonPositiveInt m = Model(non\\\\\\\\\\\\\\_positive\\\\\\\\\\\\\\_int=0) print(repr(m)) #> Model(non\\\\\\\\\\\\\\_positive\\\\\\\\\\\\\\_int=0) try: Model(non\\\\\\\\\\\\\\_positive\\\\\\\\\\\\\\_int=1) except ValidationError as e: print(e.errors()) ''' \\\\\\\\\\\\\\[ { 'type': 'less\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal', 'loc': ('non\\\\\\\\\\\\\\_positive\\\\\\\\\\\\\\_int',), 'msg': 'Input should be less than or equal to 0', 'input': 1, 'ctx': {'le': 0}, 'url': 'https://errors.pydantic.dev/2/v/less\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal', } \\\\\\\\\\\\\\] ''' NonNegativeInt module-attribute ¶ NonNegativeInt = Annotated\\\\\\\\\\\\\\[int, annotated\\\\\\\\\\\\\\_types.Ge(0)\\\\\\\\\\\\\\] An integer that must be greater than or equal to zero. from pydantic import BaseModel, NonNegativeInt, ValidationError class Model(BaseModel): non\\\\\\\\\\\\\\_negative\\\\\\\\\\\\\\_int: NonNegativeInt m = Model(non\\\\\\\\\\\\\\_negative\\\\\\\\\\\\\\_int=0) print(repr(m)) #> Model(non\\\\\\\\\\\\\\_negative\\\\\\\\\\\\\\_int=0) try: Model(non\\\\\\\\\\\\\\_negative\\\\\\\\\\\\\\_int=-1) except ValidationError as e: print(e.errors()) ''' \\\\\\\\\\\\\\[ { 'type': 'greater\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal', 'loc': ('non\\\\\\\\\\\\\\_negative\\\\\\\\\\\\\\_int',), 'msg': 'Input should be greater than or equal to 0', 'input': -1, 'ctx': {'ge': 0}, 'url': 'https://errors.pydantic.dev/2/v/greater\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal', } \\\\\\\\\\\\\\] ''' StrictInt module-attribute ¶ StrictInt = Annotated\\\\\\\\\\\\\\[int, Strict()\\\\\\\\\\\\\\] An integer that must be validated in strict mode. from pydantic import BaseModel, StrictInt, ValidationError class StrictIntModel(BaseModel): strict\\\\\\\\\\\\\\_int: StrictInt try: StrictIntModel(strict\\\\\\\\\\\\\\_int=3.14159) except ValidationError as e: print(e) ''' 1 validation error for StrictIntModel strict\\\\\\\\\\\\\\_int Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=3.14159, input\\\\\\\\\\\\\\_type=float\\\\\\\\\\\\\\] ''' PositiveFloat module-attribute ¶ PositiveFloat = Annotated\\\\\\\\\\\\\\[float, annotated\\\\\\\\\\\\\\_types.Gt(0)\\\\\\\\\\\\\\] A float that must be greater than zero. from pydantic import BaseModel, PositiveFloat, ValidationError class Model(BaseModel): positive\\\\\\\\\\\\\\_float: PositiveFloat m = Model(positive\\\\\\\\\\\\\\_float=1.0) print(repr(m)) #> Model(positive\\\\\\\\\\\\\\_float=1.0) try: Model(positive\\\\\\\\\\\\\\_float=-1.0) except ValidationError as e: print(e.errors()) ''' \\\\\\\\\\\\\\[ { 'type': 'greater\\\\\\\\\\\\\\_than', 'loc': ('positive\\\\\\\\\\\\\\_float',), 'msg': 'Input should be greater than 0', 'input': -1.0, 'ctx': {'gt': 0.0}, 'url': 'https://errors.pydantic.dev/2/v/greater\\\\\\\\\\\\\\_than', } \\\\\\\\\\\\\\] ''' NegativeFloat module-attribute ¶ NegativeFloat = Annotated\\\\\\\\\\\\\\[float, annotated\\\\\\\\\\\\\\_types.Lt(0)\\\\\\\\\\\\\\] A float that must be less than zero. from pydantic import BaseModel, NegativeFloat, ValidationError class Model(BaseModel): negative\\\\\\\\\\\\\\_float: NegativeFloat m = Model(negative\\\\\\\\\\\\\\_float=-1.0) print(repr(m)) #> Model(negative\\\\\\\\\\\\\\_float=-1.0) try: Model(negative\\\\\\\\\\\\\\_float=1.0) except ValidationError as e: print(e.errors()) ''' \\\\\\\\\\\\\\[ { 'type': 'less\\\\\\\\\\\\\\_than', 'loc': ('negative\\\\\\\\\\\\\\_float',), 'msg': 'Input should be less than 0', 'input': 1.0, 'ctx': {'lt': 0.0}, 'url': 'https://errors.pydantic.dev/2/v/less\\\\\\\\\\\\\\_than', } \\\\\\\\\\\\\\] ''' NonPositiveFloat module-attribute ¶ NonPositiveFloat = Annotated\\\\\\\\\\\\\\[float, annotated\\\\\\\\\\\\\\_types.Le(0)\\\\\\\\\\\\\\] A float that must be less than or equal to zero. from pydantic import BaseModel, NonPositiveFloat, ValidationError class Model(BaseModel): non\\\\\\\\\\\\\\_positive\\\\\\\\\\\\\\_float: NonPositiveFloat m = Model(non\\\\\\\\\\\\\\_positive\\\\\\\\\\\\\\_float=0.0) print(repr(m)) #> Model(non\\\\\\\\\\\\\\_positive\\\\\\\\\\\\\\_float=0.0) try: Model(non\\\\\\\\\\\\\\_positive\\\\\\\\\\\\\\_float=1.0) except ValidationError as e: print(e.errors()) ''' \\\\\\\\\\\\\\[ { 'type': 'less\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal', 'loc': ('non\\\\\\\\\\\\\\_positive\\\\\\\\\\\\\\_float',), 'msg': 'Input should be less than or equal to 0', 'input': 1.0, 'ctx': {'le': 0.0}, 'url': 'https://errors.pydantic.dev/2/v/less\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal', } \\\\\\\\\\\\\\] ''' NonNegativeFloat module-attribute ¶ NonNegativeFloat = Annotated\\\\\\\\\\\\\\[float, annotated\\\\\\\\\\\\\\_types.Ge(0)\\\\\\\\\\\\\\] A float that must be greater than or equal to zero. from pydantic import BaseModel, NonNegativeFloat, ValidationError class Model(BaseModel): non\\\\\\\\\\\\\\_negative\\\\\\\\\\\\\\_float: NonNegativeFloat m = Model(non\\\\\\\\\\\\\\_negative\\\\\\\\\\\\\\_float=0.0) print(repr(m)) #> Model(non\\\\\\\\\\\\\\_negative\\\\\\\\\\\\\\_float=0.0) try: Model(non\\\\\\\\\\\\\\_negative\\\\\\\\\\\\\\_float=-1.0) except ValidationError as e: print(e.errors()) ''' \\\\\\\\\\\\\\[ { 'type': 'greater\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal', 'loc': ('non\\\\\\\\\\\\\\_negative\\\\\\\\\\\\\\_float',), 'msg': 'Input should be greater than or equal to 0', 'input': -1.0, 'ctx': {'ge': 0.0}, 'url': 'https://errors.pydantic.dev/2/v/greater\\\\\\\\\\\\\\_than\\\\\\\\\\\\\\_equal', } \\\\\\\\\\\\\\] ''' StrictFloat module-attribute ¶ StrictFloat = Annotated\\\\\\\\\\\\\\[float, Strict(True)\\\\\\\\\\\\\\] A float that must be validated in strict mode. from pydantic import BaseModel, StrictFloat, ValidationError class StrictFloatModel(BaseModel): strict\\\\\\\\\\\\\\_float: StrictFloat try: StrictFloatModel(strict\\\\\\\\\\\\\\_float='1.0') except ValidationError as e: print(e) ''' 1 validation error for StrictFloatModel strict\\\\\\\\\\\\\\_float Input should be a valid number \\\\\\\\\\\\\\[type=float\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='1.0', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' FiniteFloat module-attribute ¶ FiniteFloat = Annotated\\\\\\\\\\\\\\[float, AllowInfNan(False)\\\\\\\\\\\\\\] A float that must be finite (not -inf, inf, or nan). from pydantic import BaseModel, FiniteFloat class Model(BaseModel): finite: FiniteFloat m = Model(finite=1.0) print(m) #> finite=1.0 StrictBytes module-attribute ¶ StrictBytes = Annotated\\\\\\\\\\\\\\[bytes, Strict()\\\\\\\\\\\\\\] A bytes that must be validated in strict mode. StrictStr module-attribute ¶ StrictStr = Annotated\\\\\\\\\\\\\\[str, Strict()\\\\\\\\\\\\\\] A string that must be validated in strict mode. UUID1 module-attribute ¶ UUID1 = Annotated\\\\\\\\\\\\\\[UUID, UuidVersion(1)\\\\\\\\\\\\\\] A UUID that must be version 1. import uuid from pydantic import UUID1, BaseModel class Model(BaseModel): uuid1: UUID1 Model(uuid1=uuid.uuid1()) UUID3 module-attribute ¶ UUID3 = Annotated\\\\\\\\\\\\\\[UUID, UuidVersion(3)\\\\\\\\\\\\\\] A UUID that must be version 3. import uuid from pydantic import UUID3, BaseModel class Model(BaseModel): uuid3: UUID3 Model(uuid3=uuid.uuid3(uuid.NAMESPACE\\\\\\\\\\\\\\_DNS, 'pydantic.org')) UUID4 module-attribute ¶ UUID4 = Annotated\\\\\\\\\\\\\\[UUID, UuidVersion(4)\\\\\\\\\\\\\\] A UUID that must be version 4. import uuid from pydantic import UUID4, BaseModel class Model(BaseModel): uuid4: UUID4 Model(uuid4=uuid.uuid4()) UUID5 module-attribute ¶ UUID5 = Annotated\\\\\\\\\\\\\\[UUID, UuidVersion(5)\\\\\\\\\\\\\\] A UUID that must be version 5. import uuid from pydantic import UUID5, BaseModel class Model(BaseModel): uuid5: UUID5 Model(uuid5=uuid.uuid5(uuid.NAMESPACE\\\\\\\\\\\\\\_DNS, 'pydantic.org')) FilePath module-attribute ¶ FilePath = Annotated\\\\\\\\\\\\\\[Path, PathType('file')\\\\\\\\\\\\\\] A path that must point to a file. from pathlib import Path from pydantic import BaseModel, FilePath, ValidationError class Model(BaseModel): f: FilePath path = Path('text.txt') path.touch() m = Model(f='text.txt') print(m.model\\\\\\\\\\\\\\_dump()) #> {'f': PosixPath('text.txt')} path.unlink() path = Path('directory') path.mkdir(exist\\\\\\\\\\\\\\_ok=True) try: Model(f='directory') # directory except ValidationError as e: print(e) ''' 1 validation error for Model f Path does not point to a file \\\\\\\\\\\\\\[type=path\\\\\\\\\\\\\\_not\\\\\\\\\\\\\\_file, input\\\\\\\\\\\\\\_value='directory', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' path.rmdir() try: Model(f='not-exists-file') except ValidationError as e: print(e) ''' 1 validation error for Model f Path does not point to a file \\\\\\\\\\\\\\[type=path\\\\\\\\\\\\\\_not\\\\\\\\\\\\\\_file, input\\\\\\\\\\\\\\_value='not-exists-file', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' DirectoryPath module-attribute ¶ DirectoryPath = Annotated\\\\\\\\\\\\\\[Path, PathType('dir')\\\\\\\\\\\\\\] A path that must point to a directory. from pathlib import Path from pydantic import BaseModel, DirectoryPath, ValidationError class Model(BaseModel): f: DirectoryPath path = Path('directory/') path.mkdir() m = Model(f='directory/') print(m.model\\\\\\\\\\\\\\_dump()) #> {'f': PosixPath('directory')} path.rmdir() path = Path('file.txt') path.touch() try: Model(f='file.txt') # file except ValidationError as e: print(e) ''' 1 validation error for Model f Path does not point to a directory \\\\\\\\\\\\\\[type=path\\\\\\\\\\\\\\_not\\\\\\\\\\\\\\_directory, input\\\\\\\\\\\\\\_value='file.txt', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' path.unlink() try: Model(f='not-exists-directory') except ValidationError as e: print(e) ''' 1 validation error for Model f Path does not point to a directory \\\\\\\\\\\\\\[type=path\\\\\\\\\\\\\\_not\\\\\\\\\\\\\\_directory, input\\\\\\\\\\\\\\_value='not-exists-directory', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' NewPath module-attribute ¶ NewPath = Annotated\\\\\\\\\\\\\\[Path, PathType('new')\\\\\\\\\\\\\\] A path for a new file or directory that must not already exist. Base64Bytes module-attribute ¶ Base64Bytes = Annotated\\\\\\\\\\\\\\[ bytes, EncodedBytes(encoder=Base64Encoder) \\\\\\\\\\\\\\] A bytes type that is encoded and decoded using the standard (non-URL-safe) base64 encoder. Note Under the hood, Base64Bytes use standard library base64.encodebytes and base64.decodebytes functions. As a result, attempting to decode url-safe base64 data using the Base64Bytes type may fail or produce an incorrect decoding. from pydantic import Base64Bytes, BaseModel, ValidationError class Model(BaseModel): base64\\\\\\\\\\\\\\_bytes: Base64Bytes # Initialize the model with base64 data m = Model(base64\\\\\\\\\\\\\\_bytes=b'VGhpcyBpcyB0aGUgd2F5') # Access decoded value print(m.base64\\\\\\\\\\\\\\_bytes) #> b'This is the way' # Serialize into the base64 form print(m.model\\\\\\\\\\\\\\_dump()) #> {'base64\\\\\\\\\\\\\\_bytes': b'VGhpcyBpcyB0aGUgd2F5 '} # Validate base64 data try: print(Model(base64\\\\\\\\\\\\\\_bytes=b'undecodable').base64\\\\\\\\\\\\\\_bytes) except ValidationError as e: print(e) ''' 1 validation error for Model base64\\\\\\\\\\\\\\_bytes Base64 decoding error: 'Incorrect padding' \\\\\\\\\\\\\\[type=base64\\\\\\\\\\\\\\_decode, input\\\\\\\\\\\\\\_value=b'undecodable', input\\\\\\\\\\\\\\_type=bytes\\\\\\\\\\\\\\] ''' Base64Str module-attribute ¶ Base64Str = Annotated\\\\\\\\\\\\\\[ str, EncodedStr(encoder=Base64Encoder) \\\\\\\\\\\\\\] A str type that is encoded and decoded using the standard (non-URL-safe) base64 encoder. Note Under the hood, Base64Bytes use standard library base64.encodebytes and base64.decodebytes functions. As a result, attempting to decode url-safe base64 data using the Base64Str type may fail or produce an incorrect decoding. from pydantic import Base64Str, BaseModel, ValidationError class Model(BaseModel): base64\\\\\\\\\\\\\\_str: Base64Str # Initialize the model with base64 data m = Model(base64\\\\\\\\\\\\\\_str='VGhlc2UgYXJlbid0IHRoZSBkcm9pZHMgeW91J3JlIGxvb2tpbmcgZm9y') # Access decoded value print(m.base64\\\\\\\\\\\\\\_str) #> These aren't the droids you're looking for # Serialize into the base64 form print(m.model\\\\\\\\\\\\\\_dump()) #> {'base64\\\\\\\\\\\\\\_str': 'VGhlc2UgYXJlbid0IHRoZSBkcm9pZHMgeW91J3JlIGxvb2tpbmcgZm9y '} # Validate base64 data try: print(Model(base64\\\\\\\\\\\\\\_str='undecodable').base64\\\\\\\\\\\\\\_str) except ValidationError as e: print(e) ''' 1 validation error for Model base64\\\\\\\\\\\\\\_str Base64 decoding error: 'Incorrect padding' \\\\\\\\\\\\\\[type=base64\\\\\\\\\\\\\\_decode, input\\\\\\\\\\\\\\_value='undecodable', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' Base64UrlBytes module-attribute ¶ Base64UrlBytes = Annotated\\\\\\\\\\\\\\[ bytes, EncodedBytes(encoder=Base64UrlEncoder) \\\\\\\\\\\\\\] A bytes type that is encoded and decoded using the URL-safe base64 encoder. Note Under the hood, Base64UrlBytes use standard library base64.urlsafe\\\\\\\\\\\\\\_b64encode and base64.urlsafe\\\\\\\\\\\\\\_b64decode functions. As a result, the Base64UrlBytes type can be used to faithfully decode \"vanilla\" base64 data (using '+' and '/'). from pydantic import Base64UrlBytes, BaseModel class Model(BaseModel): base64url\\\\\\\\\\\\\\_bytes: Base64UrlBytes # Initialize the model with base64 data m = Model(base64url\\\\\\\\\\\\\\_bytes=b'SHc\\\\\\\\\\\\\\_dHc-TXc==') print(m) #> base64url\\\\\\\\\\\\\\_bytes=b'Hw?tw>Mw' Base64UrlStr module-attribute ¶ Base64UrlStr = Annotated\\\\\\\\\\\\\\[ str, EncodedStr(encoder=Base64UrlEncoder) \\\\\\\\\\\\\\] A str type that is encoded and decoded using the URL-safe base64 encoder. Note Under the hood, Base64UrlStr use standard library base64.urlsafe\\\\\\\\\\\\\\_b64encode and base64.urlsafe\\\\\\\\\\\\\\_b64decode functions. As a result, the Base64UrlStr type can be used to faithfully decode \"vanilla\" base64 data (using '+' and '/'). from pydantic import Base64UrlStr, BaseModel class Model(BaseModel): base64url\\\\\\\\\\\\\\_str: Base64UrlStr # Initialize the model with base64 data m = Model(base64url\\\\\\\\\\\\\\_str='SHc\\\\\\\\\\\\\\_dHc-TXc==') print(m) #> base64url\\\\\\\\\\\\\\_str='Hw?tw>Mw' JsonValue module-attribute ¶ JsonValue: TypeAlias = Union\\\\\\\\\\\\\\[ List\\\\\\\\\\\\\\[\"JsonValue\"\\\\\\\\\\\\\\], Dict\\\\\\\\\\\\\\[str, \"JsonValue\"\\\\\\\\\\\\\\], str, bool, int, float, None, \\\\\\\\\\\\\\] A JsonValue is used to represent a value that can be serialized to JSON. It may be one of: List\\\\\\\\\\\\\\['JsonValue'\\\\\\\\\\\\\\] Dict\\\\\\\\\\\\\\[str, 'JsonValue'\\\\\\\\\\\\\\] str bool int float None The following example demonstrates how to use JsonValue to validate JSON data, and what kind of errors to expect when input data is not json serializable. import json from pydantic import BaseModel, JsonValue, ValidationError class Model(BaseModel): j: JsonValue valid\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_data = {'j': {'a': {'b': {'c': 1, 'd': \\\\\\\\\\\\\\[2, None\\\\\\\\\\\\\\]}}}} invalid\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_data = {'j': {'a': {'b': ...}}} print(repr(Model.model\\\\\\\\\\\\\\_validate(valid\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_data))) #> Model(j={'a': {'b': {'c': 1, 'd': \\\\\\\\\\\\\\[2, None\\\\\\\\\\\\\\]}}}) print(repr(Model.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json(json.dumps(valid\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_data)))) #> Model(j={'a': {'b': {'c': 1, 'd': \\\\\\\\\\\\\\[2, None\\\\\\\\\\\\\\]}}}) try: Model.model\\\\\\\\\\\\\\_validate(invalid\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_data) except ValidationError as e: print(e) ''' 1 validation error for Model j.dict.a.dict.b input was not a valid JSON value \\\\\\\\\\\\\\[type=invalid-json-value, input\\\\\\\\\\\\\\_value=Ellipsis, input\\\\\\\\\\\\\\_type=ellipsis\\\\\\\\\\\\\\] ''' Strict dataclass ¶ Bases: \\\\\\\\\\\\\\_fields.PydanticMetadata, BaseMetadata Usage Documentation Strict mode with Annotated\\\\\\\\\\\\\\[..., Strict()\\\\\\\\\\\\\\] A field metadata class to indicate that a field should be validated in strict mode. Attributes: Name Type Description strict bool Whether to validate the field in strict mode. Example from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic.types import Strict StrictBool = Annotated\\\\\\\\\\\\\\[bool, Strict()\\\\\\\\\\\\\\] AllowInfNan dataclass ¶ Bases: \\\\\\\\\\\\\\_fields.PydanticMetadata A field metadata class to indicate that a field should allow -inf, inf, and nan. StringConstraints dataclass ¶ Bases: annotated\\\\\\\\\\\\\\_types.GroupedMetadata Usage Documentation String Constraints Apply constraints to str types. Attributes: Name Type Description strip\\\\\\\\\\\\\\_whitespace bool | None Whether to strip whitespace from the string. to\\\\\\\\\\\\\\_upper bool | None Whether to convert the string to uppercase. to\\\\\\\\\\\\\\_lower bool | None Whether to convert the string to lowercase. strict bool | None Whether to validate the string in strict mode. min\\\\\\\\\\\\\\_length int | None The minimum length of the string. max\\\\\\\\\\\\\\_length int | None The maximum length of the string. pattern str | None A regex pattern that the string must match. ImportString ¶ A type that can be used to import a type from a string. ImportString expects a string and loads the Python object importable at that dotted path. Attributes of modules may be separated from the module by : or ., e.g. if 'math:cos' was provided, the resulting field value would be the functioncos. If a . is used and both an attribute and submodule are present at the same path, the module will be preferred. On model instantiation, pointers will be evaluated and imported. There is some nuance to this behavior, demonstrated in the examples below. A known limitation: setting a default value to a string won't result in validation (thus evaluation). This is actively being worked on. Good behavior: from math import cos from pydantic import BaseModel, ImportString, ValidationError class ImportThings(BaseModel): obj: ImportString # A string value will cause an automatic import my\\\\\\\\\\\\\\_cos = ImportThings(obj='math.cos') # You can use the imported function as you would expect cos\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_0 = my\\\\\\\\\\\\\\_cos.obj(0) assert cos\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_0 == 1 # A string whose value cannot be imported will raise an error try: ImportThings(obj='foo.bar') except ValidationError as e: print(e) ''' 1 validation error for ImportThings obj Invalid python path: No module named 'foo.bar' \\\\\\\\\\\\\\[type=import\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='foo.bar', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' # Actual python objects can be assigned as well my\\\\\\\\\\\\\\_cos = ImportThings(obj=cos) my\\\\\\\\\\\\\\_cos\\\\\\\\\\\\\\_2 = ImportThings(obj='math.cos') assert my\\\\\\\\\\\\\\_cos == my\\\\\\\\\\\\\\_cos\\\\\\\\\\\\\\_2 Serializing an ImportString type to json is also possible. from pydantic import BaseModel, ImportString class ImportThings(BaseModel): obj: ImportString # Create an instance m = ImportThings(obj='math:cos') print(m) #> obj= print(m.model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json()) #> {\"obj\":\"math.cos\"} UuidVersion dataclass ¶ A field metadata class to indicate a UUID version. Json ¶ A special type wrapper which loads JSON before parsing. You can use the Json data type to make Pydantic first load a raw JSON string before validating the loaded data into the parametrized type: from typing import Any, List from pydantic import BaseModel, Json, ValidationError class AnyJsonModel(BaseModel): json\\\\\\\\\\\\\\_obj: Json\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] class ConstrainedJsonModel(BaseModel): json\\\\\\\\\\\\\\_obj: Json\\\\\\\\\\\\\\[List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] print(AnyJsonModel(json\\\\\\\\\\\\\\_obj='{\"b\": 1}')) #> json\\\\\\\\\\\\\\_obj={'b': 1} print(ConstrainedJsonModel(json\\\\\\\\\\\\\\_obj='\\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\]')) #> json\\\\\\\\\\\\\\_obj=\\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\] try: ConstrainedJsonModel(json\\\\\\\\\\\\\\_obj=12) except ValidationError as e: print(e) ''' 1 validation error for ConstrainedJsonModel json\\\\\\\\\\\\\\_obj JSON input should be string, bytes or bytearray \\\\\\\\\\\\\\[type=json\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=12, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] ''' try: ConstrainedJsonModel(json\\\\\\\\\\\\\\_obj='\\\\\\\\\\\\\\[a, b\\\\\\\\\\\\\\]') except ValidationError as e: print(e) ''' 1 validation error for ConstrainedJsonModel json\\\\\\\\\\\\\\_obj Invalid JSON: expected value at line 1 column 2 \\\\\\\\\\\\\\[type=json\\\\\\\\\\\\\\_invalid, input\\\\\\\\\\\\\\_value='\\\\\\\\\\\\\\[a, b\\\\\\\\\\\\\\]', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' try: ConstrainedJsonModel(json\\\\\\\\\\\\\\_obj='\\\\\\\\\\\\\\[\"a\", \"b\"\\\\\\\\\\\\\\]') except ValidationError as e: print(e) ''' 2 validation errors for ConstrainedJsonModel json\\\\\\\\\\\\\\_obj.0 Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='a', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] json\\\\\\\\\\\\\\_obj.1 Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='b', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' When you dump the model using model\\\\\\\\\\\\\\_dump or model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json, the dumped value will be the result of validation, not the original JSON string. However, you can use the argument round\\\\\\\\\\\\\\_trip=True to get the original JSON string back: from typing import List from pydantic import BaseModel, Json class ConstrainedJsonModel(BaseModel): json\\\\\\\\\\\\\\_obj: Json\\\\\\\\\\\\\\[List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] print(ConstrainedJsonModel(json\\\\\\\\\\\\\\_obj='\\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\]').model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json()) #> {\"json\\\\\\\\\\\\\\_obj\":\\\\\\\\\\\\\\[1,2,3\\\\\\\\\\\\\\]} print( ConstrainedJsonModel(json\\\\\\\\\\\\\\_obj='\\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\]').model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json(round\\\\\\\\\\\\\\_trip=True) ) #> {\"json\\\\\\\\\\\\\\_obj\":\"\\\\\\\\\\\\\\[1,2,3\\\\\\\\\\\\\\]\"} SecretStr ¶ Bases: \\\\\\\\\\\\\\_SecretField\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] A string used for storing sensitive information that you do not want to be visible in logging or tracebacks. It displays '\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*' instead of the string value on repr() and str() calls. from pydantic import BaseModel, SecretStr class User(BaseModel): username: str password: SecretStr user = User(username='scolvin', password='password1') print(user) #> username='scolvin' password=SecretStr('\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*') print(user.password.get\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_value()) #> password1 SecretBytes ¶ Bases: \\\\\\\\\\\\\\_SecretField\\\\\\\\\\\\\\[bytes\\\\\\\\\\\\\\] A bytes used for storing sensitive information that you do not want to be visible in logging or tracebacks. It displays b'\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*' instead of the string value on repr() and str() calls. from pydantic import BaseModel, SecretBytes class User(BaseModel): username: str password: SecretBytes user = User(username='scolvin', password=b'password1') #> username='scolvin' password=SecretBytes(b'\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*') print(user.password.get\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_value()) #> b'password1' PaymentCardNumber ¶ PaymentCardNumber(card\\\\\\\\\\\\\\_number) Bases: str Based on: https://en.wikipedia.org/wiki/Payment\\\\\\\\\\\\\\_card\\\\\\\\\\\\\\_number. Source code in pydantic/types.py masked property ¶ masked: str Mask all but the last 4 digits of the card number. Returns: Type Description str A masked card number string. validate classmethod ¶ validate(\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_input\\\\\\\\\\\\\\_value, \\\\\\\\\\\\\\_) Validate the card number and return a PaymentCardNumber instance. Source code in pydantic/types.py validate\\\\\\\\\\\\\\_digits classmethod ¶ validate\\\\\\\\\\\\\\_digits(card\\\\\\\\\\\\\\_number) Validate that the card number is all digits. Source code in pydantic/types.py validate\\\\\\\\\\\\\\_luhn\\\\\\\\\\\\\\_check\\\\\\\\\\\\\\_digit classmethod ¶ validate\\\\\\\\\\\\\\_luhn\\\\\\\\\\\\\\_check\\\\\\\\\\\\\\_digit(card\\\\\\\\\\\\\\_number) Based on: https://en.wikipedia.org/wiki/Luhn\\\\\\\\\\\\\\_algorithm. Source code in pydantic/types.py validate\\\\\\\\\\\\\\_brand staticmethod ¶ validate\\\\\\\\\\\\\\_brand(card\\\\\\\\\\\\\\_number) Validate length based on BIN for major brands: https://en.wikipedia.org/wiki/Payment\\\\\\\\\\\\\\_card\\\\\\\\\\\\\\_number#Issuer\\\\\\\\\\\\\\_identification\\\\\\\\\\\\\\_number\\\\\\\\\\\\\\_(IIN). Source code in pydantic/types.py ByteSize ¶ Bases: int Converts a string representing a number of bytes with units (such as '1KB' or '11.5MiB') into an integer. You can use the ByteSize data type to (case-insensitively) convert a string representation of a number of bytes into an integer, and also to print out human-readable strings representing a number of bytes. In conformance with IEC 80000-13 Standard we interpret '1KB' to mean 1000 bytes, and '1KiB' to mean 1024 bytes. In general, including a middle 'i' will cause the unit to be interpreted as a power of 2, rather than a power of 10 (so, for example, '1 MB' is treated as 1\\\\\\\\\\\\\\_000\\\\\\\\\\\\\\_000 bytes, whereas '1 MiB' is treated as 1\\\\\\\\\\\\\\_048\\\\\\\\\\\\\\_576 bytes). Info Note that 1b will be parsed as \"1 byte\" and not \"1 bit\". from pydantic import BaseModel, ByteSize class MyModel(BaseModel): size: ByteSize print(MyModel(size=52000).size) #> 52000 print(MyModel(size='3000 KiB').size) #> 3072000 m = MyModel(size='50 PB') print(m.size.human\\\\\\\\\\\\\\_readable()) #> 44.4PiB print(m.size.human\\\\\\\\\\\\\\_readable(decimal=True)) #> 50.0PB print(m.size.to('TiB')) #> 45474.73508864641 human\\\\\\\\\\\\\\_readable ¶ human\\\\\\\\\\\\\\_readable(decimal=False) Converts a byte size to a human readable string. Parameters: Name Type Description Default decimal bool If True, use decimal units (e.g. 1000 bytes per KB). If False, use binary units (e.g. 1024 bytes per KiB). False Returns: Type Description str A human readable string representation of the byte size. Source code in pydantic/types.py to ¶ to(unit) Converts a byte size to another unit. Parameters: Name Type Description Default unit str The unit to convert to. Must be one of the following: B, KB, MB, GB, TB, PB, EiB, KiB, MiB, GiB, TiB, PiB, EiB. required Returns: Type Description float The byte size in the new unit. Source code in pydantic/types.py PastDate ¶ A date in the past. FutureDate ¶ A date in the future. AwareDatetime ¶ A datetime that requires timezone info. NaiveDatetime ¶ A datetime that doesn't require timezone info. PastDatetime ¶ A datetime that must be in the past. FutureDatetime ¶ A datetime that must be in the future. EncoderProtocol ¶ Bases: Protocol Protocol for encoding and decoding data to and from bytes. decode classmethod ¶ decode(data) Decode the data using the encoder. Parameters: Name Type Description Default data bytes The data to decode. required Returns: Type Description bytes The decoded data. Source code in pydantic/types.py encode classmethod ¶ encode(value) Encode the data using the encoder. Parameters: Name Type Description Default value bytes The data to encode. required Returns: Type Description bytes The encoded data. Source code in pydantic/types.py get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_format classmethod ¶ get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_format() Get the JSON format for the encoded data. Returns: Type Description str The JSON format for the encoded data. Source code in pydantic/types.py Base64Encoder ¶ Bases: EncoderProtocol Standard (non-URL-safe) Base64 encoder. decode classmethod ¶ decode(data) Decode the data from base64 encoded bytes to original bytes data. Parameters: Name Type Description Default data bytes The data to decode. required Returns: Type Description bytes The decoded data. Source code in pydantic/types.py encode classmethod ¶ encode(value) Encode the data from bytes to a base64 encoded bytes. Parameters: Name Type Description Default value bytes The data to encode. required Returns: Type Description bytes The encoded data. Source code in pydantic/types.py get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_format classmethod ¶ get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_format() Get the JSON format for the encoded data. Returns: Type Description Literal\\\\\\\\\\\\\\['base64'\\\\\\\\\\\\\\] The JSON format for the encoded data. Source code in pydantic/types.py Base64UrlEncoder ¶ Bases: EncoderProtocol URL-safe Base64 encoder. decode classmethod ¶ decode(data) Decode the data from base64 encoded bytes to original bytes data. Parameters: Name Type Description Default data bytes The data to decode. required Returns: Type Description bytes The decoded data. Source code in pydantic/types.py encode classmethod ¶ encode(value) Encode the data from bytes to a base64 encoded bytes. Parameters: Name Type Description Default value bytes The data to encode. required Returns: Type Description bytes The encoded data. Source code in pydantic/types.py get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_format classmethod ¶ get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_format() Get the JSON format for the encoded data. Returns: Type Description Literal\\\\\\\\\\\\\\['base64url'\\\\\\\\\\\\\\] The JSON format for the encoded data. Source code in pydantic/types.py EncodedBytes dataclass ¶ A bytes type that is encoded and decoded using the specified encoder. EncodedBytes needs an encoder that implements EncoderProtocol to operate. from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, EncodedBytes, EncoderProtocol, ValidationError class MyEncoder(EncoderProtocol): @classmethod def decode(cls, data: bytes) -> bytes: if data == b'\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*undecodable\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*': raise ValueError('Cannot decode data') return data\\\\\\\\\\\\\\[13:\\\\\\\\\\\\\\] @classmethod def encode(cls, value: bytes) -> bytes: return b'\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*encoded\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*: ' + value @classmethod def get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_format(cls) -> str: return 'my-encoder' MyEncodedBytes = Annotated\\\\\\\\\\\\\\[bytes, EncodedBytes(encoder=MyEncoder)\\\\\\\\\\\\\\] class Model(BaseModel): my\\\\\\\\\\\\\\_encoded\\\\\\\\\\\\\\_bytes: MyEncodedBytes # Initialize the model with encoded data m = Model(my\\\\\\\\\\\\\\_encoded\\\\\\\\\\\\\\_bytes=b'\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*encoded\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*: some bytes') # Access decoded value print(m.my\\\\\\\\\\\\\\_encoded\\\\\\\\\\\\\\_bytes) #> b'some bytes' # Serialize into the encoded form print(m.model\\\\\\\\\\\\\\_dump()) #> {'my\\\\\\\\\\\\\\_encoded\\\\\\\\\\\\\\_bytes': b'\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*encoded\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*: some bytes'} # Validate encoded data try: Model(my\\\\\\\\\\\\\\_encoded\\\\\\\\\\\\\\_bytes=b'\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*undecodable\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*') except ValidationError as e: print(e) ''' 1 validation error for Model my\\\\\\\\\\\\\\_encoded\\\\\\\\\\\\\\_bytes Value error, Cannot decode data \\\\\\\\\\\\\\[type=value\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value=b'\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*undecodable\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*', input\\\\\\\\\\\\\\_type=bytes\\\\\\\\\\\\\\] ''' decode ¶ decode(data, \\\\\\\\\\\\\\_) Decode the data using the specified encoder. Parameters: Name Type Description Default data bytes The data to decode. required Returns: Type Description bytes The decoded data. Source code in pydantic/types.py encode ¶ encode(value) Encode the data using the specified encoder. Parameters: Name Type Description Default value bytes The data to encode. required Returns: Type Description bytes The encoded data. Source code in pydantic/types.py EncodedStr dataclass ¶ Bases: EncodedBytes A str type that is encoded and decoded using the specified encoder. EncodedStr needs an encoder that implements EncoderProtocol to operate. from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, EncodedStr, EncoderProtocol, ValidationError class MyEncoder(EncoderProtocol): @classmethod def decode(cls, data: bytes) -> bytes: if data == b'\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*undecodable\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*': raise ValueError('Cannot decode data') return data\\\\\\\\\\\\\\[13:\\\\\\\\\\\\\\] @classmethod def encode(cls, value: bytes) -> bytes: return b'\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*encoded\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*: ' + value @classmethod def get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_format(cls) -> str: return 'my-encoder' MyEncodedStr = Annotated\\\\\\\\\\\\\\[str, EncodedStr(encoder=MyEncoder)\\\\\\\\\\\\\\] class Model(BaseModel): my\\\\\\\\\\\\\\_encoded\\\\\\\\\\\\\\_str: MyEncodedStr # Initialize the model with encoded data m = Model(my\\\\\\\\\\\\\\_encoded\\\\\\\\\\\\\\_str='\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*encoded\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*: some str') # Access decoded value print(m.my\\\\\\\\\\\\\\_encoded\\\\\\\\\\\\\\_str) #> some str # Serialize into the encoded form print(m.model\\\\\\\\\\\\\\_dump()) #> {'my\\\\\\\\\\\\\\_encoded\\\\\\\\\\\\\\_str': '\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*encoded\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*: some str'} # Validate encoded data try: Model(my\\\\\\\\\\\\\\_encoded\\\\\\\\\\\\\\_str='\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*undecodable\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*') except ValidationError as e: print(e) ''' 1 validation error for Model my\\\\\\\\\\\\\\_encoded\\\\\\\\\\\\\\_str Value error, Cannot decode data \\\\\\\\\\\\\\[type=value\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*undecodable\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' decode\\\\\\\\\\\\\\_str ¶ decode\\\\\\\\\\\\\\_str(data, \\\\\\\\\\\\\\_) Decode the data using the specified encoder. Parameters: Name Type Description Default data bytes The data to decode. required Returns: Type Description str The decoded data. Source code in pydantic/types.py encode\\\\\\\\\\\\\\_str ¶ encode\\\\\\\\\\\\\\_str(value) Encode the data using the specified encoder. Parameters: Name Type Description Default value str The data to encode. required Returns: Type Description str The encoded data. Source code in pydantic/types.py GetPydanticSchema dataclass ¶ Usage Documentation Using GetPydanticSchema to reduce boilerplate A convenience class for creating an annotation that provides pydantic custom type hooks. This class is intended to eliminate the need to create a custom \"marker\" which defines the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ custom hook methods. For example, to have a field treated by type checkers as int, but by pydantic as Any, you can do: from typing import Any from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, GetPydanticSchema HandleAsAny = GetPydanticSchema(lambda \\\\\\\\\\\\\\_s, h: h(Any)) class Model(BaseModel): x: Annotated\\\\\\\\\\\\\\[int, HandleAsAny\\\\\\\\\\\\\\] # pydantic sees \\\\\\\\\\\\\\`x: Any\\\\\\\\\\\\\\` print(repr(Model(x='abc').x)) #> 'abc' Tag dataclass ¶ Provides a way to specify the expected tag to use for a case of a (callable) discriminated union. Also provides a way to label a union case in error messages. When using a callable Discriminator, attach a Tag to each case in the Union to specify the tag that should be used to identify that case. For example, in the below example, the Tag is used to specify that if get\\\\\\\\\\\\\\_discriminator\\\\\\\\\\\\\\_value returns 'apple', the input should be validated as an ApplePie, and if it returns 'pumpkin', the input should be validated as a PumpkinPie. The primary role of the Tag here is to map the return value from the callable Discriminator function to the appropriate member of the Union in question. from typing import Any, Union from typing\\\\\\\\\\\\\\_extensions import Annotated, Literal from pydantic import BaseModel, Discriminator, Tag class Pie(BaseModel): time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook: int num\\\\\\\\\\\\\\_ingredients: int class ApplePie(Pie): fruit: Literal\\\\\\\\\\\\\\['apple'\\\\\\\\\\\\\\] = 'apple' class PumpkinPie(Pie): filling: Literal\\\\\\\\\\\\\\['pumpkin'\\\\\\\\\\\\\\] = 'pumpkin' def get\\\\\\\\\\\\\\_discriminator\\\\\\\\\\\\\\_value(v: Any) -> str: if isinstance(v, dict): return v.get('fruit', v.get('filling')) return getattr(v, 'fruit', getattr(v, 'filling', None)) class ThanksgivingDinner(BaseModel): dessert: Annotated\\\\\\\\\\\\\\[ Union\\\\\\\\\\\\\\[ Annotated\\\\\\\\\\\\\\[ApplePie, Tag('apple')\\\\\\\\\\\\\\], Annotated\\\\\\\\\\\\\\[PumpkinPie, Tag('pumpkin')\\\\\\\\\\\\\\], \\\\\\\\\\\\\\], Discriminator(get\\\\\\\\\\\\\\_discriminator\\\\\\\\\\\\\\_value), \\\\\\\\\\\\\\] apple\\\\\\\\\\\\\\_variation = ThanksgivingDinner.model\\\\\\\\\\\\\\_validate( {'dessert': {'fruit': 'apple', 'time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook': 60, 'num\\\\\\\\\\\\\\_ingredients': 8}} ) print(repr(apple\\\\\\\\\\\\\\_variation)) ''' ThanksgivingDinner(dessert=ApplePie(time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook=60, num\\\\\\\\\\\\\\_ingredients=8, fruit='apple')) ''' pumpkin\\\\\\\\\\\\\\_variation = ThanksgivingDinner.model\\\\\\\\\\\\\\_validate( { 'dessert': { 'filling': 'pumpkin', 'time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook': 40, 'num\\\\\\\\\\\\\\_ingredients': 6, } } ) print(repr(pumpkin\\\\\\\\\\\\\\_variation)) ''' ThanksgivingDinner(dessert=PumpkinPie(time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook=40, num\\\\\\\\\\\\\\_ingredients=6, filling='pumpkin')) ''' Note You must specify a Tag for every case in a Tag that is associated with a callable Discriminator. Failing to do so will result in a PydanticUserError with code callable-discriminator-no-tag. See the Discriminated Unions concepts docs for more details on how to use Tags. Discriminator dataclass ¶ Usage Documentation Discriminated Unions with callable Discriminator Provides a way to use a custom callable as the way to extract the value of a union discriminator. This allows you to get validation behavior like you'd get from Field(discriminator=), but without needing to have a single shared field across all the union choices. This also makes it possible to handle unions of models and primitive types with discriminated-union-style validation errors. Finally, this allows you to use a custom callable as the way to identify which member of a union a value belongs to, while still seeing all the performance benefits of a discriminated union. Consider this example, which is much more performant with the use of Discriminator and thus a TaggedUnion than it would be as a normal Union. from typing import Any, Union from typing\\\\\\\\\\\\\\_extensions import Annotated, Literal from pydantic import BaseModel, Discriminator, Tag class Pie(BaseModel): time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook: int num\\\\\\\\\\\\\\_ingredients: int class ApplePie(Pie): fruit: Literal\\\\\\\\\\\\\\['apple'\\\\\\\\\\\\\\] = 'apple' class PumpkinPie(Pie): filling: Literal\\\\\\\\\\\\\\['pumpkin'\\\\\\\\\\\\\\] = 'pumpkin' def get\\\\\\\\\\\\\\_discriminator\\\\\\\\\\\\\\_value(v: Any) -> str: if isinstance(v, dict): return v.get('fruit', v.get('filling')) return getattr(v, 'fruit', getattr(v, 'filling', None)) class ThanksgivingDinner(BaseModel): dessert: Annotated\\\\\\\\\\\\\\[ Union\\\\\\\\\\\\\\[ Annotated\\\\\\\\\\\\\\[ApplePie, Tag('apple')\\\\\\\\\\\\\\], Annotated\\\\\\\\\\\\\\[PumpkinPie, Tag('pumpkin')\\\\\\\\\\\\\\], \\\\\\\\\\\\\\], Discriminator(get\\\\\\\\\\\\\\_discriminator\\\\\\\\\\\\\\_value), \\\\\\\\\\\\\\] apple\\\\\\\\\\\\\\_variation = ThanksgivingDinner.model\\\\\\\\\\\\\\_validate( {'dessert': {'fruit': 'apple', 'time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook': 60, 'num\\\\\\\\\\\\\\_ingredients': 8}} ) print(repr(apple\\\\\\\\\\\\\\_variation)) ''' ThanksgivingDinner(dessert=ApplePie(time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook=60, num\\\\\\\\\\\\\\_ingredients=8, fruit='apple')) ''' pumpkin\\\\\\\\\\\\\\_variation = ThanksgivingDinner.model\\\\\\\\\\\\\\_validate( { 'dessert': { 'filling': 'pumpkin', 'time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook': 40, 'num\\\\\\\\\\\\\\_ingredients': 6, } } ) print(repr(pumpkin\\\\\\\\\\\\\\_variation)) ''' ThanksgivingDinner(dessert=PumpkinPie(time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook=40, num\\\\\\\\\\\\\\_ingredients=6, filling='pumpkin')) ''' See the Discriminated Unions concepts docs for more details on how to use Discriminators. discriminator instance-attribute ¶ discriminator: str | Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Hashable\\\\\\\\\\\\\\] The callable or field name for discriminating the type in a tagged union. A Callable discriminator must extract the value of the discriminator from the input. A str discriminator must be the name of a field to discriminate against. custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_type instance-attribute class-attribute ¶ custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_type: str | None = None Type to use in custom errors replacing the standard discriminated union validation errors. custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_message instance-attribute class-attribute ¶ custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_message: str | None = None Message to use in custom errors. custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_context instance-attribute class-attribute ¶ custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_context: dict\\\\\\\\\\\\\\[ str, int | str | float \\\\\\\\\\\\\\] | None = None Context to use in custom errors. conint ¶ conint( \\\\\\\\\\\\\\*, strict=None, gt=None, ge=None, lt=None, le=None, multiple\\\\\\\\\\\\\\_of=None ) Discouraged This function is discouraged in favor of using Annotated with Field instead. This function will be deprecated in Pydantic 3.0. The reason is that conint returns a type, which doesn't play well with static analysis tools. Don't do this Do this from pydantic import BaseModel, conint class Foo(BaseModel): bar: conint(strict=True, gt=0) A wrapper around int that allows for additional constraints. Parameters: Name Type Description Default strict bool | None Whether to validate the integer in strict mode. Defaults to None. None gt int | None The value must be greater than this. None ge int | None The value must be greater than or equal to this. None lt int | None The value must be less than this. None le int | None The value must be less than or equal to this. None multiple\\\\\\\\\\\\\\_of int | None The value must be a multiple of this. None Returns: Type Description type\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] The wrapped integer type. from pydantic import BaseModel, ValidationError, conint class ConstrainedExample(BaseModel): constrained\\\\\\\\\\\\\\_int: conint(gt=1) m = ConstrainedExample(constrained\\\\\\\\\\\\\\_int=2) print(repr(m)) #> ConstrainedExample(constrained\\\\\\\\\\\\\\_int=2) try: ConstrainedExample(constrained\\\\\\\\\\\\\\_int=0) except ValidationError as e: print(e.errors()) ''' \\\\\\\\\\\\\\[ { 'type': 'greater\\\\\\\\\\\\\\_than', 'loc': ('constrained\\\\\\\\\\\\\\_int',), 'msg': 'Input should be greater than 1', 'input': 0, 'ctx': {'gt': 1}, 'url': 'https://errors.pydantic.dev/2/v/greater\\\\\\\\\\\\\\_than', } \\\\\\\\\\\\\\] ''' Source code in pydantic/types.py confloat ¶ confloat( \\\\\\\\\\\\\\*, strict=None, gt=None, ge=None, lt=None, le=None, multiple\\\\\\\\\\\\\\_of=None, allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan=None ) Discouraged This function is discouraged in favor of using Annotated with Field instead. This function will be deprecated in Pydantic 3.0. The reason is that confloat returns a type, which doesn't play well with static analysis tools. Don't do this Do this from pydantic import BaseModel, confloat class Foo(BaseModel): bar: confloat(strict=True, gt=0) A wrapper around float that allows for additional constraints. Parameters: Name Type Description Default strict bool | None Whether to validate the float in strict mode. None gt float | None The value must be greater than this. None ge float | None The value must be greater than or equal to this. None lt float | None The value must be less than this. None le float | None The value must be less than or equal to this. None multiple\\\\\\\\\\\\\\_of float | None The value must be a multiple of this. None allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan bool | None Whether to allow -inf, inf, and nan. None Returns: Type Description type\\\\\\\\\\\\\\[float\\\\\\\\\\\\\\] The wrapped float type. from pydantic import BaseModel, ValidationError, confloat class ConstrainedExample(BaseModel): constrained\\\\\\\\\\\\\\_float: confloat(gt=1.0) m = ConstrainedExample(constrained\\\\\\\\\\\\\\_float=1.1) print(repr(m)) #> ConstrainedExample(constrained\\\\\\\\\\\\\\_float=1.1) try: ConstrainedExample(constrained\\\\\\\\\\\\\\_float=0.9) except ValidationError as e: print(e.errors()) ''' \\\\\\\\\\\\\\[ { 'type': 'greater\\\\\\\\\\\\\\_than', 'loc': ('constrained\\\\\\\\\\\\\\_float',), 'msg': 'Input should be greater than 1', 'input': 0.9, 'ctx': {'gt': 1.0}, 'url': 'https://errors.pydantic.dev/2/v/greater\\\\\\\\\\\\\\_than', } \\\\\\\\\\\\\\] ''' Source code in pydantic/types.py conbytes ¶ conbytes(\\\\\\\\\\\\\\*, min\\\\\\\\\\\\\\_length=None, max\\\\\\\\\\\\\\_length=None, strict=None) A wrapper around bytes that allows for additional constraints. Parameters: Name Type Description Default min\\\\\\\\\\\\\\_length int | None The minimum length of the bytes. None max\\\\\\\\\\\\\\_length int | None The maximum length of the bytes. None strict bool | None Whether to validate the bytes in strict mode. None Returns: Type Description type\\\\\\\\\\\\\\[bytes\\\\\\\\\\\\\\] The wrapped bytes type. Source code in pydantic/types.py constr ¶ constr( \\\\\\\\\\\\\\*, strip\\\\\\\\\\\\\\_whitespace=None, to\\\\\\\\\\\\\\_upper=None, to\\\\\\\\\\\\\\_lower=None, strict=None, min\\\\\\\\\\\\\\_length=None, max\\\\\\\\\\\\\\_length=None, pattern=None ) Discouraged This function is discouraged in favor of using Annotated with StringConstraints instead. This function will be deprecated in Pydantic 3.0. The reason is that constr returns a type, which doesn't play well with static analysis tools. Don't do this Do this from pydantic import BaseModel, constr class Foo(BaseModel): bar: constr(strip\\\\\\\\\\\\\\_whitespace=True, to\\\\\\\\\\\\\\_upper=True, pattern=r'^\\\\\\\\\\\\\\[A-Z\\\\\\\\\\\\\\]+$') A wrapper around str that allows for additional constraints. from pydantic import BaseModel, constr class Foo(BaseModel): bar: constr(strip\\\\\\\\\\\\\\_whitespace=True, to\\\\\\\\\\\\\\_upper=True, pattern=r'^\\\\\\\\\\\\\\[A-Z\\\\\\\\\\\\\\]+$') foo = Foo(bar=' hello ') print(foo) #> bar='HELLO' Parameters: Name Type Description Default strip\\\\\\\\\\\\\\_whitespace bool | None Whether to remove leading and trailing whitespace. None to\\\\\\\\\\\\\\_upper bool | None Whether to turn all characters to uppercase. None to\\\\\\\\\\\\\\_lower bool | None Whether to turn all characters to lowercase. None strict bool | None Whether to validate the string in strict mode. None min\\\\\\\\\\\\\\_length int | None The minimum length of the string. None max\\\\\\\\\\\\\\_length int | None The maximum length of the string. None pattern str | None A regex pattern to validate the string against. None Returns: Type Description type\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] The wrapped string type. Source code in pydantic/types.py conset ¶ conset(item\\\\\\\\\\\\\\_type, \\\\\\\\\\\\\\*, min\\\\\\\\\\\\\\_length=None, max\\\\\\\\\\\\\\_length=None) A wrapper around typing.Set that allows for additional constraints. Parameters: Name Type Description Default item\\\\\\\\\\\\\\_type type\\\\\\\\\\\\\\[HashableItemType\\\\\\\\\\\\\\] The type of the items in the set. required min\\\\\\\\\\\\\\_length int | None The minimum length of the set. None max\\\\\\\\\\\\\\_length int | None The maximum length of the set. None Returns: Type Description type\\\\\\\\\\\\\\[set\\\\\\\\\\\\\\[HashableItemType\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] The wrapped set type. Source code in pydantic/types.py confrozenset ¶ confrozenset( item\\\\\\\\\\\\\\_type, \\\\\\\\\\\\\\*, min\\\\\\\\\\\\\\_length=None, max\\\\\\\\\\\\\\_length=None ) A wrapper around typing.FrozenSet that allows for additional constraints. Parameters: Name Type Description Default item\\\\\\\\\\\\\\_type type\\\\\\\\\\\\\\[HashableItemType\\\\\\\\\\\\\\] The type of the items in the frozenset. required min\\\\\\\\\\\\\\_length int | None The minimum length of the frozenset. None max\\\\\\\\\\\\\\_length int | None The maximum length of the frozenset. None Returns: Type Description type\\\\\\\\\\\\\\[frozenset\\\\\\\\\\\\\\[HashableItemType\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] The wrapped frozenset type. Source code in pydantic/types.py conlist ¶ conlist( item\\\\\\\\\\\\\\_type, \\\\\\\\\\\\\\*, min\\\\\\\\\\\\\\_length=None, max\\\\\\\\\\\\\\_length=None, unique\\\\\\\\\\\\\\_items=None ) A wrapper around typing.List that adds validation. Parameters: Name Type Description Default item\\\\\\\\\\\\\\_type type\\\\\\\\\\\\\\[AnyItemType\\\\\\\\\\\\\\] The type of the items in the list. required min\\\\\\\\\\\\\\_length int | None The minimum length of the list. Defaults to None. None max\\\\\\\\\\\\\\_length int | None The maximum length of the list. Defaults to None. None unique\\\\\\\\\\\\\\_items bool | None Whether the items in the list must be unique. Defaults to None. Warning The unique\\\\\\\\\\\\\\_items parameter is deprecated, use Set instead. See this issue for more details. None Returns: Type Description type\\\\\\\\\\\\\\[list\\\\\\\\\\\\\\[AnyItemType\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] The wrapped list type. Source code in pydantic/types.py condecimal ¶ condecimal( \\\\\\\\\\\\\\*, strict=None, gt=None, ge=None, lt=None, le=None, multiple\\\\\\\\\\\\\\_of=None, max\\\\\\\\\\\\\\_digits=None, decimal\\\\\\\\\\\\\\_places=None, allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan=None ) Discouraged This function is discouraged in favor of using Annotated with Field instead. This function will be deprecated in Pydantic 3.0. The reason is that condecimal returns a type, which doesn't play well with static analysis tools. Don't do this Do this from pydantic import BaseModel, condecimal class Foo(BaseModel): bar: condecimal(strict=True, allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan=True) A wrapper around Decimal that adds validation. Parameters: Name Type Description Default strict bool | None Whether to validate the value in strict mode. Defaults to None. None gt int | Decimal | None The value must be greater than this. Defaults to None. None ge int | Decimal | None The value must be greater than or equal to this. Defaults to None. None lt int | Decimal | None The value must be less than this. Defaults to None. None le int | Decimal | None The value must be less than or equal to this. Defaults to None. None multiple\\\\\\\\\\\\\\_of int | Decimal | None The value must be a multiple of this. Defaults to None. None max\\\\\\\\\\\\\\_digits int | None The maximum number of digits. Defaults to None. None decimal\\\\\\\\\\\\\\_places int | None The number of decimal places. Defaults to None. None allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan bool | None Whether to allow infinity and NaN. Defaults to None. None from decimal import Decimal from pydantic import BaseModel, ValidationError, condecimal class ConstrainedExample(BaseModel): constrained\\\\\\\\\\\\\\_decimal: condecimal(gt=Decimal('1.0')) m = ConstrainedExample(constrained\\\\\\\\\\\\\\_decimal=Decimal('1.1')) print(repr(m)) #> ConstrainedExample(constrained\\\\\\\\\\\\\\_decimal=Decimal('1.1')) try: ConstrainedExample(constrained\\\\\\\\\\\\\\_decimal=Decimal('0.9')) except ValidationError as e: print(e.errors()) ''' \\\\\\\\\\\\\\[ { 'type': 'greater\\\\\\\\\\\\\\_than', 'loc': ('constrained\\\\\\\\\\\\\\_decimal',), 'msg': 'Input should be greater than 1.0', 'input': Decimal('0.9'), 'ctx': {'gt': Decimal('1.0')}, 'url': 'https://errors.pydantic.dev/2/v/greater\\\\\\\\\\\\\\_than', } \\\\\\\\\\\\\\] ''' Source code in pydantic/types.py condate ¶ condate(\\\\\\\\\\\\\\*, strict=None, gt=None, ge=None, lt=None, le=None) A wrapper for date that adds constraints. Parameters: Name Type Description Default strict bool | None Whether to validate the date value in strict mode. Defaults to None. None gt date | None The value must be greater than this. Defaults to None. None ge date | None The value must be greater than or equal to this. Defaults to None. None lt date | None The value must be less than this. Defaults to None. None le date | None The value must be less than or equal to this. Defaults to None. None Returns: Type Description type\\\\\\\\\\\\\\[date\\\\\\\\\\\\\\] A date type with the specified constraints. Source code in pydantic/types.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Version Information - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/version/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Version Information Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_version\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ version\\\\\\\\\\\\\\_info() Version Information pydantic.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_version\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ module-attribute ¶ pydantic.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_version\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ = VERSION pydantic.version.version\\\\\\\\\\\\\\_info ¶ pydantic.version.version\\\\\\\\\\\\\\_info() Return complete version information for Pydantic and its dependencies. Source code in pydantic/version.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Standard Library Types - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/standard_library_types/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Standard Library Types Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents Booleans Datetime Types datetime.datetime datetime.date datetime.time datetime.timedelta Number Types int float enum.IntEnum decimal.Decimal Enum Lists and Tuples list typing.List tuple typing.Tuple typing.NamedTuple Deque deque typing.Deque Sets set typing.Set frozenset typing.FrozenSet Other Iterables typing.Sequence typing.Iterable Infinite Generators Mapping Types dict typing.Dict TypedDict Callable IP Address Types UUID Union Type and TypeVar type typing.Type typing.TypeVar None Types Strings Bytes typing.Literal typing.Any typing.Annotated typing.Pattern pathlib.Path Standard Library Types Pydantic supports many common types from the Python standard library. If you need stricter processing see Strict Types, including if you need to constrain the values allowed (e.g. to require a positive int). Booleans¶ A standard bool field will raise a ValidationError if the value is not one of the following: A valid boolean (i.e. True or False), The integers 0 or 1, a str which when converted to lower case is one of '0', 'off', 'f', 'false', 'n', 'no', '1', 'on', 't', 'true', 'y', 'yes' a bytes which is valid per the previous rule when decoded to str Note If you want stricter boolean logic (e.g. a field which only permits True and False) you can use StrictBool. Here is a script demonstrating some of these behaviors: from pydantic import BaseModel, ValidationError class BooleanModel(BaseModel): bool\\\\\\\\\\\\\\_value: bool print(BooleanModel(bool\\\\\\\\\\\\\\_value=False)) #> bool\\\\\\\\\\\\\\_value=False print(BooleanModel(bool\\\\\\\\\\\\\\_value='False')) #> bool\\\\\\\\\\\\\\_value=False print(BooleanModel(bool\\\\\\\\\\\\\\_value=1)) #> bool\\\\\\\\\\\\\\_value=True try: BooleanModel(bool\\\\\\\\\\\\\\_value=\\\\\\\\\\\\\\[\\\\\\\\\\\\\\]) except ValidationError as e: print(str(e)) \"\"\" 1 validation error for BooleanModel bool\\\\\\\\\\\\\\_value Input should be a valid boolean \\\\\\\\\\\\\\[type=bool\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=\\\\\\\\\\\\\\[\\\\\\\\\\\\\\], input\\\\\\\\\\\\\\_type=list\\\\\\\\\\\\\\] \"\"\" Datetime Types¶ Pydantic supports the following datetime types: datetime.datetime¶ datetime fields will accept values of type: datetime; an existing datetime object int or float; assumed as Unix time, i.e. seconds (if >= -2e10 and <= 2e10) or milliseconds (if < -2e10or > 2e10) since 1 January 1970 str; the following formats are accepted: YYYY-MM-DD\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\]HH:MM\\\\\\\\\\\\\\[:SS\\\\\\\\\\\\\\[.ffffff\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]\\\\\\\\\\\\\\[Z or \\\\\\\\\\\\\\[±\\\\\\\\\\\\\\]HH\\\\\\\\\\\\\\[:\\\\\\\\\\\\\\]MM\\\\\\\\\\\\\\] int or float as a string (assumed as Unix time) from datetime import datetime from pydantic import BaseModel class Event(BaseModel): dt: datetime = None event = Event(dt='2032-04-23T10:20:30.400+02:30') print(event.model\\\\\\\\\\\\\\_dump()) \"\"\" {'dt': datetime.datetime(2032, 4, 23, 10, 20, 30, 400000, tzinfo=TzInfo(+02:30))} \"\"\" datetime.date¶ date fields will accept values of type: date; an existing date object int or float; handled the same as described for datetime above str; the following formats are accepted: YYYY-MM-DD int or float as a string (assumed as Unix time) from datetime import date from pydantic import BaseModel class Birthday(BaseModel): d: date = None my\\\\\\\\\\\\\\_birthday = Birthday(d=1679616000.0) print(my\\\\\\\\\\\\\\_birthday.model\\\\\\\\\\\\\\_dump()) #> {'d': datetime.date(2023, 3, 24)} datetime.time¶ time fields will accept values of type: time; an existing time object str; the following formats are accepted: HH:MM\\\\\\\\\\\\\\[:SS\\\\\\\\\\\\\\[.ffffff\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]\\\\\\\\\\\\\\[Z or \\\\\\\\\\\\\\[±\\\\\\\\\\\\\\]HH\\\\\\\\\\\\\\[:\\\\\\\\\\\\\\]MM\\\\\\\\\\\\\\] from datetime import time from pydantic import BaseModel class Meeting(BaseModel): t: time = None m = Meeting(t=time(4, 8, 16)) print(m.model\\\\\\\\\\\\\\_dump()) #> {'t': datetime.time(4, 8, 16)} datetime.timedelta¶ timedelta fields will accept values of type: timedelta; an existing timedelta object int or float; assumed to be seconds str; the following formats are accepted: \\\\\\\\\\\\\\[-\\\\\\\\\\\\\\]\\\\\\\\\\\\\\[DD\\\\\\\\\\\\\\]D\\\\\\\\\\\\\\[,\\\\\\\\\\\\\\]\\\\\\\\\\\\\\[HH:MM:\\\\\\\\\\\\\\]SS\\\\\\\\\\\\\\[.ffffff\\\\\\\\\\\\\\] Ex: '1d,01:02:03.000004' or '1D01:02:03.000004' or '01:02:03' \\\\\\\\\\\\\\[±\\\\\\\\\\\\\\]P\\\\\\\\\\\\\\[DD\\\\\\\\\\\\\\]DT\\\\\\\\\\\\\\[HH\\\\\\\\\\\\\\]H\\\\\\\\\\\\\\[MM\\\\\\\\\\\\\\]M\\\\\\\\\\\\\\[SS\\\\\\\\\\\\\\]S (ISO 8601 format for timedelta) from datetime import timedelta from pydantic import BaseModel class Model(BaseModel): td: timedelta = None m = Model(td='P3DT12H30M5S') print(m.model\\\\\\\\\\\\\\_dump()) #> {'td': datetime.timedelta(days=3, seconds=45005)} Number Types¶ Pydantic supports the following numeric types from the Python standard library: int¶ Pydantic uses int(v) to coerce types to an int; see Data conversion for details on loss of information during data conversion. float¶ Pydantic uses float(v) to coerce values to floats. enum.IntEnum¶ Validation: Pydantic checks that the value is a valid IntEnum instance. Validation for subclass of enum.IntEnum: checks that the value is a valid member of the integer enum; see Enums and Choices for more details. decimal.Decimal¶ Validation: Pydantic attempts to convert the value to a string, then passes the string to Decimal(v). Serialization: Pydantic serializes Decimal types as strings. You can use a custom serializer to override this behavior if desired. For example: from decimal import Decimal from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, PlainSerializer class Model(BaseModel): x: Decimal y: Annotated\\\\\\\\\\\\\\[ Decimal, PlainSerializer( lambda x: float(x), return\\\\\\\\\\\\\\_type=float, when\\\\\\\\\\\\\\_used='json' ), \\\\\\\\\\\\\\] my\\\\\\\\\\\\\\_model = Model(x=Decimal('1.1'), y=Decimal('2.1')) print(my\\\\\\\\\\\\\\_model.model\\\\\\\\\\\\\\_dump()) Using model\\\\\\\\\\\\\\_dump, both x and y remain instances of the Decimal type #> {'x': Decimal('1.1'), 'y': Decimal('2.1')} print(my\\\\\\\\\\\\\\_model.model\\\\\\\\\\\\\\_dump(mode='json')) Using model\\\\\\\\\\\\\\_dump with mode='json', x is serialized as a string, and y is serialized as a float because of the custom serializer applied. #> {'x': '1.1', 'y': 2.1} print(my\\\\\\\\\\\\\\_model.model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json()) Using model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json, x is serialized as a string, and y is serialized as a float because of the custom serializer applied. #> {\"x\":\"1.1\",\"y\":2.1} Enum¶ Pydantic uses Python's standard enum classes to define choices. enum.Enum checks that the value is a valid Enum instance. Subclass of enum.Enum checks that the value is a valid member of the enum. from enum import Enum, IntEnum from pydantic import BaseModel, ValidationError class FruitEnum(str, Enum): pear = 'pear' banana = 'banana' class ToolEnum(IntEnum): spanner = 1 wrench = 2 class CookingModel(BaseModel): fruit: FruitEnum = FruitEnum.pear tool: ToolEnum = ToolEnum.spanner print(CookingModel()) #> fruit= tool= print(CookingModel(tool=2, fruit='banana')) #> fruit= tool= try: CookingModel(fruit='other') except ValidationError as e: print(e) \"\"\" 1 validation error for CookingModel fruit Input should be 'pear' or 'banana' \\\\\\\\\\\\\\[type=enum, input\\\\\\\\\\\\\\_value='other', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Lists and Tuples¶ list¶ Allows list, tuple, set, frozenset, deque, or generators and casts to a list. When a generic parameter is provided, the appropriate validation is applied to all items of the list. typing.List¶ Handled the same as list above. from typing import List, Optional from pydantic import BaseModel class Model(BaseModel): simple\\\\\\\\\\\\\\_list: Optional\\\\\\\\\\\\\\[list\\\\\\\\\\\\\\] = None list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints: Optional\\\\\\\\\\\\\\[List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = None print(Model(simple\\\\\\\\\\\\\\_list=\\\\\\\\\\\\\\['1', '2', '3'\\\\\\\\\\\\\\]).simple\\\\\\\\\\\\\\_list) #> \\\\\\\\\\\\\\['1', '2', '3'\\\\\\\\\\\\\\] print(Model(list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints=\\\\\\\\\\\\\\['1', '2', '3'\\\\\\\\\\\\\\]).list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints) #> \\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\] tuple¶ Allows list, tuple, set, frozenset, deque, or generators and casts to a tuple. When generic parameters are provided, the appropriate validation is applied to the respective items of the tuple typing.Tuple¶ Handled the same as tuple above. from typing import Optional, Tuple from pydantic import BaseModel class Model(BaseModel): simple\\\\\\\\\\\\\\_tuple: Optional\\\\\\\\\\\\\\[tuple\\\\\\\\\\\\\\] = None tuple\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_different\\\\\\\\\\\\\\_types: Optional\\\\\\\\\\\\\\[Tuple\\\\\\\\\\\\\\[int, float, bool\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = None print(Model(simple\\\\\\\\\\\\\\_tuple=\\\\\\\\\\\\\\[1, 2, 3, 4\\\\\\\\\\\\\\]).simple\\\\\\\\\\\\\\_tuple) #> (1, 2, 3, 4) print(Model(tuple\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_different\\\\\\\\\\\\\\_types=\\\\\\\\\\\\\\[3, 2, 1\\\\\\\\\\\\\\]).tuple\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_different\\\\\\\\\\\\\\_types) #> (3, 2.0, True) typing.NamedTuple¶ Subclasses of typing.NamedTuple are similar to tuple, but create instances of the given namedtuple class. Subclasses of collections.namedtuple are similar to subclass of typing.NamedTuple, but since field types are not specified, all fields are treated as having type Any. from typing import NamedTuple from pydantic import BaseModel, ValidationError class Point(NamedTuple): x: int y: int class Model(BaseModel): p: Point try: Model(p=('1.3', '2')) except ValidationError as e: print(e) \"\"\" 1 validation error for Model p.0 Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='1.3', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Deque¶ deque¶ Allows list, tuple, set, frozenset, deque, or generators and casts to a deque. When generic parameters are provided, the appropriate validation is applied to the respective items of the deque typing.Deque¶ Handled the same as deque above. from typing import Deque, Optional from pydantic import BaseModel class Model(BaseModel): deque: Optional\\\\\\\\\\\\\\[Deque\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = None print(Model(deque=\\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\]).deque) #> deque(\\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\]) Sets¶ set¶ Allows list, tuple, set, frozenset, deque, or generators and casts to a set. When a generic parameter is provided, the appropriate validation is applied to all items of the set. typing.Set¶ Handled the same as set above. from typing import Optional, Set from pydantic import BaseModel class Model(BaseModel): simple\\\\\\\\\\\\\\_set: Optional\\\\\\\\\\\\\\[set\\\\\\\\\\\\\\] = None set\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints: Optional\\\\\\\\\\\\\\[Set\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = None print(Model(simple\\\\\\\\\\\\\\_set={'1', '2', '3'}).simple\\\\\\\\\\\\\\_set) #> {'1', '2', '3'} print(Model(simple\\\\\\\\\\\\\\_set=\\\\\\\\\\\\\\['1', '2', '3'\\\\\\\\\\\\\\]).simple\\\\\\\\\\\\\\_set) #> {'1', '2', '3'} print(Model(set\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints=\\\\\\\\\\\\\\['1', '2', '3'\\\\\\\\\\\\\\]).set\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints) #> {1, 2, 3} frozenset¶ Allows list, tuple, set, frozenset, deque, or generators and casts to a frozenset. When a generic parameter is provided, the appropriate validation is applied to all items of the frozen set. typing.FrozenSet¶ Handled the same as frozenset above. from typing import FrozenSet, Optional from pydantic import BaseModel class Model(BaseModel): simple\\\\\\\\\\\\\\_frozenset: Optional\\\\\\\\\\\\\\[frozenset\\\\\\\\\\\\\\] = None frozenset\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints: Optional\\\\\\\\\\\\\\[FrozenSet\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = None m1 = Model(simple\\\\\\\\\\\\\\_frozenset=\\\\\\\\\\\\\\['1', '2', '3'\\\\\\\\\\\\\\]) print(type(m1.simple\\\\\\\\\\\\\\_frozenset)) #> print(sorted(m1.simple\\\\\\\\\\\\\\_frozenset)) #> \\\\\\\\\\\\\\['1', '2', '3'\\\\\\\\\\\\\\] m2 = Model(frozenset\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints=\\\\\\\\\\\\\\['1', '2', '3'\\\\\\\\\\\\\\]) print(type(m2.frozenset\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints)) #> print(sorted(m2.frozenset\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints)) #> \\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\] Other Iterables¶ typing.Sequence¶ This is intended for use when the provided value should meet the requirements of the Sequence protocol, and it is desirable to do eager validation of the values in the container. Note that when validation must be performed on the values of the container, the type of the container may not be preserved since validation may end up replacing values. We guarantee that the validated value will be a valid typing.Sequence, but it may have a different type than was provided (generally, it will become a list). typing.Iterable¶ This is intended for use when the provided value may be an iterable that shouldn't be consumed. See Infinite Generators below for more detail on parsing and validation. Similar to typing.Sequence, we guarantee that the validated result will be a valid typing.Iterable, but it may have a different type than was provided. In particular, even if a non-generator type such as a list is provided, the post-validation value of a field of type typing.Iterable will be a generator. Here is a simple example using typing.Sequence: from typing import Sequence from pydantic import BaseModel class Model(BaseModel): sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints: Sequence\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] = None print(Model(sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints=\\\\\\\\\\\\\\[1, 2, 3, 4\\\\\\\\\\\\\\]).sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints) #> \\\\\\\\\\\\\\[1, 2, 3, 4\\\\\\\\\\\\\\] print(Model(sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints=(1, 2, 3, 4)).sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints) #> (1, 2, 3, 4) Infinite Generators¶ If you have a generator you want to validate, you can still use Sequence as described above. In that case, the generator will be consumed and stored on the model as a list and its values will be validated against the type parameter of the Sequence (e.g. int in Sequence\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]). However, if you have a generator that you don't want to be eagerly consumed (e.g. an infinite generator or a remote data loader), you can use a field of type Iterable: from typing import Iterable from pydantic import BaseModel class Model(BaseModel): infinite: Iterable\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] def infinite\\\\\\\\\\\\\\_ints(): i = 0 while True: yield i i += 1 m = Model(infinite=infinite\\\\\\\\\\\\\\_ints()) print(m) \"\"\" infinite=ValidatorIterator(index=0, schema=Some(Int(IntValidator { strict: false }))) \"\"\" for i in m.infinite: print(i) #> 0 #> 1 #> 2 #> 3 #> 4 #> 5 #> 6 #> 7 #> 8 #> 9 #> 10 if i == 10: break Warning During initial validation, Iterable fields only perform a simple check that the provided argument is iterable. To prevent it from being consumed, no validation of the yielded values is performed eagerly. Though the yielded values are not validated eagerly, they are still validated when yielded, and will raise a ValidationError at yield time when appropriate: from typing import Iterable from pydantic import BaseModel, ValidationError class Model(BaseModel): int\\\\\\\\\\\\\\_iterator: Iterable\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] def my\\\\\\\\\\\\\\_iterator(): yield 13 yield '27' yield 'a' m = Model(int\\\\\\\\\\\\\\_iterator=my\\\\\\\\\\\\\\_iterator()) print(next(m.int\\\\\\\\\\\\\\_iterator)) #> 13 print(next(m.int\\\\\\\\\\\\\\_iterator)) #> 27 try: next(m.int\\\\\\\\\\\\\\_iterator) except ValidationError as e: print(e) \"\"\" 1 validation error for ValidatorIterator 2 Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='a', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Mapping Types¶ dict¶ dict(v) is used to attempt to convert a dictionary. see typing.Dict below for sub-type constraints. from pydantic import BaseModel, ValidationError class Model(BaseModel): x: dict m = Model(x={'foo': 1}) print(m.model\\\\\\\\\\\\\\_dump()) #> {'x': {'foo': 1}} try: Model(x='test') except ValidationError as e: print(e) \"\"\" 1 validation error for Model x Input should be a valid dictionary \\\\\\\\\\\\\\[type=dict\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='test', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" typing.Dict¶ from typing import Dict from pydantic import BaseModel, ValidationError class Model(BaseModel): x: Dict\\\\\\\\\\\\\\[str, int\\\\\\\\\\\\\\] m = Model(x={'foo': 1}) print(m.model\\\\\\\\\\\\\\_dump()) #> {'x': {'foo': 1}} try: Model(x={'foo': '1'}) except ValidationError as e: print(e) \"\"\" 1 validation error for Model x Input should be a valid dictionary \\\\\\\\\\\\\\[type=dict\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='test', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" TypedDict¶ Note This is a new feature of the Python standard library as of Python 3.8. Because of limitations in typing.TypedDict before 3.12, the typing-extensions package is required for Python <3.12. You'll need to import TypedDict from typing\\\\\\\\\\\\\\_extensions instead of typing and will get a build time error if you don't. TypedDict declares a dictionary type that expects all of its instances to have a certain set of keys, where each key is associated with a value of a consistent type. It is same as dict but Pydantic will validate the dictionary since keys are annotated. from typing\\\\\\\\\\\\\\_extensions import TypedDict from pydantic import TypeAdapter, ValidationError class User(TypedDict): name: str id: int ta = TypeAdapter(User) print(ta.validate\\\\\\\\\\\\\\_python({'name': 'foo', 'id': 1})) #> {'name': 'foo', 'id': 1} try: ta.validate\\\\\\\\\\\\\\_python({'name': 'foo'}) except ValidationError as e: print(e) \"\"\" 1 validation error for typed-dict id Field required \\\\\\\\\\\\\\[type=missing, input\\\\\\\\\\\\\\_value={'name': 'foo'}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] \"\"\" You can define \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ to change the model inherited from TypedDict. See the ConfigDict API reference for more details. from typing import Optional from typing\\\\\\\\\\\\\\_extensions import TypedDict from pydantic import ConfigDict, TypeAdapter, ValidationError # \\\\\\\\\\\\\\`total=False\\\\\\\\\\\\\\` means keys are non-required class UserIdentity(TypedDict, total=False): name: Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] surname: str class User(TypedDict): \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ = ConfigDict(extra='forbid') identity: UserIdentity age: int ta = TypeAdapter(User) print( ta.validate\\\\\\\\\\\\\\_python( {'identity': {'name': 'Smith', 'surname': 'John'}, 'age': 37} ) ) #> {'identity': {'name': 'Smith', 'surname': 'John'}, 'age': 37} print( ta.validate\\\\\\\\\\\\\\_python( {'identity': {'name': None, 'surname': 'John'}, 'age': 37} ) ) #> {'identity': {'name': None, 'surname': 'John'}, 'age': 37} print(ta.validate\\\\\\\\\\\\\\_python({'identity': {}, 'age': 37})) #> {'identity': {}, 'age': 37} try: ta.validate\\\\\\\\\\\\\\_python( {'identity': {'name': \\\\\\\\\\\\\\['Smith'\\\\\\\\\\\\\\], 'surname': 'John'}, 'age': 24} ) except ValidationError as e: print(e) \"\"\" 1 validation error for typed-dict identity.name Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=\\\\\\\\\\\\\\['Smith'\\\\\\\\\\\\\\], input\\\\\\\\\\\\\\_type=list\\\\\\\\\\\\\\] \"\"\" try: ta.validate\\\\\\\\\\\\\\_python( { 'identity': {'name': 'Smith', 'surname': 'John'}, 'age': '37', 'email': 'john.smith@me.com', } ) except ValidationError as e: print(e) \"\"\" 1 validation error for typed-dict email Extra inputs are not permitted \\\\\\\\\\\\\\[type=extra\\\\\\\\\\\\\\_forbidden, input\\\\\\\\\\\\\\_value='john.smith@me.com', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Callable¶ See below for more detail on parsing and validation Fields can also be of type Callable: from typing import Callable from pydantic import BaseModel class Foo(BaseModel): callback: Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\], int\\\\\\\\\\\\\\] m = Foo(callback=lambda x: x) print(m) #> callback= at 0x0123456789ab> Warning Callable fields only perform a simple check that the argument is callable; no validation of arguments, their types, or the return type is performed. IP Address Types¶ ipaddress.IPv4Address: Uses the type itself for validation by passing the value to IPv4Address(v). ipaddress.IPv4Interface: Uses the type itself for validation by passing the value to IPv4Address(v). ipaddress.IPv4Network: Uses the type itself for validation by passing the value to IPv4Network(v). ipaddress.IPv6Address: Uses the type itself for validation by passing the value to IPv6Address(v). ipaddress.IPv6Interface: Uses the type itself for validation by passing the value to IPv6Interface(v). ipaddress.IPv6Network: Uses the type itself for validation by passing the value to IPv6Network(v). See Network Types for other custom IP address types. UUID¶ For UUID, Pydantic tries to use the type itself for validation by passing the value to UUID(v). There's a fallback to UUID(bytes=v) for bytes and bytearray. In case you want to constrain the UUID version, you can check the following types: UUID1: requires UUID version 1. UUID3: requires UUID version 3. UUID4: requires UUID version 4. UUID5: requires UUID version 5. Union¶ Pydantic has extensive support for union validation, both typing.Union and Python 3.10's pipe syntax (A | B) are supported. Read more in the Unions section of the concepts docs. Type and TypeVar¶ type¶ Pydantic supports the use of type\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\] to specify that a field may only accept classes (not instances) that are subclasses of T. typing.Type¶ Handled the same as type above. from typing import Type from pydantic import BaseModel, ValidationError class Foo: pass class Bar(Foo): pass class Other: pass class SimpleModel(BaseModel): just\\\\\\\\\\\\\\_subclasses: Type\\\\\\\\\\\\\\[Foo\\\\\\\\\\\\\\] SimpleModel(just\\\\\\\\\\\\\\_subclasses=Foo) SimpleModel(just\\\\\\\\\\\\\\_subclasses=Bar) try: SimpleModel(just\\\\\\\\\\\\\\_subclasses=Other) except ValidationError as e: print(e) \"\"\" 1 validation error for SimpleModel just\\\\\\\\\\\\\\_subclasses Input should be a subclass of Foo \\\\\\\\\\\\\\[type=is\\\\\\\\\\\\\\_subclass\\\\\\\\\\\\\\_of, input\\\\\\\\\\\\\\_value=, input\\\\\\\\\\\\\\_type=type\\\\\\\\\\\\\\] \"\"\" You may also use Type to specify that any class is allowed. from typing import Type from pydantic import BaseModel, ValidationError class Foo: pass class LenientSimpleModel(BaseModel): any\\\\\\\\\\\\\\_class\\\\\\\\\\\\\\_goes: Type LenientSimpleModel(any\\\\\\\\\\\\\\_class\\\\\\\\\\\\\\_goes=int) LenientSimpleModel(any\\\\\\\\\\\\\\_class\\\\\\\\\\\\\\_goes=Foo) try: LenientSimpleModel(any\\\\\\\\\\\\\\_class\\\\\\\\\\\\\\_goes=Foo()) except ValidationError as e: print(e) \"\"\" 1 validation error for LenientSimpleModel any\\\\\\\\\\\\\\_class\\\\\\\\\\\\\\_goes Input should be a type \\\\\\\\\\\\\\[type=is\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=<\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_main\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.Foo object at 0x0123456789ab>, input\\\\\\\\\\\\\\_type=Foo\\\\\\\\\\\\\\] \"\"\" typing.TypeVar¶ TypeVar is supported either unconstrained, constrained or with a bound. from typing import TypeVar from pydantic import BaseModel Foobar = TypeVar('Foobar') BoundFloat = TypeVar('BoundFloat', bound=float) IntStr = TypeVar('IntStr', int, str) class Model(BaseModel): a: Foobar # equivalent of \": Any\" b: BoundFloat # equivalent of \": float\" c: IntStr # equivalent of \": Union\\\\\\\\\\\\\\[int, str\\\\\\\\\\\\\\]\" print(Model(a=\\\\\\\\\\\\\\[1\\\\\\\\\\\\\\], b=4.2, c='x')) #> a=\\\\\\\\\\\\\\[1\\\\\\\\\\\\\\] b=4.2 c='x' # a may be None print(Model(a=None, b=1, c=1)) #> a=None b=1.0 c=1 None Types¶ None, type(None), or Literal\\\\\\\\\\\\\\[None\\\\\\\\\\\\\\] are all equivalent according to PEP 484. Allows only None value. Strings¶ str: Strings are accepted as-is. bytes and bytearray are converted using v.decode(). Enums inheriting fromstrare converted usingv.value\\\\\\\\\\\\\\`. All other types cause an error. Strings aren't Sequences While instances of str are technically valid instances of the Sequence\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] protocol from a type-checker's point of view, this is frequently not intended as is a common source of bugs. As a result, Pydantic raises a ValidationError if you attempt to pass a str or bytes instance into a field of type Sequence\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] or Sequence\\\\\\\\\\\\\\[bytes\\\\\\\\\\\\\\]: from typing import Optional, Sequence from pydantic import BaseModel, ValidationError class Model(BaseModel): sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_strs: Optional\\\\\\\\\\\\\\[Sequence\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = None sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_bytes: Optional\\\\\\\\\\\\\\[Sequence\\\\\\\\\\\\\\[bytes\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = None print(Model(sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_strs=\\\\\\\\\\\\\\['a', 'bc'\\\\\\\\\\\\\\]).sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_strs) #> \\\\\\\\\\\\\\['a', 'bc'\\\\\\\\\\\\\\] print(Model(sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_strs=('a', 'bc')).sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_strs) #> ('a', 'bc') print(Model(sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_bytes=\\\\\\\\\\\\\\[b'a', b'bc'\\\\\\\\\\\\\\]).sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_bytes) #> \\\\\\\\\\\\\\[b'a', b'bc'\\\\\\\\\\\\\\] print(Model(sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_bytes=(b'a', b'bc')).sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_bytes) #> (b'a', b'bc') try: Model(sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_strs='abc') except ValidationError as e: print(e) \"\"\" 1 validation error for Model sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_strs 'str' instances are not allowed as a Sequence value \\\\\\\\\\\\\\[type=sequence\\\\\\\\\\\\\\_str, input\\\\\\\\\\\\\\_value='abc', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" try: Model(sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_bytes=b'abc') except ValidationError as e: print(e) \"\"\" 1 validation error for Model sequence\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_bytes 'bytes' instances are not allowed as a Sequence value \\\\\\\\\\\\\\[type=sequence\\\\\\\\\\\\\\_str, input\\\\\\\\\\\\\\_value=b'abc', input\\\\\\\\\\\\\\_type=bytes\\\\\\\\\\\\\\] \"\"\" Bytes¶ bytes are accepted as-is. bytearray is converted using bytes(v). str are converted using v.encode(). int, float, and Decimal are coerced using str(v).encode(). See ByteSize for more details. typing.Literal¶ Note This is a new feature of the Python standard library as of Python 3.8; prior to Python 3.8, it requires the typing-extensions package. Pydantic supports the use of typing.Literal (or typing\\\\\\\\\\\\\\_extensions.Literal prior to Python 3.8) as a lightweight way to specify that a field may accept only specific literal values: from typing import Literal from pydantic import BaseModel, ValidationError class Pie(BaseModel): flavor: Literal\\\\\\\\\\\\\\['apple', 'pumpkin'\\\\\\\\\\\\\\] Pie(flavor='apple') Pie(flavor='pumpkin') try: Pie(flavor='cherry') except ValidationError as e: print(str(e)) \"\"\" 1 validation error for Pie flavor Input should be 'apple' or 'pumpkin' \\\\\\\\\\\\\\[type=literal\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='cherry', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" One benefit of this field type is that it can be used to check for equality with one or more specific values without needing to declare custom validators: from typing import ClassVar, List, Literal, Union from pydantic import BaseModel, ValidationError class Cake(BaseModel): kind: Literal\\\\\\\\\\\\\\['cake'\\\\\\\\\\\\\\] required\\\\\\\\\\\\\\_utensils: ClassVar\\\\\\\\\\\\\\[List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = \\\\\\\\\\\\\\['fork', 'knife'\\\\\\\\\\\\\\] class IceCream(BaseModel): kind: Literal\\\\\\\\\\\\\\['icecream'\\\\\\\\\\\\\\] required\\\\\\\\\\\\\\_utensils: ClassVar\\\\\\\\\\\\\\[List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = \\\\\\\\\\\\\\['spoon'\\\\\\\\\\\\\\] class Meal(BaseModel): dessert: Union\\\\\\\\\\\\\\[Cake, IceCream\\\\\\\\\\\\\\] print(type(Meal(dessert={'kind': 'cake'}).dessert).\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_) #> Cake print(type(Meal(dessert={'kind': 'icecream'}).dessert).\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_) #> IceCream try: Meal(dessert={'kind': 'pie'}) except ValidationError as e: print(str(e)) \"\"\" 2 validation errors for Meal dessert.Cake.kind Input should be 'cake' \\\\\\\\\\\\\\[type=literal\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='pie', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] dessert.IceCream.kind Input should be 'icecream' \\\\\\\\\\\\\\[type=literal\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='pie', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" With proper ordering in an annotated Union, you can use this to parse types of decreasing specificity: from typing import Literal, Optional, Union from pydantic import BaseModel class Dessert(BaseModel): kind: str class Pie(Dessert): kind: Literal\\\\\\\\\\\\\\['pie'\\\\\\\\\\\\\\] flavor: Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] class ApplePie(Pie): flavor: Literal\\\\\\\\\\\\\\['apple'\\\\\\\\\\\\\\] class PumpkinPie(Pie): flavor: Literal\\\\\\\\\\\\\\['pumpkin'\\\\\\\\\\\\\\] class Meal(BaseModel): dessert: Union\\\\\\\\\\\\\\[ApplePie, PumpkinPie, Pie, Dessert\\\\\\\\\\\\\\] print(type(Meal(dessert={'kind': 'pie', 'flavor': 'apple'}).dessert).\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_) #> ApplePie print(type(Meal(dessert={'kind': 'pie', 'flavor': 'pumpkin'}).dessert).\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_) #> PumpkinPie print(type(Meal(dessert={'kind': 'pie'}).dessert).\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_) #> Dessert print(type(Meal(dessert={'kind': 'cake'}).dessert).\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_) #> Dessert typing.Any¶ Allows any value, including None. typing.Annotated¶ Allows wrapping another type with arbitrary metadata, as per PEP-593. The Annotated hint may contain a single call to the Field function, but otherwise the additional metadata is ignored and the root type is used. typing.Pattern¶ Will cause the input value to be passed to re.compile(v) to create a regular expression pattern. pathlib.Path¶ Simply uses the type itself for validation by passing the value to Path(v). Made with Material for MkDocs Insiders"
  },
  {
    "title": "Functional Serializers - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/functional_serializers/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Functional Serializers Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.functional\\\\\\\\\\\\\\_serializers PlainSerializer WrapSerializer field\\\\\\\\\\\\\\_serializer() model\\\\\\\\\\\\\\_serializer() Functional Serializers This module contains related classes and functions for serialization. PlainSerializer dataclass ¶ Plain serializers use a function to modify the output of serialization. Attributes: Name Type Description func core\\\\\\\\\\\\\\_schema.SerializerFunction The serializer function. return\\\\\\\\\\\\\\_type Any The return type for the function. If omitted it will be inferred from the type annotation. when\\\\\\\\\\\\\\_used Literal\\\\\\\\\\\\\\['always', 'unless-none', 'json', 'json-unless-none'\\\\\\\\\\\\\\] Determines when this serializer should be used. Accepts a string with values 'always', 'unless-none', 'json', and 'json-unless-none'. Defaults to 'always'. WrapSerializer dataclass ¶ Wrap serializers receive the raw inputs along with a handler function that applies the standard serialization logic, and can modify the resulting value before returning it as the final output of serialization. Attributes: Name Type Description func core\\\\\\\\\\\\\\_schema.WrapSerializerFunction The serializer function to be wrapped. return\\\\\\\\\\\\\\_type Any The return type for the function. If omitted it will be inferred from the type annotation. when\\\\\\\\\\\\\\_used Literal\\\\\\\\\\\\\\['always', 'unless-none', 'json', 'json-unless-none'\\\\\\\\\\\\\\] Determines when this serializer should be used. Accepts a string with values 'always', 'unless-none', 'json', and 'json-unless-none'. Defaults to 'always'. field\\\\\\\\\\\\\\_serializer ¶ field\\\\\\\\\\\\\\_serializer( \\\\\\\\\\\\\\*fields, mode=\"plain\", return\\\\\\\\\\\\\\_type=PydanticUndefined, when\\\\\\\\\\\\\\_used=\"always\", check\\\\\\\\\\\\\\_fields=None ) Decorator that enables custom field serialization. See Custom serializers for more information. Four signatures are supported: (self, value: Any, info: FieldSerializationInfo) (self, value: Any, nxt: SerializerFunctionWrapHandler, info: FieldSerializationInfo) (value: Any, info: SerializationInfo) (value: Any, nxt: SerializerFunctionWrapHandler, info: SerializationInfo) Parameters: Name Type Description Default fields str Which field(s) the method should be called on. () mode Literal\\\\\\\\\\\\\\['plain', 'wrap'\\\\\\\\\\\\\\] The serialization mode. plain means the function will be called instead of the default serialization logic, wrap means the function will be called with an argument to optionally call the default serialization logic. 'plain' return\\\\\\\\\\\\\\_type Any Optional return type for the function, if omitted it will be inferred from the type annotation. PydanticUndefined when\\\\\\\\\\\\\\_used Literal\\\\\\\\\\\\\\['always', 'unless-none', 'json', 'json-unless-none'\\\\\\\\\\\\\\] Determines the serializer will be used for serialization. 'always' check\\\\\\\\\\\\\\_fields bool | None Whether to check that the fields actually exist on the model. None Returns: Type Description Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] The decorator function. Source code in pydantic/functional\\\\\\\\\\\\\\_serializers.py model\\\\\\\\\\\\\\_serializer ¶ model\\\\\\\\\\\\\\_serializer( \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_f=None, \\\\\\\\\\\\\\*, mode=\"plain\", when\\\\\\\\\\\\\\_used=\"always\", return\\\\\\\\\\\\\\_type=PydanticUndefined ) Decorator that enables custom model serialization. See Custom serializers for more information. Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_f Callable\\\\\\\\\\\\\\[..., Any\\\\\\\\\\\\\\] | None The function to be decorated. None mode Literal\\\\\\\\\\\\\\['plain', 'wrap'\\\\\\\\\\\\\\] The serialization mode. 'plain' means the function will be called instead of the default serialization logic 'wrap' means the function will be called with an argument to optionally call the default serialization logic. 'plain' when\\\\\\\\\\\\\\_used Literal\\\\\\\\\\\\\\['always', 'unless-none', 'json', 'json-unless-none'\\\\\\\\\\\\\\] Determines when this serializer should be used. 'always' return\\\\\\\\\\\\\\_type Any The return type for the function. If omitted it will be inferred from the type annotation. PydanticUndefined Returns: Type Description Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] The decorator function. Source code in pydantic/functional\\\\\\\\\\\\\\_serializers.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Functional Validators - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/functional_validators/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Functional Validators Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.functional\\\\\\\\\\\\\\_validators ModelAfterValidatorWithoutInfo ModelAfterValidator AfterValidator BeforeValidator PlainValidator WrapValidator ModelWrapValidatorHandler ModelWrapValidatorWithoutInfo ModelWrapValidator ModelBeforeValidatorWithoutInfo ModelBeforeValidator InstanceOf SkipValidation field\\\\\\\\\\\\\\_validator() model\\\\\\\\\\\\\\_validator() Functional Validators This module contains related classes and functions for validation. ModelAfterValidatorWithoutInfo module-attribute ¶ ModelAfterValidatorWithoutInfo = Callable\\\\\\\\\\\\\\[ \\\\\\\\\\\\\\[\\\\\\\\\\\\\\_ModelType\\\\\\\\\\\\\\], \\\\\\\\\\\\\\_ModelType \\\\\\\\\\\\\\] A @model\\\\\\\\\\\\\\_validator decorated function signature. This is used when mode='after' and the function does not have info argument. ModelAfterValidator module-attribute ¶ ModelAfterValidator = Callable\\\\\\\\\\\\\\[ \\\\\\\\\\\\\\[\\\\\\\\\\\\\\_ModelType, \\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema.ValidationInfo\\\\\\\\\\\\\\], \\\\\\\\\\\\\\_ModelType \\\\\\\\\\\\\\] A @model\\\\\\\\\\\\\\_validator decorated function signature. This is used when mode='after'. AfterValidator dataclass ¶ Usage Documentation Annotated Validators A metadata class that indicates that a validation should be applied after the inner validation logic. Attributes: Name Type Description func core\\\\\\\\\\\\\\_schema.NoInfoValidatorFunction | core\\\\\\\\\\\\\\_schema.WithInfoValidatorFunction The validator function. Example from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import AfterValidator, BaseModel, ValidationError MyInt = Annotated\\\\\\\\\\\\\\[int, AfterValidator(lambda v: v + 1)\\\\\\\\\\\\\\] class Model(BaseModel): a: MyInt print(Model(a=1).a) #> 2 try: Model(a='a') except ValidationError as e: print(e.json(indent=2)) ''' \\\\\\\\\\\\\\[ { \"type\": \"int\\\\\\\\\\\\\\_parsing\", \"loc\": \\\\\\\\\\\\\\[ \"a\" \\\\\\\\\\\\\\], \"msg\": \"Input should be a valid integer, unable to parse string as an integer\", \"input\": \"a\", \"url\": \"https://errors.pydantic.dev/2/v/int\\\\\\\\\\\\\\_parsing\" } \\\\\\\\\\\\\\] ''' BeforeValidator dataclass ¶ Usage Documentation Annotated Validators A metadata class that indicates that a validation should be applied before the inner validation logic. Attributes: Name Type Description func core\\\\\\\\\\\\\\_schema.NoInfoValidatorFunction | core\\\\\\\\\\\\\\_schema.WithInfoValidatorFunction The validator function. Example from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, BeforeValidator MyInt = Annotated\\\\\\\\\\\\\\[int, BeforeValidator(lambda v: v + 1)\\\\\\\\\\\\\\] class Model(BaseModel): a: MyInt print(Model(a=1).a) #> 2 try: Model(a='a') except TypeError as e: print(e) #> can only concatenate str (not \"int\") to str PlainValidator dataclass ¶ Usage Documentation Annotated Validators A metadata class that indicates that a validation should be applied instead of the inner validation logic. Attributes: Name Type Description func core\\\\\\\\\\\\\\_schema.NoInfoValidatorFunction | core\\\\\\\\\\\\\\_schema.WithInfoValidatorFunction The validator function. Example from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, PlainValidator MyInt = Annotated\\\\\\\\\\\\\\[int, PlainValidator(lambda v: int(v) + 1)\\\\\\\\\\\\\\] class Model(BaseModel): a: MyInt print(Model(a='1').a) #> 2 WrapValidator dataclass ¶ Usage Documentation Annotated Validators A metadata class that indicates that a validation should be applied around the inner validation logic. Attributes: Name Type Description func core\\\\\\\\\\\\\\_schema.NoInfoWrapValidatorFunction | core\\\\\\\\\\\\\\_schema.WithInfoWrapValidatorFunction The validator function. from datetime import datetime from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, ValidationError, WrapValidator def validate\\\\\\\\\\\\\\_timestamp(v, handler): if v == 'now': # we don't want to bother with further validation, just return the new value return datetime.now() try: return handler(v) except ValidationError: # validation failed, in this case we want to return a default value return datetime(2000, 1, 1) MyTimestamp = Annotated\\\\\\\\\\\\\\[datetime, WrapValidator(validate\\\\\\\\\\\\\\_timestamp)\\\\\\\\\\\\\\] class Model(BaseModel): a: MyTimestamp print(Model(a='now').a) #> 2032-01-02 03:04:05.000006 print(Model(a='invalid').a) #> 2000-01-01 00:00:00 ModelWrapValidatorHandler ¶ Bases: \\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema.ValidatorFunctionWrapHandler, Protocol\\\\\\\\\\\\\\[\\\\\\\\\\\\\\_ModelTypeCo\\\\\\\\\\\\\\] @model\\\\\\\\\\\\\\_validator decorated function handler argument type. This is used when mode='wrap'. ModelWrapValidatorWithoutInfo ¶ Bases: Protocol\\\\\\\\\\\\\\[\\\\\\\\\\\\\\_ModelType\\\\\\\\\\\\\\] A @model\\\\\\\\\\\\\\_validator decorated function signature. This is used when mode='wrap' and the function does not have info argument. ModelWrapValidator ¶ Bases: Protocol\\\\\\\\\\\\\\[\\\\\\\\\\\\\\_ModelType\\\\\\\\\\\\\\] A @model\\\\\\\\\\\\\\_validator decorated function signature. This is used when mode='wrap'. ModelBeforeValidatorWithoutInfo ¶ Bases: Protocol A @model\\\\\\\\\\\\\\_validator decorated function signature. This is used when mode='before' and the function does not have info argument. ModelBeforeValidator ¶ Bases: Protocol A @model\\\\\\\\\\\\\\_validator decorated function signature. This is used when mode='before'. InstanceOf dataclass ¶ Generic type for annotating a type that is an instance of a given class. Example from pydantic import BaseModel, InstanceOf class Foo: ... class Bar(BaseModel): foo: InstanceOf\\\\\\\\\\\\\\[Foo\\\\\\\\\\\\\\] Bar(foo=Foo()) try: Bar(foo=42) except ValidationError as e: print(e) \"\"\" \\\\\\\\\\\\\\[ │ { │ │ 'type': 'is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_of', │ │ 'loc': ('foo',), │ │ 'msg': 'Input should be an instance of Foo', │ │ 'input': 42, │ │ 'ctx': {'class': 'Foo'}, │ │ 'url': 'https://errors.pydantic.dev/0.38.0/v/is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_of' │ } \\\\\\\\\\\\\\] \"\"\" SkipValidation dataclass ¶ If this is applied as an annotation (e.g., via x: Annotated\\\\\\\\\\\\\\[int, SkipValidation\\\\\\\\\\\\\\]), validation will be skipped. You can also use SkipValidation\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] as a shorthand for Annotated\\\\\\\\\\\\\\[int, SkipValidation\\\\\\\\\\\\\\]. This can be useful if you want to use a type annotation for documentation/IDE/type-checking purposes, and know that it is safe to skip validation for one or more of the fields. Because this converts the validation schema to any\\\\\\\\\\\\\\_schema, subsequent annotation-applied transformations may not have the expected effects. Therefore, when used, this annotation should generally be the final annotation applied to a type. field\\\\\\\\\\\\\\_validator ¶ field\\\\\\\\\\\\\\_validator( \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_field, \\\\\\\\\\\\\\*fields, mode=\"after\", check\\\\\\\\\\\\\\_fields=None ) Usage Documentation Field validators Decorate methods on the class indicating that they should be used to validate fields. Example usage: from typing import Any from pydantic import ( BaseModel, ValidationError, field\\\\\\\\\\\\\\_validator, ) class Model(BaseModel): a: str @field\\\\\\\\\\\\\\_validator('a') @classmethod def ensure\\\\\\\\\\\\\\_foobar(cls, v: Any): if 'foobar' not in v: raise ValueError('\"foobar\" not found in a') return v print(repr(Model(a='this is foobar good'))) #> Model(a='this is foobar good') try: Model(a='snap') except ValidationError as exc\\\\\\\\\\\\\\_info: print(exc\\\\\\\\\\\\\\_info) ''' 1 validation error for Model a Value error, \"foobar\" not found in a \\\\\\\\\\\\\\[type=value\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='snap', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' For more in depth examples, see Field Validators. Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_field str The first field the field\\\\\\\\\\\\\\_validator should be called on; this is separate from fields to ensure an error is raised if you don't pass at least one. required \\\\\\\\\\\\\\*fields str Additional field(s) the field\\\\\\\\\\\\\\_validator should be called on. () mode FieldValidatorModes Specifies whether to validate the fields before or after validation. 'after' check\\\\\\\\\\\\\\_fields bool | None Whether to check that the fields actually exist on the model. None Returns: Type Description Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] A decorator that can be used to decorate a function to be used as a field\\\\\\\\\\\\\\_validator. Raises: Type Description PydanticUserError If @field\\\\\\\\\\\\\\_validator is used bare (with no fields). If the args passed to @field\\\\\\\\\\\\\\_validator as fields are not strings. If @field\\\\\\\\\\\\\\_validator applied to instance methods. Source code in pydantic/functional\\\\\\\\\\\\\\_validators.py model\\\\\\\\\\\\\\_validator ¶ model\\\\\\\\\\\\\\_validator(\\\\\\\\\\\\\\*, mode) Usage Documentation Model validators Decorate model methods for validation purposes. Example usage: from typing import Optional from pydantic import BaseModel, ValidationError, model\\\\\\\\\\\\\\_validator class Square(BaseModel): width: float height: float @model\\\\\\\\\\\\\\_validator(mode='after') def verify\\\\\\\\\\\\\\_square(self) -> 'Rectangle': if self.width != self.height: raise ValueError('width and height do not match') return self s = Square(width=1, height=1) print(repr(s)) #> Square(width=1.0, height=1.0) try: Square(width=1, height=2) except ValidationError as e: print(e) ''' 1 validation error for Square \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ width and height do not match (type=value\\\\\\\\\\\\\\_error) ''' For more in depth examples, see Model Validators. Parameters: Name Type Description Default mode Literal\\\\\\\\\\\\\\['wrap', 'before', 'after'\\\\\\\\\\\\\\] A required string literal that specifies the validation mode. It can be one of the following: 'wrap', 'before', or 'after'. required Returns: Type Description Any A decorator that can be used to decorate a function to be used as a model validator. Source code in pydantic/functional\\\\\\\\\\\\\\_validators.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Errors - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/errors/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Errors Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.errors PydanticErrorMixin PydanticUserError PydanticUndefinedAnnotation from\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_error() PydanticImportError PydanticSchemaGenerationError PydanticInvalidForJsonSchema Errors Pydantic-specific errors. PydanticErrorMixin ¶ PydanticErrorMixin(message, \\\\\\\\\\\\\\*, code) A mixin class for common functionality shared by all Pydantic-specific errors. Attributes: Name Type Description message A message describing the error. code An optional error code from PydanticErrorCodes enum. Source code in pydantic/errors.py PydanticUserError ¶ Bases: PydanticErrorMixin, TypeError An error raised due to incorrect use of Pydantic. PydanticUndefinedAnnotation ¶ PydanticUndefinedAnnotation(name, message) Bases: PydanticErrorMixin, NameError A subclass of NameError raised when handling undefined annotations during CoreSchema generation. Attributes: Name Type Description name Name of the error. message Description of the error. Source code in pydantic/errors.py from\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_error classmethod ¶ from\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_error(name\\\\\\\\\\\\\\_error) Convert a NameError to a PydanticUndefinedAnnotation error. Parameters: Name Type Description Default name\\\\\\\\\\\\\\_error NameError NameError to be converted. required Returns: Type Description Self Converted PydanticUndefinedAnnotation error. Source code in pydantic/errors.py PydanticImportError ¶ PydanticImportError(message) Bases: PydanticErrorMixin, ImportError An error raised when an import fails due to module changes between V1 and V2. Attributes: Name Type Description message Description of the error. Source code in pydantic/errors.py PydanticSchemaGenerationError ¶ PydanticSchemaGenerationError(message) Bases: PydanticUserError An error raised during failures to generate a CoreSchema for some type. Attributes: Name Type Description message Description of the error. Source code in pydantic/errors.py PydanticInvalidForJsonSchema ¶ PydanticInvalidForJsonSchema(message) Bases: PydanticUserError An error raised during failures to generate a JSON schema for some CoreSchema. Attributes: Name Type Description message Description of the error. Source code in pydantic/errors.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "JSON Schema - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/json_schema/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 JSON Schema Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.json\\\\\\\\\\\\\\_schema CoreSchemaOrFieldType JsonSchemaValue JsonSchemaMode JsonSchemaWarningKind DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE PydanticJsonSchemaWarning GenerateJsonSchema ValidationsMapping build\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_method() generate\\\\\\\\\\\\\\_definitions() generate() generate\\\\\\\\\\\\\\_inner() any\\\\\\\\\\\\\\_schema() none\\\\\\\\\\\\\\_schema() bool\\\\\\\\\\\\\\_schema() int\\\\\\\\\\\\\\_schema() float\\\\\\\\\\\\\\_schema() decimal\\\\\\\\\\\\\\_schema() str\\\\\\\\\\\\\\_schema() bytes\\\\\\\\\\\\\\_schema() date\\\\\\\\\\\\\\_schema() time\\\\\\\\\\\\\\_schema() datetime\\\\\\\\\\\\\\_schema() timedelta\\\\\\\\\\\\\\_schema() literal\\\\\\\\\\\\\\_schema() is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_schema() is\\\\\\\\\\\\\\_subclass\\\\\\\\\\\\\\_schema() callable\\\\\\\\\\\\\\_schema() list\\\\\\\\\\\\\\_schema() tuple\\\\\\\\\\\\\\_positional\\\\\\\\\\\\\\_schema() tuple\\\\\\\\\\\\\\_variable\\\\\\\\\\\\\\_schema() set\\\\\\\\\\\\\\_schema() frozenset\\\\\\\\\\\\\\_schema() generator\\\\\\\\\\\\\\_schema() dict\\\\\\\\\\\\\\_schema() function\\\\\\\\\\\\\\_before\\\\\\\\\\\\\\_schema() function\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_schema() function\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_schema() function\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_schema() default\\\\\\\\\\\\\\_schema() nullable\\\\\\\\\\\\\\_schema() union\\\\\\\\\\\\\\_schema() tagged\\\\\\\\\\\\\\_union\\\\\\\\\\\\\\_schema() chain\\\\\\\\\\\\\\_schema() lax\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_strict\\\\\\\\\\\\\\_schema() json\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_python\\\\\\\\\\\\\\_schema() typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema() typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_schema() dataclass\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_schema() model\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_schema() computed\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_schema() model\\\\\\\\\\\\\\_schema() resolve\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_update() model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_schema() field\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_present() field\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_required() dataclass\\\\\\\\\\\\\\_args\\\\\\\\\\\\\\_schema() dataclass\\\\\\\\\\\\\\_schema() arguments\\\\\\\\\\\\\\_schema() kw\\\\\\\\\\\\\\_arguments\\\\\\\\\\\\\\_schema() p\\\\\\\\\\\\\\_arguments\\\\\\\\\\\\\\_schema() get\\\\\\\\\\\\\\_argument\\\\\\\\\\\\\\_name() call\\\\\\\\\\\\\\_schema() custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_schema() json\\\\\\\\\\\\\\_schema() url\\\\\\\\\\\\\\_schema() multi\\\\\\\\\\\\\\_host\\\\\\\\\\\\\\_url\\\\\\\\\\\\\\_schema() uuid\\\\\\\\\\\\\\_schema() definitions\\\\\\\\\\\\\\_schema() definition\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema() ser\\\\\\\\\\\\\\_schema() get\\\\\\\\\\\\\\_title\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_name() field\\\\\\\\\\\\\\_title\\\\\\\\\\\\\\_should\\\\\\\\\\\\\\_be\\\\\\\\\\\\\\_set() normalize\\\\\\\\\\\\\\_name() get\\\\\\\\\\\\\\_defs\\\\\\\\\\\\\\_ref() get\\\\\\\\\\\\\\_cache\\\\\\\\\\\\\\_defs\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema() handle\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_overrides() encode\\\\\\\\\\\\\\_default() update\\\\\\\\\\\\\\_with\\\\\\\\\\\\\\_validations() get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_counts() emit\\\\\\\\\\\\\\_warning() render\\\\\\\\\\\\\\_warning\\\\\\\\\\\\\\_message() WithJsonSchema Examples SkipJsonSchema update\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema() model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema() models\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema() JSON Schema Usage Documentation Json Schema The json\\\\\\\\\\\\\\_schema module contains classes and functions to allow the way JSON Schema is generated to be customized. In general you shouldn't need to use this module directly; instead, you can BaseModel.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema and TypeAdapter.json\\\\\\\\\\\\\\_schema. CoreSchemaOrFieldType module-attribute ¶ CoreSchemaOrFieldType = Literal\\\\\\\\\\\\\\[ core\\\\\\\\\\\\\\_schema.CoreSchemaType, core\\\\\\\\\\\\\\_schema.CoreSchemaFieldType, \\\\\\\\\\\\\\] A type alias for defined schema types that represents a union of core\\\\\\\\\\\\\\_schema.CoreSchemaType and core\\\\\\\\\\\\\\_schema.CoreSchemaFieldType. JsonSchemaValue module-attribute ¶ JsonSchemaValue = Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] A type alias for a JSON schema value. This is a dictionary of string keys to arbitrary values. JsonSchemaMode module-attribute ¶ JsonSchemaMode = Literal\\\\\\\\\\\\\\['validation', 'serialization'\\\\\\\\\\\\\\] A type alias that represents the mode of a JSON schema; either 'validation' or 'serialization'. For some types, the inputs to validation differ from the outputs of serialization. For example, computed fields will only be present when serializing, and should not be provided when validating. This flag provides a way to indicate whether you want the JSON schema required for validation inputs, or that will be matched by serialization outputs. JsonSchemaWarningKind module-attribute ¶ JsonSchemaWarningKind = Literal\\\\\\\\\\\\\\[ \"skipped-choice\", \"non-serializable-default\" \\\\\\\\\\\\\\] A type alias representing the kinds of warnings that can be emitted during JSON schema generation. See GenerateJsonSchema.render\\\\\\\\\\\\\\_warning\\\\\\\\\\\\\\_message for more details. DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE module-attribute ¶ DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE = '#/$defs/{model}' The default format string used to generate reference names. PydanticJsonSchemaWarning ¶ Bases: UserWarning This class is used to emit warnings produced during JSON schema generation. See the GenerateJsonSchema.emit\\\\\\\\\\\\\\_warning and GenerateJsonSchema.render\\\\\\\\\\\\\\_warning\\\\\\\\\\\\\\_message methods for more details; these can be overridden to control warning behavior. GenerateJsonSchema ¶ GenerateJsonSchema( by\\\\\\\\\\\\\\_alias=True, ref\\\\\\\\\\\\\\_template=DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE ) Usage Documentation Customizing the JSON schema generation process A class for generating JSON schemas. This class generates JSON schemas based on configured parameters. The default schema dialect is https://json-schema.org/draft/2020-12/schema. The class uses by\\\\\\\\\\\\\\_alias to configure how fields with multiple names are handled and ref\\\\\\\\\\\\\\_template to format reference names. Attributes: Name Type Description schema\\\\\\\\\\\\\\_dialect The JSON schema dialect used to generate the schema. See Declaring a Dialect in the JSON Schema documentation for more information about dialects. ignored\\\\\\\\\\\\\\_warning\\\\\\\\\\\\\\_kinds set\\\\\\\\\\\\\\[JsonSchemaWarningKind\\\\\\\\\\\\\\] Warnings to ignore when generating the schema. self.render\\\\\\\\\\\\\\_warning\\\\\\\\\\\\\\_message will do nothing if its argument kind is in ignored\\\\\\\\\\\\\\_warning\\\\\\\\\\\\\\_kinds; this value can be modified on subclasses to easily control which warnings are emitted. by\\\\\\\\\\\\\\_alias Whether or not to use field names when generating the schema. ref\\\\\\\\\\\\\\_template The format string used when generating reference names. core\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_refs dict\\\\\\\\\\\\\\[CoreModeRef, JsonRef\\\\\\\\\\\\\\] A mapping of core refs to JSON refs. core\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_defs\\\\\\\\\\\\\\_refs dict\\\\\\\\\\\\\\[CoreModeRef, DefsRef\\\\\\\\\\\\\\] A mapping of core refs to definition refs. defs\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_refs dict\\\\\\\\\\\\\\[DefsRef, CoreModeRef\\\\\\\\\\\\\\] A mapping of definition refs to core refs. json\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_defs\\\\\\\\\\\\\\_refs dict\\\\\\\\\\\\\\[JsonRef, DefsRef\\\\\\\\\\\\\\] A mapping of JSON refs to definition refs. definitions dict\\\\\\\\\\\\\\[DefsRef, JsonSchemaValue\\\\\\\\\\\\\\] Definitions in the schema. collisions dict\\\\\\\\\\\\\\[DefsRef, JsonSchemaValue\\\\\\\\\\\\\\] Definitions with colliding names. When collisions are detected, we choose a non-colliding name during generation, but we also track the colliding tag so that it can be remapped for the first occurrence at the end of the process. defs\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_fallbacks dict\\\\\\\\\\\\\\[DefsRef, JsonSchemaValue\\\\\\\\\\\\\\] Core refs to fallback definitions refs. \\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_method A mapping of schema types to generator methods. \\\\\\\\\\\\\\_used Set to True after generating a schema to avoid re-use issues. mode JsonSchemaMode The schema mode. Parameters: Name Type Description Default by\\\\\\\\\\\\\\_alias bool Whether or not to include field names. True ref\\\\\\\\\\\\\\_template str The format string to use when generating reference names. DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE Raises: Type Description JsonSchemaError If the instance of the class is inadvertently re-used after generating a schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py ValidationsMapping ¶ This class just contains mappings from core\\\\\\\\\\\\\\_schema attribute names to the corresponding JSON schema attribute names. While I suspect it is unlikely to be necessary, you can in principle override this class in a subclass of GenerateJsonSchema (by inheriting from GenerateJsonSchema.ValidationsMapping) to change these mappings. build\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_method ¶ build\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_method() Builds a dictionary mapping fields to methods for generating JSON schemas. Returns: Type Description dict\\\\\\\\\\\\\\[CoreSchemaOrFieldType, Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[CoreSchemaOrField\\\\\\\\\\\\\\], JsonSchemaValue\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] A dictionary containing the mapping of CoreSchemaOrFieldType to a handler method. Raises: Type Description TypeError If no method has been defined for generating a JSON schema for a given pydantic core schema type. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py generate\\\\\\\\\\\\\\_definitions ¶ generate\\\\\\\\\\\\\\_definitions(inputs) Generates JSON schema definitions from a list of core schemas, pairing the generated definitions with a mapping that links the input keys to the definition references. Parameters: Name Type Description Default inputs Sequence\\\\\\\\\\\\\\[tuple\\\\\\\\\\\\\\[JsonSchemaKeyT, JsonSchemaMode, core\\\\\\\\\\\\\\_schema.CoreSchema\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] A sequence of tuples, where: The first element is a JSON schema key type. The second element is the JSON mode: either 'validation' or 'serialization'. The third element is a core schema. required Returns: Type Description tuple\\\\\\\\\\\\\\[dict\\\\\\\\\\\\\\[tuple\\\\\\\\\\\\\\[JsonSchemaKeyT, JsonSchemaMode\\\\\\\\\\\\\\], JsonSchemaValue\\\\\\\\\\\\\\], dict\\\\\\\\\\\\\\[DefsRef, JsonSchemaValue\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] A tuple where: The first element is a dictionary whose keys are tuples of JSON schema key type and JSON mode, and whose values are the JSON schema corresponding to that pair of inputs. (These schemas may have JsonRef references to definitions that are defined in the second returned element.) The second element is a dictionary whose keys are definition references for the JSON schemas from the first returned element, and whose values are the actual JSON schema definitions. Raises: Type Description PydanticUserError Raised if the JSON schema generator has already been used to generate a JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py generate ¶ generate(schema, mode='validation') Generates a JSON schema for a specified schema in a specified mode. Parameters: Name Type Description Default schema CoreSchema A Pydantic model. required mode JsonSchemaMode The mode in which to generate the schema. Defaults to 'validation'. 'validation' Returns: Type Description JsonSchemaValue A JSON schema representing the specified schema. Raises: Type Description PydanticUserError If the JSON schema generator has already been used to generate a JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py generate\\\\\\\\\\\\\\_inner ¶ generate\\\\\\\\\\\\\\_inner(schema) Generates a JSON schema for a given core schema. Parameters: Name Type Description Default schema CoreSchemaOrField The given core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py any\\\\\\\\\\\\\\_schema ¶ any\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches any value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.AnySchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py none\\\\\\\\\\\\\\_schema ¶ none\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a None value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.NoneSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py bool\\\\\\\\\\\\\\_schema ¶ bool\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a bool value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.BoolSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py int\\\\\\\\\\\\\\_schema ¶ int\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches an Int value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.IntSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py float\\\\\\\\\\\\\\_schema ¶ float\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a float value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.FloatSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py decimal\\\\\\\\\\\\\\_schema ¶ decimal\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a decimal value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.DecimalSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py str\\\\\\\\\\\\\\_schema ¶ str\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a string value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.StringSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py bytes\\\\\\\\\\\\\\_schema ¶ bytes\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a bytes value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.BytesSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py date\\\\\\\\\\\\\\_schema ¶ date\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a date value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.DateSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py time\\\\\\\\\\\\\\_schema ¶ time\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a time value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.TimeSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py datetime\\\\\\\\\\\\\\_schema ¶ datetime\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a datetime value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.DatetimeSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py timedelta\\\\\\\\\\\\\\_schema ¶ timedelta\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a timedelta value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.TimedeltaSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py literal\\\\\\\\\\\\\\_schema ¶ literal\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a literal value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.LiteralSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_schema ¶ is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that checks if a value is an instance of a class, equivalent to Python's isinstance method. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.IsInstanceSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py is\\\\\\\\\\\\\\_subclass\\\\\\\\\\\\\\_schema ¶ is\\\\\\\\\\\\\\_subclass\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that checks if a value is a subclass of a class, equivalent to Python's issubclass method. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.IsSubclassSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py callable\\\\\\\\\\\\\\_schema ¶ callable\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a callable value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.CallableSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py list\\\\\\\\\\\\\\_schema ¶ list\\\\\\\\\\\\\\_schema(schema) Returns a schema that matches a list schema. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.ListSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py tuple\\\\\\\\\\\\\\_positional\\\\\\\\\\\\\\_schema ¶ tuple\\\\\\\\\\\\\\_positional\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a positional tuple schema e.g. Tuple\\\\\\\\\\\\\\[int, str, bool\\\\\\\\\\\\\\]. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.TuplePositionalSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py tuple\\\\\\\\\\\\\\_variable\\\\\\\\\\\\\\_schema ¶ tuple\\\\\\\\\\\\\\_variable\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a variable tuple schema e.g. Tuple\\\\\\\\\\\\\\[int, ...\\\\\\\\\\\\\\]. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.TupleVariableSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py set\\\\\\\\\\\\\\_schema ¶ set\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a set schema. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.SetSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py frozenset\\\\\\\\\\\\\\_schema ¶ frozenset\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a frozenset schema. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.FrozenSetSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py generator\\\\\\\\\\\\\\_schema ¶ generator\\\\\\\\\\\\\\_schema(schema) Returns a JSON schema that represents the provided GeneratorSchema. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.GeneratorSchema The schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py dict\\\\\\\\\\\\\\_schema ¶ dict\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a dict schema. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.DictSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py function\\\\\\\\\\\\\\_before\\\\\\\\\\\\\\_schema ¶ function\\\\\\\\\\\\\\_before\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a function-before schema. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.BeforeValidatorFunctionSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py function\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_schema ¶ function\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a function-after schema. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.AfterValidatorFunctionSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py function\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_schema ¶ function\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a function-plain schema. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.PlainValidatorFunctionSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py function\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_schema ¶ function\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a function-wrap schema. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.WrapValidatorFunctionSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py default\\\\\\\\\\\\\\_schema ¶ default\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema with a default value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.WithDefaultSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py nullable\\\\\\\\\\\\\\_schema ¶ nullable\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that allows null values. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.NullableSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py union\\\\\\\\\\\\\\_schema ¶ union\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that allows values matching any of the given schemas. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.UnionSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py tagged\\\\\\\\\\\\\\_union\\\\\\\\\\\\\\_schema ¶ tagged\\\\\\\\\\\\\\_union\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that allows values matching any of the given schemas, where the schemas are tagged with a discriminator field that indicates which schema should be used to validate the value. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.TaggedUnionSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py chain\\\\\\\\\\\\\\_schema ¶ chain\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a core\\\\\\\\\\\\\\_schema.ChainSchema. When generating a schema for validation, we return the validation JSON schema for the first step in the chain. For serialization, we return the serialization JSON schema for the last step in the chain. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.ChainSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py lax\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_strict\\\\\\\\\\\\\\_schema ¶ lax\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_strict\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that allows values matching either the lax schema or the strict schema. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.LaxOrStrictSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py json\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_python\\\\\\\\\\\\\\_schema ¶ json\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_python\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that allows values matching either the JSON schema or the Python schema. The JSON schema is used instead of the Python schema. If you want to use the Python schema, you should override this method. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.JsonOrPythonSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema ¶ typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a typed dict. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.TypedDictSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_schema ¶ typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a typed dict field. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.TypedDictField The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py dataclass\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_schema ¶ dataclass\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a dataclass field. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.DataclassField The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py model\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_schema ¶ model\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a model field. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.ModelField The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py computed\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_schema ¶ computed\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a computed field. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.ComputedField The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py model\\\\\\\\\\\\\\_schema ¶ model\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a model. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.ModelSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py resolve\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_update ¶ resolve\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_update(json\\\\\\\\\\\\\\_schema) Resolve a JsonSchemaValue to the non-ref schema if it is a $ref schema. Parameters: Name Type Description Default json\\\\\\\\\\\\\\_schema JsonSchemaValue The schema to resolve. required Returns: Type Description JsonSchemaValue The resolved schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_schema ¶ model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a model's fields. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.ModelFieldsSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py field\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_present ¶ field\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_present(field) Whether the field should be included in the generated JSON schema. Parameters: Name Type Description Default field CoreSchemaField The schema for the field itself. required Returns: Type Description bool True if the field should be included in the generated JSON schema, False otherwise. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py field\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_required ¶ field\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_required(field, total) Whether the field should be marked as required in the generated JSON schema. (Note that this is irrelevant if the field is not present in the JSON schema.). Parameters: Name Type Description Default field core\\\\\\\\\\\\\\_schema.ModelField | core\\\\\\\\\\\\\\_schema.DataclassField | core\\\\\\\\\\\\\\_schema.TypedDictField The schema for the field itself. required total bool Only applies to TypedDictFields. Indicates if the TypedDict this field belongs to is total, in which case any fields that don't explicitly specify required=False are required. required Returns: Type Description bool True if the field should be marked as required in the generated JSON schema, False otherwise. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py dataclass\\\\\\\\\\\\\\_args\\\\\\\\\\\\\\_schema ¶ dataclass\\\\\\\\\\\\\\_args\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a dataclass's constructor arguments. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.DataclassArgsSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py dataclass\\\\\\\\\\\\\\_schema ¶ dataclass\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a dataclass. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.DataclassSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py arguments\\\\\\\\\\\\\\_schema ¶ arguments\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a function's arguments. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.ArgumentsSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py kw\\\\\\\\\\\\\\_arguments\\\\\\\\\\\\\\_schema ¶ kw\\\\\\\\\\\\\\_arguments\\\\\\\\\\\\\\_schema(arguments, var\\\\\\\\\\\\\\_kwargs\\\\\\\\\\\\\\_schema) Generates a JSON schema that matches a schema that defines a function's keyword arguments. Parameters: Name Type Description Default arguments list\\\\\\\\\\\\\\[core\\\\\\\\\\\\\\_schema.ArgumentsParameter\\\\\\\\\\\\\\] The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py p\\\\\\\\\\\\\\_arguments\\\\\\\\\\\\\\_schema ¶ p\\\\\\\\\\\\\\_arguments\\\\\\\\\\\\\\_schema(arguments, var\\\\\\\\\\\\\\_args\\\\\\\\\\\\\\_schema) Generates a JSON schema that matches a schema that defines a function's positional arguments. Parameters: Name Type Description Default arguments list\\\\\\\\\\\\\\[core\\\\\\\\\\\\\\_schema.ArgumentsParameter\\\\\\\\\\\\\\] The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py get\\\\\\\\\\\\\\_argument\\\\\\\\\\\\\\_name ¶ get\\\\\\\\\\\\\\_argument\\\\\\\\\\\\\\_name(argument) Retrieves the name of an argument. Parameters: Name Type Description Default argument core\\\\\\\\\\\\\\_schema.ArgumentsParameter The core schema. required Returns: Type Description str The name of the argument. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py call\\\\\\\\\\\\\\_schema ¶ call\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a function call. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.CallSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_schema ¶ custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a custom error. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.CustomErrorSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py json\\\\\\\\\\\\\\_schema ¶ json\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a JSON object. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.JsonSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py url\\\\\\\\\\\\\\_schema ¶ url\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a URL. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.UrlSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py multi\\\\\\\\\\\\\\_host\\\\\\\\\\\\\\_url\\\\\\\\\\\\\\_schema ¶ multi\\\\\\\\\\\\\\_host\\\\\\\\\\\\\\_url\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a URL that can be used with multiple hosts. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.MultiHostUrlSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py uuid\\\\\\\\\\\\\\_schema ¶ uuid\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a UUID. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.UuidSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py definitions\\\\\\\\\\\\\\_schema ¶ definitions\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a JSON object with definitions. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.DefinitionsSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py definition\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema ¶ definition\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that references a definition. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.DefinitionReferenceSchema The core schema. required Returns: Type Description JsonSchemaValue The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py ser\\\\\\\\\\\\\\_schema ¶ ser\\\\\\\\\\\\\\_schema(schema) Generates a JSON schema that matches a schema that defines a serialized object. Parameters: Name Type Description Default schema core\\\\\\\\\\\\\\_schema.SerSchema | core\\\\\\\\\\\\\\_schema.IncExSeqSerSchema | core\\\\\\\\\\\\\\_schema.IncExDictSerSchema The core schema. required Returns: Type Description JsonSchemaValue | None The generated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py get\\\\\\\\\\\\\\_title\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_name ¶ get\\\\\\\\\\\\\\_title\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_name(name) Retrieves a title from a name. Parameters: Name Type Description Default name str The name to retrieve a title from. required Returns: Type Description str The title. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py field\\\\\\\\\\\\\\_title\\\\\\\\\\\\\\_should\\\\\\\\\\\\\\_be\\\\\\\\\\\\\\_set ¶ field\\\\\\\\\\\\\\_title\\\\\\\\\\\\\\_should\\\\\\\\\\\\\\_be\\\\\\\\\\\\\\_set(schema) Returns true if a field with the given schema should have a title set based on the field name. Intuitively, we want this to return true for schemas that wouldn't otherwise provide their own title (e.g., int, float, str), and false for those that would (e.g., BaseModel subclasses). Parameters: Name Type Description Default schema CoreSchemaOrField The schema to check. required Returns: Type Description bool True if the field should have a title set, False otherwise. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py normalize\\\\\\\\\\\\\\_name ¶ normalize\\\\\\\\\\\\\\_name(name) Normalizes a name to be used as a key in a dictionary. Parameters: Name Type Description Default name str The name to normalize. required Returns: Type Description str The normalized name. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py get\\\\\\\\\\\\\\_defs\\\\\\\\\\\\\\_ref ¶ get\\\\\\\\\\\\\\_defs\\\\\\\\\\\\\\_ref(core\\\\\\\\\\\\\\_mode\\\\\\\\\\\\\\_ref) Override this method to change the way that definitions keys are generated from a core reference. Parameters: Name Type Description Default core\\\\\\\\\\\\\\_mode\\\\\\\\\\\\\\_ref CoreModeRef The core reference. required Returns: Type Description DefsRef The definitions key. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py get\\\\\\\\\\\\\\_cache\\\\\\\\\\\\\\_defs\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema ¶ get\\\\\\\\\\\\\\_cache\\\\\\\\\\\\\\_defs\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema(core\\\\\\\\\\\\\\_ref) This method wraps the get\\\\\\\\\\\\\\_defs\\\\\\\\\\\\\\_ref method with some cache-lookup/population logic, and returns both the produced defs\\\\\\\\\\\\\\_ref and the JSON schema that will refer to the right definition. Parameters: Name Type Description Default core\\\\\\\\\\\\\\_ref CoreRef The core reference to get the definitions reference for. required Returns: Type Description tuple\\\\\\\\\\\\\\[DefsRef, JsonSchemaValue\\\\\\\\\\\\\\] A tuple of the definitions reference and the JSON schema that will refer to it. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py handle\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_overrides ¶ handle\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_overrides(json\\\\\\\\\\\\\\_schema) It is not valid for a schema with a top-level $ref to have sibling keys. During our own schema generation, we treat sibling keys as overrides to the referenced schema, but this is not how the official JSON schema spec works. Because of this, we first remove any sibling keys that are redundant with the referenced schema, then if any remain, we transform the schema from a top-level '$ref' to use allOf to move the $ref out of the top level. (See bottom of https://swagger.io/docs/specification/using-ref/ for a reference about this behavior) Source code in pydantic/json\\\\\\\\\\\\\\_schema.py encode\\\\\\\\\\\\\\_default ¶ encode\\\\\\\\\\\\\\_default(dft) Encode a default value to a JSON-serializable value. This is used to encode default values for fields in the generated JSON schema. Parameters: Name Type Description Default dft Any The default value to encode. required Returns: Type Description Any The encoded default value. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py update\\\\\\\\\\\\\\_with\\\\\\\\\\\\\\_validations ¶ update\\\\\\\\\\\\\\_with\\\\\\\\\\\\\\_validations(json\\\\\\\\\\\\\\_schema, core\\\\\\\\\\\\\\_schema, mapping) Update the json\\\\\\\\\\\\\\_schema with the corresponding validations specified in the core\\\\\\\\\\\\\\_schema, using the provided mapping to translate keys in core\\\\\\\\\\\\\\_schema to the appropriate keys for a JSON schema. Parameters: Name Type Description Default json\\\\\\\\\\\\\\_schema JsonSchemaValue The JSON schema to update. required core\\\\\\\\\\\\\\_schema CoreSchema The core schema to get the validations from. required mapping dict\\\\\\\\\\\\\\[str, str\\\\\\\\\\\\\\] A mapping from core\\\\\\\\\\\\\\_schema attribute names to the corresponding JSON schema attribute names. required Source code in pydantic/json\\\\\\\\\\\\\\_schema.py get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_counts ¶ get\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_counts(json\\\\\\\\\\\\\\_schema) Get all values corresponding to the key '$ref' anywhere in the json\\\\\\\\\\\\\\_schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py emit\\\\\\\\\\\\\\_warning ¶ emit\\\\\\\\\\\\\\_warning(kind, detail) This method simply emits PydanticJsonSchemaWarnings based on handling in the warning\\\\\\\\\\\\\\_message method. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py render\\\\\\\\\\\\\\_warning\\\\\\\\\\\\\\_message ¶ render\\\\\\\\\\\\\\_warning\\\\\\\\\\\\\\_message(kind, detail) This method is responsible for ignoring warnings as desired, and for formatting the warning messages. You can override the value of ignored\\\\\\\\\\\\\\_warning\\\\\\\\\\\\\\_kinds in a subclass of GenerateJsonSchema to modify what warnings are generated. If you want more control, you can override this method; just return None in situations where you don't want warnings to be emitted. Parameters: Name Type Description Default kind JsonSchemaWarningKind The kind of warning to render. It can be one of the following: 'skipped-choice': A choice field was skipped because it had no valid choices. 'non-serializable-default': A default value was skipped because it was not JSON-serializable. required detail str A string with additional details about the warning. required Returns: Type Description str | None The formatted warning message, or None if no warning should be emitted. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py WithJsonSchema dataclass ¶ Add this as an annotation on a field to override the (base) JSON schema that would be generated for that field. This provides a way to set a JSON schema for types that would otherwise raise errors when producing a JSON schema, such as Callable, or types that have an is-instance core schema, without needing to go so far as creating a custom subclass of pydantic.json\\\\\\\\\\\\\\_schema.GenerateJsonSchema. Note that any modifications to the schema that would normally be made (such as setting the title for model fields) will still be performed. If mode is set this will only apply to that schema generation mode, allowing you to set different json schemas for validation and serialization. Examples dataclass ¶ Add examples to a JSON schema. Examples should be a map of example names (strings) to example values (any valid JSON). If mode is set this will only apply to that schema generation mode, allowing you to add different examples for validation and serialization. SkipJsonSchema dataclass ¶ Add this as an annotation on a field to skip generating a JSON schema for that field. Example from pydantic import BaseModel from pydantic.json\\\\\\\\\\\\\\_schema import SkipJsonSchema class Model(BaseModel): a: int | SkipJsonSchema\\\\\\\\\\\\\\[None\\\\\\\\\\\\\\] = None print(Model.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema()) #> {'properties': {'a': {'default': None, 'title': 'A', 'type': 'integer'}}, 'title': 'Model', 'type': 'object'} update\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema ¶ update\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema(schema, updates) Update a JSON schema by providing a dictionary of updates. This function sets the provided key-value pairs in the schema and returns the updated schema. Parameters: Name Type Description Default schema JsonSchemaValue The JSON schema to update. required updates dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] A dictionary of key-value pairs to set in the schema. required Returns: Type Description JsonSchemaValue The updated JSON schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema ¶ model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema( cls, by\\\\\\\\\\\\\\_alias=True, ref\\\\\\\\\\\\\\_template=DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE, schema\\\\\\\\\\\\\\_generator=GenerateJsonSchema, mode=\"validation\", ) Utility function to generate a JSON Schema for a model. Parameters: Name Type Description Default cls type\\\\\\\\\\\\\\[BaseModel\\\\\\\\\\\\\\] | type\\\\\\\\\\\\\\[PydanticDataclass\\\\\\\\\\\\\\] The model class to generate a JSON Schema for. required by\\\\\\\\\\\\\\_alias bool If True (the default), fields will be serialized according to their alias. If False, fields will be serialized according to their attribute name. True ref\\\\\\\\\\\\\\_template str The template to use for generating JSON Schema references. DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE schema\\\\\\\\\\\\\\_generator type\\\\\\\\\\\\\\[GenerateJsonSchema\\\\\\\\\\\\\\] The class to use for generating the JSON Schema. GenerateJsonSchema mode JsonSchemaMode The mode to use for generating the JSON Schema. It can be one of the following: 'validation': Generate a JSON Schema for validating data. 'serialization': Generate a JSON Schema for serializing data. 'validation' Returns: Type Description dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] The generated JSON Schema. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py models\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema ¶ models\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema( models, \\\\\\\\\\\\\\*, by\\\\\\\\\\\\\\_alias=True, title=None, description=None, ref\\\\\\\\\\\\\\_template=DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE, schema\\\\\\\\\\\\\\_generator=GenerateJsonSchema ) Utility function to generate a JSON Schema for multiple models. Parameters: Name Type Description Default models Sequence\\\\\\\\\\\\\\[tuple\\\\\\\\\\\\\\[type\\\\\\\\\\\\\\[BaseModel\\\\\\\\\\\\\\] | type\\\\\\\\\\\\\\[PydanticDataclass\\\\\\\\\\\\\\], JsonSchemaMode\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] A sequence of tuples of the form (model, mode). required by\\\\\\\\\\\\\\_alias bool Whether field aliases should be used as keys in the generated JSON Schema. True title str | None The title of the generated JSON Schema. None description str | None The description of the generated JSON Schema. None ref\\\\\\\\\\\\\\_template str The reference template to use for generating JSON Schema references. DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE schema\\\\\\\\\\\\\\_generator type\\\\\\\\\\\\\\[GenerateJsonSchema\\\\\\\\\\\\\\] The schema generator to use for generating the JSON Schema. GenerateJsonSchema Returns: Type Description tuple\\\\\\\\\\\\\\[dict\\\\\\\\\\\\\\[tuple\\\\\\\\\\\\\\[type\\\\\\\\\\\\\\[BaseModel\\\\\\\\\\\\\\] | type\\\\\\\\\\\\\\[PydanticDataclass\\\\\\\\\\\\\\], JsonSchemaMode\\\\\\\\\\\\\\], JsonSchemaValue\\\\\\\\\\\\\\], JsonSchemaValue\\\\\\\\\\\\\\] A tuple where: - The first element is a dictionary whose keys are tuples of JSON schema key type and JSON mode, and whose values are the JSON schema corresponding to that pair of inputs. (These schemas may have JsonRef references to definitions that are defined in the second returned element.) - The second element is a JSON schema containing all definitions referenced in the first returned element, along with the optional title and description keys. Source code in pydantic/json\\\\\\\\\\\\\\_schema.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Configuration - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/config/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Configuration Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.config ConfigDict title str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_lower str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_upper str\\\\\\\\\\\\\\_strip\\\\\\\\\\\\\\_whitespace str\\\\\\\\\\\\\\_min\\\\\\\\\\\\\\_length str\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_length extra frozen populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name use\\\\\\\\\\\\\\_enum\\\\\\\\\\\\\\_values validate\\\\\\\\\\\\\\_assignment arbitrary\\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_allowed from\\\\\\\\\\\\\\_attributes loc\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_alias alias\\\\\\\\\\\\\\_generator ignored\\\\\\\\\\\\\\_types allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra json\\\\\\\\\\\\\\_encoders strict revalidate\\\\\\\\\\\\\\_instances ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_timedelta ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_bytes ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan validate\\\\\\\\\\\\\\_default validate\\\\\\\\\\\\\\_return protected\\\\\\\\\\\\\\_namespaces hide\\\\\\\\\\\\\\_input\\\\\\\\\\\\\\_in\\\\\\\\\\\\\\_errors defer\\\\\\\\\\\\\\_build plugin\\\\\\\\\\\\\\_settings schema\\\\\\\\\\\\\\_generator json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_serialization\\\\\\\\\\\\\\_defaults\\\\\\\\\\\\\\_required json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_mode\\\\\\\\\\\\\\_override coerce\\\\\\\\\\\\\\_numbers\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_str regex\\\\\\\\\\\\\\_engine validation\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_cause ExtraValues alias\\\\\\\\\\\\\\_generators to\\\\\\\\\\\\\\_pascal() to\\\\\\\\\\\\\\_camel() to\\\\\\\\\\\\\\_snake() Configuration Configuration for Pydantic models. ConfigDict ¶ Bases: TypedDict A TypedDict for configuring Pydantic behaviour. title instance-attribute ¶ title: str | None The title for the generated JSON schema, defaults to the model's name str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_lower instance-attribute ¶ str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_lower: bool Whether to convert all characters to lowercase for str types. Defaults to False. str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_upper instance-attribute ¶ str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_upper: bool Whether to convert all characters to uppercase for str types. Defaults to False. str\\\\\\\\\\\\\\_strip\\\\\\\\\\\\\\_whitespace instance-attribute ¶ str\\\\\\\\\\\\\\_strip\\\\\\\\\\\\\\_whitespace: bool Whether to strip leading and trailing whitespace for str types. str\\\\\\\\\\\\\\_min\\\\\\\\\\\\\\_length instance-attribute ¶ str\\\\\\\\\\\\\\_min\\\\\\\\\\\\\\_length: int The minimum length for str types. Defaults to None. str\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_length instance-attribute ¶ str\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_length: int | None The maximum length for str types. Defaults to None. extra instance-attribute ¶ extra: ExtraValues | None Whether to ignore, allow, or forbid extra attributes during model initialization. Defaults to 'ignore'. You can configure how pydantic handles the attributes that are not defined in the model: allow - Allow any extra attributes. forbid - Forbid any extra attributes. ignore - Ignore any extra attributes. from pydantic import BaseModel, ConfigDict class User(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(extra='ignore') This is the default behaviour. name: str user = User(name='John Doe', age=20) The age argument is ignored. print(user) #> name='John Doe' Instead, with extra='allow', the age argument is included: from pydantic import BaseModel, ConfigDict class User(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(extra='allow') name: str user = User(name='John Doe', age=20) The age argument is included. print(user) #> name='John Doe' age=20 With extra='forbid', an error is raised: from pydantic import BaseModel, ConfigDict, ValidationError class User(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(extra='forbid') name: str try: User(name='John Doe', age=20) except ValidationError as e: print(e) ''' 1 validation error for User age Extra inputs are not permitted \\\\\\\\\\\\\\[type=extra\\\\\\\\\\\\\\_forbidden, input\\\\\\\\\\\\\\_value=20, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] ''' frozen instance-attribute ¶ frozen: bool Whether or not models are faux-immutable, i.e. whether \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_setattr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ is allowed, and also generates a \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_hash\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_() method for the model. This makes instances of the model potentially hashable if all the attributes are hashable. Defaults to False. Note On V1, this setting was called allow\\\\\\\\\\\\\\_mutation, and was True by default. populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name instance-attribute ¶ populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name: bool Whether an aliased field may be populated by its name as given by the model attribute, as well as the alias. Defaults to False. Note The name of this configuration setting was changed in v2.0 from allow\\\\\\\\\\\\\\_population\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_name to populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name. from pydantic import BaseModel, ConfigDict, Field class User(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name=True) name: str = Field(alias='full\\\\\\\\\\\\\\_name') The field 'name' has an alias 'full\\\\\\\\\\\\\\_name'. age: int user = User(full\\\\\\\\\\\\\\_name='John Doe', age=20) The model is populated by the alias 'full\\\\\\\\\\\\\\_name'. print(user) #> name='John Doe' age=20 user = User(name='John Doe', age=20) The model is populated by the field name 'name'. print(user) #> name='John Doe' age=20 use\\\\\\\\\\\\\\_enum\\\\\\\\\\\\\\_values instance-attribute ¶ use\\\\\\\\\\\\\\_enum\\\\\\\\\\\\\\_values: bool Whether to populate models with the value property of enums, rather than the raw enum. This may be useful if you want to serialize model.model\\\\\\\\\\\\\\_dump() later. Defaults to False. Note If you have an Optional\\\\\\\\\\\\\\[Enum\\\\\\\\\\\\\\] value that you set a default for, you need to use validate\\\\\\\\\\\\\\_default=True for said Field to ensure that the use\\\\\\\\\\\\\\_enum\\\\\\\\\\\\\\_values flag takes effect on the default, as extracting an enum's value occurs during validation, not serialization. from enum import Enum from typing import Optional from pydantic import BaseModel, ConfigDict, Field class SomeEnum(Enum): FOO = 'foo' BAR = 'bar' BAZ = 'baz' class SomeModel(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(use\\\\\\\\\\\\\\_enum\\\\\\\\\\\\\\_values=True) some\\\\\\\\\\\\\\_enum: SomeEnum another\\\\\\\\\\\\\\_enum: Optional\\\\\\\\\\\\\\[SomeEnum\\\\\\\\\\\\\\] = Field(default=SomeEnum.FOO, validate\\\\\\\\\\\\\\_default=True) model1 = SomeModel(some\\\\\\\\\\\\\\_enum=SomeEnum.BAR) print(model1.model\\\\\\\\\\\\\\_dump()) # {'some\\\\\\\\\\\\\\_enum': 'bar', 'another\\\\\\\\\\\\\\_enum': 'foo'} model2 = SomeModel(some\\\\\\\\\\\\\\_enum=SomeEnum.BAR, another\\\\\\\\\\\\\\_enum=SomeEnum.BAZ) print(model2.model\\\\\\\\\\\\\\_dump()) #> {'some\\\\\\\\\\\\\\_enum': 'bar', 'another\\\\\\\\\\\\\\_enum': 'baz'} validate\\\\\\\\\\\\\\_assignment instance-attribute ¶ validate\\\\\\\\\\\\\\_assignment: bool Whether to validate the data when the model is changed. Defaults to False. The default behavior of Pydantic is to validate the data when the model is created. In case the user changes the data after the model is created, the model is not revalidated. from pydantic import BaseModel class User(BaseModel): name: str user = User(name='John Doe') print(user) #> name='John Doe' user.name = 123 The validation happens only when the model is created. print(user) #> name=123 In case you want to revalidate the model when the data is changed, you can use validate\\\\\\\\\\\\\\_assignment=True: from pydantic import BaseModel, ValidationError class User(BaseModel, validate\\\\\\\\\\\\\\_assignment=True): You can either use class keyword arguments, or model\\\\\\\\\\\\\\_config to set validate\\\\\\\\\\\\\\_assignment=True. name: str user = User(name='John Doe') The validation happens when the model is created. print(user) #> name='John Doe' try: user.name = 123 The validation also happens when the data is changed. except ValidationError as e: print(e) ''' 1 validation error for User name Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=123, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] ''' arbitrary\\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_allowed instance-attribute ¶ arbitrary\\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_allowed: bool Whether arbitrary types are allowed for field types. Defaults to False. from pydantic import BaseModel, ConfigDict, ValidationError # This is not a pydantic model, it's an arbitrary class class Pet: def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, name: str): self.name = name class Model(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(arbitrary\\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_allowed=True) pet: Pet owner: str pet = Pet(name='Hedwig') # A simple check of instance type is used to validate the data model = Model(owner='Harry', pet=pet) print(model) #> pet=<\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_main\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.Pet object at 0x0123456789ab> owner='Harry' print(model.pet) #> <\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_main\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.Pet object at 0x0123456789ab> print(model.pet.name) #> Hedwig print(type(model.pet)) #> try: # If the value is not an instance of the type, it's invalid Model(owner='Harry', pet='Hedwig') except ValidationError as e: print(e) ''' 1 validation error for Model pet Input should be an instance of Pet \\\\\\\\\\\\\\[type=is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_of, input\\\\\\\\\\\\\\_value='Hedwig', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' # Nothing in the instance of the arbitrary type is checked # Here name probably should have been a str, but it's not validated pet2 = Pet(name=42) model2 = Model(owner='Harry', pet=pet2) print(model2) #> pet=<\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_main\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.Pet object at 0x0123456789ab> owner='Harry' print(model2.pet) #> <\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_main\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.Pet object at 0x0123456789ab> print(model2.pet.name) #> 42 print(type(model2.pet)) #> from\\\\\\\\\\\\\\_attributes instance-attribute ¶ from\\\\\\\\\\\\\\_attributes: bool Whether to build models and look up discriminators of tagged unions using python object attributes. loc\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_alias instance-attribute ¶ loc\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_alias: bool Whether to use the actual key provided in the data (e.g. alias) for error locs rather than the field's name. Defaults to True. alias\\\\\\\\\\\\\\_generator instance-attribute ¶ alias\\\\\\\\\\\\\\_generator: Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\], str\\\\\\\\\\\\\\] | None A callable that takes a field name and returns an alias for it. If data source field names do not match your code style (e. g. CamelCase fields), you can automatically generate aliases using alias\\\\\\\\\\\\\\_generator: from pydantic import BaseModel, ConfigDict from pydantic.alias\\\\\\\\\\\\\\_generators import to\\\\\\\\\\\\\\_pascal class Voice(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(alias\\\\\\\\\\\\\\_generator=to\\\\\\\\\\\\\\_pascal) name: str language\\\\\\\\\\\\\\_code: str voice = Voice(Name='Filiz', LanguageCode='tr-TR') print(voice.language\\\\\\\\\\\\\\_code) #> tr-TR print(voice.model\\\\\\\\\\\\\\_dump(by\\\\\\\\\\\\\\_alias=True)) #> {'Name': 'Filiz', 'LanguageCode': 'tr-TR'} Note Pydantic offers three built-in alias generators: to\\\\\\\\\\\\\\_pascal, to\\\\\\\\\\\\\\_camel, and to\\\\\\\\\\\\\\_snake. ignored\\\\\\\\\\\\\\_types instance-attribute ¶ ignored\\\\\\\\\\\\\\_types: tuple\\\\\\\\\\\\\\[type, ...\\\\\\\\\\\\\\] A tuple of types that may occur as values of class attributes without annotations. This is typically used for custom descriptors (classes that behave like property). If an attribute is set on a class without an annotation and has a type that is not in this tuple (or otherwise recognized by pydantic), an error will be raised. Defaults to (). allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan instance-attribute ¶ allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan: bool Whether to allow infinity (+inf an -inf) and NaN values to float fields. Defaults to True. json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra instance-attribute ¶ json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra: JsonDict | JsonSchemaExtraCallable | None A dict or callable to provide extra JSON schema properties. Defaults to None. json\\\\\\\\\\\\\\_encoders instance-attribute ¶ json\\\\\\\\\\\\\\_encoders: dict\\\\\\\\\\\\\\[type\\\\\\\\\\\\\\[object\\\\\\\\\\\\\\], JsonEncoder\\\\\\\\\\\\\\] | None A dict of custom JSON encoders for specific types. Defaults to None. Deprecated This config option is a carryover from v1. We originally planned to remove it in v2 but didn't have a 1:1 replacement so we are keeping it for now. It is still deprecated and will likely be removed in the future. strict instance-attribute ¶ strict: bool (new in V2) If True, strict validation is applied to all fields on the model. By default, Pydantic attempts to coerce values to the correct type, when possible. There are situations in which you may want to disable this behavior, and instead raise an error if a value's type does not match the field's type annotation. To configure strict mode for all fields on a model, you can set strict=True on the model. from pydantic import BaseModel, ConfigDict class Model(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(strict=True) name: str age: int See Strict Mode for more details. See the Conversion Table for more details on how Pydantic converts data in both strict and lax modes. revalidate\\\\\\\\\\\\\\_instances instance-attribute ¶ revalidate\\\\\\\\\\\\\\_instances: Literal\\\\\\\\\\\\\\[ \"always\", \"never\", \"subclass-instances\" \\\\\\\\\\\\\\] When and how to revalidate models and dataclasses during validation. Accepts the string values of 'never', 'always' and 'subclass-instances'. Defaults to 'never'. 'never' will not revalidate models and dataclasses during validation 'always' will revalidate models and dataclasses during validation 'subclass-instances' will revalidate models and dataclasses during validation if the instance is a subclass of the model or dataclass By default, model and dataclass instances are not revalidated during validation. from typing import List from pydantic import BaseModel class User(BaseModel, revalidate\\\\\\\\\\\\\\_instances='never'): revalidate\\\\\\\\\\\\\\_instances is set to 'never' by \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*default. hobbies: List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] class SubUser(User): sins: List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] class Transaction(BaseModel): user: User my\\\\\\\\\\\\\\_user = User(hobbies=\\\\\\\\\\\\\\['reading'\\\\\\\\\\\\\\]) t = Transaction(user=my\\\\\\\\\\\\\\_user) print(t) #> user=User(hobbies=\\\\\\\\\\\\\\['reading'\\\\\\\\\\\\\\]) my\\\\\\\\\\\\\\_user.hobbies = \\\\\\\\\\\\\\[1\\\\\\\\\\\\\\] The assignment is not validated, unless you set validate\\\\\\\\\\\\\\_assignment to True in the model's config. t = Transaction(user=my\\\\\\\\\\\\\\_user) Since revalidate\\\\\\\\\\\\\\_instances is set to never, this is not revalidated. print(t) #> user=User(hobbies=\\\\\\\\\\\\\\[1\\\\\\\\\\\\\\]) my\\\\\\\\\\\\\\_sub\\\\\\\\\\\\\\_user = SubUser(hobbies=\\\\\\\\\\\\\\['scuba diving'\\\\\\\\\\\\\\], sins=\\\\\\\\\\\\\\['lying'\\\\\\\\\\\\\\]) t = Transaction(user=my\\\\\\\\\\\\\\_sub\\\\\\\\\\\\\\_user) print(t) #> user=SubUser(hobbies=\\\\\\\\\\\\\\['scuba diving'\\\\\\\\\\\\\\], sins=\\\\\\\\\\\\\\['lying'\\\\\\\\\\\\\\]) If you want to revalidate instances during validation, you can set revalidate\\\\\\\\\\\\\\_instances to 'always' in the model's config. from typing import List from pydantic import BaseModel, ValidationError class User(BaseModel, revalidate\\\\\\\\\\\\\\_instances='always'): revalidate\\\\\\\\\\\\\\_instances is set to 'always'. hobbies: List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] class SubUser(User): sins: List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] class Transaction(BaseModel): user: User my\\\\\\\\\\\\\\_user = User(hobbies=\\\\\\\\\\\\\\['reading'\\\\\\\\\\\\\\]) t = Transaction(user=my\\\\\\\\\\\\\\_user) print(t) #> user=User(hobbies=\\\\\\\\\\\\\\['reading'\\\\\\\\\\\\\\]) my\\\\\\\\\\\\\\_user.hobbies = \\\\\\\\\\\\\\[1\\\\\\\\\\\\\\] try: t = Transaction(user=my\\\\\\\\\\\\\\_user) The model is revalidated, since revalidate\\\\\\\\\\\\\\_instances is set to 'always'. except ValidationError as e: print(e) ''' 1 validation error for Transaction user.hobbies.0 Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=1, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] ''' my\\\\\\\\\\\\\\_sub\\\\\\\\\\\\\\_user = SubUser(hobbies=\\\\\\\\\\\\\\['scuba diving'\\\\\\\\\\\\\\], sins=\\\\\\\\\\\\\\['lying'\\\\\\\\\\\\\\]) t = Transaction(user=my\\\\\\\\\\\\\\_sub\\\\\\\\\\\\\\_user) print(t) Using 'never' we would have gotten user=SubUser(hobbies=\\\\\\\\\\\\\\['scuba diving'\\\\\\\\\\\\\\], sins=\\\\\\\\\\\\\\['lying'\\\\\\\\\\\\\\]). #> user=User(hobbies=\\\\\\\\\\\\\\['scuba diving'\\\\\\\\\\\\\\]) It's also possible to set revalidate\\\\\\\\\\\\\\_instances to 'subclass-instances' to only revalidate instances of subclasses of the model. from typing import List from pydantic import BaseModel class User(BaseModel, revalidate\\\\\\\\\\\\\\_instances='subclass-instances'): revalidate\\\\\\\\\\\\\\_instances is set to 'subclass-instances'. hobbies: List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] class SubUser(User): sins: List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] class Transaction(BaseModel): user: User my\\\\\\\\\\\\\\_user = User(hobbies=\\\\\\\\\\\\\\['reading'\\\\\\\\\\\\\\]) t = Transaction(user=my\\\\\\\\\\\\\\_user) print(t) #> user=User(hobbies=\\\\\\\\\\\\\\['reading'\\\\\\\\\\\\\\]) my\\\\\\\\\\\\\\_user.hobbies = \\\\\\\\\\\\\\[1\\\\\\\\\\\\\\] t = Transaction(user=my\\\\\\\\\\\\\\_user) This is not revalidated, since my\\\\\\\\\\\\\\_user is not a subclass of User. print(t) #> user=User(hobbies=\\\\\\\\\\\\\\[1\\\\\\\\\\\\\\]) my\\\\\\\\\\\\\\_sub\\\\\\\\\\\\\\_user = SubUser(hobbies=\\\\\\\\\\\\\\['scuba diving'\\\\\\\\\\\\\\], sins=\\\\\\\\\\\\\\['lying'\\\\\\\\\\\\\\]) t = Transaction(user=my\\\\\\\\\\\\\\_sub\\\\\\\\\\\\\\_user) print(t) Using 'never' we would have gotten user=SubUser(hobbies=\\\\\\\\\\\\\\['scuba diving'\\\\\\\\\\\\\\], sins=\\\\\\\\\\\\\\['lying'\\\\\\\\\\\\\\]). #> user=User(hobbies=\\\\\\\\\\\\\\['scuba diving'\\\\\\\\\\\\\\]) ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_timedelta instance-attribute ¶ ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_timedelta: Literal\\\\\\\\\\\\\\['iso8601', 'float'\\\\\\\\\\\\\\] The format of JSON serialized timedeltas. Accepts the string values of 'iso8601' and 'float'. Defaults to 'iso8601'. 'iso8601' will serialize timedeltas to ISO 8601 durations. 'float' will serialize timedeltas to the total number of seconds. ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_bytes instance-attribute ¶ ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_bytes: Literal\\\\\\\\\\\\\\['utf8', 'base64'\\\\\\\\\\\\\\] The encoding of JSON serialized bytes. Accepts the string values of 'utf8' and 'base64'. Defaults to 'utf8'. 'utf8' will serialize bytes to UTF-8 strings. 'base64' will serialize bytes to URL safe base64 strings. ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan instance-attribute ¶ ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan: Literal\\\\\\\\\\\\\\['null', 'constants'\\\\\\\\\\\\\\] The encoding of JSON serialized infinity and NaN float values. Accepts the string values of 'null' and 'constants'. Defaults to 'null'. 'null' will serialize infinity and NaN values as null. 'constants' will serialize infinity and NaN values as Infinity and NaN. validate\\\\\\\\\\\\\\_default instance-attribute ¶ validate\\\\\\\\\\\\\\_default: bool Whether to validate default values during validation. Defaults to False. validate\\\\\\\\\\\\\\_return instance-attribute ¶ validate\\\\\\\\\\\\\\_return: bool whether to validate the return value from call validators. Defaults to False. protected\\\\\\\\\\\\\\_namespaces instance-attribute ¶ protected\\\\\\\\\\\\\\_namespaces: tuple\\\\\\\\\\\\\\[str, ...\\\\\\\\\\\\\\] A tuple of strings that prevent model to have field which conflict with them. Defaults to ('model\\\\\\\\\\\\\\_', )). Pydantic prevents collisions between model attributes and BaseModel's own methods by namespacing them with the prefix model\\\\\\\\\\\\\\_. import warnings from pydantic import BaseModel warnings.filterwarnings('error') # Raise warnings as errors try: class Model(BaseModel): model\\\\\\\\\\\\\\_prefixed\\\\\\\\\\\\\\_field: str except UserWarning as e: print(e) ''' Field \"model\\\\\\\\\\\\\\_prefixed\\\\\\\\\\\\\\_field\" has conflict with protected namespace \"model\\\\\\\\\\\\\\_\". You may be able to resolve this warning by setting \\\\\\\\\\\\\\`model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['protected\\\\\\\\\\\\\\_namespaces'\\\\\\\\\\\\\\] = ()\\\\\\\\\\\\\\`. ''' You can customize this behavior using the protected\\\\\\\\\\\\\\_namespaces setting: import warnings from pydantic import BaseModel, ConfigDict warnings.filterwarnings('error') # Raise warnings as errors try: class Model(BaseModel): model\\\\\\\\\\\\\\_prefixed\\\\\\\\\\\\\\_field: str also\\\\\\\\\\\\\\_protect\\\\\\\\\\\\\\_field: str model\\\\\\\\\\\\\\_config = ConfigDict( protected\\\\\\\\\\\\\\_namespaces=('protect\\\\\\\\\\\\\\_me\\\\\\\\\\\\\\_', 'also\\\\\\\\\\\\\\_protect\\\\\\\\\\\\\\_') ) except UserWarning as e: print(e) ''' Field \"also\\\\\\\\\\\\\\_protect\\\\\\\\\\\\\\_field\" has conflict with protected namespace \"also\\\\\\\\\\\\\\_protect\\\\\\\\\\\\\\_\". You may be able to resolve this warning by setting \\\\\\\\\\\\\\`model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['protected\\\\\\\\\\\\\\_namespaces'\\\\\\\\\\\\\\] = ('protect\\\\\\\\\\\\\\_me\\\\\\\\\\\\\\_',)\\\\\\\\\\\\\\`. ''' While Pydantic will only emit a warning when an item is in a protected namespace but does not actually have a collision, an error is raised if there is an actual collision with an existing attribute: from pydantic import BaseModel try: class Model(BaseModel): model\\\\\\\\\\\\\\_validate: str except NameError as e: print(e) ''' Field \"model\\\\\\\\\\\\\\_validate\" conflicts with member \\\\\\\\> of protected namespace \"model\\\\\\\\\\\\\\_\". ''' hide\\\\\\\\\\\\\\_input\\\\\\\\\\\\\\_in\\\\\\\\\\\\\\_errors instance-attribute ¶ hide\\\\\\\\\\\\\\_input\\\\\\\\\\\\\\_in\\\\\\\\\\\\\\_errors: bool Whether to hide inputs when printing errors. Defaults to False. Pydantic shows the input value and type when it raises ValidationError during the validation. from pydantic import BaseModel, ValidationError class Model(BaseModel): a: str try: Model(a=123) except ValidationError as e: print(e) ''' 1 validation error for Model a Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=123, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] ''' You can hide the input value and type by setting the hide\\\\\\\\\\\\\\_input\\\\\\\\\\\\\\_in\\\\\\\\\\\\\\_errors config to True. from pydantic import BaseModel, ConfigDict, ValidationError class Model(BaseModel): a: str model\\\\\\\\\\\\\\_config = ConfigDict(hide\\\\\\\\\\\\\\_input\\\\\\\\\\\\\\_in\\\\\\\\\\\\\\_errors=True) try: Model(a=123) except ValidationError as e: print(e) ''' 1 validation error for Model a Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\] ''' defer\\\\\\\\\\\\\\_build instance-attribute ¶ defer\\\\\\\\\\\\\\_build: bool Whether to defer model validator and serializer construction until the first model validation. This can be useful to avoid the overhead of building models which are only used nested within other models, or when you want to manually define type namespace via Model.model\\\\\\\\\\\\\\_rebuild(\\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_namespace=...). Defaults to False. plugin\\\\\\\\\\\\\\_settings instance-attribute ¶ plugin\\\\\\\\\\\\\\_settings: dict\\\\\\\\\\\\\\[str, object\\\\\\\\\\\\\\] | None A dict of settings for plugins. Defaults to None. See Pydantic Plugins for details. schema\\\\\\\\\\\\\\_generator instance-attribute ¶ schema\\\\\\\\\\\\\\_generator: type\\\\\\\\\\\\\\[\\\\\\\\\\\\\\_GenerateSchema\\\\\\\\\\\\\\] | None A custom core schema generator class to use when generating JSON schemas. Useful if you want to change the way types are validated across an entire model/schema. Defaults to None. The GenerateSchema interface is subject to change, currently only the string\\\\\\\\\\\\\\_schema method is public. See #6737 for details. json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_serialization\\\\\\\\\\\\\\_defaults\\\\\\\\\\\\\\_required instance-attribute ¶ json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_serialization\\\\\\\\\\\\\\_defaults\\\\\\\\\\\\\\_required: bool Whether fields with default values should be marked as required in the serialization schema. Defaults to False. This ensures that the serialization schema will reflect the fact a field with a default will always be present when serializing the model, even though it is not required for validation. However, there are scenarios where this may be undesirable — in particular, if you want to share the schema between validation and serialization, and don't mind fields with defaults being marked as not required during serialization. See #7209 for more details. from pydantic import BaseModel, ConfigDict class Model(BaseModel): a: str = 'a' model\\\\\\\\\\\\\\_config = ConfigDict(json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_serialization\\\\\\\\\\\\\\_defaults\\\\\\\\\\\\\\_required=True) print(Model.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema(mode='validation')) ''' { 'properties': {'a': {'default': 'a', 'title': 'A', 'type': 'string'}}, 'title': 'Model', 'type': 'object', } ''' print(Model.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema(mode='serialization')) ''' { 'properties': {'a': {'default': 'a', 'title': 'A', 'type': 'string'}}, 'required': \\\\\\\\\\\\\\['a'\\\\\\\\\\\\\\], 'title': 'Model', 'type': 'object', } ''' json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_mode\\\\\\\\\\\\\\_override instance-attribute ¶ json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_mode\\\\\\\\\\\\\\_override: Literal\\\\\\\\\\\\\\[ \"validation\", \"serialization\", None \\\\\\\\\\\\\\] If not None, the specified mode will be used to generate the JSON schema regardless of what mode was passed to the function call. Defaults to None. This provides a way to force the JSON schema generation to reflect a specific mode, e.g., to always use the validation schema. It can be useful when using frameworks (such as FastAPI) that may generate different schemas for validation and serialization that must both be referenced from the same schema; when this happens, we automatically append -Input to the definition reference for the validation schema and -Output to the definition reference for the serialization schema. By specifying a json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_mode\\\\\\\\\\\\\\_override though, this prevents the conflict between the validation and serialization schemas (since both will use the specified schema), and so prevents the suffixes from being added to the definition references. from pydantic import BaseModel, ConfigDict, Json class Model(BaseModel): a: Json\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] # requires a string to validate, but will dump an int print(Model.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema(mode='serialization')) ''' { 'properties': {'a': {'title': 'A', 'type': 'integer'}}, 'required': \\\\\\\\\\\\\\['a'\\\\\\\\\\\\\\], 'title': 'Model', 'type': 'object', } ''' class ForceInputModel(Model): # the following ensures that even with mode='serialization', we # will get the schema that would be generated for validation. model\\\\\\\\\\\\\\_config = ConfigDict(json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_mode\\\\\\\\\\\\\\_override='validation') print(ForceInputModel.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema(mode='serialization')) ''' { 'properties': { 'a': { 'contentMediaType': 'application/json', 'contentSchema': {'type': 'integer'}, 'title': 'A', 'type': 'string', } }, 'required': \\\\\\\\\\\\\\['a'\\\\\\\\\\\\\\], 'title': 'ForceInputModel', 'type': 'object', } ''' coerce\\\\\\\\\\\\\\_numbers\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_str instance-attribute ¶ coerce\\\\\\\\\\\\\\_numbers\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_str: bool If True, enables automatic coercion of any Number type to str in \"lax\" (non-strict) mode. Defaults to False. Pydantic doesn't allow number types (int, float, Decimal) to be coerced as type str by default. from decimal import Decimal from pydantic import BaseModel, ConfigDict, ValidationError class Model(BaseModel): value: str try: print(Model(value=42)) except ValidationError as e: print(e) ''' 1 validation error for Model value Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=42, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] ''' class Model(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(coerce\\\\\\\\\\\\\\_numbers\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_str=True) value: str repr(Model(value=42).value) #> \"42\" repr(Model(value=42.13).value) #> \"42.13\" repr(Model(value=Decimal('42.13')).value) #> \"42.13\" regex\\\\\\\\\\\\\\_engine instance-attribute ¶ regex\\\\\\\\\\\\\\_engine: Literal\\\\\\\\\\\\\\['rust-regex', 'python-re'\\\\\\\\\\\\\\] The regex engine to used for pattern validation Defaults to 'rust-regex'. rust-regex uses the regex Rust crate, which is non-backtracking and therefore more DDoS resistant, but does not support all regex features. python-re use the re module, which supports all regex features, but may be slower. from pydantic import BaseModel, ConfigDict, Field, ValidationError class Model(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(regex\\\\\\\\\\\\\\_engine='python-re') value: str = Field(pattern=r'^abc(?=def)') print(Model(value='abcdef').value) #> abcdef try: print(Model(value='abxyzcdef')) except ValidationError as e: print(e) ''' 1 validation error for Model value String should match pattern '^abc(?=def)' \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_pattern\\\\\\\\\\\\\\_mismatch, input\\\\\\\\\\\\\\_value='abxyzcdef', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] ''' validation\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_cause instance-attribute ¶ validation\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_cause: bool If True, python exceptions that were part of a validation failure will be shown as an exception group as a cause. Can be useful for debugging. Defaults to False. Note Python 3.10 and older don't support exception groups natively. <=3.10, backport must be installed: pip install exceptiongroup. Note The structure of validation errors are likely to change in future pydantic versions. Pydantic offers no guarantees about the structure of validation errors. Should be used for visual traceback debugging only. ExtraValues module-attribute ¶ ExtraValues = Literal\\\\\\\\\\\\\\['allow', 'ignore', 'forbid'\\\\\\\\\\\\\\] pydantic.alias\\\\\\\\\\\\\\_generators ¶ Alias generators for converting between different capitalization conventions. to\\\\\\\\\\\\\\_pascal ¶ to\\\\\\\\\\\\\\_pascal(snake) Convert a snake\\\\\\\\\\\\\\_case string to PascalCase. Parameters: Name Type Description Default snake str The string to convert. required Returns: Type Description str The PascalCase string. Source code in pydantic/alias\\\\\\\\\\\\\\_generators.py to\\\\\\\\\\\\\\_camel ¶ to\\\\\\\\\\\\\\_camel(snake) Convert a snake\\\\\\\\\\\\\\_case string to camelCase. Parameters: Name Type Description Default snake str The string to convert. required Returns: Type Description str The converted camelCase string. Source code in pydantic/alias\\\\\\\\\\\\\\_generators.py to\\\\\\\\\\\\\\_snake ¶ to\\\\\\\\\\\\\\_snake(camel) Convert a PascalCase or camelCase string to snake\\\\\\\\\\\\\\_case. Parameters: Name Type Description Default camel str The string to convert. required Returns: Type Description str The converted string in snake\\\\\\\\\\\\\\_case. Source code in pydantic/alias\\\\\\\\\\\\\\_generators.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Fields - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/fields/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Fields Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.fields Field() FieldInfo from\\\\\\\\\\\\\\_field() from\\\\\\\\\\\\\\_annotation() from\\\\\\\\\\\\\\_annotated\\\\\\\\\\\\\\_attribute() merge\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_infos() get\\\\\\\\\\\\\\_default() is\\\\\\\\\\\\\\_required() rebuild\\\\\\\\\\\\\\_annotation() apply\\\\\\\\\\\\\\_typevars\\\\\\\\\\\\\\_map() AliasChoices convert\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_aliases() AliasPath convert\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_aliases() PrivateAttr() ModelPrivateAttr get\\\\\\\\\\\\\\_default() computed\\\\\\\\\\\\\\_field() ComputedFieldInfo Fields Defining fields on models. Field ¶ Field( default=PydanticUndefined, \\\\\\\\\\\\\\*, default\\\\\\\\\\\\\\_factory=\\\\\\\\\\\\\\_Unset, alias=\\\\\\\\\\\\\\_Unset, alias\\\\\\\\\\\\\\_priority=\\\\\\\\\\\\\\_Unset, validation\\\\\\\\\\\\\\_alias=\\\\\\\\\\\\\\_Unset, serialization\\\\\\\\\\\\\\_alias=\\\\\\\\\\\\\\_Unset, title=\\\\\\\\\\\\\\_Unset, description=\\\\\\\\\\\\\\_Unset, examples=\\\\\\\\\\\\\\_Unset, exclude=\\\\\\\\\\\\\\_Unset, discriminator=\\\\\\\\\\\\\\_Unset, json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra=\\\\\\\\\\\\\\_Unset, frozen=\\\\\\\\\\\\\\_Unset, validate\\\\\\\\\\\\\\_default=\\\\\\\\\\\\\\_Unset, repr=\\\\\\\\\\\\\\_Unset, init\\\\\\\\\\\\\\_var=\\\\\\\\\\\\\\_Unset, kw\\\\\\\\\\\\\\_only=\\\\\\\\\\\\\\_Unset, pattern=\\\\\\\\\\\\\\_Unset, strict=\\\\\\\\\\\\\\_Unset, gt=\\\\\\\\\\\\\\_Unset, ge=\\\\\\\\\\\\\\_Unset, lt=\\\\\\\\\\\\\\_Unset, le=\\\\\\\\\\\\\\_Unset, multiple\\\\\\\\\\\\\\_of=\\\\\\\\\\\\\\_Unset, allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan=\\\\\\\\\\\\\\_Unset, max\\\\\\\\\\\\\\_digits=\\\\\\\\\\\\\\_Unset, decimal\\\\\\\\\\\\\\_places=\\\\\\\\\\\\\\_Unset, min\\\\\\\\\\\\\\_length=\\\\\\\\\\\\\\_Unset, max\\\\\\\\\\\\\\_length=\\\\\\\\\\\\\\_Unset, union\\\\\\\\\\\\\\_mode=\\\\\\\\\\\\\\_Unset, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*extra ) Usage Documentation Fields Create a field for objects that can be configured. Used to provide extra information about a field, either for the model schema or complex validation. Some arguments apply only to number fields (int, float, Decimal) and some apply only to str. Note Any \\\\\\\\\\\\\\_Unset objects will be replaced by the corresponding value defined in the \\\\\\\\\\\\\\_DefaultValues dictionary. If a key for the \\\\\\\\\\\\\\_Unset object is not found in the \\\\\\\\\\\\\\_DefaultValues dictionary, it will default to None Parameters: Name Type Description Default default Any Default value if the field is not set. PydanticUndefined default\\\\\\\\\\\\\\_factory typing.Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] | None A callable to generate the default value, such as :func:~datetime.utcnow. \\\\\\\\\\\\\\_Unset alias str | None An alternative name for the attribute. \\\\\\\\\\\\\\_Unset alias\\\\\\\\\\\\\\_priority int | None Priority of the alias. This affects whether an alias generator is used. \\\\\\\\\\\\\\_Unset validation\\\\\\\\\\\\\\_alias str | AliasPath | AliasChoices | None 'Whitelist' validation step. The field will be the single one allowed by the alias or set of aliases defined. \\\\\\\\\\\\\\_Unset serialization\\\\\\\\\\\\\\_alias str | None 'Blacklist' validation step. The vanilla field will be the single one of the alias' or set of aliases' fields and all the other fields will be ignored at serialization time. \\\\\\\\\\\\\\_Unset title str | None Human-readable title. \\\\\\\\\\\\\\_Unset description str | None Human-readable description. \\\\\\\\\\\\\\_Unset examples list\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] | None Example values for this field. \\\\\\\\\\\\\\_Unset exclude bool | None Whether to exclude the field from the model serialization. \\\\\\\\\\\\\\_Unset discriminator str | types.Discriminator | None Field name or Discriminator for discriminating the type in a tagged union. \\\\\\\\\\\\\\_Unset json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra JsonDict | typing.Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[JsonDict\\\\\\\\\\\\\\], None\\\\\\\\\\\\\\] | None Any additional JSON schema data for the schema property. \\\\\\\\\\\\\\_Unset frozen bool | None Whether the field is frozen. \\\\\\\\\\\\\\_Unset validate\\\\\\\\\\\\\\_default bool | None Run validation that isn't only checking existence of defaults. This can be set to True or False. If not set, it defaults to None. \\\\\\\\\\\\\\_Unset repr bool A boolean indicating whether to include the field in the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_repr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ output. \\\\\\\\\\\\\\_Unset init\\\\\\\\\\\\\\_var bool | None Whether the field should be included in the constructor of the dataclass. \\\\\\\\\\\\\\_Unset kw\\\\\\\\\\\\\\_only bool | None Whether the field should be a keyword-only argument in the constructor of the dataclass. \\\\\\\\\\\\\\_Unset strict bool | None If True, strict validation is applied to the field. See Strict Mode for details. \\\\\\\\\\\\\\_Unset gt float | None Greater than. If set, value must be greater than this. Only applicable to numbers. \\\\\\\\\\\\\\_Unset ge float | None Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers. \\\\\\\\\\\\\\_Unset lt float | None Less than. If set, value must be less than this. Only applicable to numbers. \\\\\\\\\\\\\\_Unset le float | None Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers. \\\\\\\\\\\\\\_Unset multiple\\\\\\\\\\\\\\_of float | None Value must be a multiple of this. Only applicable to numbers. \\\\\\\\\\\\\\_Unset min\\\\\\\\\\\\\\_length int | None Minimum length for strings. \\\\\\\\\\\\\\_Unset max\\\\\\\\\\\\\\_length int | None Maximum length for strings. \\\\\\\\\\\\\\_Unset pattern str | None Pattern for strings. \\\\\\\\\\\\\\_Unset allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan bool | None Allow inf, -inf, nan. Only applicable to numbers. \\\\\\\\\\\\\\_Unset max\\\\\\\\\\\\\\_digits int | None Maximum number of allow digits for strings. \\\\\\\\\\\\\\_Unset decimal\\\\\\\\\\\\\\_places int | None Maximum number of decimal places allowed for numbers. \\\\\\\\\\\\\\_Unset union\\\\\\\\\\\\\\_mode Literal\\\\\\\\\\\\\\['smart', 'left\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_right'\\\\\\\\\\\\\\] The strategy to apply when validating a union. Can be smart (the default), or left\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_right. See Union Mode for details. \\\\\\\\\\\\\\_Unset extra Unpack\\\\\\\\\\\\\\[\\\\\\\\\\\\\\_EmptyKwargs\\\\\\\\\\\\\\] Include extra fields used by the JSON schema. Warning The extra kwargs is deprecated. Use json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra instead. {} Returns: Type Description Any A new FieldInfo, the return annotation is Any so Field can be used on type annotated fields without causing a typing error. Source code in pydantic/fields.py FieldInfo ¶ FieldInfo(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*kwargs) Bases: \\\\\\\\\\\\\\_repr.Representation This class holds information about a field. FieldInfo is used for any field definition regardless of whether the Field() function is explicitly used. Warning You generally shouldn't be creating FieldInfo directly, you'll only need to use it when accessing BaseModel .model\\\\\\\\\\\\\\_fields internals. Attributes: Name Type Description annotation type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] | None The type annotation of the field. default Any The default value of the field. default\\\\\\\\\\\\\\_factory typing.Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] | None The factory function used to construct the default for the field. alias str | None The alias name of the field. alias\\\\\\\\\\\\\\_priority int | None The priority of the field's alias. validation\\\\\\\\\\\\\\_alias str | AliasPath | AliasChoices | None The validation alias name of the field. serialization\\\\\\\\\\\\\\_alias str | None The serialization alias name of the field. title str | None The title of the field. description str | None The description of the field. examples list\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] | None List of examples of the field. exclude bool | None Whether to exclude the field from the model serialization. discriminator str | types.Discriminator | None Field name or Discriminator for discriminating the type in a tagged union. json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra JsonDict | typing.Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[JsonDict\\\\\\\\\\\\\\], None\\\\\\\\\\\\\\] | None Dictionary of extra JSON schema properties. frozen bool | None Whether the field is frozen. validate\\\\\\\\\\\\\\_default bool | None Whether to validate the default value of the field. repr bool Whether to include the field in representation of the model. init\\\\\\\\\\\\\\_var bool | None Whether the field should be included in the constructor of the dataclass. kw\\\\\\\\\\\\\\_only bool | None Whether the field should be a keyword-only argument in the constructor of the dataclass. metadata list\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] List of metadata constraints. See the signature of pydantic.fields.Field for more details about the expected arguments. Source code in pydantic/fields.py from\\\\\\\\\\\\\\_field classmethod ¶ from\\\\\\\\\\\\\\_field(default=PydanticUndefined, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*kwargs) Create a new FieldInfo object with the Field function. Parameters: Name Type Description Default default Any The default value for the field. Defaults to Undefined. PydanticUndefined \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*kwargs Unpack\\\\\\\\\\\\\\[\\\\\\\\\\\\\\_FromFieldInfoInputs\\\\\\\\\\\\\\] Additional arguments dictionary. {} Raises: Type Description TypeError If 'annotation' is passed as a keyword argument. Returns: Type Description typing\\\\\\\\\\\\\\_extensions.Self A new FieldInfo object with the given parameters. Example This is how you can create a field with default value like this: import pydantic class MyModel(pydantic.BaseModel): foo: int = pydantic.Field(4) Source code in pydantic/fields.py from\\\\\\\\\\\\\\_annotation classmethod ¶ from\\\\\\\\\\\\\\_annotation(annotation) Creates a FieldInfo instance from a bare annotation. Parameters: Name Type Description Default annotation type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] An annotation object. required Returns: Type Description FieldInfo An instance of the field metadata. Example This is how you can create a field from a bare annotation like this: import pydantic class MyModel(pydantic.BaseModel): foo: int # <-- like this We also account for the case where the annotation can be an instance of Annotated and where one of the (not first) arguments in Annotated are an instance of FieldInfo, e.g.: import annotated\\\\\\\\\\\\\\_types from typing\\\\\\\\\\\\\\_extensions import Annotated import pydantic class MyModel(pydantic.BaseModel): foo: Annotated\\\\\\\\\\\\\\[int, annotated\\\\\\\\\\\\\\_types.Gt(42)\\\\\\\\\\\\\\] bar: Annotated\\\\\\\\\\\\\\[int, pydantic.Field(gt=42)\\\\\\\\\\\\\\] Source code in pydantic/fields.py from\\\\\\\\\\\\\\_annotated\\\\\\\\\\\\\\_attribute classmethod ¶ from\\\\\\\\\\\\\\_annotated\\\\\\\\\\\\\\_attribute(annotation, default) Create FieldInfo from an annotation with a default value. Parameters: Name Type Description Default annotation type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] The type annotation of the field. required default Any The default value of the field. required Returns: Type Description FieldInfo A field object with the passed values. Example import annotated\\\\\\\\\\\\\\_types from typing\\\\\\\\\\\\\\_extensions import Annotated import pydantic class MyModel(pydantic.BaseModel): foo: int = 4 # <-- like this bar: Annotated\\\\\\\\\\\\\\[int, annotated\\\\\\\\\\\\\\_types.Gt(4)\\\\\\\\\\\\\\] = 4 # <-- or this spam: Annotated\\\\\\\\\\\\\\[int, pydantic.Field(gt=4)\\\\\\\\\\\\\\] = 4 # <-- or this Source code in pydantic/fields.py merge\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_infos staticmethod ¶ merge\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_infos(\\\\\\\\\\\\\\*field\\\\\\\\\\\\\\_infos, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*overrides) Merge FieldInfo instances keeping only explicitly set attributes. Later FieldInfo instances override earlier ones. Returns: Name Type Description FieldInfo FieldInfo A merged FieldInfo instance. Source code in pydantic/fields.py get\\\\\\\\\\\\\\_default ¶ get\\\\\\\\\\\\\\_default(\\\\\\\\\\\\\\*, call\\\\\\\\\\\\\\_default\\\\\\\\\\\\\\_factory=False) Get the default value. We expose an option for whether to call the default\\\\\\\\\\\\\\_factory (if present), as calling it may result in side effects that we want to avoid. However, there are times when it really should be called (namely, when instantiating a model via model\\\\\\\\\\\\\\_construct). Parameters: Name Type Description Default call\\\\\\\\\\\\\\_default\\\\\\\\\\\\\\_factory bool Whether to call the default\\\\\\\\\\\\\\_factory or not. Defaults to False. False Returns: Type Description Any The default value, calling the default factory if requested or None if not set. Source code in pydantic/fields.py is\\\\\\\\\\\\\\_required ¶ is\\\\\\\\\\\\\\_required() Check if the argument is required. Returns: Type Description bool True if the argument is required, False otherwise. Source code in pydantic/fields.py rebuild\\\\\\\\\\\\\\_annotation ¶ rebuild\\\\\\\\\\\\\\_annotation() Rebuilds the original annotation for use in function signatures. If metadata is present, it adds it to the original annotation using an AnnotatedAlias. Otherwise, it returns the original annotation as is. Returns: Type Description Any The rebuilt annotation. Source code in pydantic/fields.py apply\\\\\\\\\\\\\\_typevars\\\\\\\\\\\\\\_map ¶ apply\\\\\\\\\\\\\\_typevars\\\\\\\\\\\\\\_map(typevars\\\\\\\\\\\\\\_map, types\\\\\\\\\\\\\\_namespace) Apply a typevars\\\\\\\\\\\\\\_map to the annotation. This method is used when analyzing parametrized generic types to replace typevars with their concrete types. This method applies the typevars\\\\\\\\\\\\\\_map to the annotation in place. Parameters: Name Type Description Default typevars\\\\\\\\\\\\\\_map dict\\\\\\\\\\\\\\[Any, Any\\\\\\\\\\\\\\] | None A dictionary mapping type variables to their concrete types. required types\\\\\\\\\\\\\\_namespace dict | None A dictionary containing related types to the annotated type. required See Also pydantic.\\\\\\\\\\\\\\_internal.\\\\\\\\\\\\\\_generics.replace\\\\\\\\\\\\\\_types is used for replacing the typevars with their concrete types. Source code in pydantic/fields.py AliasChoices dataclass ¶ AliasChoices(first\\\\\\\\\\\\\\_choice, \\\\\\\\\\\\\\*choices) Usage Documentation AliasPath and AliasChoices A data class used by validation\\\\\\\\\\\\\\_alias as a convenience to create aliases. Attributes: Name Type Description choices list\\\\\\\\\\\\\\[str | AliasPath\\\\\\\\\\\\\\] A list containing a string or AliasPath. Source code in pydantic/fields.py convert\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_aliases ¶ convert\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_aliases() Converts arguments to a list of lists containing string or integer aliases. Returns: Type Description list\\\\\\\\\\\\\\[list\\\\\\\\\\\\\\[str | int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] The list of aliases. Source code in pydantic/fields.py AliasPath dataclass ¶ AliasPath(first\\\\\\\\\\\\\\_arg, \\\\\\\\\\\\\\*args) Usage Documentation AliasPath and AliasChoices A data class used by validation\\\\\\\\\\\\\\_alias as a convenience to create aliases. Attributes: Name Type Description path list\\\\\\\\\\\\\\[int | str\\\\\\\\\\\\\\] A list of string or integer aliases. Source code in pydantic/fields.py convert\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_aliases ¶ convert\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_aliases() Converts arguments to a list of string or integer aliases. Returns: Type Description list\\\\\\\\\\\\\\[str | int\\\\\\\\\\\\\\] The list of aliases. Source code in pydantic/fields.py PrivateAttr ¶ PrivateAttr( default=PydanticUndefined, \\\\\\\\\\\\\\*, default\\\\\\\\\\\\\\_factory=None ) Indicates that attribute is only used internally and never mixed with regular fields. Private attributes are not checked by Pydantic, so it's up to you to maintain their accuracy. Private attributes are stored in \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_private\\\\\\\\\\\\\\_attributes\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ on the model. Parameters: Name Type Description Default default Any The attribute's default value. Defaults to Undefined. PydanticUndefined default\\\\\\\\\\\\\\_factory typing.Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] | None Callable that will be called when a default value is needed for this attribute. If both default and default\\\\\\\\\\\\\\_factory are set, an error will be raised. None Returns: Type Description Any An instance of ModelPrivateAttr class. Raises: Type Description ValueError If both default and default\\\\\\\\\\\\\\_factory are set. Source code in pydantic/fields.py ModelPrivateAttr ¶ ModelPrivateAttr( default=PydanticUndefined, \\\\\\\\\\\\\\*, default\\\\\\\\\\\\\\_factory=None ) Bases: \\\\\\\\\\\\\\_repr.Representation A descriptor for private attributes in class models. Attributes: Name Type Description default The default value of the attribute if not provided. default\\\\\\\\\\\\\\_factory A callable function that generates the default value of the attribute if not provided. Source code in pydantic/fields.py get\\\\\\\\\\\\\\_default ¶ get\\\\\\\\\\\\\\_default() Retrieve the default value of the object. If self.default\\\\\\\\\\\\\\_factory is None, the method will return a deep copy of the self.default object. If self.default\\\\\\\\\\\\\\_factory is not None, it will call self.default\\\\\\\\\\\\\\_factory and return the value returned. Returns: Type Description Any The default value of the object. Source code in pydantic/fields.py computed\\\\\\\\\\\\\\_field ¶ computed\\\\\\\\\\\\\\_field( \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_f=None, \\\\\\\\\\\\\\*, alias=None, alias\\\\\\\\\\\\\\_priority=None, title=None, description=None, examples=None, json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra=None, repr=None, return\\\\\\\\\\\\\\_type=PydanticUndefined ) Decorator to include property and cached\\\\\\\\\\\\\\_property when serializing models or dataclasses. This is useful for fields that are computed from other fields, or for fields that are expensive to compute and should be cached. from pydantic import BaseModel, computed\\\\\\\\\\\\\\_field class Rectangle(BaseModel): width: int length: int @computed\\\\\\\\\\\\\\_field @property def area(self) -> int: return self.width \\\\\\\\\\\\\\* self.length print(Rectangle(width=3, length=2).model\\\\\\\\\\\\\\_dump()) #> {'width': 3, 'length': 2, 'area': 6} If applied to functions not yet decorated with @property or @cached\\\\\\\\\\\\\\_property, the function is automatically wrapped with property. Although this is more concise, you will lose IntelliSense in your IDE, and confuse static type checkers, thus explicit use of @property is recommended. Mypy Warning Even with the @property or @cached\\\\\\\\\\\\\\_property applied to your function before @computed\\\\\\\\\\\\\\_field, mypy may throw a Decorated property not supported error. See mypy issue #1362, for more information. To avoid this error message, add # type: ignore\\\\\\\\\\\\\\[misc\\\\\\\\\\\\\\] to the @computed\\\\\\\\\\\\\\_field line. pyright supports @computed\\\\\\\\\\\\\\_field without error. import random from pydantic import BaseModel, computed\\\\\\\\\\\\\\_field class Square(BaseModel): width: float @computed\\\\\\\\\\\\\\_field def area(self) -> float: # converted to a \\\\\\\\\\\\\\`property\\\\\\\\\\\\\\` by \\\\\\\\\\\\\\`computed\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\` return round(self.width\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*2, 2) @area.setter def area(self, new\\\\\\\\\\\\\\_area: float) -> None: self.width = new\\\\\\\\\\\\\\_area\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*0.5 @computed\\\\\\\\\\\\\\_field(alias='the magic number', repr=False) def random\\\\\\\\\\\\\\_number(self) -> int: return random.randint(0, 1\\\\\\\\\\\\\\_000) square = Square(width=1.3) # \\\\\\\\\\\\\\`random\\\\\\\\\\\\\\_number\\\\\\\\\\\\\\` does not appear in representation print(repr(square)) #> Square(width=1.3, area=1.69) print(square.random\\\\\\\\\\\\\\_number) #> 3 square.area = 4 print(square.model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json(by\\\\\\\\\\\\\\_alias=True)) #> {\"width\":2.0,\"area\":4.0,\"the magic number\":3} Overriding with computed\\\\\\\\\\\\\\_field You can't override a field from a parent class with a computed\\\\\\\\\\\\\\_field in the child class. mypy complains about this behavior if allowed, and dataclasses doesn't allow this pattern either. See the example below: from pydantic import BaseModel, computed\\\\\\\\\\\\\\_field class Parent(BaseModel): a: str try: class Child(Parent): @computed\\\\\\\\\\\\\\_field @property def a(self) -> str: return 'new a' except ValueError as e: print(repr(e)) #> ValueError(\"you can't override a field with a computed field\") Private properties decorated with @computed\\\\\\\\\\\\\\_field have repr=False by default. from functools import cached\\\\\\\\\\\\\\_property from pydantic import BaseModel, computed\\\\\\\\\\\\\\_field class Model(BaseModel): foo: int @computed\\\\\\\\\\\\\\_field @cached\\\\\\\\\\\\\\_property def \\\\\\\\\\\\\\_private\\\\\\\\\\\\\\_cached\\\\\\\\\\\\\\_property(self) -> int: return -self.foo @computed\\\\\\\\\\\\\\_field @property def \\\\\\\\\\\\\\_private\\\\\\\\\\\\\\_property(self) -> int: return -self.foo m = Model(foo=1) print(repr(m)) #> M(foo=1) Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_f PropertyT | None the function to wrap. None alias str | None alias to use when serializing this computed field, only used when by\\\\\\\\\\\\\\_alias=True None alias\\\\\\\\\\\\\\_priority int | None priority of the alias. This affects whether an alias generator is used None title str | None Title to use when including this computed field in JSON Schema None description str | None Description to use when including this computed field in JSON Schema, defaults to the function's docstring None examples list\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] | None Example values to use when including this computed field in JSON Schema None json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra JsonDict | typing.Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[JsonDict\\\\\\\\\\\\\\], None\\\\\\\\\\\\\\] | None Dictionary of extra JSON schema properties. None repr bool | None whether to include this computed field in model repr. Default is False for private properties and True for public properties. None return\\\\\\\\\\\\\\_type Any optional return for serialization logic to expect when serializing to JSON, if included this must be correct, otherwise a TypeError is raised. If you don't include a return type Any is used, which does runtime introspection to handle arbitrary objects. PydanticUndefined Returns: Type Description PropertyT | typing.Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[PropertyT\\\\\\\\\\\\\\], PropertyT\\\\\\\\\\\\\\] A proxy wrapper for the property. Source code in pydantic/fields.py ComputedFieldInfo dataclass ¶ A container for data from @computed\\\\\\\\\\\\\\_field so that we can access it while building the pydantic-core schema. Attributes: Name Type Description decorator\\\\\\\\\\\\\\_repr str A class variable representing the decorator string, '@computed\\\\\\\\\\\\\\_field'. wrapped\\\\\\\\\\\\\\_property property The wrapped computed field property. return\\\\\\\\\\\\\\_type Any The type of the computed field property's return value. alias str | None The alias of the property to be used during encoding and decoding. alias\\\\\\\\\\\\\\_priority int | None priority of the alias. This affects whether an alias generator is used title str | None Title of the computed field as in OpenAPI document, should be a short summary. description str | None Description of the computed field as in OpenAPI document. examples list\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] | None Example values of the computed field as in OpenAPI document. json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra JsonDict | typing.Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[JsonDict\\\\\\\\\\\\\\], None\\\\\\\\\\\\\\] | None Dictionary of extra JSON schema properties. repr bool A boolean indicating whether or not to include the field in the repr output. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Validate Call - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/validate_call/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Validate Call Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.validate\\\\\\\\\\\\\\_call\\\\\\\\\\\\\\_decorator validate\\\\\\\\\\\\\\_call() Validate Call Decorator for validating function calls. validate\\\\\\\\\\\\\\_call ¶ validate\\\\\\\\\\\\\\_call( \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_func=None, \\\\\\\\\\\\\\*, config=None, validate\\\\\\\\\\\\\\_return=False ) Usage Documentation Validation Decorator Returns a decorated wrapper around the function that validates the arguments and, optionally, the return value. Usage may be either as a plain decorator @validate\\\\\\\\\\\\\\_call or with arguments @validate\\\\\\\\\\\\\\_call(...). Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_func AnyCallableT | None The function to be decorated. None config ConfigDict | None The configuration dictionary. None validate\\\\\\\\\\\\\\_return bool Whether to validate the return value. False Returns: Type Description AnyCallableT | Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[AnyCallableT\\\\\\\\\\\\\\], AnyCallableT\\\\\\\\\\\\\\] The decorated function. Source code in pydantic/validate\\\\\\\\\\\\\\_call\\\\\\\\\\\\\\_decorator.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Pydantic Dataclasses - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/dataclasses/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Pydantic Dataclasses Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.dataclasses dataclass() rebuild\\\\\\\\\\\\\\_dataclass() is\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_dataclass() Pydantic Dataclasses Provide an enhanced dataclass that performs validation. dataclass ¶ dataclass( \\\\\\\\\\\\\\_cls=None, \\\\\\\\\\\\\\*, init=False, repr=True, eq=True, order=False, unsafe\\\\\\\\\\\\\\_hash=False, frozen=False, config=None, validate\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_init=None, kw\\\\\\\\\\\\\\_only=False, slots=False ) Usage Documentation Dataclasses A decorator used to create a Pydantic-enhanced dataclass, similar to the standard Python dataclass, but with added validation. This function should be used similarly to dataclasses.dataclass. Parameters: Name Type Description Default \\\\\\\\\\\\\\_cls type\\\\\\\\\\\\\\[\\\\\\\\\\\\\\_T\\\\\\\\\\\\\\] | None The target dataclass. None init Literal\\\\\\\\\\\\\\[False\\\\\\\\\\\\\\] Included for signature compatibility with dataclasses.dataclass, and is passed through to dataclasses.dataclass when appropriate. If specified, must be set to False, as pydantic inserts its own \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ function. False repr bool A boolean indicating whether or not to include the field in the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_repr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ output. True eq bool Determines if a \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_eq\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ should be generated for the class. True order bool Determines if comparison magic methods should be generated, such as \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_lt\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, but not \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_eq\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. False unsafe\\\\\\\\\\\\\\_hash bool Determines if an unsafe hashing function should be included in the class. False frozen bool Determines if the generated class should be a 'frozen' dataclass, which does not allow its attributes to be modified from its constructor. False config ConfigDict | type\\\\\\\\\\\\\\[object\\\\\\\\\\\\\\] | None A configuration for the dataclass generation. None validate\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_init bool | None A deprecated parameter included for backwards compatibility; in V2, all Pydantic dataclasses are validated on init. None kw\\\\\\\\\\\\\\_only bool Determines if \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method parameters must be specified by keyword only. Defaults to False. False slots bool Determines if the generated class should be a 'slots' dataclass, which does not allow the addition of new attributes after instantiation. False Returns: Type Description Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[type\\\\\\\\\\\\\\[\\\\\\\\\\\\\\_T\\\\\\\\\\\\\\]\\\\\\\\\\\\\\], type\\\\\\\\\\\\\\[PydanticDataclass\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] | type\\\\\\\\\\\\\\[PydanticDataclass\\\\\\\\\\\\\\] A decorator that accepts a class as its argument and returns a Pydantic dataclass. Raises: Type Description AssertionError Raised if init is not False or validate\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_init is False. Source code in pydantic/dataclasses.py rebuild\\\\\\\\\\\\\\_dataclass ¶ rebuild\\\\\\\\\\\\\\_dataclass( cls, \\\\\\\\\\\\\\*, force=False, raise\\\\\\\\\\\\\\_errors=True, \\\\\\\\\\\\\\_parent\\\\\\\\\\\\\\_namespace\\\\\\\\\\\\\\_depth=2, \\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_namespace=None ) Try to rebuild the pydantic-core schema for the dataclass. This may be necessary when one of the annotations is a ForwardRef which could not be resolved during the initial attempt to build the schema, and automatic rebuilding fails. This is analogous to BaseModel.model\\\\\\\\\\\\\\_rebuild. Parameters: Name Type Description Default cls type\\\\\\\\\\\\\\[PydanticDataclass\\\\\\\\\\\\\\] The class to build the dataclass core schema for. required force bool Whether to force the rebuilding of the model schema, defaults to False. False raise\\\\\\\\\\\\\\_errors bool Whether to raise errors, defaults to True. True \\\\\\\\\\\\\\_parent\\\\\\\\\\\\\\_namespace\\\\\\\\\\\\\\_depth int The depth level of the parent namespace, defaults to 2. 2 \\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_namespace dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None The types namespace, defaults to None. None Returns: Type Description bool | None Returns None if the schema is already \"complete\" and rebuilding was not required. bool | None If rebuilding was required, returns True if rebuilding was successful, otherwise False. Source code in pydantic/dataclasses.py is\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_dataclass ¶ is\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_dataclass(\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_cls) Whether a class is a pydantic dataclass. Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_cls type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] The class. required Returns: Type Description TypeGuard\\\\\\\\\\\\\\[type\\\\\\\\\\\\\\[PydanticDataclass\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] True if the class is a pydantic dataclass, False otherwise. Source code in pydantic/dataclasses.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "TypeAdapter - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/type_adapter/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 TypeAdapter Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.type\\\\\\\\\\\\\\_adapter.TypeAdapter validate\\\\\\\\\\\\\\_python() validate\\\\\\\\\\\\\\_json() validate\\\\\\\\\\\\\\_strings() get\\\\\\\\\\\\\\_default\\\\\\\\\\\\\\_value() dump\\\\\\\\\\\\\\_python() dump\\\\\\\\\\\\\\_json() json\\\\\\\\\\\\\\_schema() json\\\\\\\\\\\\\\_schemas() TypeAdapter Bases: Generic\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\] Type adapters provide a flexible way to perform validation and serialization based on a Python type. A TypeAdapter instance exposes some of the functionality from BaseModel instance methods for types that do not have such methods (such as dataclasses, primitive types, and more). Note that TypeAdapter is not an actual type, so you cannot use it in type annotations. Attributes: Name Type Description core\\\\\\\\\\\\\\_schema The core schema for the type. validator SchemaValidator The schema validator for the type. serializer The schema serializer for the type. Parameters: Name Type Description Default type Any The type associated with the TypeAdapter. required config ConfigDict | None Configuration for the TypeAdapter, should be a dictionary conforming to ConfigDict. None \\\\\\\\\\\\\\_parent\\\\\\\\\\\\\\_depth int depth at which to search the parent namespace to construct the local namespace. 2 module str | None The module that passes to plugin if provided. None Note You cannot use the config argument when instantiating a TypeAdapter if the type you're using has its own config that cannot be overridden (ex: BaseModel, TypedDict, and dataclass). A type-adapter-config-unused error will be raised in this case. Note The \\\\\\\\\\\\\\_parent\\\\\\\\\\\\\\_depth argument is named with an underscore to suggest its private nature and discourage use. It may be deprecated in a minor version, so we only recommend using it if you're comfortable with potential change in behavior / support. Returns: Type Description None A type adapter configured for the specified type. Source code in pydantic/type\\\\\\\\\\\\\\_adapter.py validate\\\\\\\\\\\\\\_python ¶ validate\\\\\\\\\\\\\\_python( \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_object, \\\\\\\\\\\\\\*, strict=None, from\\\\\\\\\\\\\\_attributes=None, context=None ) Validate a Python object against the model. Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_object Any The Python object to validate against the model. required strict bool | None Whether to strictly check types. None from\\\\\\\\\\\\\\_attributes bool | None Whether to extract data from object attributes. None context dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None Additional context to pass to the validator. None Note When using TypeAdapter with a Pydantic dataclass, the use of the from\\\\\\\\\\\\\\_attributes argument is not supported. Returns: Type Description T The validated object. Source code in pydantic/type\\\\\\\\\\\\\\_adapter.py validate\\\\\\\\\\\\\\_json ¶ validate\\\\\\\\\\\\\\_json(\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_data, \\\\\\\\\\\\\\*, strict=None, context=None) Usage Documentation Json Parsing Validate a JSON string or bytes against the model. Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_data str | bytes The JSON data to validate against the model. required strict bool | None Whether to strictly check types. None context dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None Additional context to use during validation. None Returns: Type Description T The validated object. Source code in pydantic/type\\\\\\\\\\\\\\_adapter.py validate\\\\\\\\\\\\\\_strings ¶ validate\\\\\\\\\\\\\\_strings(\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_obj, \\\\\\\\\\\\\\*, strict=None, context=None) Validate object contains string data against the model. Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_obj Any The object contains string data to validate. required strict bool | None Whether to strictly check types. None context dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None Additional context to use during validation. None Returns: Type Description T The validated object. Source code in pydantic/type\\\\\\\\\\\\\\_adapter.py get\\\\\\\\\\\\\\_default\\\\\\\\\\\\\\_value ¶ get\\\\\\\\\\\\\\_default\\\\\\\\\\\\\\_value(\\\\\\\\\\\\\\*, strict=None, context=None) Get the default value for the wrapped type. Parameters: Name Type Description Default strict bool | None Whether to strictly check types. None context dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None Additional context to pass to the validator. None Returns: Type Description Some\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\] | None The default value wrapped in a Some if there is one or None if not. Source code in pydantic/type\\\\\\\\\\\\\\_adapter.py dump\\\\\\\\\\\\\\_python ¶ dump\\\\\\\\\\\\\\_python( \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_instance, \\\\\\\\\\\\\\*, mode=\"python\", include=None, exclude=None, by\\\\\\\\\\\\\\_alias=False, exclude\\\\\\\\\\\\\\_unset=False, exclude\\\\\\\\\\\\\\_defaults=False, exclude\\\\\\\\\\\\\\_none=False, round\\\\\\\\\\\\\\_trip=False, warnings=True ) Dump an instance of the adapted type to a Python object. Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_instance T The Python object to serialize. required mode Literal\\\\\\\\\\\\\\['json', 'python'\\\\\\\\\\\\\\] The output format. 'python' include IncEx | None Fields to include in the output. None exclude IncEx | None Fields to exclude from the output. None by\\\\\\\\\\\\\\_alias bool Whether to use alias names for field names. False exclude\\\\\\\\\\\\\\_unset bool Whether to exclude unset fields. False exclude\\\\\\\\\\\\\\_defaults bool Whether to exclude fields with default values. False exclude\\\\\\\\\\\\\\_none bool Whether to exclude fields with None values. False round\\\\\\\\\\\\\\_trip bool Whether to output the serialized data in a way that is compatible with deserialization. False warnings bool Whether to display serialization warnings. True Returns: Type Description Any The serialized object. Source code in pydantic/type\\\\\\\\\\\\\\_adapter.py dump\\\\\\\\\\\\\\_json ¶ dump\\\\\\\\\\\\\\_json( \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_instance, \\\\\\\\\\\\\\*, indent=None, include=None, exclude=None, by\\\\\\\\\\\\\\_alias=False, exclude\\\\\\\\\\\\\\_unset=False, exclude\\\\\\\\\\\\\\_defaults=False, exclude\\\\\\\\\\\\\\_none=False, round\\\\\\\\\\\\\\_trip=False, warnings=True ) Usage Documentation JSON Serialization Serialize an instance of the adapted type to JSON. Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_instance T The instance to be serialized. required indent int | None Number of spaces for JSON indentation. None include IncEx | None Fields to include. None exclude IncEx | None Fields to exclude. None by\\\\\\\\\\\\\\_alias bool Whether to use alias names for field names. False exclude\\\\\\\\\\\\\\_unset bool Whether to exclude unset fields. False exclude\\\\\\\\\\\\\\_defaults bool Whether to exclude fields with default values. False exclude\\\\\\\\\\\\\\_none bool Whether to exclude fields with a value of None. False round\\\\\\\\\\\\\\_trip bool Whether to serialize and deserialize the instance to ensure round-tripping. False warnings bool Whether to emit serialization warnings. True Returns: Type Description bytes The JSON representation of the given instance as bytes. Source code in pydantic/type\\\\\\\\\\\\\\_adapter.py json\\\\\\\\\\\\\\_schema ¶ json\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\*, by\\\\\\\\\\\\\\_alias=True, ref\\\\\\\\\\\\\\_template=DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE, schema\\\\\\\\\\\\\\_generator=GenerateJsonSchema, mode=\"validation\" ) Generate a JSON schema for the adapted type. Parameters: Name Type Description Default by\\\\\\\\\\\\\\_alias bool Whether to use alias names for field names. True ref\\\\\\\\\\\\\\_template str The format string used for generating $ref strings. DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE schema\\\\\\\\\\\\\\_generator type\\\\\\\\\\\\\\[GenerateJsonSchema\\\\\\\\\\\\\\] The generator class used for creating the schema. GenerateJsonSchema mode JsonSchemaMode The mode to use for schema generation. 'validation' Returns: Type Description dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] The JSON schema for the model as a dictionary. Source code in pydantic/type\\\\\\\\\\\\\\_adapter.py json\\\\\\\\\\\\\\_schemas staticmethod ¶ json\\\\\\\\\\\\\\_schemas( \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_inputs, \\\\\\\\\\\\\\*, by\\\\\\\\\\\\\\_alias=True, title=None, description=None, ref\\\\\\\\\\\\\\_template=DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE, schema\\\\\\\\\\\\\\_generator=GenerateJsonSchema ) Generate a JSON schema including definitions from multiple type adapters. Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_inputs Iterable\\\\\\\\\\\\\\[tuple\\\\\\\\\\\\\\[JsonSchemaKeyT, JsonSchemaMode, TypeAdapter\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] Inputs to schema generation. The first two items will form the keys of the (first) output mapping; the type adapters will provide the core schemas that get converted into definitions in the output JSON schema. required by\\\\\\\\\\\\\\_alias bool Whether to use alias names. True title str | None The title for the schema. None description str | None The description for the schema. None ref\\\\\\\\\\\\\\_template str The format string used for generating $ref strings. DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE schema\\\\\\\\\\\\\\_generator type\\\\\\\\\\\\\\[GenerateJsonSchema\\\\\\\\\\\\\\] The generator class used for creating the schema. GenerateJsonSchema Returns: Type Description tuple\\\\\\\\\\\\\\[dict\\\\\\\\\\\\\\[tuple\\\\\\\\\\\\\\[JsonSchemaKeyT, JsonSchemaMode\\\\\\\\\\\\\\], JsonSchemaValue\\\\\\\\\\\\\\], JsonSchemaValue\\\\\\\\\\\\\\] A tuple where: The first element is a dictionary whose keys are tuples of JSON schema key type and JSON mode, and whose values are the JSON schema corresponding to that pair of inputs. (These schemas may have JsonRef references to definitions that are defined in the second returned element.) The second element is a JSON schema containing all definitions referenced in the first returned element, along with the optional title and description keys. Source code in pydantic/type\\\\\\\\\\\\\\_adapter.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "RootModel - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/root_model/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic RootModel Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents pydantic.root\\\\\\\\\\\\\\_model RootModel model\\\\\\\\\\\\\\_construct() model\\\\\\\\\\\\\\_dump() RootModel RootModel class and type definitions. RootModel ¶ RootModel( \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_self\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, root=PydanticUndefined, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data ) Bases: BaseModel, typing.Generic\\\\\\\\\\\\\\[RootModelRootType\\\\\\\\\\\\\\] Usage Documentation RootModel and custom root types A Pydantic BaseModel for the root object of the model. Attributes: Name Type Description root RootModelRootType The root object of the model. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ Whether the model is a RootModel. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_private\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ Private fields in the model. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ Extra fields in the model. Source code in pydantic/root\\\\\\\\\\\\\\_model.py model\\\\\\\\\\\\\\_construct classmethod ¶ model\\\\\\\\\\\\\\_construct(root, \\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set=None) Create a new model using the provided root object and update fields set. Parameters: Name Type Description Default root RootModelRootType The root object of the model. required \\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set set\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] | None The set of fields to be updated. None Returns: Type Description Model The new model. Raises: Type Description NotImplemented If the model is not a subclass of RootModel. Source code in pydantic/root\\\\\\\\\\\\\\_model.py model\\\\\\\\\\\\\\_dump ¶ model\\\\\\\\\\\\\\_dump( \\\\\\\\\\\\\\*, mode=\"python\", include=None, exclude=None, by\\\\\\\\\\\\\\_alias=False, exclude\\\\\\\\\\\\\\_unset=False, exclude\\\\\\\\\\\\\\_defaults=False, exclude\\\\\\\\\\\\\\_none=False, round\\\\\\\\\\\\\\_trip=False, warnings=True ) This method is included just to get a more accurate return type for type checkers. It is included in this if TYPE\\\\\\\\\\\\\\_CHECKING: block since no override is actually necessary. See the documentation of BaseModel.model\\\\\\\\\\\\\\_dump for more details about the arguments. Source code in pydantic/root\\\\\\\\\\\\\\_model.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Pydantic Plugins - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/plugins/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Pydantic Plugins Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Build a plugin Using Plugin Settings Pydantic Plugins Experimental feature Plugins support is experimental and is subject to change in minor releases. Developing plugins is not recommended until the feature becomes stable. Pydantic allows users to create plugins that can be used to extend the functionality of the library. Plugins are installed via Python entry points. You can read more about entry points in the Entry points specification from the Python Packaging Authority. In case you have a project called my-pydantic-plugin, you can create a plugin by adding the following to your pyproject.toml: \\\\\\\\\\\\\\[project.entry-points.pydantic\\\\\\\\\\\\\\] my\\\\\\\\\\\\\\_plugin = \"my\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_plugin:plugin\" The entry point group is pydantic, my\\\\\\\\\\\\\\_plugin is the name of the plugin, my\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_plugin is the module to load plugin object from, and plugin is the object name to load. Plugins are loaded in the order they are found, and the order they are found is not guaranteed. As a user, you can modify the behavior of the plugin in a BaseModel using the plugin\\\\\\\\\\\\\\_settings Model Config argument or class keyword argument. This argument takes a dictionary of settings that will be passed to all plugins as is. The plugin can then use these settings to modify its behavior. It is recommended for plugins to separate their settings into their own dedicates keys in a plugin specific key in the plugin\\\\\\\\\\\\\\_settings dictionary. from pydantic import BaseModel class Foo(BaseModel, plugin\\\\\\\\\\\\\\_settings={'my-plugin': {'observe': 'all'}}): ... Build a plugin¶ API Documentation Pydantic provides an API for creating plugins. The API is exposed via the pydantic.plugin module. On your plugin you can wrap the following methods: validate\\\\\\\\\\\\\\_python: Used to validate the data from a Python object. validate\\\\\\\\\\\\\\_json: Used to validate the data from a JSON string. validate\\\\\\\\\\\\\\_strings: Used to validate the data from strings. For each method, you can implement the following callbacks: on\\\\\\\\\\\\\\_enter: Called before the validation of a field starts. on\\\\\\\\\\\\\\_success: Called when the validation of a field succeeds. on\\\\\\\\\\\\\\_error: Called when the validation of a field fails. Let's see an example of a plugin that wraps the validate\\\\\\\\\\\\\\_python method of the SchemaValidator. from typing import Any, Dict, Optional, Union from pydantic\\\\\\\\\\\\\\_core import CoreConfig, CoreSchema, ValidationError from pydantic.plugin import ( NewSchemaReturns, PydanticPluginProtocol, SchemaKind, SchemaTypePath, ValidatePythonHandlerProtocol, ) class OnValidatePython(ValidatePythonHandlerProtocol): def on\\\\\\\\\\\\\\_enter( self, input: Any, \\\\\\\\\\\\\\*, strict: Optional\\\\\\\\\\\\\\[bool\\\\\\\\\\\\\\] = None, from\\\\\\\\\\\\\\_attributes: Optional\\\\\\\\\\\\\\[bool\\\\\\\\\\\\\\] = None, context: Optional\\\\\\\\\\\\\\[Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = None, self\\\\\\\\\\\\\\_instance: Optional\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] = None, ) -> None: print(input) def on\\\\\\\\\\\\\\_success(self, result: Any) -> None: print(result) def on\\\\\\\\\\\\\\_error(self, error: ValidationError) -> None: print(error.json()) class Plugin(PydanticPluginProtocol): def new\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_validator( self, schema: CoreSchema, schema\\\\\\\\\\\\\\_type: Any, schema\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_path: SchemaTypePath, schema\\\\\\\\\\\\\\_kind: SchemaKind, config: Union\\\\\\\\\\\\\\[CoreConfig, None\\\\\\\\\\\\\\], plugin\\\\\\\\\\\\\\_settings: Dict\\\\\\\\\\\\\\[str, object\\\\\\\\\\\\\\], ) -> NewSchemaReturns: return OnValidatePython(), None, None plugin = Plugin() Using Plugin Settings¶ Consider that you have a plugin called setting called \"observer\", then you can use it like this: from pydantic import BaseModel class Foo(BaseModel, plugin\\\\\\\\\\\\\\_settings={'observer': 'all'}): ... On each validation call, the plugin\\\\\\\\\\\\\\_settings will be passed to a callable registered for the events. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Performance - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/performance/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Performance Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Use model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json() not model\\\\\\\\\\\\\\_validate(json.loads(...)) TypeAdapter instantiated once Sequence vs list or tuple - Mapping vs dict Don't do validation when you don't have to - use Any to keep the value unchanged Avoid extra information via subclasses of primitives Use tagged union, not union Use Literal not Enum Use TypedDict over nested models Avoid wrap validators if you really care about performance Performance tips¶ In most cases Pydantic won't be your bottle neck, only follow this if you're sure it's necessary. Use model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json() not model\\\\\\\\\\\\\\_validate(json.loads(...))¶ On model\\\\\\\\\\\\\\_validate(json.loads(...)), the JSON is parsed in Python, then converted to a dict, then it's validated internally. On the other hand, model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json() already performs the validation internally. TypeAdapter instantiated once¶ The idea here is to avoid constructing validators and serializers more than necessary. Each time a TypeAdapter is instantiated, it will construct a new validator and serializer. If you're using a TypeAdapter in a function, it will be instantiated each time the function is called. Instead, instantiate it once, and reuse it. Bad Good from typing import List from pydantic import TypeAdapter def my\\\\\\\\\\\\\\_func(): adapter = TypeAdapter(List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]) # do something with adapter Sequence vs list or tuple - Mapping vs dict¶ When using Sequence, Pydantic calls isinstance(value, Sequence) to check if the value is a sequence. Also, Pydantic will try to validate against different types of sequences, like list and tuple. If you know the value is a list or tuple, use list or tuple instead of Sequence. The same applies to Mapping and dict. If you know the value is a dict, use dict instead of Mapping. Don't do validation when you don't have to - use Any to keep the value unchanged¶ If you don't need to validate a value, use Any to keep the value unchanged. from typing import Any from pydantic import BaseModel class Model(BaseModel): a: Any model = Model(a=1) Avoid extra information via subclasses of primitives¶ Don't do this Do this class CompletedStr(str): def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, s: str): self.s = s self.done = False === Use tagged union, not union¶ Tagged union (or discriminated union) is a union with a field that indicates which type it is. from typing import Any from typing\\\\\\\\\\\\\\_extensions import Literal from pydantic import BaseModel, Field class DivModel(BaseModel): el\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['div'\\\\\\\\\\\\\\] = 'div' class\\\\\\\\\\\\\\_name: str | None = None children: list\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] | None = None class SpanModel(BaseModel): el\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['span'\\\\\\\\\\\\\\] = 'span' class\\\\\\\\\\\\\\_name: str | None = None contents: str | None = None class ButtonModel(BaseModel): el\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['button'\\\\\\\\\\\\\\] = 'button' class\\\\\\\\\\\\\\_name: str | None = None contents: str | None = None class InputModel(BaseModel): el\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['input'\\\\\\\\\\\\\\] = 'input' class\\\\\\\\\\\\\\_name: str | None = None value: str | None = None class Html(BaseModel): contents: DivModel | SpanModel | ButtonModel | InputModel = Field( discriminator='el\\\\\\\\\\\\\\_type' ) See Discriminated Unions for more details. Use Literal not Enum¶ Instead of using Enum, use Literal to define the structure of the data. Performance comparison Use TypedDict over nested models¶ Instead of using nested models, use TypedDict to define the structure of the data. Performance comparison Avoid wrap validators if you really care about performance¶ Made with Material for MkDocs Insiders"
  },
  {
    "title": "Conversion Table - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/conversion_table/",
    "html": "Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Conversion Table Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Conversion Table The following table provides details on how Pydantic converts data during validation in both strict and lax modes. The \"Strict\" column contains checkmarks for type conversions that are allowed when validating in Strict Mode. All JSON JSON - Strict Python Python - Strict Field Type Input Strict Input Source Conditions bool bool ✓ Python & JSON bool float Python & JSON Allowed values: 0.0, 1.0. bool int Python & JSON Allowed values: 0, 1. bool str Python & JSON Allowed values: 'f', 'n', 'no', 'off', 'false', 'False', 't', 'y', 'on', 'yes', 'true', 'True'. bool Decimal Python Allowed values: Decimal(0), Decimal(1). bytes bytearray Python bytes bytes ✓ Python bytes str ✓ JSON bytes str Python callable - JSON Never valid. callable Any ✓ Python callable() check must return True. date bytes Python Format: YYYY-MM-DD (UTF-8). date date ✓ Python date datetime Python Must be exact date, eg. no H, M, S, f. date float Python & JSON Interpreted as seconds or ms from epoch. See speedate. Must be exact date. date int Python & JSON Interpreted as seconds or ms from epoch. See speedate. Must be exact date. date str Python & JSON Format: YYYY-MM-DD. date Decimal Python Interpreted as seconds or ms from epoch. See speedate. Must be exact date. datetime bytes Python Format: YYYY-MM-DDTHH:MM:SS.f. See speedate, (UTF-8). datetime date Python datetime datetime ✓ Python datetime float Python & JSON Interpreted as seconds or ms from epoch, see speedate. datetime int Python & JSON Interpreted as seconds or ms from epoch, see speedate. datetime str Python & JSON Format: YYYY-MM-DDTHH:MM:SS.f. See speedate. datetime Decimal Python Interpreted as seconds or ms from epoch, see speedate. deque deque ✓ Python deque frozenset Python deque list Python deque set Python deque tuple Python deque Array ✓ JSON dict dict ✓ Python dict Mapping Python Must implement the mapping interface and have an items() method. dict Object ✓ JSON float bool Python & JSON float bytes Python Must match \\\\\\\\\\\\\\[0-9\\\\\\\\\\\\\\]+(\\\\\\\\\\\\\\\\.\\\\\\\\\\\\\\[0-9\\\\\\\\\\\\\\]+)?. float float ✓ Python & JSON bool is explicitly forbidden. float int ✓ Python & JSON float str Python & JSON Must match \\\\\\\\\\\\\\[0-9\\\\\\\\\\\\\\]+(\\\\\\\\\\\\\\\\.\\\\\\\\\\\\\\[0-9\\\\\\\\\\\\\\]+)?. float Decimal Python frozenset deque Python frozenset dict\\\\\\\\\\\\\\_keys Python frozenset dict\\\\\\\\\\\\\\_values Python frozenset frozenset ✓ Python frozenset list Python frozenset set Python frozenset tuple Python frozenset Array ✓ JSON int bool Python & JSON int bytes Python Must be numeric only, e.g. \\\\\\\\\\\\\\[0-9\\\\\\\\\\\\\\]+. int float Python & JSON Must be exact int, e.g. val % 1 == 0, raises error for nan, inf. int int ✓ Python & JSON bool is explicitly forbidden. int int Python & JSON int str Python & JSON Must be numeric only, e.g. \\\\\\\\\\\\\\[0-9\\\\\\\\\\\\\\]+. int Decimal Python Must be exact int, e.g. val % 1 == 0. list deque Python list dict\\\\\\\\\\\\\\_keys Python list dict\\\\\\\\\\\\\\_values Python list frozenset Python list list ✓ Python list set Python list tuple Python list Array ✓ JSON namedtuple dict ✓ Python namedtuple list ✓ Python namedtuple namedtuple ✓ Python namedtuple tuple ✓ Python namedtuple Array ✓ JSON namedtuple NamedTuple ✓ Python set deque Python set dict\\\\\\\\\\\\\\_keys Python set dict\\\\\\\\\\\\\\_values Python set frozenset Python set list Python set set ✓ Python set tuple Python set Array ✓ JSON str bytearray Python Assumes UTF-8, error on unicode decoding error. str bytes Python Assumes UTF-8, error on unicode decoding error. str str ✓ Python & JSON time bytes Python Format: HH:MM:SS.FFFFFF. See speedate. time float Python & JSON Interpreted as seconds, range 0 - 86399.9\\\\\\\\\\\\\\*. time int Python & JSON Interpreted as seconds, range 0 - 86399. time str Python & JSON Format: HH:MM:SS.FFFFFF. See speedate. time time ✓ Python time Decimal Python Interpreted as seconds, range 0 - 86399.9\\\\\\\\\\\\\\*. timedelta bytes Python Format: ISO8601. See speedate, (UTF-8). timedelta float Python & JSON Interpreted as seconds. timedelta int Python & JSON Interpreted as seconds. timedelta str Python & JSON Format: ISO8601. See speedate. timedelta timedelta ✓ Python timedelta Decimal Python Interpreted as seconds. tuple deque Python tuple dict\\\\\\\\\\\\\\_keys Python tuple dict\\\\\\\\\\\\\\_values Python tuple frozenset Python tuple list Python tuple set Python tuple tuple ✓ Python tuple Array ✓ JSON Any Any ✓ Python & JSON ByteSize float ✓ Python & JSON ByteSize int ✓ Python & JSON ByteSize str ✓ Python & JSON ByteSize Decimal ✓ Python Decimal float ✓ JSON Decimal float Python & JSON Decimal int ✓ JSON Decimal int Python & JSON Decimal str ✓ JSON Decimal str Python & JSON Must match \\\\\\\\\\\\\\[0-9\\\\\\\\\\\\\\]+(\\\\\\\\\\\\\\\\.\\\\\\\\\\\\\\[0-9\\\\\\\\\\\\\\]+)?. Decimal Decimal ✓ Python Enum Any ✓ JSON Input value must be convertible to enum values. Enum Any Python Input value must be convertible to enum values. Enum Enum ✓ Python IPv4Address bytes Python IPv4Address int Python integer representing the IP address, must be less than 2\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*32 IPv4Address str ✓ JSON IPv4Address str Python & JSON IPv4Address IPv4Address ✓ Python IPv4Address IPv4Interface ✓ Python IPv4Interface bytes Python IPv4Interface int Python integer representing the IP address, must be less than 2\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*32 IPv4Interface str ✓ JSON IPv4Interface str Python & JSON IPv4Interface tuple Python IPv4Interface IPv4Address Python IPv4Interface IPv4Interface ✓ Python IPv4Network bytes Python IPv4Network int Python integer representing the IP network, must be less than 2\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*32 IPv4Network str ✓ JSON IPv4Network str Python & JSON IPv4Network IPv4Address Python IPv4Network IPv4Interface Python IPv4Network IPv4Network ✓ Python IPv6Address bytes Python IPv6Address int Python integer representing the IP address, must be less than 2\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*128 IPv6Address str ✓ JSON IPv6Address str Python & JSON IPv6Address IPv6Address ✓ Python IPv6Address IPv6Interface ✓ Python IPv6Interface bytes Python IPv6Interface int Python integer representing the IP address, must be less than 2\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*128 IPv6Interface str ✓ JSON IPv6Interface str Python & JSON IPv6Interface tuple Python IPv6Interface IPv6Address Python IPv6Interface IPv6Interface ✓ Python IPv6Network bytes Python IPv6Network int Python integer representing the IP address, must be less than 2\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*128 IPv6Network str ✓ JSON IPv6Network str Python & JSON IPv6Network IPv6Address Python IPv6Network IPv6Interface Python IPv6Network IPv6Network ✓ Python InstanceOf - JSON Never valid. InstanceOf Any ✓ Python isinstance() check must return True. IntEnum Any ✓ JSON Input value must be convertible to enum values. IntEnum Any Python Input value must be convertible to enum values. IntEnum IntEnum ✓ Python Iterable deque ✓ Python Iterable frozenset ✓ Python Iterable list ✓ Python Iterable set ✓ Python Iterable tuple ✓ Python Iterable Array ✓ JSON NamedTuple dict ✓ Python NamedTuple list ✓ Python NamedTuple namedtuple ✓ Python NamedTuple tuple ✓ Python NamedTuple Array ✓ JSON NamedTuple NamedTuple ✓ Python None None ✓ Python & JSON Path str ✓ JSON Path str Python Path Path ✓ Python Pattern bytes ✓ Python Input must be a valid pattern. Pattern str ✓ Python & JSON Input must be a valid pattern. Sequence deque Python Sequence list ✓ Python Sequence tuple Python Sequence Array ✓ JSON Type Type ✓ Python TypedDict dict ✓ Python TypedDict Any ✓ Python TypedDict Mapping Python Must implement the mapping interface and have an items() method. TypedDict Object ✓ JSON UUID str ✓ JSON UUID str Python UUID UUID ✓ Python Made with Material for MkDocs Insiders"
  },
  {
    "title": "Settings Management - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/pydantic_settings/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Settings Management Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Installation Usage Validation of default values Environment variable names Case-sensitivity Parsing environment variable values Dotenv (.env) support Secrets Use Case: Docker Secrets Field value priority Customise settings sources Changing Priority Adding sources Removing sources Settings Management¶ Pydantic Settings provides optional Pydantic features for loading a settings or config class from environment variables or secrets files. Installation¶ Installation is as simple as: pip install pydantic-settings Usage¶ If you create a model that inherits from BaseSettings, the model initialiser will attempt to determine the values of any fields not passed as keyword arguments by reading from the environment. (Default values will still be used if the matching environment variable is not set.) This makes it easy to: Create a clearly-defined, type-hinted application configuration class Automatically read modifications to the configuration from environment variables Manually override specific settings in the initialiser where desired (e.g. in unit tests) For example: from typing import Any, Callable, Set from pydantic import ( AliasChoices, AmqpDsn, BaseModel, Field, ImportString, PostgresDsn, RedisDsn, ) from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, SettingsConfigDict class SubModel(BaseModel): foo: str = 'bar' apple: int = 1 class Settings(BaseSettings): auth\\\\\\\\\\\\\\_key: str = Field(validation\\\\\\\\\\\\\\_alias='my\\\\\\\\\\\\\\_auth\\\\\\\\\\\\\\_key') The environment variable name is overridden using validation\\\\\\\\\\\\\\_alias. In this case, the environment variable my\\\\\\\\\\\\\\_auth\\\\\\\\\\\\\\_key will be read instead of auth\\\\\\\\\\\\\\_key. Check the Field documentation for more information. api\\\\\\\\\\\\\\_key: str = Field(alias='my\\\\\\\\\\\\\\_api\\\\\\\\\\\\\\_key') The environment variable name is overridden using alias. In this case, the environment variable my\\\\\\\\\\\\\\_api\\\\\\\\\\\\\\_key will be used for both validation and serialization instead of api\\\\\\\\\\\\\\_key. redis\\\\\\\\\\\\\\_dsn: RedisDsn = Field( 'redis://user:pass@localhost:6379/1', validation\\\\\\\\\\\\\\_alias=AliasChoices('service\\\\\\\\\\\\\\_redis\\\\\\\\\\\\\\_dsn', 'redis\\\\\\\\\\\\\\_url'), (3) ) pg\\\\\\\\\\\\\\_dsn: PostgresDsn = 'postgres://user:pass@localhost:5432/foobar' amqp\\\\\\\\\\\\\\_dsn: AmqpDsn = 'amqp://user:pass@localhost:5672/' special\\\\\\\\\\\\\\_function: ImportString\\\\\\\\\\\\\\[Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = 'math.cos' (4) # to override domains: # export my\\\\\\\\\\\\\\_prefix\\\\\\\\\\\\\\_domains='\\\\\\\\\\\\\\[\"foo.com\", \"bar.com\"\\\\\\\\\\\\\\]' domains: Set\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] = set() # to override more\\\\\\\\\\\\\\_settings: # export my\\\\\\\\\\\\\\_prefix\\\\\\\\\\\\\\_more\\\\\\\\\\\\\\_settings='{\"foo\": \"x\", \"apple\": 1}' more\\\\\\\\\\\\\\_settings: SubModel = SubModel() model\\\\\\\\\\\\\\_config = SettingsConfigDict(env\\\\\\\\\\\\\\_prefix='my\\\\\\\\\\\\\\_prefix\\\\\\\\\\\\\\_') (5) print(Settings().model\\\\\\\\\\\\\\_dump()) \"\"\" { 'auth\\\\\\\\\\\\\\_key': 'xxx', 'api\\\\\\\\\\\\\\_key': 'xxx', 'redis\\\\\\\\\\\\\\_dsn': Url('redis://user:pass@localhost:6379/1'), 'pg\\\\\\\\\\\\\\_dsn': MultiHostUrl('postgres://user:pass@localhost:5432/foobar'), 'amqp\\\\\\\\\\\\\\_dsn': Url('amqp://user:pass@localhost:5672/'), 'special\\\\\\\\\\\\\\_function': math.cos, 'domains': set(), 'more\\\\\\\\\\\\\\_settings': {'foo': 'bar', 'apple': 1}, } \"\"\" Check the Field documentation for more information. The AliasChoices class allows to have multiple environment variable names for a single field. The first environment variable that is found will be used. Check the AliasChoices for more information. The ImportString class allows to import an object from a string. In this case, the environment variable special\\\\\\\\\\\\\\_function will be read and the function math.cos will be imported. The env\\\\\\\\\\\\\\_prefix config setting allows to set a prefix for all environment variables. Check the Environment variable names documentation for more information. Validation of default values¶ Unlike pydantic BaseModel, default values of BaseSettings fields are validated by default. You can disable this behaviour by setting validate\\\\\\\\\\\\\\_default=False either in model\\\\\\\\\\\\\\_config or on field level by Field(validate\\\\\\\\\\\\\\_default=False): from pydantic import Field from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, SettingsConfigDict class Settings(BaseSettings): model\\\\\\\\\\\\\\_config = SettingsConfigDict(validate\\\\\\\\\\\\\\_default=False) # default won't be validated foo: int = 'test' print(Settings()) #> foo='test' class Settings1(BaseSettings): # default won't be validated foo: int = Field('test', validate\\\\\\\\\\\\\\_default=False) print(Settings1()) #> foo='test' Check the Validation of default values for more information. Environment variable names¶ By default, the environment variable name is the same as the field name. You can change the prefix for all environment variables by setting the env\\\\\\\\\\\\\\_prefix config setting, or via the \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_prefix keyword argument on instantiation: from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, SettingsConfigDict class Settings(BaseSettings): model\\\\\\\\\\\\\\_config = SettingsConfigDict(env\\\\\\\\\\\\\\_prefix='my\\\\\\\\\\\\\\_prefix\\\\\\\\\\\\\\_') auth\\\\\\\\\\\\\\_key: str = 'xxx' # will be read from \\\\\\\\\\\\\\`my\\\\\\\\\\\\\\_prefix\\\\\\\\\\\\\\_auth\\\\\\\\\\\\\\_key\\\\\\\\\\\\\\` Note The default env\\\\\\\\\\\\\\_prefix is '' (empty string). If you want to change the environment variable name for a single field, you can use an alias. There are two ways to do this: Using Field(alias=...) (see api\\\\\\\\\\\\\\_key above) Using Field(validation\\\\\\\\\\\\\\_alias=...) (see auth\\\\\\\\\\\\\\_key above) Check the Field aliases documentation for more information about aliases. env\\\\\\\\\\\\\\_prefix does not apply to fields with alias. It means the environment variable name is the same as field alias: from pydantic import Field from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, SettingsConfigDict class Settings(BaseSettings): model\\\\\\\\\\\\\\_config = SettingsConfigDict(env\\\\\\\\\\\\\\_prefix='my\\\\\\\\\\\\\\_prefix\\\\\\\\\\\\\\_') foo: str = Field('xxx', alias='FooAlias') env\\\\\\\\\\\\\\_prefix will be ignored and the value will be read from FooAlias environment variable. Case-sensitivity¶ By default, environment variable names are case-insensitive. If you want to make environment variable names case-sensitive, you can set the case\\\\\\\\\\\\\\_sensitive config setting: from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, SettingsConfigDict class Settings(BaseSettings): model\\\\\\\\\\\\\\_config = SettingsConfigDict(case\\\\\\\\\\\\\\_sensitive=True) redis\\\\\\\\\\\\\\_host: str = 'localhost' When case\\\\\\\\\\\\\\_sensitive is True, the environment variable names must match field names (optionally with a prefix), so in this example redis\\\\\\\\\\\\\\_host could only be modified via export redis\\\\\\\\\\\\\\_host. If you want to name environment variables all upper-case, you should name attribute all upper-case too. You can still name environment variables anything you like through Field(validation\\\\\\\\\\\\\\_alias=...). Case-sensitivity can also be set via the \\\\\\\\\\\\\\_case\\\\\\\\\\\\\\_sensitive keyword argument on instantiation. In case of nested models, the case\\\\\\\\\\\\\\_sensitive setting will be applied to all nested models. import os from pydantic import ValidationError from pydantic\\\\\\\\\\\\\\_settings import BaseSettings class RedisSettings(BaseSettings): host: str port: int class Settings(BaseSettings, case\\\\\\\\\\\\\\_sensitive=True): redis: RedisSettings os.environ\\\\\\\\\\\\\\['redis'\\\\\\\\\\\\\\] = '{\"host\": \"localhost\", \"port\": 6379}' print(Settings().model\\\\\\\\\\\\\\_dump()) #> {'redis': {'host': 'localhost', 'port': 6379}} os.environ\\\\\\\\\\\\\\['redis'\\\\\\\\\\\\\\] = '{\"HOST\": \"localhost\", \"port\": 6379}' Note that the host field is not found because the environment variable name is HOST (all upper-case). try: Settings() except ValidationError as e: print(e) \"\"\" 2 validation errors for RedisSettings host Field required \\\\\\\\\\\\\\[type=missing, input\\\\\\\\\\\\\\_value={'HOST': 'localhost', 'port': 6379}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] For further information visit https://errors.pydantic.dev/2/v/missing HOST Extra inputs are not permitted \\\\\\\\\\\\\\[type=extra\\\\\\\\\\\\\\_forbidden, input\\\\\\\\\\\\\\_value='localhost', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] For further information visit https://errors.pydantic.dev/2/v/extra\\\\\\\\\\\\\\_forbidden \"\"\" Note On Windows, Python's os module always treats environment variables as case-insensitive, so the case\\\\\\\\\\\\\\_sensitive config setting will have no effect - settings will always be updated ignoring case. Parsing environment variable values¶ For most simple field types (such as int, float, str, etc.), the environment variable value is parsed the same way it would be if passed directly to the initialiser (as a string). Complex types like list, set, dict, and sub-models are populated from the environment by treating the environment variable's value as a JSON-encoded string. Another way to populate nested complex variables is to configure your model with the env\\\\\\\\\\\\\\_nested\\\\\\\\\\\\\\_delimiter config setting, then use an environment variable with a name pointing to the nested module fields. What it does is simply explodes your variable into nested models or dicts. So if you define a variable FOO\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_BAR\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_BAZ=123 it will convert it into FOO={'BAR': {'BAZ': 123}} If you have multiple variables with the same structure they will be merged. As an example, given the following environment variables: # your environment export V0=0 export SUB\\\\\\\\\\\\\\_MODEL='{\"v1\": \"json-1\", \"v2\": \"json-2\"}' export SUB\\\\\\\\\\\\\\_MODEL\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_V2=nested-2 export SUB\\\\\\\\\\\\\\_MODEL\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_V3=3 export SUB\\\\\\\\\\\\\\_MODEL\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_DEEP\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_V4=v4 You could load them into the following settings model: from pydantic import BaseModel from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, SettingsConfigDict class DeepSubModel(BaseModel): Sub model has to inherit from pydantic.BaseModel, Otherwise pydantic-settings will initialize sub model, collects values for sub model fields separately, and you may get unexpected results. v4: str class SubModel(BaseModel): Sub model has to inherit from pydantic.BaseModel, Otherwise pydantic-settings will initialize sub model, collects values for sub model fields separately, and you may get unexpected results. v1: str v2: bytes v3: int deep: DeepSubModel class Settings(BaseSettings): model\\\\\\\\\\\\\\_config = SettingsConfigDict(env\\\\\\\\\\\\\\_nested\\\\\\\\\\\\\\_delimiter='\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_') v0: str sub\\\\\\\\\\\\\\_model: SubModel print(Settings().model\\\\\\\\\\\\\\_dump()) \"\"\" { 'v0': '0', 'sub\\\\\\\\\\\\\\_model': {'v1': 'json-1', 'v2': b'nested-2', 'v3': 3, 'deep': {'v4': 'v4'}}, } \"\"\" env\\\\\\\\\\\\\\_nested\\\\\\\\\\\\\\_delimiter can be configured via the model\\\\\\\\\\\\\\_config as shown above, or via the \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_nested\\\\\\\\\\\\\\_delimiter keyword argument on instantiation. JSON is only parsed in top-level fields, if you need to parse JSON in sub-models, you will need to implement validators on those models. Nested environment variables take precedence over the top-level environment variable JSON (e.g. in the example above, SUB\\\\\\\\\\\\\\_MODEL\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_V2 trumps SUB\\\\\\\\\\\\\\_MODEL). You may also populate a complex type by providing your own source class. import json import os from typing import Any, List, Tuple, Type from pydantic.fields import FieldInfo from pydantic\\\\\\\\\\\\\\_settings import ( BaseSettings, EnvSettingsSource, PydanticBaseSettingsSource, ) class MyCustomSource(EnvSettingsSource): def prepare\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value( self, field\\\\\\\\\\\\\\_name: str, field: FieldInfo, value: Any, value\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_complex: bool ) -> Any: if field\\\\\\\\\\\\\\_name == 'numbers': return \\\\\\\\\\\\\\[int(x) for x in value.split(',')\\\\\\\\\\\\\\] return json.loads(value) class Settings(BaseSettings): numbers: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] @classmethod def settings\\\\\\\\\\\\\\_customise\\\\\\\\\\\\\\_sources( cls, settings\\\\\\\\\\\\\\_cls: Type\\\\\\\\\\\\\\[BaseSettings\\\\\\\\\\\\\\], init\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, env\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, dotenv\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, file\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, ) -> Tuple\\\\\\\\\\\\\\[PydanticBaseSettingsSource, ...\\\\\\\\\\\\\\]: return (MyCustomSource(settings\\\\\\\\\\\\\\_cls),) os.environ\\\\\\\\\\\\\\['numbers'\\\\\\\\\\\\\\] = '1,2,3' print(Settings().model\\\\\\\\\\\\\\_dump()) #> {'numbers': \\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\]} Dotenv (.env) support¶ Dotenv files (generally named .env) are a common pattern that make it easy to use environment variables in a platform-independent manner. A dotenv file follows the same general principles of all environment variables, and it looks like this: .env # ignore comment ENVIRONMENT=\"production\" REDIS\\\\\\\\\\\\\\_ADDRESS=localhost:6379 MEANING\\\\\\\\\\\\\\_OF\\\\\\\\\\\\\\_LIFE=42 MY\\\\\\\\\\\\\\_VAR='Hello world' Once you have your .env file filled with variables, pydantic supports loading it in two ways: Setting the env\\\\\\\\\\\\\\_file (and env\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_encoding if you don't want the default encoding of your OS) on model\\\\\\\\\\\\\\_config in the BaseSettings class: from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, SettingsConfigDict class Settings(BaseSettings): model\\\\\\\\\\\\\\_config = SettingsConfigDict(env\\\\\\\\\\\\\\_file='.env', env\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_encoding='utf-8') Instantiating the BaseSettings derived class with the \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_file keyword argument (and the \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_encoding if needed): from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, SettingsConfigDict class Settings(BaseSettings): model\\\\\\\\\\\\\\_config = SettingsConfigDict(env\\\\\\\\\\\\\\_file='.env', env\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_encoding='utf-8') settings = Settings(\\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_file='prod.env', \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_encoding='utf-8') In either case, the value of the passed argument can be any valid path or filename, either absolute or relative to the current working directory. From there, pydantic will handle everything for you by loading in your variables and validating them. Note If a filename is specified for env\\\\\\\\\\\\\\_file, Pydantic will only check the current working directory and won't check any parent directories for the .env file. Even when using a dotenv file, pydantic will still read environment variables as well as the dotenv file, environment variables will always take priority over values loaded from a dotenv file. Passing a file path via the \\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_file keyword argument on instantiation (method 2) will override the value (if any) set on the model\\\\\\\\\\\\\\_config class. If the above snippets were used in conjunction, prod.env would be loaded while .env would be ignored. If you need to load multiple dotenv files, you can pass multiple file paths as a tuple or list. The files will be loaded in order, with each file overriding the previous one. from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, SettingsConfigDict class Settings(BaseSettings): model\\\\\\\\\\\\\\_config = SettingsConfigDict( # \\\\\\\\\\\\\\`.env.prod\\\\\\\\\\\\\\` takes priority over \\\\\\\\\\\\\\`.env\\\\\\\\\\\\\\` env\\\\\\\\\\\\\\_file=('.env', '.env.prod') ) You can also use the keyword argument override to tell Pydantic not to load any file at all (even if one is set in the model\\\\\\\\\\\\\\_config class) by passing None as the instantiation keyword argument, e.g. settings = Settings(\\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_file=None). Because python-dotenv is used to parse the file, bash-like semantics such as export can be used which (depending on your OS and environment) may allow your dotenv file to also be used with source, see python-dotenv's documentation for more details. Pydantic settings consider extra config in case of dotenv file. It means if you set the extra=forbid (default) on model\\\\\\\\\\\\\\_config and your dotenv file contains an entry for a field that is not defined in settings model, it will raise ValidationError in settings construction. For compatibility with pydantic 1.x BaseSettings you should use extra=ignore: from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, SettingsConfigDict class Settings(BaseSettings): model\\\\\\\\\\\\\\_config = SettingsConfigDict(env\\\\\\\\\\\\\\_file='.env', extra='ignore') Secrets¶ Placing secret values in files is a common pattern to provide sensitive configuration to an application. A secret file follows the same principal as a dotenv file except it only contains a single value and the file name is used as the key. A secret file will look like the following: /var/run/database\\\\\\\\\\\\\\_password super\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_database\\\\\\\\\\\\\\_password Once you have your secret files, pydantic supports loading it in two ways: Setting the secrets\\\\\\\\\\\\\\_dir on model\\\\\\\\\\\\\\_config in a BaseSettings class to the directory where your secret files are stored. from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, SettingsConfigDict class Settings(BaseSettings): model\\\\\\\\\\\\\\_config = SettingsConfigDict(secrets\\\\\\\\\\\\\\_dir='/var/run') database\\\\\\\\\\\\\\_password: str Instantiating the BaseSettings derived class with the \\\\\\\\\\\\\\_secrets\\\\\\\\\\\\\\_dir keyword argument: settings = Settings(\\\\\\\\\\\\\\_secrets\\\\\\\\\\\\\\_dir='/var/run') In either case, the value of the passed argument can be any valid directory, either absolute or relative to the current working directory. Note that a non existent directory will only generate a warning. From there, pydantic will handle everything for you by loading in your variables and validating them. Even when using a secrets directory, pydantic will still read environment variables from a dotenv file or the environment, a dotenv file and environment variables will always take priority over values loaded from the secrets directory. Passing a file path via the \\\\\\\\\\\\\\_secrets\\\\\\\\\\\\\\_dir keyword argument on instantiation (method 2) will override the value (if any) set on the model\\\\\\\\\\\\\\_config class. Use Case: Docker Secrets¶ Docker Secrets can be used to provide sensitive configuration to an application running in a Docker container. To use these secrets in a pydantic application the process is simple. More information regarding creating, managing and using secrets in Docker see the official Docker documentation. First, define your Settings class with a SettingsConfigDict that specifies the secrets directory. from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, SettingsConfigDict class Settings(BaseSettings): model\\\\\\\\\\\\\\_config = SettingsConfigDict(secrets\\\\\\\\\\\\\\_dir='/run/secrets') my\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_data: str Note By default Docker uses /run/secrets as the target mount point. If you want to use a different location, change Config.secrets\\\\\\\\\\\\\\_dir accordingly. Then, create your secret via the Docker CLI printf \"This is a secret\" | docker secret create my\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_data - Last, run your application inside a Docker container and supply your newly created secret docker service create --name pydantic-with-secrets --secret my\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_data pydantic-app:latest Field value priority¶ In the case where a value is specified for the same Settings field in multiple ways, the selected value is determined as follows (in descending order of priority): Arguments passed to the Settings class initialiser. Environment variables, e.g. my\\\\\\\\\\\\\\_prefix\\\\\\\\\\\\\\_special\\\\\\\\\\\\\\_function as described above. Variables loaded from a dotenv (.env) file. Variables loaded from the secrets directory. The default field values for the Settings model. Customise settings sources¶ If the default order of priority doesn't match your needs, it's possible to change it by overriding the settings\\\\\\\\\\\\\\_customise\\\\\\\\\\\\\\_sources method of your Settings . settings\\\\\\\\\\\\\\_customise\\\\\\\\\\\\\\_sources takes four callables as arguments and returns any number of callables as a tuple. In turn these callables are called to build the inputs to the fields of the settings class. Each callable should take an instance of the settings class as its sole argument and return a dict. Changing Priority¶ The order of the returned callables decides the priority of inputs; first item is the highest priority. from typing import Tuple, Type from pydantic import PostgresDsn from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, PydanticBaseSettingsSource class Settings(BaseSettings): database\\\\\\\\\\\\\\_dsn: PostgresDsn @classmethod def settings\\\\\\\\\\\\\\_customise\\\\\\\\\\\\\\_sources( cls, settings\\\\\\\\\\\\\\_cls: Type\\\\\\\\\\\\\\[BaseSettings\\\\\\\\\\\\\\], init\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, env\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, dotenv\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, file\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, ) -> Tuple\\\\\\\\\\\\\\[PydanticBaseSettingsSource, ...\\\\\\\\\\\\\\]: return env\\\\\\\\\\\\\\_settings, init\\\\\\\\\\\\\\_settings, file\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_settings print(Settings(database\\\\\\\\\\\\\\_dsn='postgres://postgres@localhost:5432/kwargs\\\\\\\\\\\\\\_db')) #> database\\\\\\\\\\\\\\_dsn=MultiHostUrl('postgres://postgres@localhost:5432/kwargs\\\\\\\\\\\\\\_db') By flipping env\\\\\\\\\\\\\\_settings and init\\\\\\\\\\\\\\_settings, environment variables now have precedence over \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ kwargs. Adding sources¶ As explained earlier, pydantic ships with multiples built-in settings sources. However, you may occasionally need to add your own custom sources, settings\\\\\\\\\\\\\\_customise\\\\\\\\\\\\\\_sources makes this very easy: import json from pathlib import Path from typing import Any, Dict, Tuple, Type from pydantic.fields import FieldInfo from pydantic\\\\\\\\\\\\\\_settings import ( BaseSettings, PydanticBaseSettingsSource, SettingsConfigDict, ) class JsonConfigSettingsSource(PydanticBaseSettingsSource): \"\"\" A simple settings source class that loads variables from a JSON file at the project's root. Here we happen to choose to use the \\\\\\\\\\\\\\`env\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_encoding\\\\\\\\\\\\\\` from Config when reading \\\\\\\\\\\\\\`config.json\\\\\\\\\\\\\\` \"\"\" def get\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value( self, field: FieldInfo, field\\\\\\\\\\\\\\_name: str ) -> Tuple\\\\\\\\\\\\\\[Any, str, bool\\\\\\\\\\\\\\]: encoding = self.config.get('env\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_encoding') file\\\\\\\\\\\\\\_content\\\\\\\\\\\\\\_json = json.loads( Path('tests/example\\\\\\\\\\\\\\_test\\\\\\\\\\\\\\_config.json').read\\\\\\\\\\\\\\_text(encoding) ) field\\\\\\\\\\\\\\_value = file\\\\\\\\\\\\\\_content\\\\\\\\\\\\\\_json.get(field\\\\\\\\\\\\\\_name) return field\\\\\\\\\\\\\\_value, field\\\\\\\\\\\\\\_name, False def prepare\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value( self, field\\\\\\\\\\\\\\_name: str, field: FieldInfo, value: Any, value\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_complex: bool ) -> Any: return value def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_call\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self) -> Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\]: d: Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] = {} for field\\\\\\\\\\\\\\_name, field in self.settings\\\\\\\\\\\\\\_cls.model\\\\\\\\\\\\\\_fields.items(): field\\\\\\\\\\\\\\_value, field\\\\\\\\\\\\\\_key, value\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_complex = self.get\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value( field, field\\\\\\\\\\\\\\_name ) field\\\\\\\\\\\\\\_value = self.prepare\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_value( field\\\\\\\\\\\\\\_name, field, field\\\\\\\\\\\\\\_value, value\\\\\\\\\\\\\\_is\\\\\\\\\\\\\\_complex ) if field\\\\\\\\\\\\\\_value is not None: d\\\\\\\\\\\\\\[field\\\\\\\\\\\\\\_key\\\\\\\\\\\\\\] = field\\\\\\\\\\\\\\_value return d class Settings(BaseSettings): model\\\\\\\\\\\\\\_config = SettingsConfigDict(env\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_encoding='utf-8') foobar: str @classmethod def settings\\\\\\\\\\\\\\_customise\\\\\\\\\\\\\\_sources( cls, settings\\\\\\\\\\\\\\_cls: Type\\\\\\\\\\\\\\[BaseSettings\\\\\\\\\\\\\\], init\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, env\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, dotenv\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, file\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, ) -> Tuple\\\\\\\\\\\\\\[PydanticBaseSettingsSource, ...\\\\\\\\\\\\\\]: return ( init\\\\\\\\\\\\\\_settings, JsonConfigSettingsSource(settings\\\\\\\\\\\\\\_cls), env\\\\\\\\\\\\\\_settings, file\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_settings, ) print(Settings()) #> foobar='test' Removing sources¶ You might also want to disable a source: from typing import Tuple, Type from pydantic import ValidationError from pydantic\\\\\\\\\\\\\\_settings import BaseSettings, PydanticBaseSettingsSource class Settings(BaseSettings): my\\\\\\\\\\\\\\_api\\\\\\\\\\\\\\_key: str @classmethod def settings\\\\\\\\\\\\\\_customise\\\\\\\\\\\\\\_sources( cls, settings\\\\\\\\\\\\\\_cls: Type\\\\\\\\\\\\\\[BaseSettings\\\\\\\\\\\\\\], init\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, env\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, dotenv\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, file\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_settings: PydanticBaseSettingsSource, ) -> Tuple\\\\\\\\\\\\\\[PydanticBaseSettingsSource, ...\\\\\\\\\\\\\\]: # here we choose to ignore arguments from init\\\\\\\\\\\\\\_settings return env\\\\\\\\\\\\\\_settings, file\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_settings try: Settings(my\\\\\\\\\\\\\\_api\\\\\\\\\\\\\\_key='this is ignored') except ValidationError as exc\\\\\\\\\\\\\\_info: print(exc\\\\\\\\\\\\\\_info) \"\"\" 1 validation error for Settings my\\\\\\\\\\\\\\_api\\\\\\\\\\\\\\_key Field required \\\\\\\\\\\\\\[type=missing, input\\\\\\\\\\\\\\_value={}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] For further information visit https://errors.pydantic.dev/2/v/missing \"\"\" Made with Material for MkDocs Insiders"
  },
  {
    "title": "Validation Decorator - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/validation_decorator/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Validation Decorator Initializing search pydantic/pydantic Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Argument types Function signatures Using Field to describe function arguments Usage with mypy Raw function Async functions Custom config Limitations Validation exception Coercion and strictness Performance Return value Validation Decorator API Documentation The @validate\\\\\\\\\\\\\\_call decorator allows the arguments passed to a function to be parsed and validated using the function's annotations before the function is called. While under the hood this uses the same approach of model creation and initialisation (see Validators for more details), it provides an extremely easy way to apply validation to your code with minimal boilerplate. Example of usage: from pydantic import ValidationError, validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call def repeat(s: str, count: int, \\\\\\\\\\\\\\*, separator: bytes = b'') -> bytes: b = s.encode() return separator.join(b for \\\\\\\\\\\\\\_ in range(count)) a = repeat('hello', 3) print(a) #> b'hellohellohello' b = repeat('x', '4', separator=b' ') print(b) #> b'x x x x' try: c = repeat('hello', 'wrong') except ValidationError as exc: print(exc) \"\"\" 1 validation error for repeat 1 Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='wrong', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Argument types¶ Argument types are inferred from type annotations on the function, arguments without a type decorator are considered as Any. All types listed in types can be validated, including Pydantic models and custom types. As with the rest of Pydantic, types can be coerced by the decorator before they're passed to the actual function: # TODO replace find\\\\\\\\\\\\\\_file with something that isn't affected the filesystem import os from pathlib import Path from typing import Optional, Pattern from pydantic import DirectoryPath, validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call def find\\\\\\\\\\\\\\_file(path: DirectoryPath, regex: Pattern, max=None) -> Optional\\\\\\\\\\\\\\[Path\\\\\\\\\\\\\\]: for i, f in enumerate(path.glob('\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*/\\\\\\\\\\\\\\*')): if max and i > max: return if f.is\\\\\\\\\\\\\\_file() and regex.fullmatch(str(f.relative\\\\\\\\\\\\\\_to(path))): return f # note: this\\\\\\\\\\\\\\_dir is a string here this\\\\\\\\\\\\\\_dir = os.path.dirname(\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_) print(find\\\\\\\\\\\\\\_file(this\\\\\\\\\\\\\\_dir, '^validation.\\\\\\\\\\\\\\*')) print(find\\\\\\\\\\\\\\_file(this\\\\\\\\\\\\\\_dir, '^foobar.\\\\\\\\\\\\\\*', max=3)) A few notes: Though they're passed as strings, path and regex are converted to a Path object and regex respectively by the decorator. max has no type annotation, so will be considered as Any by the decorator. Type coercion like this can be extremely helpful, but also confusing or not desired. See Coercion and strictness for a discussion of @validate\\\\\\\\\\\\\\_call's limitations in this regard. Function signatures¶ The @validate\\\\\\\\\\\\\\_call decorator is designed to work with functions using all possible parameter configurations and all possible combinations of these: Positional or keyword arguments with or without defaults. Variable positional arguments defined via \\\\\\\\\\\\\\* (often \\\\\\\\\\\\\\*args). Variable keyword arguments defined via \\\\\\\\\\\\\\*\\\\\\\\\\\\\\* (often \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*kwargs). Keyword-only arguments: arguments after \\\\\\\\\\\\\\*,. Positional-only arguments: arguments before , / (new in Python 3.8). To demonstrate all the above parameter types: from pydantic import validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call def pos\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_kw(a: int, b: int = 2) -> str: return f'a={a} b={b}' print(pos\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_kw(1)) #> a=1 b=2 print(pos\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_kw(a=1)) #> a=1 b=2 print(pos\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_kw(1, 3)) #> a=1 b=3 print(pos\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_kw(a=1, b=3)) #> a=1 b=3 @validate\\\\\\\\\\\\\\_call def kw\\\\\\\\\\\\\\_only(\\\\\\\\\\\\\\*, a: int, b: int = 2) -> str: return f'a={a} b={b}' print(kw\\\\\\\\\\\\\\_only(a=1)) #> a=1 b=2 print(kw\\\\\\\\\\\\\\_only(a=1, b=3)) #> a=1 b=3 @validate\\\\\\\\\\\\\\_call def pos\\\\\\\\\\\\\\_only(a: int, b: int = 2, /) -> str: # python 3.8 only return f'a={a} b={b}' print(pos\\\\\\\\\\\\\\_only(1)) #> a=1 b=2 print(pos\\\\\\\\\\\\\\_only(1, 2)) #> a=1 b=2 @validate\\\\\\\\\\\\\\_call def var\\\\\\\\\\\\\\_args(\\\\\\\\\\\\\\*args: int) -> str: return str(args) print(var\\\\\\\\\\\\\\_args(1)) #> (1,) print(var\\\\\\\\\\\\\\_args(1, 2)) #> (1, 2) print(var\\\\\\\\\\\\\\_args(1, 2, 3)) #> (1, 2, 3) @validate\\\\\\\\\\\\\\_call def var\\\\\\\\\\\\\\_kwargs(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*kwargs: int) -> str: return str(kwargs) print(var\\\\\\\\\\\\\\_kwargs(a=1)) #> {'a': 1} print(var\\\\\\\\\\\\\\_kwargs(a=1, b=2)) #> {'a': 1, 'b': 2} @validate\\\\\\\\\\\\\\_call def armageddon( a: int, /, # python 3.8 only b: int, \\\\\\\\\\\\\\*c: int, d: int, e: int = None, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*f: int, ) -> str: return f'a={a} b={b} c={c} d={d} e={e} f={f}' print(armageddon(1, 2, d=3)) #> a=1 b=2 c=() d=3 e=None f={} print(armageddon(1, 2, 3, 4, 5, 6, d=8, e=9, f=10, spam=11)) #> a=1 b=2 c=(3, 4, 5, 6) d=8 e=9 f={'f': 10, 'spam': 11} Using Field to describe function arguments¶ Field can also be used with @validate\\\\\\\\\\\\\\_call to provide extra information about the field and validations. In general it should be used in a type hint with Annotated, unless default\\\\\\\\\\\\\\_factory is specified, in which case it should be used as the default value of the field: from datetime import datetime from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import Field, ValidationError, validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call def how\\\\\\\\\\\\\\_many(num: Annotated\\\\\\\\\\\\\\[int, Field(gt=10)\\\\\\\\\\\\\\]): return num try: how\\\\\\\\\\\\\\_many(1) except ValidationError as e: print(e) \"\"\" 1 validation error for how\\\\\\\\\\\\\\_many 0 Input should be greater than 10 \\\\\\\\\\\\\\[type=greater\\\\\\\\\\\\\\_than, input\\\\\\\\\\\\\\_value=1, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] \"\"\" @validate\\\\\\\\\\\\\\_call def when(dt: datetime = Field(default\\\\\\\\\\\\\\_factory=datetime.now)): return dt print(type(when())) #> The alias can be used with the decorator as normal. from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import Field, validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call def how\\\\\\\\\\\\\\_many(num: Annotated\\\\\\\\\\\\\\[int, Field(gt=10, alias='number')\\\\\\\\\\\\\\]): return num how\\\\\\\\\\\\\\_many(number=42) Usage with mypy¶ The validate\\\\\\\\\\\\\\_call decorator should work \"out of the box\" with mypy since it's defined to return a function with the same signature as the function it decorates. The only limitation is that since we trick mypy into thinking the function returned by the decorator is the same as the function being decorated; access to the raw function or other attributes will require type: ignore. Raw function¶ The raw function which was decorated is accessible, this is useful if in some scenarios you trust your input arguments and want to call the function in the most performant way (see notes on performance below): from pydantic import validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call def repeat(s: str, count: int, \\\\\\\\\\\\\\*, separator: bytes = b'') -> bytes: b = s.encode() return separator.join(b for \\\\\\\\\\\\\\_ in range(count)) a = repeat('hello', 3) print(a) #> b'hellohellohello' b = repeat.raw\\\\\\\\\\\\\\_function('good bye', 2, separator=b', ') print(b) #> b'good bye, good bye' Async functions¶ @validate\\\\\\\\\\\\\\_call can also be used on async functions: class Connection: async def execute(self, sql, \\\\\\\\\\\\\\*args): return 'testing@example.com' conn = Connection() # ignore-above import asyncio from pydantic import PositiveInt, ValidationError, validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call async def get\\\\\\\\\\\\\\_user\\\\\\\\\\\\\\_email(user\\\\\\\\\\\\\\_id: PositiveInt): # \\\\\\\\\\\\\\`conn\\\\\\\\\\\\\\` is some fictional connection to a database email = await conn.execute('select email from users where id=$1', user\\\\\\\\\\\\\\_id) if email is None: raise RuntimeError('user not found') else: return email async def main(): email = await get\\\\\\\\\\\\\\_user\\\\\\\\\\\\\\_email(123) print(email) #> testing@example.com try: await get\\\\\\\\\\\\\\_user\\\\\\\\\\\\\\_email(-4) except ValidationError as exc: print(exc.errors()) \"\"\" \\\\\\\\\\\\\\[ { 'type': 'greater\\\\\\\\\\\\\\_than', 'loc': (0,), 'msg': 'Input should be greater than 0', 'input': -4, 'ctx': {'gt': 0}, 'url': 'https://errors.pydantic.dev/2/v/greater\\\\\\\\\\\\\\_than', } \\\\\\\\\\\\\\] \"\"\" asyncio.run(main()) # requires: \\\\\\\\\\\\\\`conn.execute()\\\\\\\\\\\\\\` that will return \\\\\\\\\\\\\\`'testing@example.com'\\\\\\\\\\\\\\` Custom config¶ The model behind @validate\\\\\\\\\\\\\\_call can be customised using a config setting, which is equivalent to setting the ConfigDict sub-class in normal models. Configuration is set using the config keyword argument to the decorator, it may be either a config class or a dict of properties which are converted to a class later. from pydantic import ValidationError, validate\\\\\\\\\\\\\\_call class Foobar: def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, v: str): self.v = v def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_add\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, other: 'Foobar') -> str: return f'{self} + {other}' def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_str\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self) -> str: return f'Foobar({self.v})' @validate\\\\\\\\\\\\\\_call(config=dict(arbitrary\\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_allowed=True)) def add\\\\\\\\\\\\\\_foobars(a: Foobar, b: Foobar): return a + b c = add\\\\\\\\\\\\\\_foobars(Foobar('a'), Foobar('b')) print(c) #> Foobar(a) + Foobar(b) try: add\\\\\\\\\\\\\\_foobars(1, 2) except ValidationError as e: print(e) \"\"\" 2 validation errors for add\\\\\\\\\\\\\\_foobars 0 Input should be an instance of Foobar \\\\\\\\\\\\\\[type=is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_of, input\\\\\\\\\\\\\\_value=1, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] 1 Input should be an instance of Foobar \\\\\\\\\\\\\\[type=is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_of, input\\\\\\\\\\\\\\_value=2, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] \"\"\" Limitations¶ Validation exception¶ Currently upon validation failure, a standard Pydantic ValidationError is raised. See model error handling for details. This is helpful since its str() method provides useful details of the error which occurred and methods like .errors() and .json() can be useful when exposing the errors to end users. However, ValidationError inherits from ValueError not TypeError, which may be unexpected since Python would raise a TypeError upon invalid or missing arguments. This may be addressed in future by either allowing a custom error or raising a different exception by default, or both. Coercion and strictness¶ Pydantic currently leans on the side of trying to coerce types rather than raise an error if a type is wrong, see model data conversion and @validate\\\\\\\\\\\\\\_call is no different. Performance¶ We've made a big effort to make Pydantic as performant as possible and argument inspect and model creation is only performed once when the function is defined, however there will still be a performance impact to using the @validate\\\\\\\\\\\\\\_call decorator compared to calling the raw function. In many situations this will have little or no noticeable effect, however be aware that @validate\\\\\\\\\\\\\\_call is not an equivalent or alternative to function definitions in strongly typed languages; it never will be. Return value¶ The return value of the function may optionally be validated against its return type annotation. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Type Adapter - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/type_adapter/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Type Adapter Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Parsing data into a specified type Type Adapter You may have types that are not BaseModels that you want to validate data against. Or you may want to validate a List\\\\\\\\\\\\\\[SomeModel\\\\\\\\\\\\\\], or dump it to JSON. API Documentation For use cases like this, Pydantic provides TypeAdapter, which can be used for type validation, serialization, and JSON schema generation without needing to create a BaseModel. A TypeAdapter instance exposes some of the functionality from BaseModel instance methods for types that do not have such methods (such as dataclasses, primitive types, and more): from typing import List from typing\\\\\\\\\\\\\\_extensions import TypedDict from pydantic import TypeAdapter, ValidationError class User(TypedDict): name: str id: int UserListAdapter = TypeAdapter(List\\\\\\\\\\\\\\[User\\\\\\\\\\\\\\]) print(repr(UserListAdapter.validate\\\\\\\\\\\\\\_python(\\\\\\\\\\\\\\[{'name': 'Fred', 'id': '3'}\\\\\\\\\\\\\\]))) #> \\\\\\\\\\\\\\[{'name': 'Fred', 'id': 3}\\\\\\\\\\\\\\] try: UserListAdapter.validate\\\\\\\\\\\\\\_python( \\\\\\\\\\\\\\[{'name': 'Fred', 'id': 'wrong', 'other': 'no'}\\\\\\\\\\\\\\] ) except ValidationError as e: print(e) \"\"\" 1 validation error for list\\\\\\\\\\\\\\[typed-dict\\\\\\\\\\\\\\] 0.id Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='wrong', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Note Despite some overlap in use cases with RootModel, TypeAdapter should not be used as a type annotation for specifying fields of a BaseModel, etc. Parsing data into a specified type¶ TypeAdapter can be used to apply the parsing logic to populate Pydantic models in a more ad-hoc way. This function behaves similarly to BaseModel.model\\\\\\\\\\\\\\_validate, but works with arbitrary Pydantic-compatible types. This is especially useful when you want to parse results into a type that is not a direct subclass of BaseModel. For example: from typing import List from pydantic import BaseModel, TypeAdapter class Item(BaseModel): id: int name: str # \\\\\\\\\\\\\\`item\\\\\\\\\\\\\\_data\\\\\\\\\\\\\\` could come from an API call, eg., via something like: # item\\\\\\\\\\\\\\_data = requests.get('https://my-api.com/items').json() item\\\\\\\\\\\\\\_data = \\\\\\\\\\\\\\[{'id': 1, 'name': 'My Item'}\\\\\\\\\\\\\\] items = TypeAdapter(List\\\\\\\\\\\\\\[Item\\\\\\\\\\\\\\]).validate\\\\\\\\\\\\\\_python(item\\\\\\\\\\\\\\_data) print(items) #> \\\\\\\\\\\\\\[Item(id=1, name='My Item')\\\\\\\\\\\\\\] TypeAdapter is capable of parsing data into any of the types Pydantic can handle as fields of a BaseModel. Performance considerations When creating an instance of TypeAdapter, the provided type must be analyzed and converted into a pydantic-core schema. This comes with some non-trivial overhead, so it is recommended to create a TypeAdapter for a given type just once and reuse it in loops or other performance-critical code. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Strict Mode - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/strict_mode/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Strict Mode Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Type coercions in strict mode Strict mode in method calls Strict mode with Field Using Field as an annotation Strict mode with Annotated\\\\\\\\\\\\\\[..., Strict()\\\\\\\\\\\\\\] Strict mode with ConfigDict BaseModel Dataclasses and TypedDict TypeAdapter @validate\\\\\\\\\\\\\\_call Strict Mode API Documentation By default, Pydantic will attempt to coerce values to the desired type when possible. For example, you can pass the string \"123\" as the input to an int field, and it will be converted to 123. This coercion behavior is useful in many scenarios — think: UUIDs, URL parameters, HTTP headers, environment variables, user input, etc. However, there are also situations where this is not desirable, and you want Pydantic to error instead of coercing data. To better support this use case, Pydantic provides a \"strict mode\" that can be enabled on a per-model, per-field, or even per-validation-call basis. When strict mode is enabled, Pydantic will be much less lenient when coercing data, and will instead error if the data is not of the correct type. Here is a brief example showing the difference between validation behavior in strict and the default/\"lax\" mode: from pydantic import BaseModel, ValidationError class MyModel(BaseModel): x: int print(MyModel.model\\\\\\\\\\\\\\_validate({'x': '123'})) # lax mode #> x=123 try: MyModel.model\\\\\\\\\\\\\\_validate({'x': '123'}, strict=True) # strict mode except ValidationError as exc: print(exc) \"\"\" 1 validation error for MyModel x Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='123', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" There are various ways to get strict-mode validation while using Pydantic, which will be discussed in more detail below: \\\\\\\\\\\\\\* Passing strict=True to the validation methods, such as BaseModel.model\\\\\\\\\\\\\\_validate, TypeAdapter.validate\\\\\\\\\\\\\\_python, and similar for JSON \\\\\\\\\\\\\\* Using Field(strict=True) with fields of a BaseModel, dataclass, or TypedDict \\\\\\\\\\\\\\* Using pydantic.types.Strict as a type annotation on a field \\\\\\\\\\\\\\* Pydantic provides some type aliases that are already annotated with Strict, such as pydantic.types.StrictInt \\\\\\\\\\\\\\* Using ConfigDict(strict=True) Type coercions in strict mode¶ For most types, when validating data from python in strict mode, only the instances of the exact types are accepted. For example, when validating an int field, only instances of int are accepted; passing instances of float or str will result in raising a ValidationError. Note that we are looser when validating data from JSON in strict mode. For example, when validating a UUID field, instances of str will be accepted when validating from JSON, but not from python: import json from uuid import UUID from pydantic import BaseModel, ValidationError class MyModel(BaseModel): guid: UUID data = {'guid': '12345678-1234-1234-1234-123456789012'} print(MyModel.model\\\\\\\\\\\\\\_validate(data)) # OK: lax #> guid=UUID('12345678-1234-1234-1234-123456789012') print( MyModel.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json(json.dumps(data), strict=True) ) # OK: strict, but from json #> guid=UUID('12345678-1234-1234-1234-123456789012') try: MyModel.model\\\\\\\\\\\\\\_validate(data, strict=True) # Not OK: strict, from python except ValidationError as exc: print(exc.errors(include\\\\\\\\\\\\\\_url=False)) \"\"\" \\\\\\\\\\\\\\[ { 'type': 'is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_of', 'loc': ('guid',), 'msg': 'Input should be an instance of UUID', 'input': '12345678-1234-1234-1234-123456789012', 'ctx': {'class': 'UUID'}, } \\\\\\\\\\\\\\] \"\"\" For more details about what types are allowed as inputs in strict mode, you can review the Conversion Table. Strict mode in method calls¶ All the examples included so far get strict-mode validation through the use of strict=True as a keyword argument to the validation methods. While we have shown this for BaseModel.model\\\\\\\\\\\\\\_validate, this also works with arbitrary types through the use of TypeAdapter: from pydantic import TypeAdapter, ValidationError print(TypeAdapter(bool).validate\\\\\\\\\\\\\\_python('yes')) # OK: lax #> True try: TypeAdapter(bool).validate\\\\\\\\\\\\\\_python('yes', strict=True) # Not OK: strict except ValidationError as exc: print(exc) \"\"\" 1 validation error for bool Input should be a valid boolean \\\\\\\\\\\\\\[type=bool\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='yes', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Note this also works even when using more \"complex\" types in TypeAdapter: from dataclasses import dataclass from pydantic import TypeAdapter, ValidationError @dataclass class MyDataclass: x: int try: TypeAdapter(MyDataclass).validate\\\\\\\\\\\\\\_python({'x': '123'}, strict=True) except ValidationError as exc: print(exc) \"\"\" 1 validation error for MyDataclass Input should be an instance of MyDataclass \\\\\\\\\\\\\\[type=dataclass\\\\\\\\\\\\\\_exact\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value={'x': '123'}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] \"\"\" This also works with the TypeAdapter.validate\\\\\\\\\\\\\\_json and BaseModel.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json methods: import json from typing import List from uuid import UUID from pydantic import BaseModel, TypeAdapter, ValidationError try: TypeAdapter(List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]).validate\\\\\\\\\\\\\\_json('\\\\\\\\\\\\\\[\"1\", 2, \"3\"\\\\\\\\\\\\\\]', strict=True) except ValidationError as exc: print(exc) \"\"\" 2 validation errors for list\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] 0 Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='1', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] 2 Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='3', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" class Model(BaseModel): x: int y: UUID data = {'x': '1', 'y': '12345678-1234-1234-1234-123456789012'} try: Model.model\\\\\\\\\\\\\\_validate(data, strict=True) except ValidationError as exc: # Neither x nor y are valid in strict mode from python: print(exc) \"\"\" 2 validation errors for Model x Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='1', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] y Input should be an instance of UUID \\\\\\\\\\\\\\[type=is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_of, input\\\\\\\\\\\\\\_value='12345678-1234-1234-1234-123456789012', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" json\\\\\\\\\\\\\\_data = json.dumps(data) try: Model.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json(json\\\\\\\\\\\\\\_data, strict=True) except ValidationError as exc: # From JSON, x is still not valid in strict mode, but y is: print(exc) \"\"\" 1 validation error for Model x Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='1', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Strict mode with Field¶ For individual fields on a model, you can set strict=True on the field. This will cause strict-mode validation to be used for that field, even when the validation methods are called without strict=True. Only the fields for which strict=True is set will be affected: from pydantic import BaseModel, Field, ValidationError class User(BaseModel): name: str age: int n\\\\\\\\\\\\\\_pets: int user = User(name='John', age='42', n\\\\\\\\\\\\\\_pets='1') print(user) #> name='John' age=42 n\\\\\\\\\\\\\\_pets=1 class AnotherUser(BaseModel): name: str age: int = Field(strict=True) n\\\\\\\\\\\\\\_pets: int try: anotheruser = AnotherUser(name='John', age='42', n\\\\\\\\\\\\\\_pets='1') except ValidationError as e: print(e) \"\"\" 1 validation error for AnotherUser age Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='42', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Note that making fields strict will also affect the validation performed when instantiating the model class: from pydantic import BaseModel, Field, ValidationError class Model(BaseModel): x: int = Field(strict=True) y: int = Field(strict=False) try: Model(x='1', y='2') except ValidationError as exc: print(exc) \"\"\" 1 validation error for Model x Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='1', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Using Field as an annotation¶ Note that Field(strict=True) (or with any other keyword arguments) can be used as an annotation if necessary, e.g., when working with TypedDict: from typing\\\\\\\\\\\\\\_extensions import Annotated, TypedDict from pydantic import Field, TypeAdapter, ValidationError class MyDict(TypedDict): x: Annotated\\\\\\\\\\\\\\[int, Field(strict=True)\\\\\\\\\\\\\\] try: TypeAdapter(MyDict).validate\\\\\\\\\\\\\\_python({'x': '1'}) except ValidationError as exc: print(exc) \"\"\" 1 validation error for typed-dict x Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='1', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Strict mode with Annotated\\\\\\\\\\\\\\[..., Strict()\\\\\\\\\\\\\\]¶ API Documentation Pydantic also provides the Strict class, which is intended for use as metadata with typing.Annotated class; this annotation indicates that the annotated field should be validated in strict mode: from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, Strict, ValidationError class User(BaseModel): name: str age: int is\\\\\\\\\\\\\\_active: Annotated\\\\\\\\\\\\\\[bool, Strict()\\\\\\\\\\\\\\] User(name='David', age=33, is\\\\\\\\\\\\\\_active=True) try: User(name='David', age=33, is\\\\\\\\\\\\\\_active='True') except ValidationError as exc: print(exc) \"\"\" 1 validation error for User is\\\\\\\\\\\\\\_active Input should be a valid boolean \\\\\\\\\\\\\\[type=bool\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='True', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" This is, in fact, the method used to implement some of the strict-out-of-the-box types provided by Pydantic, such as StrictInt. Strict mode with ConfigDict¶ BaseModel¶ If you want to enable strict mode for all fields on a complex input type, you can use ConfigDict(strict=True) in the model\\\\\\\\\\\\\\_config: from pydantic import BaseModel, ConfigDict, ValidationError class User(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(strict=True) name: str age: int is\\\\\\\\\\\\\\_active: bool try: User(name='David', age='33', is\\\\\\\\\\\\\\_active='yes') except ValidationError as exc: print(exc) \"\"\" 2 validation errors for User age Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='33', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] is\\\\\\\\\\\\\\_active Input should be a valid boolean \\\\\\\\\\\\\\[type=bool\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='yes', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Note When using strict=True through a model's model\\\\\\\\\\\\\\_config, you can still override the strictness of individual fields by setting strict=False on individual fields: from pydantic import BaseModel, ConfigDict, Field class User(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(strict=True) name: str age: int = Field(strict=False) Note that strict mode is not recursively applied to nested model fields: from pydantic import BaseModel, ConfigDict, ValidationError class Inner(BaseModel): y: int class Outer(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(strict=True) x: int inner: Inner print(Outer(x=1, inner=Inner(y='2'))) #> x=1 inner=Inner(y=2) try: Outer(x='1', inner=Inner(y='2')) except ValidationError as exc: print(exc) \"\"\" 1 validation error for Outer x Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='1', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" (This is also the case for dataclasses and TypedDict.) If this is undesirable, you should make sure that strict mode is enabled for all the types involved. For example, this can be done for model classes by using a shared base class with model\\\\\\\\\\\\\\_config = ConfigDict(strict=True): from pydantic import BaseModel, ConfigDict, ValidationError class MyBaseModel(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(strict=True) class Inner(MyBaseModel): y: int class Outer(MyBaseModel): x: int inner: Inner try: Outer.model\\\\\\\\\\\\\\_validate({'x': 1, 'inner': {'y': '2'}}) except ValidationError as exc: print(exc) \"\"\" 1 validation error for Outer inner.y Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='2', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Dataclasses and TypedDict¶ Pydantic dataclasses behave similarly to the examples shown above with BaseModel, just that instead of model\\\\\\\\\\\\\\_config you should use the config keyword argument to the @pydantic.dataclasses.dataclass decorator. When possible, you can achieve nested strict mode for vanilla dataclasses or TypedDict subclasses by annotating fields with the pydantic.types.Strict annotation. However, if this is not possible (e.g., when working with third-party types), you can set the config that Pydantic should use for the type by setting the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ attribute on the type: from typing\\\\\\\\\\\\\\_extensions import TypedDict from pydantic import ConfigDict, TypeAdapter, ValidationError class Inner(TypedDict): y: int Inner.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ = ConfigDict(strict=True) class Outer(TypedDict): x: int inner: Inner adapter = TypeAdapter(Outer) print(adapter.validate\\\\\\\\\\\\\\_python({'x': '1', 'inner': {'y': 2}})) #> {'x': 1, 'inner': {'y': 2}} try: adapter.validate\\\\\\\\\\\\\\_python({'x': '1', 'inner': {'y': '2'}}) except ValidationError as exc: print(exc) \"\"\" 1 validation error for typed-dict inner.y Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='2', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" TypeAdapter¶ You can also get strict mode through the use of the config keyword argument to the TypeAdapter class: from pydantic import ConfigDict, TypeAdapter, ValidationError adapter = TypeAdapter(bool, config=ConfigDict(strict=True)) try: adapter.validate\\\\\\\\\\\\\\_python('yes') except ValidationError as exc: print(exc) \"\"\" 1 validation error for bool Input should be a valid boolean \\\\\\\\\\\\\\[type=bool\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='yes', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" @validate\\\\\\\\\\\\\\_call¶ Strict mode is also usable with the @validate\\\\\\\\\\\\\\_call decorator by passing the config keyword argument: from pydantic import ConfigDict, ValidationError, validate\\\\\\\\\\\\\\_call @validate\\\\\\\\\\\\\\_call(config=ConfigDict(strict=True)) def foo(x: int) -> int: return x try: foo('1') except ValidationError as exc: print(exc) \"\"\" 1 validation error for foo 0 Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='1', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Made with Material for MkDocs Insiders"
  },
  {
    "title": "Postponed Annotations - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/postponed_annotations/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Postponed Annotations Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Self-referencing (or \"Recursive\") Models Cyclic references Postponed Annotations Postponed annotations (as described in PEP563) \"just work\". from \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_future\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ import annotations from typing import Any from pydantic import BaseModel class Model(BaseModel): a: list\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] b: Any print(Model(a=('1', 2, 3), b='ok')) #> a=\\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\] b='ok' Internally, Pydantic will call a method similar to typing.get\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_hints to resolve annotations. Even without using from \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_future\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ import annotations, in cases where the referenced type is not yet defined, a ForwardRef or string can be used: from typing import ForwardRef from pydantic import BaseModel Foo = ForwardRef('Foo') class Foo(BaseModel): a: int = 123 b: Foo = None print(Foo()) #> a=123 b=None print(Foo(b={'a': '321'})) #> a=123 b=Foo(a=321, b=None) Self-referencing (or \"Recursive\") Models¶ Models with self-referencing fields are also supported. Self-referencing fields will be automatically resolved after model creation. Within the model, you can refer to the not-yet-constructed model using a string: from pydantic import BaseModel class Foo(BaseModel): a: int = 123 #: The sibling of \\\\\\\\\\\\\\`Foo\\\\\\\\\\\\\\` is referenced by string sibling: 'Foo' = None print(Foo()) #> a=123 sibling=None print(Foo(sibling={'a': '321'})) #> a=123 sibling=Foo(a=321, sibling=None) If you use from \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_future\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ import annotations, you can also just refer to the model by its type name: from \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_future\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ import annotations from pydantic import BaseModel class Foo(BaseModel): a: int = 123 #: The sibling of \\\\\\\\\\\\\\`Foo\\\\\\\\\\\\\\` is referenced directly by type sibling: Foo = None print(Foo()) #> a=123 sibling=None print(Foo(sibling={'a': '321'})) #> a=123 sibling=Foo(a=321, sibling=None) Cyclic references¶ When working with self-referencing recursive models, it is possible that you might encounter cyclic references in validation inputs. For example, this can happen when validating ORM instances with back-references from attributes. Rather than raising a Python RecursionError while attempting to validate data with cyclic references, Pydantic is able to detect the cyclic reference and raise an appropriate ValidationError: from typing import Optional from pydantic import BaseModel, ValidationError class ModelA(BaseModel): b: 'Optional\\\\\\\\\\\\\\[ModelB\\\\\\\\\\\\\\]' = None class ModelB(BaseModel): a: Optional\\\\\\\\\\\\\\[ModelA\\\\\\\\\\\\\\] = None cyclic\\\\\\\\\\\\\\_data = {} cyclic\\\\\\\\\\\\\\_data\\\\\\\\\\\\\\['a'\\\\\\\\\\\\\\] = {'b': cyclic\\\\\\\\\\\\\\_data} print(cyclic\\\\\\\\\\\\\\_data) #> {'a': {'b': {...}}} try: ModelB.model\\\\\\\\\\\\\\_validate(cyclic\\\\\\\\\\\\\\_data) except ValidationError as exc: print(exc) \"\"\" 1 validation error for ModelB a.b Recursion error - cyclic reference detected \\\\\\\\\\\\\\[type=recursion\\\\\\\\\\\\\\_loop, input\\\\\\\\\\\\\\_value={'a': {'b': {...}}}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] \"\"\" Because this error is raised without actually exceeding the maximum recursion depth, you can catch and handle the raised ValidationError without needing to worry about the limited remaining recursion depth: from contextlib import contextmanager from dataclasses import field from typing import Iterator, List from pydantic import BaseModel, ValidationError, field\\\\\\\\\\\\\\_validator def is\\\\\\\\\\\\\\_recursion\\\\\\\\\\\\\\_validation\\\\\\\\\\\\\\_error(exc: ValidationError) -> bool: errors = exc.errors() return len(errors) == 1 and errors\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\] == 'recursion\\\\\\\\\\\\\\_loop' @contextmanager def suppress\\\\\\\\\\\\\\_recursion\\\\\\\\\\\\\\_validation\\\\\\\\\\\\\\_error() -> Iterator\\\\\\\\\\\\\\[None\\\\\\\\\\\\\\]: try: yield except ValidationError as exc: if not is\\\\\\\\\\\\\\_recursion\\\\\\\\\\\\\\_validation\\\\\\\\\\\\\\_error(exc): raise exc class Node(BaseModel): id: int children: List\\\\\\\\\\\\\\['Node'\\\\\\\\\\\\\\] = field(default\\\\\\\\\\\\\\_factory=list) @field\\\\\\\\\\\\\\_validator('children', mode='wrap') @classmethod def drop\\\\\\\\\\\\\\_cyclic\\\\\\\\\\\\\\_references(cls, children, h): try: return h(children) except ValidationError as exc: if not ( is\\\\\\\\\\\\\\_recursion\\\\\\\\\\\\\\_validation\\\\\\\\\\\\\\_error(exc) and isinstance(children, list) ): raise exc value\\\\\\\\\\\\\\_without\\\\\\\\\\\\\\_cyclic\\\\\\\\\\\\\\_refs = \\\\\\\\\\\\\\[\\\\\\\\\\\\\\] for child in children: with suppress\\\\\\\\\\\\\\_recursion\\\\\\\\\\\\\\_validation\\\\\\\\\\\\\\_error(): value\\\\\\\\\\\\\\_without\\\\\\\\\\\\\\_cyclic\\\\\\\\\\\\\\_refs.extend(h(\\\\\\\\\\\\\\[child\\\\\\\\\\\\\\])) return h(value\\\\\\\\\\\\\\_without\\\\\\\\\\\\\\_cyclic\\\\\\\\\\\\\\_refs) # Create data with cyclic references representing the graph 1 -> 2 -> 3 -> 1 node\\\\\\\\\\\\\\_data = {'id': 1, 'children': \\\\\\\\\\\\\\[{'id': 2, 'children': \\\\\\\\\\\\\\[{'id': 3}\\\\\\\\\\\\\\]}\\\\\\\\\\\\\\]} node\\\\\\\\\\\\\\_data\\\\\\\\\\\\\\['children'\\\\\\\\\\\\\\]\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['children'\\\\\\\\\\\\\\]\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['children'\\\\\\\\\\\\\\] = \\\\\\\\\\\\\\[node\\\\\\\\\\\\\\_data\\\\\\\\\\\\\\] print(Node.model\\\\\\\\\\\\\\_validate(node\\\\\\\\\\\\\\_data)) #> id=1 children=\\\\\\\\\\\\\\[Node(id=2, children=\\\\\\\\\\\\\\[Node(id=3, children=\\\\\\\\\\\\\\[\\\\\\\\\\\\\\])\\\\\\\\\\\\\\])\\\\\\\\\\\\\\] Similarly, if Pydantic encounters a recursive reference during serialization, rather than waiting for the maximum recursion depth to be exceeded, a ValueError is raised immediately: from pydantic import TypeAdapter # Create data with cyclic references representing the graph 1 -> 2 -> 3 -> 1 node\\\\\\\\\\\\\\_data = {'id': 1, 'children': \\\\\\\\\\\\\\[{'id': 2, 'children': \\\\\\\\\\\\\\[{'id': 3}\\\\\\\\\\\\\\]}\\\\\\\\\\\\\\]} node\\\\\\\\\\\\\\_data\\\\\\\\\\\\\\['children'\\\\\\\\\\\\\\]\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['children'\\\\\\\\\\\\\\]\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['children'\\\\\\\\\\\\\\] = \\\\\\\\\\\\\\[node\\\\\\\\\\\\\\_data\\\\\\\\\\\\\\] try: # Try serializing the circular reference as JSON TypeAdapter(dict).dump\\\\\\\\\\\\\\_json(node\\\\\\\\\\\\\\_data) except ValueError as exc: print(exc) \"\"\" Error serializing to JSON: ValueError: Circular reference detected (id repeated) \"\"\" This can also be handled if desired: from dataclasses import field from typing import Any, List from pydantic import ( SerializerFunctionWrapHandler, TypeAdapter, field\\\\\\\\\\\\\\_serializer, ) from pydantic.dataclasses import dataclass @dataclass class NodeReference: id: int @dataclass class Node(NodeReference): children: List\\\\\\\\\\\\\\['Node'\\\\\\\\\\\\\\] = field(default\\\\\\\\\\\\\\_factory=list) @field\\\\\\\\\\\\\\_serializer('children', mode='wrap') def serialize( self, children: List\\\\\\\\\\\\\\['Node'\\\\\\\\\\\\\\], handler: SerializerFunctionWrapHandler ) -> Any: \"\"\" Serialize a list of nodes, handling circular references by excluding the children. \"\"\" try: return handler(children) except ValueError as exc: if not str(exc).startswith('Circular reference'): raise exc result = \\\\\\\\\\\\\\[\\\\\\\\\\\\\\] for node in children: try: serialized = handler(\\\\\\\\\\\\\\[node\\\\\\\\\\\\\\]) except ValueError as exc: if not str(exc).startswith('Circular reference'): raise exc result.append({'id': node.id}) else: result.append(serialized) return result # Create a cyclic graph: nodes = \\\\\\\\\\\\\\[Node(id=1), Node(id=2), Node(id=3)\\\\\\\\\\\\\\] nodes\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\].children.append(nodes\\\\\\\\\\\\\\[1\\\\\\\\\\\\\\]) nodes\\\\\\\\\\\\\\[1\\\\\\\\\\\\\\].children.append(nodes\\\\\\\\\\\\\\[2\\\\\\\\\\\\\\]) nodes\\\\\\\\\\\\\\[2\\\\\\\\\\\\\\].children.append(nodes\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]) print(nodes\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]) #> Node(id=1, children=\\\\\\\\\\\\\\[Node(id=2, children=\\\\\\\\\\\\\\[Node(id=3, children=\\\\\\\\\\\\\\[...\\\\\\\\\\\\\\])\\\\\\\\\\\\\\])\\\\\\\\\\\\\\]) # Serialize the cyclic graph: print(TypeAdapter(Node).dump\\\\\\\\\\\\\\_python(nodes\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\])) \"\"\" { 'id': 1, 'children': \\\\\\\\\\\\\\[{'id': 2, 'children': \\\\\\\\\\\\\\[{'id': 3, 'children': \\\\\\\\\\\\\\[{'id': 1}\\\\\\\\\\\\\\]}\\\\\\\\\\\\\\]}\\\\\\\\\\\\\\], } \"\"\" Made with Material for MkDocs Insiders"
  },
  {
    "title": "Dataclasses - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/dataclasses/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Dataclasses Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Dataclass config Nested dataclasses Generic dataclasses Stdlib dataclasses and Pydantic dataclasses Inherit from stdlib dataclasses Use of stdlib dataclasses with BaseModel Use custom types Checking if a dataclass is a pydantic dataclass Initialization hooks Difference with stdlib dataclasses JSON dumping Dataclasses API Documentation If you don't want to use Pydantic's BaseModel you can instead get the same data validation on standard dataclasses (introduced in Python 3.7). from datetime import datetime from pydantic.dataclasses import dataclass @dataclass class User: id: int name: str = 'John Doe' signup\\\\\\\\\\\\\\_ts: datetime = None user = User(id='42', signup\\\\\\\\\\\\\\_ts='2032-06-21T12:00') print(user) \"\"\" User(id=42, name='John Doe', signup\\\\\\\\\\\\\\_ts=datetime.datetime(2032, 6, 21, 12, 0)) \"\"\" Note Keep in mind that pydantic.dataclasses.dataclass is not a replacement for pydantic.BaseModel. pydantic.dataclasses.dataclass provides a similar functionality to dataclasses.dataclass with the addition of Pydantic validation. There are cases where subclassing pydantic.BaseModel is the better choice. For more information and discussion see pydantic/pydantic#710. Some differences between Pydantic dataclasses and BaseModel include: How initialization hooks work JSON dumping You can use all the standard Pydantic field types. Note, however, that arguments passed to constructor will be copied in order to perform validation and, where necessary coercion. To perform validation or generate a JSON schema on a Pydantic dataclass, you should now wrap the dataclass with a TypeAdapter and make use of its methods. Fields that require a default\\\\\\\\\\\\\\_factory can be specified by either a pydantic.Field or a dataclasses.field. import dataclasses from typing import List, Optional from pydantic import Field, TypeAdapter from pydantic.dataclasses import dataclass @dataclass class User: id: int name: str = 'John Doe' friends: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] = dataclasses.field(default\\\\\\\\\\\\\\_factory=lambda: \\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]) age: Optional\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] = dataclasses.field( default=None, metadata=dict(title='The age of the user', description='do not lie!'), ) height: Optional\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] = Field(None, title='The height in cm', ge=50, le=300) user = User(id='42') print(TypeAdapter(User).json\\\\\\\\\\\\\\_schema()) \"\"\" { 'properties': { 'id': {'title': 'Id', 'type': 'integer'}, 'name': {'default': 'John Doe', 'title': 'Name', 'type': 'string'}, 'friends': { 'items': {'type': 'integer'}, 'title': 'Friends', 'type': 'array', }, 'age': { 'anyOf': \\\\\\\\\\\\\\[{'type': 'integer'}, {'type': 'null'}\\\\\\\\\\\\\\], 'default': None, 'description': 'do not lie!', 'title': 'The age of the user', }, 'height': { 'anyOf': \\\\\\\\\\\\\\[ {'maximum': 300, 'minimum': 50, 'type': 'integer'}, {'type': 'null'}, \\\\\\\\\\\\\\], 'default': None, 'title': 'The height in cm', }, }, 'required': \\\\\\\\\\\\\\['id'\\\\\\\\\\\\\\], 'title': 'User', 'type': 'object', } \"\"\" pydantic.dataclasses.dataclass's arguments are the same as the standard decorator, except one extra keyword argument config which has the same meaning as model\\\\\\\\\\\\\\_config. Warning After v1.2, The Mypy plugin must be installed to type check pydantic dataclasses. For more information about combining validators with dataclasses, see dataclass validators. Dataclass config¶ If you want to modify the config like you would with a BaseModel, you have two options: Apply config to the dataclass decorator as a dict Use ConfigDict as the config from pydantic import ConfigDict from pydantic.dataclasses import dataclass # Option 1 - use directly a dict # Note: \\\\\\\\\\\\\\`mypy\\\\\\\\\\\\\\` will still raise typo error @dataclass(config=dict(validate\\\\\\\\\\\\\\_assignment=True)) You can read more about validate\\\\\\\\\\\\\\_assignment in API reference. class MyDataclass1: a: int # Option 2 - use \\\\\\\\\\\\\\`ConfigDict\\\\\\\\\\\\\\` # (same as before at runtime since it's a \\\\\\\\\\\\\\`TypedDict\\\\\\\\\\\\\\` but with intellisense) @dataclass(config=ConfigDict(validate\\\\\\\\\\\\\\_assignment=True)) class MyDataclass2: a: int Note Pydantic dataclasses support extra configuration to ignore, forbid, or allow extra fields passed to the initializer. However, some default behavior of stdlib dataclasses may prevail. For example, any extra fields present on a Pydantic dataclass using extra='allow' are omitted when the dataclass is printed. Nested dataclasses¶ Nested dataclasses are supported both in dataclasses and normal models. from pydantic import AnyUrl from pydantic.dataclasses import dataclass @dataclass class NavbarButton: href: AnyUrl @dataclass class Navbar: button: NavbarButton navbar = Navbar(button={'href': 'https://example.com'}) print(navbar) #> Navbar(button=NavbarButton(href=Url('https://example.com/'))) When used as fields, dataclasses (Pydantic or vanilla) should use dicts as validation inputs. Generic dataclasses¶ Pydantic supports generic dataclasses, including those with type variables. from typing import Generic, TypeVar from pydantic import TypeAdapter from pydantic.dataclasses import dataclass T = TypeVar('T') @dataclass class GenericDataclass(Generic\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\]): x: T validator = TypeAdapter(GenericDataclass) assert validator.validate\\\\\\\\\\\\\\_python({'x': None}).x is None assert validator.validate\\\\\\\\\\\\\\_python({'x': 1}).x == 1 assert validator.validate\\\\\\\\\\\\\\_python({'x': 'a'}).x == 'a' Note that, if you use the dataclass as a field of a BaseModel or via FastAPI you don't need a TypeAdapter. Stdlib dataclasses and Pydantic dataclasses¶ Inherit from stdlib dataclasses¶ Stdlib dataclasses (nested or not) can also be inherited and Pydantic will automatically validate all the inherited fields. import dataclasses import pydantic @dataclasses.dataclass class Z: z: int @dataclasses.dataclass class Y(Z): y: int = 0 @pydantic.dataclasses.dataclass class X(Y): x: int = 0 foo = X(x=b'1', y='2', z='3') print(foo) #> X(z=3, y=2, x=1) try: X(z='pika') except pydantic.ValidationError as e: print(e) \"\"\" 1 validation error for X z Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='pika', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Use of stdlib dataclasses with BaseModel¶ Bear in mind that stdlib dataclasses (nested or not) are automatically converted into Pydantic dataclasses when mixed with BaseModel! Furthermore the generated Pydantic dataclass will have the exact same configuration (order, frozen, ...) as the original one. import dataclasses from datetime import datetime from typing import Optional from pydantic import BaseModel, ValidationError @dataclasses.dataclass(frozen=True) class User: name: str @dataclasses.dataclass class File: filename: str last\\\\\\\\\\\\\\_modification\\\\\\\\\\\\\\_time: Optional\\\\\\\\\\\\\\[datetime\\\\\\\\\\\\\\] = None class Foo(BaseModel): file: File user: Optional\\\\\\\\\\\\\\[User\\\\\\\\\\\\\\] = None file = File( filename=\\\\\\\\\\\\\\['not', 'a', 'string'\\\\\\\\\\\\\\], last\\\\\\\\\\\\\\_modification\\\\\\\\\\\\\\_time='2020-01-01T00:00', ) # nothing is validated as expected print(file) \"\"\" File(filename=\\\\\\\\\\\\\\['not', 'a', 'string'\\\\\\\\\\\\\\], last\\\\\\\\\\\\\\_modification\\\\\\\\\\\\\\_time='2020-01-01T00:00') \"\"\" try: Foo(file=file) except ValidationError as e: print(e) \"\"\" 1 validation error for Foo file.filename Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=\\\\\\\\\\\\\\['not', 'a', 'string'\\\\\\\\\\\\\\], input\\\\\\\\\\\\\\_type=list\\\\\\\\\\\\\\] \"\"\" foo = Foo(file=File(filename='myfile'), user=User(name='pika')) try: foo.user.name = 'bulbi' except dataclasses.FrozenInstanceError as e: print(e) #> cannot assign to field 'name' Use custom types¶ Since stdlib dataclasses are automatically converted to add validation, using custom types may cause some unexpected behavior. In this case you can simply add arbitrary\\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_allowed in the config! import dataclasses from pydantic import BaseModel, ConfigDict from pydantic.errors import PydanticSchemaGenerationError class ArbitraryType: def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, value): self.value = value def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_repr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self): return f'ArbitraryType(value={self.value!r})' @dataclasses.dataclass class DC: a: ArbitraryType b: str # valid as it is a builtin dataclass without validation my\\\\\\\\\\\\\\_dc = DC(a=ArbitraryType(value=3), b='qwe') try: class Model(BaseModel): dc: DC other: str # invalid as it is now a pydantic dataclass Model(dc=my\\\\\\\\\\\\\\_dc, other='other') except PydanticSchemaGenerationError as e: print(e.message) \"\"\" Unable to generate pydantic-core schema for . Set \\\\\\\\\\\\\\`arbitrary\\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_allowed=True\\\\\\\\\\\\\\` in the model\\\\\\\\\\\\\\_config to ignore this error or implement \\\\\\\\\\\\\\`\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_\\\\\\\\\\\\\\` on your type to fully support it. If you got this error by calling handler() within \\\\\\\\\\\\\\`\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_\\\\\\\\\\\\\\` then you likely need to call \\\\\\\\\\\\\\`handler.generate\\\\\\\\\\\\\\_schema()\\\\\\\\\\\\\\` since we do not call \\\\\\\\\\\\\\`\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_\\\\\\\\\\\\\\` on \\\\\\\\\\\\\\`\\\\\\\\\\\\\\` otherwise to avoid infinite recursion. \"\"\" class Model(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(arbitrary\\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_allowed=True) dc: DC other: str m = Model(dc=my\\\\\\\\\\\\\\_dc, other='other') print(repr(m)) #> Model(dc=DC(a=ArbitraryType(value=3), b='qwe'), other='other') Checking if a dataclass is a pydantic dataclass¶ Pydantic dataclasses are still considered dataclasses, so using dataclasses.is\\\\\\\\\\\\\\_dataclass will return True. To check if a type is specifically a pydantic dataclass you can use pydantic.dataclasses.is\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_dataclass. import dataclasses import pydantic @dataclasses.dataclass class StdLibDataclass: id: int PydanticDataclass = pydantic.dataclasses.dataclass(StdLibDataclass) print(dataclasses.is\\\\\\\\\\\\\\_dataclass(StdLibDataclass)) #> True print(pydantic.dataclasses.is\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_dataclass(StdLibDataclass)) #> False print(dataclasses.is\\\\\\\\\\\\\\_dataclass(PydanticDataclass)) #> True print(pydantic.dataclasses.is\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_dataclass(PydanticDataclass)) #> True Initialization hooks¶ When you initialize a dataclass, it is possible to execute code before or after validation with the help of the @model\\\\\\\\\\\\\\_validator decorator mode parameter. from typing import Any, Dict from pydantic import model\\\\\\\\\\\\\\_validator from pydantic.dataclasses import dataclass @dataclass class Birth: year: int month: int day: int @dataclass class User: birth: Birth @model\\\\\\\\\\\\\\_validator(mode='before') def pre\\\\\\\\\\\\\\_root(cls, values: Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\]) -> Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\]: print(f'First: {values}') \"\"\" First: ArgsKwargs((), {'birth': {'year': 1995, 'month': 3, 'day': 2}}) \"\"\" return values @model\\\\\\\\\\\\\\_validator(mode='after') def post\\\\\\\\\\\\\\_root(self) -> 'User': print(f'Third: {self}') #> Third: User(birth=Birth(year=1995, month=3, day=2)) return self def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self): print(f'Second: {self.birth}') #> Second: Birth(year=1995, month=3, day=2) user = User(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*{'birth': {'year': 1995, 'month': 3, 'day': 2}}) The \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ in Pydantic dataclasses is called in the middle of validators. Here is the order: model\\\\\\\\\\\\\\_validator(mode='before') field\\\\\\\\\\\\\\_validator(mode='before') field\\\\\\\\\\\\\\_validator(mode='after') Inner validators. e.g. validation for types like int, str, ... \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. model\\\\\\\\\\\\\\_validator(mode='after') from dataclasses import InitVar from pathlib import Path from typing import Optional from pydantic.dataclasses import dataclass @dataclass class PathData: path: Path base\\\\\\\\\\\\\\_path: InitVar\\\\\\\\\\\\\\[Optional\\\\\\\\\\\\\\[Path\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, base\\\\\\\\\\\\\\_path): print(f'Received path={self.path!r}, base\\\\\\\\\\\\\\_path={base\\\\\\\\\\\\\\_path!r}') #> Received path=PosixPath('world'), base\\\\\\\\\\\\\\_path=PosixPath('/hello') if base\\\\\\\\\\\\\\_path is not None: self.path = base\\\\\\\\\\\\\\_path / self.path path\\\\\\\\\\\\\\_data = PathData('world', base\\\\\\\\\\\\\\_path='/hello') # Received path='world', base\\\\\\\\\\\\\\_path='/hello' assert path\\\\\\\\\\\\\\_data.path == Path('/hello/world') Difference with stdlib dataclasses¶ Note that the dataclasses.dataclass from Python stdlib implements only the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method since it doesn't run a validation step. JSON dumping¶ Pydantic dataclasses do not feature a .model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json() function. To dump them as JSON, you will need to make use of the RootModel as follows: import dataclasses from typing import List from pydantic import RootModel from pydantic.dataclasses import dataclass @dataclass class User: id: int name: str = 'John Doe' friends: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] = dataclasses.field(default\\\\\\\\\\\\\\_factory=lambda: \\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]) user = User(id='42') print(RootModel\\\\\\\\\\\\\\[User\\\\\\\\\\\\\\](User(id='42')).model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json(indent=4)) JSON output: { \"id\": 42, \"name\": \"John Doe\", \"friends\": \\\\\\\\\\\\\\[ 0 \\\\\\\\\\\\\\] } Made with Material for MkDocs Insiders"
  },
  {
    "title": "Validators - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/validators/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Validators Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Annotated Validators Before, After, Wrap and Plain validators Ordering of validators within Annotated Validation of default values Field validators Model validators Handling errors in validators Special Types Field checks Dataclass validators Validation Context Using validation context with BaseModel initialization Validators Annotated Validators¶ API Documentation Pydantic provides a way to apply validators via use of Annotated. You should use this whenever you want to bind validation to a type instead of model or field. from typing import Any, List from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, ValidationError from pydantic.functional\\\\\\\\\\\\\\_validators import AfterValidator def check\\\\\\\\\\\\\\_squares(v: int) -> int: assert v\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*0.5 % 1 == 0, f'{v} is not a square number' return v def double(v: Any) -> Any: return v \\\\\\\\\\\\\\* 2 MyNumber = Annotated\\\\\\\\\\\\\\[int, AfterValidator(double), AfterValidator(check\\\\\\\\\\\\\\_squares)\\\\\\\\\\\\\\] class DemoModel(BaseModel): number: List\\\\\\\\\\\\\\[MyNumber\\\\\\\\\\\\\\] print(DemoModel(number=\\\\\\\\\\\\\\[2, 8\\\\\\\\\\\\\\])) #> number=\\\\\\\\\\\\\\[4, 16\\\\\\\\\\\\\\] try: DemoModel(number=\\\\\\\\\\\\\\[2, 4\\\\\\\\\\\\\\]) except ValidationError as e: print(e) \"\"\" 1 validation error for DemoModel number.1 Assertion failed, 8 is not a square number assert ((8 \\\\\\\\\\\\\\*\\\\\\\\\\\\\\* 0.5) % 1) == 0 \\\\\\\\\\\\\\[type=assertion\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value=4, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] \"\"\" In this example we used some type aliases (MyNumber = Annotated\\\\\\\\\\\\\\[...\\\\\\\\\\\\\\]). While this can help with legibility of the code, it is not required, you can use Annotated directly in a model field type hint. These type aliases are also not actual types but you can use a similar approach with TypeAliasType to create actual types. See Custom Types for a more detailed explanation of custom types. It is also worth noting that you can nest Annotated inside other types. In this example we used that to apply validation to the inner items of a list. The same approach can be used for dict keys, etc. Before, After, Wrap and Plain validators¶ Pydantic provides multiple types of validator functions: After validators run after Pydantic's internal parsing. They are generally more type safe and thus easier to implement. Before validators run before Pydantic's internal parsing and validation (e.g. coercion of a str to an int). These are more flexible than After validators since they can modify the raw input, but they also have to deal with the raw input, which in theory could be any arbitrary object. Plain validators are like a mode='before' validator but they terminate validation immediately, no further validators are called and Pydantic does not do any of its internal validation. Wrap validators are the most flexible of all. You can run code before or after Pydantic and other validators do their thing or you can terminate validation immediately, both with a successful value or an error. You can use multiple before, after, or mode='wrap' validators, but only one PlainValidator since a plain validator will not call any inner validators. Here's an example of a mode='wrap' validator: import json from typing import Any, List from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import ( BaseModel, ValidationError, ValidationInfo, ValidatorFunctionWrapHandler, ) from pydantic.functional\\\\\\\\\\\\\\_validators import WrapValidator def maybe\\\\\\\\\\\\\\_strip\\\\\\\\\\\\\\_whitespace( v: Any, handler: ValidatorFunctionWrapHandler, info: ValidationInfo ) -> int: if info.mode == 'json': assert isinstance(v, str), 'In JSON mode the input must be a string!' # you can call the handler multiple times try: return handler(v) except ValidationError: return handler(v.strip()) assert info.mode == 'python' assert isinstance(v, int), 'In Python mode the input must be an int!' # do no further validation return v MyNumber = Annotated\\\\\\\\\\\\\\[int, WrapValidator(maybe\\\\\\\\\\\\\\_strip\\\\\\\\\\\\\\_whitespace)\\\\\\\\\\\\\\] class DemoModel(BaseModel): number: List\\\\\\\\\\\\\\[MyNumber\\\\\\\\\\\\\\] print(DemoModel(number=\\\\\\\\\\\\\\[2, 8\\\\\\\\\\\\\\])) #> number=\\\\\\\\\\\\\\[2, 8\\\\\\\\\\\\\\] print(DemoModel.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json(json.dumps({'number': \\\\\\\\\\\\\\[' 2 ', '8'\\\\\\\\\\\\\\]}))) #> number=\\\\\\\\\\\\\\[2, 8\\\\\\\\\\\\\\] try: DemoModel(number=\\\\\\\\\\\\\\['2'\\\\\\\\\\\\\\]) except ValidationError as e: print(e) \"\"\" 1 validation error for DemoModel number.0 Assertion failed, In Python mode the input must be an int! assert False + where False = isinstance('2', int) \\\\\\\\\\\\\\[type=assertion\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='2', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" The same \"modes\" apply to @field\\\\\\\\\\\\\\_validator, which is discussed in the next section. Ordering of validators within Annotated¶ Order of validation metadata within Annotated matters. Validation goes from right to left and back. That is, it goes from right to left running all \"before\" validators (or calling into \"wrap\" validators), then left to right back out calling all \"after\" validators. from typing import Any, Callable, List, cast from typing\\\\\\\\\\\\\\_extensions import Annotated, TypedDict from pydantic import ( AfterValidator, BaseModel, BeforeValidator, PlainValidator, ValidationInfo, ValidatorFunctionWrapHandler, WrapValidator, ) from pydantic.functional\\\\\\\\\\\\\\_validators import field\\\\\\\\\\\\\\_validator class Context(TypedDict): logs: List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] def make\\\\\\\\\\\\\\_validator(label: str) -> Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[str, ValidationInfo\\\\\\\\\\\\\\], str\\\\\\\\\\\\\\]: def validator(v: Any, info: ValidationInfo) -> Any: context = cast(Context, info.context) context\\\\\\\\\\\\\\['logs'\\\\\\\\\\\\\\].append(label) return v return validator def make\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator( label: str, ) -> Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[str, ValidatorFunctionWrapHandler, ValidationInfo\\\\\\\\\\\\\\], str\\\\\\\\\\\\\\]: def validator( v: Any, handler: ValidatorFunctionWrapHandler, info: ValidationInfo ) -> Any: context = cast(Context, info.context) context\\\\\\\\\\\\\\['logs'\\\\\\\\\\\\\\].append(f'{label}: pre') result = handler(v) context\\\\\\\\\\\\\\['logs'\\\\\\\\\\\\\\].append(f'{label}: post') return result return validator class A(BaseModel): x: Annotated\\\\\\\\\\\\\\[ str, BeforeValidator(make\\\\\\\\\\\\\\_validator('before-1')), AfterValidator(make\\\\\\\\\\\\\\_validator('after-1')), WrapValidator(make\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator('wrap-1')), BeforeValidator(make\\\\\\\\\\\\\\_validator('before-2')), AfterValidator(make\\\\\\\\\\\\\\_validator('after-2')), WrapValidator(make\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator('wrap-2')), BeforeValidator(make\\\\\\\\\\\\\\_validator('before-3')), AfterValidator(make\\\\\\\\\\\\\\_validator('after-3')), WrapValidator(make\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator('wrap-3')), BeforeValidator(make\\\\\\\\\\\\\\_validator('before-4')), AfterValidator(make\\\\\\\\\\\\\\_validator('after-4')), WrapValidator(make\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator('wrap-4')), \\\\\\\\\\\\\\] y: Annotated\\\\\\\\\\\\\\[ str, BeforeValidator(make\\\\\\\\\\\\\\_validator('before-1')), AfterValidator(make\\\\\\\\\\\\\\_validator('after-1')), WrapValidator(make\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator('wrap-1')), BeforeValidator(make\\\\\\\\\\\\\\_validator('before-2')), AfterValidator(make\\\\\\\\\\\\\\_validator('after-2')), WrapValidator(make\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator('wrap-2')), PlainValidator(make\\\\\\\\\\\\\\_validator('plain')), BeforeValidator(make\\\\\\\\\\\\\\_validator('before-3')), AfterValidator(make\\\\\\\\\\\\\\_validator('after-3')), WrapValidator(make\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator('wrap-3')), BeforeValidator(make\\\\\\\\\\\\\\_validator('before-4')), AfterValidator(make\\\\\\\\\\\\\\_validator('after-4')), WrapValidator(make\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator('wrap-4')), \\\\\\\\\\\\\\] val\\\\\\\\\\\\\\_x\\\\\\\\\\\\\\_before = field\\\\\\\\\\\\\\_validator('x', mode='before')( make\\\\\\\\\\\\\\_validator('val\\\\\\\\\\\\\\_x before') ) val\\\\\\\\\\\\\\_x\\\\\\\\\\\\\\_after = field\\\\\\\\\\\\\\_validator('x', mode='after')( make\\\\\\\\\\\\\\_validator('val\\\\\\\\\\\\\\_x after') ) val\\\\\\\\\\\\\\_y\\\\\\\\\\\\\\_wrap = field\\\\\\\\\\\\\\_validator('y', mode='wrap')( make\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator('val\\\\\\\\\\\\\\_y wrap') ) context = Context(logs=\\\\\\\\\\\\\\[\\\\\\\\\\\\\\]) A.model\\\\\\\\\\\\\\_validate({'x': 'abc', 'y': 'def'}, context=context) print(context\\\\\\\\\\\\\\['logs'\\\\\\\\\\\\\\]) \"\"\" \\\\\\\\\\\\\\[ 'val\\\\\\\\\\\\\\_x before', 'wrap-4: pre', 'before-4', 'wrap-3: pre', 'before-3', 'wrap-2: pre', 'before-2', 'wrap-1: pre', 'before-1', 'after-1', 'wrap-1: post', 'after-2', 'wrap-2: post', 'after-3', 'wrap-3: post', 'after-4', 'wrap-4: post', 'val\\\\\\\\\\\\\\_x after', 'val\\\\\\\\\\\\\\_y wrap: pre', 'wrap-4: pre', 'before-4', 'wrap-3: pre', 'before-3', 'plain', 'after-3', 'wrap-3: post', 'after-4', 'wrap-4: post', 'val\\\\\\\\\\\\\\_y wrap: post', \\\\\\\\\\\\\\] \"\"\" Validation of default values¶ Validators won't run when the default value is used. This applies both to @field\\\\\\\\\\\\\\_validator validators and Annotated validators. You can force them to run with Field(validate\\\\\\\\\\\\\\_default=True). Setting validate\\\\\\\\\\\\\\_default to True has the closest behavior to using always=True in validator in Pydantic v1. However, you are generally better off using a @model\\\\\\\\\\\\\\_validator(mode='before') where the function is called before the inner validator is called. from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, Field, field\\\\\\\\\\\\\\_validator class Model(BaseModel): x: str = 'abc' y: Annotated\\\\\\\\\\\\\\[str, Field(validate\\\\\\\\\\\\\\_default=True)\\\\\\\\\\\\\\] = 'xyz' @field\\\\\\\\\\\\\\_validator('x', 'y') @classmethod def double(cls, v: str) -> str: return v \\\\\\\\\\\\\\* 2 print(Model()) #> x='abc' y='xyzxyz' print(Model(x='foo')) #> x='foofoo' y='xyzxyz' print(Model(x='abc')) #> x='abcabc' y='xyzxyz' print(Model(x='foo', y='bar')) #> x='foofoo' y='barbar' Field validators¶ API Documentation If you want to attach a validator to a specific field of a model you can use the @field\\\\\\\\\\\\\\_validator decorator. from pydantic import ( BaseModel, ValidationError, ValidationInfo, field\\\\\\\\\\\\\\_validator, ) class UserModel(BaseModel): id: int name: str @field\\\\\\\\\\\\\\_validator('name') @classmethod def name\\\\\\\\\\\\\\_must\\\\\\\\\\\\\\_contain\\\\\\\\\\\\\\_space(cls, v: str) -> str: if ' ' not in v: raise ValueError('must contain a space') return v.title() # you can select multiple fields, or use '\\\\\\\\\\\\\\*' to select all fields @field\\\\\\\\\\\\\\_validator('id', 'name') @classmethod def check\\\\\\\\\\\\\\_alphanumeric(cls, v: str, info: ValidationInfo) -> str: if isinstance(v, str): # info.field\\\\\\\\\\\\\\_name is the name of the field being validated is\\\\\\\\\\\\\\_alphanumeric = v.replace(' ', '').isalnum() assert is\\\\\\\\\\\\\\_alphanumeric, f'{info.field\\\\\\\\\\\\\\_name} must be alphanumeric' return v print(UserModel(id=1, name='John Doe')) #> id=1 name='John Doe' try: UserModel(id=1, name='samuel') except ValidationError as e: print(e) \"\"\" 1 validation error for UserModel name Value error, must contain a space \\\\\\\\\\\\\\[type=value\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='samuel', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" try: UserModel(id='abc', name='John Doe') except ValidationError as e: print(e) \"\"\" 1 validation error for UserModel id Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='abc', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" try: UserModel(id=1, name='John Doe!') except ValidationError as e: print(e) \"\"\" 1 validation error for UserModel name Assertion failed, name must be alphanumeric assert False \\\\\\\\\\\\\\[type=assertion\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='John Doe!', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" A few things to note on validators: @field\\\\\\\\\\\\\\_validators are \"class methods\", so the first argument value they receive is the UserModel class, not an instance of UserModel. We recommend you use the @classmethod decorator on them below the @field\\\\\\\\\\\\\\_validator decorator to get proper type checking. the second argument is the field value to validate; it can be named as you please the third argument, if present, is an instance of pydantic.ValidationInfo validators should either return the parsed value or raise a ValueError or AssertionError (assert statements may be used). A single validator can be applied to multiple fields by passing it multiple field names. A single validator can also be called on all fields by passing the special value '\\\\\\\\\\\\\\*'. Warning If you make use of assert statements, keep in mind that running Python with the -O optimization flag disables assert statements, and validators will stop working. Note FieldValidationInfo is deprecated in 2.4, use ValidationInfo instead. If you want to access values from another field inside a @field\\\\\\\\\\\\\\_validator, this may be possible using ValidationInfo.data, which is a dict of field name to field value. Validation is done in the order fields are defined, so you have to be careful when using ValidationInfo.data to not access a field that has not yet been validated/populated — in the code above, for example, you would not be able to access info.data\\\\\\\\\\\\\\['id'\\\\\\\\\\\\\\] from within name\\\\\\\\\\\\\\_must\\\\\\\\\\\\\\_contain\\\\\\\\\\\\\\_space. However, in most cases where you want to perform validation using multiple field values, it is better to use @model\\\\\\\\\\\\\\_validator which is discussed in the section below. Model validators¶ API Documentation Validation can also be performed on the entire model's data using @model\\\\\\\\\\\\\\_validator. from typing import Any from pydantic import BaseModel, ValidationError, model\\\\\\\\\\\\\\_validator class UserModel(BaseModel): username: str password1: str password2: str @model\\\\\\\\\\\\\\_validator(mode='before') @classmethod def check\\\\\\\\\\\\\\_card\\\\\\\\\\\\\\_number\\\\\\\\\\\\\\_omitted(cls, data: Any) -> Any: if isinstance(data, dict): assert ( 'card\\\\\\\\\\\\\\_number' not in data ), 'card\\\\\\\\\\\\\\_number should not be included' return data @model\\\\\\\\\\\\\\_validator(mode='after') def check\\\\\\\\\\\\\\_passwords\\\\\\\\\\\\\\_match(self) -> 'UserModel': pw1 = self.password1 pw2 = self.password2 if pw1 is not None and pw2 is not None and pw1 != pw2: raise ValueError('passwords do not match') return self print(UserModel(username='scolvin', password1='zxcvbn', password2='zxcvbn')) #> username='scolvin' password1='zxcvbn' password2='zxcvbn' try: UserModel(username='scolvin', password1='zxcvbn', password2='zxcvbn2') except ValidationError as e: print(e) \"\"\" 1 validation error for UserModel Value error, passwords do not match \\\\\\\\\\\\\\[type=value\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value={'username': 'scolvin', '... 'password2': 'zxcvbn2'}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] \"\"\" try: UserModel( username='scolvin', password1='zxcvbn', password2='zxcvbn', card\\\\\\\\\\\\\\_number='1234', ) except ValidationError as e: print(e) \"\"\" 1 validation error for UserModel Assertion failed, card\\\\\\\\\\\\\\_number should not be included assert 'card\\\\\\\\\\\\\\_number' not in {'card\\\\\\\\\\\\\\_number': '1234', 'password1': 'zxcvbn', 'password2': 'zxcvbn', 'username': 'scolvin'} \\\\\\\\\\\\\\[type=assertion\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value={'username': 'scolvin', '..., 'card\\\\\\\\\\\\\\_number': '1234'}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] \"\"\" Model validators can be mode='before', mode='after' or mode='wrap'. Before model validators are passed the raw input which is often a dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] but could also be an instance of the model itself (e.g. if UserModel.model\\\\\\\\\\\\\\_validate(UserModel.construct(...)) is called) or anything else since you can pass arbitrary objects into model\\\\\\\\\\\\\\_validate. Because of this mode='before' validators are extremely flexible and powerful but can be cumbersome and error prone to implement. Before model validators should be class methods. The first argument should be cls (and we also recommend you use @classmethod below @model\\\\\\\\\\\\\\_validator for proper type checking), the second argument will be the input (you should generally type it as Any and use isinstance to narrow the type) and the third argument (if present) will be a pydantic.ValidationInfo. mode='after' validators are instance methods and always receive an instance of the model as the first argument. You should not use (cls, ModelType) as the signature, instead just use (self) and let type checkers infer the type of self for you. Since these are fully type safe they are often easier to implement than mode='before' validators. If any field fails to validate, mode='after' validators for that field will not be called. Handling errors in validators¶ As mentioned in the previous sections you can raise either a ValueError or AssertionError (including ones generated by assert ... statements) within a validator to indicate validation failed. You can also raise a PydanticCustomError which is a bit more verbose but gives you extra flexibility. Any other errors (including TypeError) are bubbled up and not wrapped in a ValidationError. from pydantic\\\\\\\\\\\\\\_core import PydanticCustomError from pydantic import BaseModel, ValidationError, field\\\\\\\\\\\\\\_validator class Model(BaseModel): x: int @field\\\\\\\\\\\\\\_validator('x') @classmethod def validate\\\\\\\\\\\\\\_x(cls, v: int) -> int: if v % 42 == 0: raise PydanticCustomError( 'the\\\\\\\\\\\\\\_answer\\\\\\\\\\\\\\_error', '{number} is the answer!', {'number': v}, ) return v try: Model(x=42 \\\\\\\\\\\\\\* 2) except ValidationError as e: print(e) \"\"\" 1 validation error for Model x 84 is the answer! \\\\\\\\\\\\\\[type=the\\\\\\\\\\\\\\_answer\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value=84, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] \"\"\" Special Types¶ Pydantic provides a few special types that can be used to customize validation. InstanceOf is a type that can be used to validate that a value is an instance of a given class. from typing import List from pydantic import BaseModel, InstanceOf, ValidationError class Fruit: def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_repr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self): return self.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_class\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ class Banana(Fruit): ... class Apple(Fruit): ... class Basket(BaseModel): fruits: List\\\\\\\\\\\\\\[InstanceOf\\\\\\\\\\\\\\[Fruit\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] print(Basket(fruits=\\\\\\\\\\\\\\[Banana(), Apple()\\\\\\\\\\\\\\])) #> fruits=\\\\\\\\\\\\\\[Banana, Apple\\\\\\\\\\\\\\] try: Basket(fruits=\\\\\\\\\\\\\\[Banana(), 'Apple'\\\\\\\\\\\\\\]) except ValidationError as e: print(e) \"\"\" 1 validation error for Basket fruits.1 Input should be an instance of Fruit \\\\\\\\\\\\\\[type=is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_of, input\\\\\\\\\\\\\\_value='Apple', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" SkipValidation is a type that can be used to skip validation on a field. from typing import List from pydantic import BaseModel, SkipValidation class Model(BaseModel): names: List\\\\\\\\\\\\\\[SkipValidation\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] m = Model(names=\\\\\\\\\\\\\\['foo', 'bar'\\\\\\\\\\\\\\]) print(m) #> names=\\\\\\\\\\\\\\['foo', 'bar'\\\\\\\\\\\\\\] m = Model(names=\\\\\\\\\\\\\\['foo', 123\\\\\\\\\\\\\\]) Note that the validation of the second item is skipped. If it has the wrong type it will emit a warning during serialization. print(m) #> names=\\\\\\\\\\\\\\['foo', 123\\\\\\\\\\\\\\] Field checks¶ During class creation, validators are checked to confirm that the fields they specify actually exist on the model. This may be undesirable if, for example, you want to define a validator to validate fields that will only be present on subclasses of the model where the validator is defined. If you want to disable these checks during class creation, you can pass check\\\\\\\\\\\\\\_fields=False as a keyword argument to the validator. Dataclass validators¶ Validators also work with Pydantic dataclasses. from pydantic import field\\\\\\\\\\\\\\_validator from pydantic.dataclasses import dataclass @dataclass class DemoDataclass: product\\\\\\\\\\\\\\_id: str # should be a five-digit string, may have leading zeros @field\\\\\\\\\\\\\\_validator('product\\\\\\\\\\\\\\_id', mode='before') @classmethod def convert\\\\\\\\\\\\\\_int\\\\\\\\\\\\\\_serial(cls, v): if isinstance(v, int): v = str(v).zfill(5) return v print(DemoDataclass(product\\\\\\\\\\\\\\_id='01234')) #> DemoDataclass(product\\\\\\\\\\\\\\_id='01234') print(DemoDataclass(product\\\\\\\\\\\\\\_id=2468)) #> DemoDataclass(product\\\\\\\\\\\\\\_id='02468') Validation Context¶ You can pass a context object to the validation methods which can be accessed from the info argument to decorated validator functions: from pydantic import BaseModel, ValidationInfo, field\\\\\\\\\\\\\\_validator class Model(BaseModel): text: str @field\\\\\\\\\\\\\\_validator('text') @classmethod def remove\\\\\\\\\\\\\\_stopwords(cls, v: str, info: ValidationInfo): context = info.context if context: stopwords = context.get('stopwords', set()) v = ' '.join(w for w in v.split() if w.lower() not in stopwords) return v data = {'text': 'This is an example document'} print(Model.model\\\\\\\\\\\\\\_validate(data)) # no context #> text='This is an example document' print(Model.model\\\\\\\\\\\\\\_validate(data, context={'stopwords': \\\\\\\\\\\\\\['this', 'is', 'an'\\\\\\\\\\\\\\]})) #> text='example document' print(Model.model\\\\\\\\\\\\\\_validate(data, context={'stopwords': \\\\\\\\\\\\\\['document'\\\\\\\\\\\\\\]})) #> text='This is an example' This is useful when you need to dynamically update the validation behavior during runtime. For example, if you wanted a field to have a dynamically controllable set of allowed values, this could be done by passing the allowed values by context, and having a separate mechanism for updating what is allowed: from typing import Any, Dict, List from pydantic import ( BaseModel, ValidationError, ValidationInfo, field\\\\\\\\\\\\\\_validator, ) \\\\\\\\\\\\\\_allowed\\\\\\\\\\\\\\_choices = \\\\\\\\\\\\\\['a', 'b', 'c'\\\\\\\\\\\\\\] def set\\\\\\\\\\\\\\_allowed\\\\\\\\\\\\\\_choices(allowed\\\\\\\\\\\\\\_choices: List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\]) -> None: global \\\\\\\\\\\\\\_allowed\\\\\\\\\\\\\\_choices \\\\\\\\\\\\\\_allowed\\\\\\\\\\\\\\_choices = allowed\\\\\\\\\\\\\\_choices def get\\\\\\\\\\\\\\_context() -> Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\]: return {'allowed\\\\\\\\\\\\\\_choices': \\\\\\\\\\\\\\_allowed\\\\\\\\\\\\\\_choices} class Model(BaseModel): choice: str @field\\\\\\\\\\\\\\_validator('choice') @classmethod def validate\\\\\\\\\\\\\\_choice(cls, v: str, info: ValidationInfo): allowed\\\\\\\\\\\\\\_choices = info.context.get('allowed\\\\\\\\\\\\\\_choices') if allowed\\\\\\\\\\\\\\_choices and v not in allowed\\\\\\\\\\\\\\_choices: raise ValueError(f'choice must be one of {allowed\\\\\\\\\\\\\\_choices}') return v print(Model.model\\\\\\\\\\\\\\_validate({'choice': 'a'}, context=get\\\\\\\\\\\\\\_context())) #> choice='a' try: print(Model.model\\\\\\\\\\\\\\_validate({'choice': 'd'}, context=get\\\\\\\\\\\\\\_context())) except ValidationError as exc: print(exc) \"\"\" 1 validation error for Model choice Value error, choice must be one of \\\\\\\\\\\\\\['a', 'b', 'c'\\\\\\\\\\\\\\] \\\\\\\\\\\\\\[type=value\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='d', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" set\\\\\\\\\\\\\\_allowed\\\\\\\\\\\\\\_choices(\\\\\\\\\\\\\\['b', 'c'\\\\\\\\\\\\\\]) try: print(Model.model\\\\\\\\\\\\\\_validate({'choice': 'a'}, context=get\\\\\\\\\\\\\\_context())) except ValidationError as exc: print(exc) \"\"\" 1 validation error for Model choice Value error, choice must be one of \\\\\\\\\\\\\\['b', 'c'\\\\\\\\\\\\\\] \\\\\\\\\\\\\\[type=value\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='a', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Using validation context with BaseModel initialization¶ Although there is no way to specify a context in the standard BaseModel initializer, you can work around this through the use of contextvars.ContextVar and a custom \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method: from contextlib import contextmanager from contextvars import ContextVar from typing import Any, Dict, Iterator from pydantic import BaseModel, ValidationInfo, field\\\\\\\\\\\\\\_validator \\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_context\\\\\\\\\\\\\\_var = ContextVar('\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_context\\\\\\\\\\\\\\_var', default=None) @contextmanager def init\\\\\\\\\\\\\\_context(value: Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\]) -> Iterator\\\\\\\\\\\\\\[None\\\\\\\\\\\\\\]: token = \\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_context\\\\\\\\\\\\\\_var.set(value) try: yield finally: \\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_context\\\\\\\\\\\\\\_var.reset(token) class Model(BaseModel): my\\\\\\\\\\\\\\_number: int def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_self\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data: Any) -> None: \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_self\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.validate\\\\\\\\\\\\\\_python( data, self\\\\\\\\\\\\\\_instance=\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_self\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, context=\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_context\\\\\\\\\\\\\\_var.get(), ) @field\\\\\\\\\\\\\\_validator('my\\\\\\\\\\\\\\_number') @classmethod def multiply\\\\\\\\\\\\\\_with\\\\\\\\\\\\\\_context(cls, value: int, info: ValidationInfo) -> int: if info.context: multiplier = info.context.get('multiplier', 1) value = value \\\\\\\\\\\\\\* multiplier return value print(Model(my\\\\\\\\\\\\\\_number=2)) #> my\\\\\\\\\\\\\\_number=2 with init\\\\\\\\\\\\\\_context({'multiplier': 3}): print(Model(my\\\\\\\\\\\\\\_number=2)) #> my\\\\\\\\\\\\\\_number=6 print(Model(my\\\\\\\\\\\\\\_number=2)) #> my\\\\\\\\\\\\\\_number=2 Made with Material for MkDocs Insiders"
  },
  {
    "title": "Serialization - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/serialization/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Serialization Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents model.model\\\\\\\\\\\\\\_dump(...) model.model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json(...) dict(model) and iteration Custom serializers Overriding the return type when dumping a model Serializing subclasses Subclasses of standard types Subclass instances for fields of BaseModel, dataclasses, TypedDict Serializing with duck-typing pickle.dumps(model) Advanced include and exclude Model- and field-level include and exclude model\\\\\\\\\\\\\\_copy(...) Serialization Beyond accessing model attributes directly via their field names (e.g. model.foobar), models can be converted, dumped, serialized, and exported in a number of ways. Serialize versus dump Pydantic uses the terms \"serialize\" and \"dump\" interchangeably. Both refer to the process of converting a model to a dictionary or JSON-encoded string. Outside of Pydantic, the word \"serialize\" usually refers to converting in-memory data into a string or bytes. However, in the context of Pydantic, there is a very close relationship between converting an object from a more structured form — such as a Pydantic model, a dataclass, etc. — into a less structured form comprised of Python built-ins such as dict. While we could (and on occasion, do) distinguish between these scenarios by using the word \"dump\" when converting to primitives and \"serialize\" when converting to string, for practical purposes, we frequently use the word \"serialize\" to refer to both of these situations, even though it does not always imply conversion to a string or bytes. model.model\\\\\\\\\\\\\\_dump(...)¶ API Documentation This is the primary way of converting a model to a dictionary. Sub-models will be recursively converted to dictionaries. Note The one exception to sub-models being converted to dictionaries is that RootModel and its subclasses will have the root field value dumped directly, without a wrapping dictionary. This is also done recursively. Note You can use computed fields to include property and cached\\\\\\\\\\\\\\_property data in the model.model\\\\\\\\\\\\\\_dump(...) output. Example: from typing import Any, List, Optional from pydantic import BaseModel, Field, Json class BarModel(BaseModel): whatever: int class FooBarModel(BaseModel): banana: Optional\\\\\\\\\\\\\\[float\\\\\\\\\\\\\\] = 1.1 foo: str = Field(serialization\\\\\\\\\\\\\\_alias='foo\\\\\\\\\\\\\\_alias') bar: BarModel m = FooBarModel(banana=3.14, foo='hello', bar={'whatever': 123}) # returns a dictionary: print(m.model\\\\\\\\\\\\\\_dump()) #> {'banana': 3.14, 'foo': 'hello', 'bar': {'whatever': 123}} print(m.model\\\\\\\\\\\\\\_dump(include={'foo', 'bar'})) #> {'foo': 'hello', 'bar': {'whatever': 123}} print(m.model\\\\\\\\\\\\\\_dump(exclude={'foo', 'bar'})) #> {'banana': 3.14} print(m.model\\\\\\\\\\\\\\_dump(by\\\\\\\\\\\\\\_alias=True)) #> {'banana': 3.14, 'foo\\\\\\\\\\\\\\_alias': 'hello', 'bar': {'whatever': 123}} print( FooBarModel(foo='hello', bar={'whatever': 123}).model\\\\\\\\\\\\\\_dump( exclude\\\\\\\\\\\\\\_unset=True ) ) #> {'foo': 'hello', 'bar': {'whatever': 123}} print( FooBarModel(banana=1.1, foo='hello', bar={'whatever': 123}).model\\\\\\\\\\\\\\_dump( exclude\\\\\\\\\\\\\\_defaults=True ) ) #> {'foo': 'hello', 'bar': {'whatever': 123}} print( FooBarModel(foo='hello', bar={'whatever': 123}).model\\\\\\\\\\\\\\_dump( exclude\\\\\\\\\\\\\\_defaults=True ) ) #> {'foo': 'hello', 'bar': {'whatever': 123}} print( FooBarModel(banana=None, foo='hello', bar={'whatever': 123}).model\\\\\\\\\\\\\\_dump( exclude\\\\\\\\\\\\\\_none=True ) ) #> {'foo': 'hello', 'bar': {'whatever': 123}} class Model(BaseModel): x: List\\\\\\\\\\\\\\[Json\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] print(Model(x=\\\\\\\\\\\\\\['{\"a\": 1}', '\\\\\\\\\\\\\\[1, 2\\\\\\\\\\\\\\]'\\\\\\\\\\\\\\]).model\\\\\\\\\\\\\\_dump()) #> {'x': \\\\\\\\\\\\\\[{'a': 1}, \\\\\\\\\\\\\\[1, 2\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]} print(Model(x=\\\\\\\\\\\\\\['{\"a\": 1}', '\\\\\\\\\\\\\\[1, 2\\\\\\\\\\\\\\]'\\\\\\\\\\\\\\]).model\\\\\\\\\\\\\\_dump(round\\\\\\\\\\\\\\_trip=True)) #> {'x': \\\\\\\\\\\\\\['{\"a\":1}', '\\\\\\\\\\\\\\[1,2\\\\\\\\\\\\\\]'\\\\\\\\\\\\\\]} model.model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json(...)¶ API Documentation The .model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json() method serializes a model directly to a JSON-encoded string that is equivalent to the result produced by .model\\\\\\\\\\\\\\_dump(). See arguments for more information. Note Pydantic can serialize many commonly used types to JSON that would otherwise be incompatible with a simple json.dumps(foobar) (e.g. datetime, date or UUID) . from datetime import datetime from pydantic import BaseModel class BarModel(BaseModel): whatever: int class FooBarModel(BaseModel): foo: datetime bar: BarModel m = FooBarModel(foo=datetime(2032, 6, 1, 12, 13, 14), bar={'whatever': 123}) print(m.model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json()) #> {\"foo\":\"2032-06-01T12:13:14\",\"bar\":{\"whatever\":123}} print(m.model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json(indent=2)) \"\"\" { \"foo\": \"2032-06-01T12:13:14\", \"bar\": { \"whatever\": 123 } } \"\"\" dict(model) and iteration¶ Pydantic models can also be converted to dictionaries using dict(model), and you can also iterate over a model's fields using for field\\\\\\\\\\\\\\_name, field\\\\\\\\\\\\\\_value in model:. With this approach the raw field values are returned, so sub-models will not be converted to dictionaries. Example: from pydantic import BaseModel class BarModel(BaseModel): whatever: int class FooBarModel(BaseModel): banana: float foo: str bar: BarModel m = FooBarModel(banana=3.14, foo='hello', bar={'whatever': 123}) print(dict(m)) #> {'banana': 3.14, 'foo': 'hello', 'bar': BarModel(whatever=123)} for name, value in m: print(f'{name}: {value}') #> banana: 3.14 #> foo: hello #> bar: whatever=123 Note also that RootModel does get converted to a dictionary with the key 'root'. Custom serializers¶ Pydantic provides several functional serializers to customise how a model is serialized to a dictionary or JSON. @field\\\\\\\\\\\\\\_serializer @model\\\\\\\\\\\\\\_serializer PlainSerializer WrapSerializer Serialization can be customised on a field using the @field\\\\\\\\\\\\\\_serializer decorator, and on a model using the @model\\\\\\\\\\\\\\_serializer decorator. from datetime import datetime, timedelta, timezone from typing import Any, Dict from pydantic import BaseModel, ConfigDict, field\\\\\\\\\\\\\\_serializer, model\\\\\\\\\\\\\\_serializer class WithCustomEncoders(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_timedelta='iso8601') dt: datetime diff: timedelta @field\\\\\\\\\\\\\\_serializer('dt') def serialize\\\\\\\\\\\\\\_dt(self, dt: datetime, \\\\\\\\\\\\\\_info): return dt.timestamp() m = WithCustomEncoders( dt=datetime(2032, 6, 1, tzinfo=timezone.utc), diff=timedelta(hours=100) ) print(m.model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json()) #> {\"dt\":1969660800.0,\"diff\":\"P4DT14400S\"} class Model(BaseModel): x: str @model\\\\\\\\\\\\\\_serializer def ser\\\\\\\\\\\\\\_model(self) -> Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\]: return {'x': f'serialized {self.x}'} print(Model(x='test value').model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json()) #> {\"x\":\"serialized test value\"} In addition, PlainSerializer and WrapSerializer enable you to use a function to modify the output of serialization. Both serializers accept optional arguments including: return\\\\\\\\\\\\\\_type specifies the return type for the function. If omitted it will be inferred from the type annotation. when\\\\\\\\\\\\\\_used specifies when this serializer should be used. Accepts a string with values 'always', 'unless-none', 'json', and 'json-unless-none'. Defaults to 'always'. PlainSerializer uses a simple function to modify the output of serialization. from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel from pydantic.functional\\\\\\\\\\\\\\_serializers import PlainSerializer FancyInt = Annotated\\\\\\\\\\\\\\[ int, PlainSerializer(lambda x: f'{x:,}', return\\\\\\\\\\\\\\_type=str, when\\\\\\\\\\\\\\_used='json') \\\\\\\\\\\\\\] class MyModel(BaseModel): x: FancyInt print(MyModel(x=1234).model\\\\\\\\\\\\\\_dump()) #> {'x': 1234} print(MyModel(x=1234).model\\\\\\\\\\\\\\_dump(mode='json')) #> {'x': '1,234'} WrapSerializer receives the raw inputs along with a handler function that applies the standard serialization logic, and can modify the resulting value before returning it as the final output of serialization. from typing import Any from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, SerializerFunctionWrapHandler from pydantic.functional\\\\\\\\\\\\\\_serializers import WrapSerializer def ser\\\\\\\\\\\\\\_wrap(v: Any, nxt: SerializerFunctionWrapHandler) -> str: return f'{nxt(v + 1):,}' FancyInt = Annotated\\\\\\\\\\\\\\[int, WrapSerializer(ser\\\\\\\\\\\\\\_wrap, when\\\\\\\\\\\\\\_used='json')\\\\\\\\\\\\\\] class MyModel(BaseModel): x: FancyInt print(MyModel(x=1234).model\\\\\\\\\\\\\\_dump()) #> {'x': 1234} print(MyModel(x=1234).model\\\\\\\\\\\\\\_dump(mode='json')) #> {'x': '1,235'} Overriding the return type when dumping a model¶ While the return value of .model\\\\\\\\\\\\\\_dump() can usually be described as dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\], through the use of @model\\\\\\\\\\\\\\_serializer you can actually cause it to return a value that doesn't match this signature: from pydantic import BaseModel, model\\\\\\\\\\\\\\_serializer class Model(BaseModel): x: str @model\\\\\\\\\\\\\\_serializer def ser\\\\\\\\\\\\\\_model(self) -> str: return self.x print(Model(x='not a dict').model\\\\\\\\\\\\\\_dump()) #> not a dict If you want to do this and still get proper type-checking for this method, you can override .model\\\\\\\\\\\\\\_dump() in an if TYPE\\\\\\\\\\\\\\_CHECKING: block: from typing import TYPE\\\\\\\\\\\\\\_CHECKING, Any from typing\\\\\\\\\\\\\\_extensions import Literal from pydantic import BaseModel, model\\\\\\\\\\\\\\_serializer class Model(BaseModel): x: str @model\\\\\\\\\\\\\\_serializer def ser\\\\\\\\\\\\\\_model(self) -> str: return self.x if TYPE\\\\\\\\\\\\\\_CHECKING: # Ensure type checkers see the correct return type def model\\\\\\\\\\\\\\_dump( self, \\\\\\\\\\\\\\*, mode: Literal\\\\\\\\\\\\\\['json', 'python'\\\\\\\\\\\\\\] | str = 'python', include: Any = None, exclude: Any = None, by\\\\\\\\\\\\\\_alias: bool = False, exclude\\\\\\\\\\\\\\_unset: bool = False, exclude\\\\\\\\\\\\\\_defaults: bool = False, exclude\\\\\\\\\\\\\\_none: bool = False, round\\\\\\\\\\\\\\_trip: bool = False, warnings: bool = True, ) -> str: ... This trick is actually used in RootModel for precisely this purpose. Serializing subclasses¶ Subclasses of standard types¶ Subclasses of standard types are automatically dumped like their super-classes: from datetime import date, timedelta from typing import Any, Type from pydantic\\\\\\\\\\\\\\_core import core\\\\\\\\\\\\\\_schema from pydantic import BaseModel, GetCoreSchemaHandler class DayThisYear(date): \"\"\" Contrived example of a special type of date that takes an int and interprets it as a day in the current year \"\"\" @classmethod def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( cls, source: Type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], handler: GetCoreSchemaHandler ) -> core\\\\\\\\\\\\\\_schema.CoreSchema: return core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( cls.validate, core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(), serialization=core\\\\\\\\\\\\\\_schema.format\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema('%Y-%m-%d'), ) @classmethod def validate(cls, v: int): return date.today().replace(month=1, day=1) + timedelta(days=v) class FooModel(BaseModel): date: DayThisYear m = FooModel(date=300) print(m.model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json()) #> {\"date\":\"2023-10-28\"} Subclass instances for fields of BaseModel, dataclasses, TypedDict¶ When using fields whose annotations are themselves struct-like types (e.g., BaseModel subclasses, dataclasses, etc.), the default behavior is to serialize the attribute value as though it was an instance of the annotated type, even if it is a subclass. More specifically, only the fields from the annotated type will be included in the dumped object: from pydantic import BaseModel class User(BaseModel): name: str class UserLogin(User): password: str class OuterModel(BaseModel): user: User user = UserLogin(name='pydantic', password='hunter2') m = OuterModel(user=user) print(m) #> user=UserLogin(name='pydantic', password='hunter2') print(m.model\\\\\\\\\\\\\\_dump()) # note: the password field is not included #> {'user': {'name': 'pydantic'}} Migration Warning This behavior is different from how things worked in Pydantic V1, where we would always include all (subclass) fields when recursively dumping models to dicts. The motivation behind this change in behavior is that it helps ensure that you know precisely which fields could be included when serializing, even if subclasses get passed when instantiating the object. In particular, this can help prevent surprises when adding sensitive information like secrets as fields of subclasses. Serializing with duck-typing¶ If you want to preserve the old duck-typing serialization behavior, this can be done using SerializeAsAny: from pydantic import BaseModel, SerializeAsAny class User(BaseModel): name: str class UserLogin(User): password: str class OuterModel(BaseModel): as\\\\\\\\\\\\\\_any: SerializeAsAny\\\\\\\\\\\\\\[User\\\\\\\\\\\\\\] as\\\\\\\\\\\\\\_user: User user = UserLogin(name='pydantic', password='password') print(OuterModel(as\\\\\\\\\\\\\\_any=user, as\\\\\\\\\\\\\\_user=user).model\\\\\\\\\\\\\\_dump()) \"\"\" { 'as\\\\\\\\\\\\\\_any': {'name': 'pydantic', 'password': 'password'}, 'as\\\\\\\\\\\\\\_user': {'name': 'pydantic'}, } \"\"\" When a field is annotated as SerializeAsAny\\\\\\\\\\\\\\[\\\\\\\\\\\\\\], the validation behavior will be the same as if it was annotated as , and type-checkers like mypy will treat the attribute as having the appropriate type as well. But when serializing, the field will be serialized as though the type hint for the field was Any, which is where the name comes from. pickle.dumps(model)¶ Pydantic models support efficient pickling and unpickling. # TODO need to get pickling to work import pickle from pydantic import BaseModel class FooBarModel(BaseModel): a: str b: int m = FooBarModel(a='hello', b=123) print(m) #> a='hello' b=123 data = pickle.dumps(m) print(data\\\\\\\\\\\\\\[:20\\\\\\\\\\\\\\]) #> b'\\\\\\\\\\\\\\\\x80\\\\\\\\\\\\\\\\x04\\\\\\\\\\\\\\\\x95\\\\\\\\\\\\\\\\x95\\\\\\\\\\\\\\\\x00\\\\\\\\\\\\\\\\x00\\\\\\\\\\\\\\\\x00\\\\\\\\\\\\\\\\x00\\\\\\\\\\\\\\\\x00\\\\\\\\\\\\\\\\x00\\\\\\\\\\\\\\\\x00\\\\\\\\\\\\\\\\x8c\\\\\\\\\\\\\\\\x08\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_main\\\\\\\\\\\\\\_' m2 = pickle.loads(data) print(m2) #> a='hello' b=123 Advanced include and exclude¶ The model\\\\\\\\\\\\\\_dump and model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json methods support include and exclude arguments which can either be sets or dictionaries. This allows nested selection of which fields to export: from pydantic import BaseModel, SecretStr class User(BaseModel): id: int username: str password: SecretStr class Transaction(BaseModel): id: str user: User value: int t = Transaction( id='1234567890', user=User(id=42, username='JohnDoe', password='hashedpassword'), value=9876543210, ) # using a set: print(t.model\\\\\\\\\\\\\\_dump(exclude={'user', 'value'})) #> {'id': '1234567890'} # using a dict: print(t.model\\\\\\\\\\\\\\_dump(exclude={'user': {'username', 'password'}, 'value': True})) #> {'id': '1234567890', 'user': {'id': 42}} print(t.model\\\\\\\\\\\\\\_dump(include={'id': True, 'user': {'id'}})) #> {'id': '1234567890', 'user': {'id': 42}} The True indicates that we want to exclude or include an entire key, just as if we included it in a set. This can be done at any depth level. Special care must be taken when including or excluding fields from a list or tuple of submodels or dictionaries. In this scenario, model\\\\\\\\\\\\\\_dump and related methods expect integer keys for element-wise inclusion or exclusion. To exclude a field from every member of a list or tuple, the dictionary key '\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_all\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_' can be used, as shown here: import datetime from typing import List from pydantic import BaseModel, SecretStr class Country(BaseModel): name: str phone\\\\\\\\\\\\\\_code: int class Address(BaseModel): post\\\\\\\\\\\\\\_code: int country: Country class CardDetails(BaseModel): number: SecretStr expires: datetime.date class Hobby(BaseModel): name: str info: str class User(BaseModel): first\\\\\\\\\\\\\\_name: str second\\\\\\\\\\\\\\_name: str address: Address card\\\\\\\\\\\\\\_details: CardDetails hobbies: List\\\\\\\\\\\\\\[Hobby\\\\\\\\\\\\\\] user = User( first\\\\\\\\\\\\\\_name='John', second\\\\\\\\\\\\\\_name='Doe', address=Address( post\\\\\\\\\\\\\\_code=123456, country=Country(name='USA', phone\\\\\\\\\\\\\\_code=1) ), card\\\\\\\\\\\\\\_details=CardDetails( number='4212934504460000', expires=datetime.date(2020, 5, 1) ), hobbies=\\\\\\\\\\\\\\[ Hobby(name='Programming', info='Writing code and stuff'), Hobby(name='Gaming', info='Hell Yeah!!!'), \\\\\\\\\\\\\\], ) exclude\\\\\\\\\\\\\\_keys = { 'second\\\\\\\\\\\\\\_name': True, 'address': {'post\\\\\\\\\\\\\\_code': True, 'country': {'phone\\\\\\\\\\\\\\_code'}}, 'card\\\\\\\\\\\\\\_details': True, # You can exclude fields from specific members of a tuple/list by index: 'hobbies': {-1: {'info'}}, } include\\\\\\\\\\\\\\_keys = { 'first\\\\\\\\\\\\\\_name': True, 'address': {'country': {'name'}}, 'hobbies': {0: True, -1: {'name'}}, } # would be the same as user.model\\\\\\\\\\\\\\_dump(exclude=exclude\\\\\\\\\\\\\\_keys) in this case: print(user.model\\\\\\\\\\\\\\_dump(include=include\\\\\\\\\\\\\\_keys)) \"\"\" { 'first\\\\\\\\\\\\\\_name': 'John', 'address': {'country': {'name': 'USA'}}, 'hobbies': \\\\\\\\\\\\\\[ {'name': 'Programming', 'info': 'Writing code and stuff'}, {'name': 'Gaming'}, \\\\\\\\\\\\\\], } \"\"\" # To exclude a field from all members of a nested list or tuple, use \"\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_all\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_\": print(user.model\\\\\\\\\\\\\\_dump(exclude={'hobbies': {'\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_all\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_': {'info'}}})) \"\"\" { 'first\\\\\\\\\\\\\\_name': 'John', 'second\\\\\\\\\\\\\\_name': 'Doe', 'address': { 'post\\\\\\\\\\\\\\_code': 123456, 'country': {'name': 'USA', 'phone\\\\\\\\\\\\\\_code': 1}, }, 'card\\\\\\\\\\\\\\_details': { 'number': SecretStr('\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*'), 'expires': datetime.date(2020, 5, 1), }, 'hobbies': \\\\\\\\\\\\\\[{'name': 'Programming'}, {'name': 'Gaming'}\\\\\\\\\\\\\\], } \"\"\" The same holds for the model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json method. Model- and field-level include and exclude¶ In addition to the explicit arguments exclude and include passed to model\\\\\\\\\\\\\\_dump and model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json methods, we can also pass the exclude: bool arguments directly to the Field constructor: Setting exclude on the field constructor (Field(..., exclude=True)) takes priority over the exclude/include on model\\\\\\\\\\\\\\_dump and model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json: from pydantic import BaseModel, Field, SecretStr class User(BaseModel): id: int username: str password: SecretStr = Field(..., exclude=True) class Transaction(BaseModel): id: str value: int = Field(exclude=True) t = Transaction( id='1234567890', value=9876543210, ) print(t.model\\\\\\\\\\\\\\_dump()) #> {'id': '1234567890'} print(t.model\\\\\\\\\\\\\\_dump(include={'id': True, 'value': True})) value excluded from the output because it excluded in Field. #> {'id': '1234567890'} That being said, setting exclude on the field constructor (Field(..., exclude=True)) does not take priority over the exclude\\\\\\\\\\\\\\_unset, exclude\\\\\\\\\\\\\\_none, and exclude\\\\\\\\\\\\\\_default parameters on model\\\\\\\\\\\\\\_dump and model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json: Python 3.7 and above Python 3.10 and above from typing import Optional from pydantic import BaseModel, Field class Person(BaseModel): name: str age: Optional\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] = Field(None, exclude=False) person = Person(name='Jeremy') print(person.model\\\\\\\\\\\\\\_dump()) #> {'name': 'Jeremy', 'age': None} print(person.model\\\\\\\\\\\\\\_dump(exclude\\\\\\\\\\\\\\_none=True)) age excluded from the output because exclude\\\\\\\\\\\\\\_none was set to True, and age is None. #> {'name': 'Jeremy'} print(person.model\\\\\\\\\\\\\\_dump(exclude\\\\\\\\\\\\\\_unset=True)) age excluded from the output because exclude\\\\\\\\\\\\\\_unset was set to True, and age was not set in the Person constructor. #> {'name': 'Jeremy'} print(person.model\\\\\\\\\\\\\\_dump(exclude\\\\\\\\\\\\\\_defaults=True)) age excluded from the output because exclude\\\\\\\\\\\\\\_defaults was set to True, and age takes the default value of None. #> {'name': 'Jeremy'} model\\\\\\\\\\\\\\_copy(...)¶ API Documentation model\\\\\\\\\\\\\\_copy() allows models to be duplicated (with optional updates), which is particularly useful when working with frozen models. Example: from pydantic import BaseModel class BarModel(BaseModel): whatever: int class FooBarModel(BaseModel): banana: float foo: str bar: BarModel m = FooBarModel(banana=3.14, foo='hello', bar={'whatever': 123}) print(m.model\\\\\\\\\\\\\\_copy(update={'banana': 0})) #> banana=0 foo='hello' bar=BarModel(whatever=123) print(id(m.bar) == id(m.model\\\\\\\\\\\\\\_copy().bar)) #> True # normal copy gives the same object reference for bar print(id(m.bar) == id(m.model\\\\\\\\\\\\\\_copy(deep=True).bar)) #> False # deep copy gives a new object reference for \\\\\\\\\\\\\\`bar\\\\\\\\\\\\\\` Made with Material for MkDocs Insiders"
  },
  {
    "title": "Configuration - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/config/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Configuration Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Change behaviour globally Configuration Behaviour of Pydantic can be controlled via the BaseModel.model\\\\\\\\\\\\\\_config, and as an argument to TypeAdapter. Note Before v2.0, the Config class was used. This is still supported, but deprecated. from pydantic import BaseModel, ConfigDict, ValidationError class Model(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(str\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_length=10) v: str try: m = Model(v='x' \\\\\\\\\\\\\\* 20) except ValidationError as e: print(e) \"\"\" 1 validation error for Model v String should have at most 10 characters \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_long, input\\\\\\\\\\\\\\_value='xxxxxxxxxxxxxxxxxxxx', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Also, you can specify config options as model class kwargs: from pydantic import BaseModel, ValidationError class Model(BaseModel, extra='forbid'): See the Extra Attributes section for more details. a: str try: Model(a='spam', b='oh no') except ValidationError as e: print(e) \"\"\" 1 validation error for Model b Extra inputs are not permitted \\\\\\\\\\\\\\[type=extra\\\\\\\\\\\\\\_forbidden, input\\\\\\\\\\\\\\_value='oh no', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Similarly, if using the @dataclass decorator from Pydantic: from datetime import datetime from pydantic import ConfigDict, ValidationError from pydantic.dataclasses import dataclass config = ConfigDict(str\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_length=10, validate\\\\\\\\\\\\\\_assignment=True) @dataclass(config=config) If using the dataclass from the standard library or TypedDict, you should use \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ instead. See: from dataclasses import dataclass from datetime import datetime from pydantic import ConfigDict @dataclass class User: \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ = ConfigDict(strict=True) id: int name: str = 'John Doe' signup\\\\\\\\\\\\\\_ts: datetime = None class User: id: int name: str = 'John Doe' signup\\\\\\\\\\\\\\_ts: datetime = None user = User(id='42', signup\\\\\\\\\\\\\\_ts='2032-06-21T12:00') try: user.name = 'x' \\\\\\\\\\\\\\* 20 except ValidationError as e: print(e) \"\"\" 1 validation error for User name String should have at most 10 characters \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_long, input\\\\\\\\\\\\\\_value='xxxxxxxxxxxxxxxxxxxx', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Change behaviour globally¶ If you wish to change the behaviour of Pydantic globally, you can create your own custom BaseModel with custom model\\\\\\\\\\\\\\_config since the config is inherited: from pydantic import BaseModel, ConfigDict class Parent(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(extra='allow') class Model(Parent): x: str m = Model(x='foo', y='bar') print(m.model\\\\\\\\\\\\\\_dump()) #> {'x': 'foo', 'y': 'bar'} If you add a model\\\\\\\\\\\\\\_config to the Model class, it will merge with the model\\\\\\\\\\\\\\_config from Parent: from pydantic import BaseModel, ConfigDict class Parent(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(extra='allow') class Model(Parent): model\\\\\\\\\\\\\\_config = ConfigDict(str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_lower=True) # (1)! x: str m = Model(x='FOO', y='bar') print(m.model\\\\\\\\\\\\\\_dump()) #> {'x': 'foo', 'y': 'bar'} print(m.model\\\\\\\\\\\\\\_config) #> {'extra': 'allow', 'str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_lower': True} Made with Material for MkDocs Insiders"
  },
  {
    "title": "Alias - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/alias/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Alias Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Alias Precedence Alias Priority Alias An alias is an alternative name for a field, used when serializing and deserializing data. You can specify an alias in the following ways: alias on the Field validation\\\\\\\\\\\\\\_alias on the Field serialization\\\\\\\\\\\\\\_alias on the Field alias\\\\\\\\\\\\\\_generator on the Config Alias Precedence¶ If you specify an alias on the Field, it will take precedence over the generated alias by default: from pydantic import BaseModel, ConfigDict, Field def to\\\\\\\\\\\\\\_camel(string: str) -> str: return ''.join(word.capitalize() for word in string.split('\\\\\\\\\\\\\\_')) class Voice(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(alias\\\\\\\\\\\\\\_generator=to\\\\\\\\\\\\\\_camel) name: str language\\\\\\\\\\\\\\_code: str = Field(alias='lang') voice = Voice(Name='Filiz', lang='tr-TR') print(voice.language\\\\\\\\\\\\\\_code) #> tr-TR print(voice.model\\\\\\\\\\\\\\_dump(by\\\\\\\\\\\\\\_alias=True)) #> {'Name': 'Filiz', 'lang': 'tr-TR'} Alias Priority¶ You may set alias\\\\\\\\\\\\\\_priority on a field to change this behavior: alias\\\\\\\\\\\\\\_priority=2 the alias will not be overridden by the alias generator. alias\\\\\\\\\\\\\\_priority=1 the alias will be overridden by the alias generator. alias\\\\\\\\\\\\\\_priority not set, the alias will be overridden by the alias generator. The same precedence applies to validation\\\\\\\\\\\\\\_alias and serialization\\\\\\\\\\\\\\_alias. See more about the different field aliases under field aliases. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Types - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/types/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Types Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Type conversion Strict Types Constrained types Custom Types Composing types via Annotated Adding validation and serialization Generics Named type aliases Named recursive types Customizing validation with \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ As a method on a custom type As an annotation Handling third-party types Using GetPydanticSchema to reduce boilerplate Summary Handling custom generic classes Generic containers Access to field name Types Where possible Pydantic uses standard library types to define fields, thus smoothing the learning curve. For many useful applications, however, no standard library type exists, so Pydantic implements many commonly used types. There are also more complex types that can be found in the Pydantic Extra Types package. If no existing type suits your purpose you can also implement your own Pydantic-compatible types with custom properties and validation. The following sections describe the types supported by Pydantic. Standard Library Types — types from the Python standard library. Strict Types — types that enable you to prevent coercion from compatible types. Custom Data Types — create your own custom data types. Field Type Conversions — strict and lax conversion between different field types. Type conversion¶ During validation, Pydantic can coerce data into expected types. There are two modes of coercion: strict and lax. See Conversion Table for more details on how Pydantic converts data in both strict and lax modes. See Strict mode and Strict Types for details on enabling strict coercion. Strict Types¶ Pydantic provides the following strict types: StrictBool StrictBytes StrictFloat StrictInt StrictStr These types will only pass validation when the validated value is of the respective type or is a subtype of that type. Constrained types¶ This behavior is also exposed via the strict field of the constrained types and can be combined with a multitude of complex validation rules. See the individual type signatures for supported arguments. conbytes() condate() condecimal() confloat() confrozenset() conint() conlist() conset() constr() The following caveats apply: StrictBytes (and the strict option of conbytes()) will accept both bytes, and bytearray types. StrictInt (and the strict option of conint()) will not accept bool types, even though bool is a subclass of int in Python. Other subclasses will work. StrictFloat (and the strict option of confloat()) will not accept int. Besides the above, you can also have a FiniteFloat type that will only accept finite values (i.e. not inf, -inf or nan). Custom Types¶ You can also define your own custom data types. There are several ways to achieve it. Composing types via Annotated¶ PEP 593 introduced Annotated as a way to attach runtime metadata to types without changing how type checkers interpret them. Pydantic takes advantage of this to allow you to create types that are identical to the original type as far as type checkers are concerned, but add validation, serialize differently, etc. For example, to create a type representing a positive int: # or \\\\\\\\\\\\\\`from typing import Annotated\\\\\\\\\\\\\\` for Python 3.9+ from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import Field, TypeAdapter, ValidationError PositiveInt = Annotated\\\\\\\\\\\\\\[int, Field(gt=0)\\\\\\\\\\\\\\] ta = TypeAdapter(PositiveInt) print(ta.validate\\\\\\\\\\\\\\_python(1)) #> 1 try: ta.validate\\\\\\\\\\\\\\_python(-1) except ValidationError as exc: print(exc) \"\"\" 1 validation error for constrained-int Input should be greater than 0 \\\\\\\\\\\\\\[type=greater\\\\\\\\\\\\\\_than, input\\\\\\\\\\\\\\_value=-1, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] \"\"\" Note that you can also use constraints from annotated-types to make this Pydantic-agnostic: from annotated\\\\\\\\\\\\\\_types import Gt from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import TypeAdapter, ValidationError PositiveInt = Annotated\\\\\\\\\\\\\\[int, Gt(0)\\\\\\\\\\\\\\] ta = TypeAdapter(PositiveInt) print(ta.validate\\\\\\\\\\\\\\_python(1)) #> 1 try: ta.validate\\\\\\\\\\\\\\_python(-1) except ValidationError as exc: print(exc) \"\"\" 1 validation error for constrained-int Input should be greater than 0 \\\\\\\\\\\\\\[type=greater\\\\\\\\\\\\\\_than, input\\\\\\\\\\\\\\_value=-1, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] \"\"\" Adding validation and serialization¶ You can add or override validation, serialization, and JSON schemas to an arbitrary type using the markers that Pydantic exports: from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import ( AfterValidator, PlainSerializer, TypeAdapter, WithJsonSchema, ) TruncatedFloat = Annotated\\\\\\\\\\\\\\[ float, AfterValidator(lambda x: round(x, 1)), PlainSerializer(lambda x: f'{x:.1e}', return\\\\\\\\\\\\\\_type=str), WithJsonSchema({'type': 'string'}, mode='serialization'), \\\\\\\\\\\\\\] ta = TypeAdapter(TruncatedFloat) input = 1.02345 assert input != 1.0 assert ta.validate\\\\\\\\\\\\\\_python(input) == 1.0 assert ta.dump\\\\\\\\\\\\\\_json(input) == b'\"1.0e+00\"' assert ta.json\\\\\\\\\\\\\\_schema(mode='validation') == {'type': 'number'} assert ta.json\\\\\\\\\\\\\\_schema(mode='serialization') == {'type': 'string'} Generics¶ You can use type variables within Annotated to make re-usable modifications to types: from typing import Any, List, Sequence, TypeVar from annotated\\\\\\\\\\\\\\_types import Gt, Len from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import ValidationError from pydantic.type\\\\\\\\\\\\\\_adapter import TypeAdapter SequenceType = TypeVar('SequenceType', bound=Sequence\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\]) ShortSequence = Annotated\\\\\\\\\\\\\\[SequenceType, Len(max\\\\\\\\\\\\\\_length=10)\\\\\\\\\\\\\\] ta = TypeAdapter(ShortSequence\\\\\\\\\\\\\\[List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]) v = ta.validate\\\\\\\\\\\\\\_python(\\\\\\\\\\\\\\[1, 2, 3, 4, 5\\\\\\\\\\\\\\]) assert v == \\\\\\\\\\\\\\[1, 2, 3, 4, 5\\\\\\\\\\\\\\] try: ta.validate\\\\\\\\\\\\\\_python(\\\\\\\\\\\\\\[1\\\\\\\\\\\\\\] \\\\\\\\\\\\\\* 100) except ValidationError as exc: print(exc) \"\"\" 1 validation error for list\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] List should have at most 10 items after validation, not 100 \\\\\\\\\\\\\\[type=too\\\\\\\\\\\\\\_long, input\\\\\\\\\\\\\\_value=\\\\\\\\\\\\\\[1, 1, 1, 1, 1, 1, 1, 1, ... 1, 1, 1, 1, 1, 1, 1, 1\\\\\\\\\\\\\\], input\\\\\\\\\\\\\\_type=list\\\\\\\\\\\\\\] \"\"\" T = TypeVar('T') # or a bound=SupportGt PositiveList = List\\\\\\\\\\\\\\[Annotated\\\\\\\\\\\\\\[T, Gt(0)\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] ta = TypeAdapter(PositiveList\\\\\\\\\\\\\\[float\\\\\\\\\\\\\\]) v = ta.validate\\\\\\\\\\\\\\_python(\\\\\\\\\\\\\\[1\\\\\\\\\\\\\\]) assert type(v\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]) is float try: ta.validate\\\\\\\\\\\\\\_python(\\\\\\\\\\\\\\[-1\\\\\\\\\\\\\\]) except ValidationError as exc: print(exc) \"\"\" 1 validation error for list\\\\\\\\\\\\\\[constrained-float\\\\\\\\\\\\\\] 0 Input should be greater than 0 \\\\\\\\\\\\\\[type=greater\\\\\\\\\\\\\\_than, input\\\\\\\\\\\\\\_value=-1, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] \"\"\" Named type aliases¶ The above examples make use of implicit type aliases. This means that they will not be able to have a title in JSON schemas and their schema will be copied between fields. You can use PEP 695's TypeAliasType via its typing-extensions backport to make named aliases, allowing you to define a new type without creating subclasses. This new type can be as simple as a name or have complex validation logic attached to it: from typing import List, TypeVar from annotated\\\\\\\\\\\\\\_types import Gt from typing\\\\\\\\\\\\\\_extensions import Annotated, TypeAliasType from pydantic import BaseModel T = TypeVar('T') # or a \\\\\\\\\\\\\\`bound=SupportGt\\\\\\\\\\\\\\` ImplicitAliasPositiveIntList = List\\\\\\\\\\\\\\[Annotated\\\\\\\\\\\\\\[int, Gt(0)\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] class Model1(BaseModel): x: ImplicitAliasPositiveIntList y: ImplicitAliasPositiveIntList print(Model1.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema()) \"\"\" { 'properties': { 'x': { 'items': {'exclusiveMinimum': 0, 'type': 'integer'}, 'title': 'X', 'type': 'array', }, 'y': { 'items': {'exclusiveMinimum': 0, 'type': 'integer'}, 'title': 'Y', 'type': 'array', }, }, 'required': \\\\\\\\\\\\\\['x', 'y'\\\\\\\\\\\\\\], 'title': 'Model1', 'type': 'object', } \"\"\" PositiveIntList = TypeAliasType('PositiveIntList', List\\\\\\\\\\\\\\[Annotated\\\\\\\\\\\\\\[int, Gt(0)\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]) class Model2(BaseModel): x: PositiveIntList y: PositiveIntList print(Model2.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema()) \"\"\" { '$defs': { 'PositiveIntList': { 'items': {'exclusiveMinimum': 0, 'type': 'integer'}, 'type': 'array', } }, 'properties': { 'x': {'$ref': '#/$defs/PositiveIntList'}, 'y': {'$ref': '#/$defs/PositiveIntList'}, }, 'required': \\\\\\\\\\\\\\['x', 'y'\\\\\\\\\\\\\\], 'title': 'Model2', 'type': 'object', } \"\"\" These named type aliases can also be generic: from typing import Generic, List, TypeVar from annotated\\\\\\\\\\\\\\_types import Gt from typing\\\\\\\\\\\\\\_extensions import Annotated, TypeAliasType from pydantic import BaseModel, ValidationError T = TypeVar('T') # or a bound=SupportGt PositiveList = TypeAliasType( 'PositiveList', List\\\\\\\\\\\\\\[Annotated\\\\\\\\\\\\\\[T, Gt(0)\\\\\\\\\\\\\\]\\\\\\\\\\\\\\], type\\\\\\\\\\\\\\_params=(T,) ) class Model(BaseModel, Generic\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\]): x: PositiveList\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\] assert Model\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\].model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json('{\"x\": \\\\\\\\\\\\\\[\"1\"\\\\\\\\\\\\\\]}').x == \\\\\\\\\\\\\\[1\\\\\\\\\\\\\\] try: Model\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\](x=\\\\\\\\\\\\\\[-1\\\\\\\\\\\\\\]) except ValidationError as exc: print(exc) \"\"\" 1 validation error for Model\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] x.0 Input should be greater than 0 \\\\\\\\\\\\\\[type=greater\\\\\\\\\\\\\\_than, input\\\\\\\\\\\\\\_value=-1, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] \"\"\" Named recursive types¶ You can also use TypeAliasType to create recursive types: from typing import Any, Dict, List, Union from pydantic\\\\\\\\\\\\\\_core import PydanticCustomError from typing\\\\\\\\\\\\\\_extensions import Annotated, TypeAliasType from pydantic import ( TypeAdapter, ValidationError, ValidationInfo, ValidatorFunctionWrapHandler, WrapValidator, ) def json\\\\\\\\\\\\\\_custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_validator( value: Any, handler: ValidatorFunctionWrapHandler, \\\\\\\\\\\\\\_info: ValidationInfo ) -> Any: \"\"\"Simplify the error message to avoid a gross error stemming from exhaustive checking of all union options. \"\"\" try: return handler(value) except ValidationError: raise PydanticCustomError( 'invalid\\\\\\\\\\\\\\_json', 'Input is not valid json', ) Json = TypeAliasType( 'Json', Annotated\\\\\\\\\\\\\\[ Union\\\\\\\\\\\\\\[Dict\\\\\\\\\\\\\\[str, 'Json'\\\\\\\\\\\\\\], List\\\\\\\\\\\\\\['Json'\\\\\\\\\\\\\\], str, int, float, bool, None\\\\\\\\\\\\\\], WrapValidator(json\\\\\\\\\\\\\\_custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_validator), \\\\\\\\\\\\\\], ) ta = TypeAdapter(Json) v = ta.validate\\\\\\\\\\\\\\_python({'x': \\\\\\\\\\\\\\[1\\\\\\\\\\\\\\], 'y': {'z': True}}) assert v == {'x': \\\\\\\\\\\\\\[1\\\\\\\\\\\\\\], 'y': {'z': True}} try: ta.validate\\\\\\\\\\\\\\_python({'x': object()}) except ValidationError as exc: print(exc) \"\"\" 1 validation error for function-wrap\\\\\\\\\\\\\\[json\\\\\\\\\\\\\\_custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_validator()\\\\\\\\\\\\\\] Input is not valid json \\\\\\\\\\\\\\[type=invalid\\\\\\\\\\\\\\_json, input\\\\\\\\\\\\\\_value={'x': }, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] \"\"\" Customizing validation with \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_¶ To do more extensive customization of how Pydantic handles custom classes, and in particular when you have access to the class or can subclass it, you can implement a special \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ to tell Pydantic how to generate the pydantic-core schema. While pydantic uses pydantic-core internally to handle validation and serialization, it is a new API for Pydantic V2, thus it is one of the areas most likely to be tweaked in the future and you should try to stick to the built-in constructs like those provided by annotated-types, pydantic.Field, or BeforeValidator and so on. You can implement \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ both on a custom type and on metadata intended to be put in Annotated. In both cases the API is middleware-like and similar to that of \"wrap\" validators: you get a source\\\\\\\\\\\\\\_type (which isn't necessarily the same as the class, in particular for generics) and a handler that you can call with a type to either call the next metadata in Annotated or call into Pydantic's internal schema generation. The simplest no-op implementation calls the handler with the type you are given, then returns that as the result. You can also choose to modify the type before calling the handler, modify the core schema returned by the handler, or not call the handler at all. As a method on a custom type¶ The following is an example of a type that uses \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ to customize how it gets validated. This is equivalent to implementing \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ in Pydantic V1. from typing import Any from pydantic\\\\\\\\\\\\\\_core import CoreSchema, core\\\\\\\\\\\\\\_schema from pydantic import GetCoreSchemaHandler, TypeAdapter class Username(str): @classmethod def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( cls, source\\\\\\\\\\\\\\_type: Any, handler: GetCoreSchemaHandler ) -> CoreSchema: return core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function(cls, handler(str)) ta = TypeAdapter(Username) res = ta.validate\\\\\\\\\\\\\\_python('abc') assert isinstance(res, Username) assert res == 'abc' See JSON Schema for more details on how to customize JSON schemas for custom types. As an annotation¶ Often you'll want to parametrize your custom type by more than just generic type parameters (which you can do via the type system and will be discussed later). Or you may not actually care (or want to) make an instance of your subclass; you actually want the original type, just with some extra validation done. For example, if you were to implement pydantic.AfterValidator (see Adding validation and serialization) yourself, you'd do something similar to the following: from dataclasses import dataclass from typing import Any, Callable from pydantic\\\\\\\\\\\\\\_core import CoreSchema, core\\\\\\\\\\\\\\_schema from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, GetCoreSchemaHandler @dataclass class MyAfterValidator: func: Callable\\\\\\\\\\\\\\[\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], Any\\\\\\\\\\\\\\] def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( self, source\\\\\\\\\\\\\\_type: Any, handler: GetCoreSchemaHandler ) -> CoreSchema: return core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( self.func, handler(source\\\\\\\\\\\\\\_type) ) Username = Annotated\\\\\\\\\\\\\\[str, MyAfterValidator(str.lower)\\\\\\\\\\\\\\] class Model(BaseModel): name: Username assert Model(name='ABC').name == 'abc' Notice that type checkers will not complain about assigning 'abc' to Username like they did in the previous example because they do not consider Username to be a distinct type from str. Handling third-party types¶ Another use case for the pattern in the previous section is to handle third party types. from typing import Any from pydantic\\\\\\\\\\\\\\_core import core\\\\\\\\\\\\\\_schema from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import ( BaseModel, GetCoreSchemaHandler, GetJsonSchemaHandler, ValidationError, ) from pydantic.json\\\\\\\\\\\\\\_schema import JsonSchemaValue class ThirdPartyType: \"\"\" This is meant to represent a type from a third-party library that wasn't designed with Pydantic integration in mind, and so doesn't have a \\\\\\\\\\\\\\`pydantic\\\\\\\\\\\\\\_core.CoreSchema\\\\\\\\\\\\\\` or anything. \"\"\" x: int def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self): self.x = 0 class \\\\\\\\\\\\\\_ThirdPartyTypePydanticAnnotation: @classmethod def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( cls, \\\\\\\\\\\\\\_source\\\\\\\\\\\\\\_type: Any, \\\\\\\\\\\\\\_handler: GetCoreSchemaHandler, ) -> core\\\\\\\\\\\\\\_schema.CoreSchema: \"\"\" We return a pydantic\\\\\\\\\\\\\\_core.CoreSchema that behaves in the following ways: \\\\\\\\\\\\\\* ints will be parsed as \\\\\\\\\\\\\\`ThirdPartyType\\\\\\\\\\\\\\` instances with the int as the x attribute \\\\\\\\\\\\\\* \\\\\\\\\\\\\\`ThirdPartyType\\\\\\\\\\\\\\` instances will be parsed as \\\\\\\\\\\\\\`ThirdPartyType\\\\\\\\\\\\\\` instances without any changes \\\\\\\\\\\\\\* Nothing else will pass validation \\\\\\\\\\\\\\* Serialization will always return just an int \"\"\" def validate\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_int(value: int) -> ThirdPartyType: result = ThirdPartyType() result.x = value return result from\\\\\\\\\\\\\\_int\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.chain\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\[ core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema(), core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function(validate\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_int), \\\\\\\\\\\\\\] ) return core\\\\\\\\\\\\\\_schema.json\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_python\\\\\\\\\\\\\\_schema( json\\\\\\\\\\\\\\_schema=from\\\\\\\\\\\\\\_int\\\\\\\\\\\\\\_schema, python\\\\\\\\\\\\\\_schema=core\\\\\\\\\\\\\\_schema.union\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\[ # check if it's an instance first before doing any further work core\\\\\\\\\\\\\\_schema.is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_schema(ThirdPartyType), from\\\\\\\\\\\\\\_int\\\\\\\\\\\\\\_schema, \\\\\\\\\\\\\\] ), serialization=core\\\\\\\\\\\\\\_schema.plain\\\\\\\\\\\\\\_serializer\\\\\\\\\\\\\\_function\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema( lambda instance: instance.x ), ) @classmethod def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( cls, \\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema: core\\\\\\\\\\\\\\_schema.CoreSchema, handler: GetJsonSchemaHandler ) -> JsonSchemaValue: # Use the same schema that would be used for \\\\\\\\\\\\\\`int\\\\\\\\\\\\\\` return handler(core\\\\\\\\\\\\\\_schema.int\\\\\\\\\\\\\\_schema()) # We now create an \\\\\\\\\\\\\\`Annotated\\\\\\\\\\\\\\` wrapper that we'll use as the annotation for fields on \\\\\\\\\\\\\\`BaseModel\\\\\\\\\\\\\\`s, etc. PydanticThirdPartyType = Annotated\\\\\\\\\\\\\\[ ThirdPartyType, \\\\\\\\\\\\\\_ThirdPartyTypePydanticAnnotation \\\\\\\\\\\\\\] # Create a model class that uses this annotation as a field class Model(BaseModel): third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type: PydanticThirdPartyType # Demonstrate that this field is handled correctly, that ints are parsed into \\\\\\\\\\\\\\`ThirdPartyType\\\\\\\\\\\\\\`, and that # these instances are also \"dumped\" directly into ints as expected. m\\\\\\\\\\\\\\_int = Model(third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type=1) assert isinstance(m\\\\\\\\\\\\\\_int.third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type, ThirdPartyType) assert m\\\\\\\\\\\\\\_int.third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type.x == 1 assert m\\\\\\\\\\\\\\_int.model\\\\\\\\\\\\\\_dump() == {'third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type': 1} # Do the same thing where an instance of ThirdPartyType is passed in instance = ThirdPartyType() assert instance.x == 0 instance.x = 10 m\\\\\\\\\\\\\\_instance = Model(third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type=instance) assert isinstance(m\\\\\\\\\\\\\\_instance.third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type, ThirdPartyType) assert m\\\\\\\\\\\\\\_instance.third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type.x == 10 assert m\\\\\\\\\\\\\\_instance.model\\\\\\\\\\\\\\_dump() == {'third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type': 10} # Demonstrate that validation errors are raised as expected for invalid inputs try: Model(third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type='a') except ValidationError as e: print(e) \"\"\" 2 validation errors for Model third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type.is-instance\\\\\\\\\\\\\\[ThirdPartyType\\\\\\\\\\\\\\] Input should be an instance of ThirdPartyType \\\\\\\\\\\\\\[type=is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_of, input\\\\\\\\\\\\\\_value='a', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type.chain\\\\\\\\\\\\\\[int,function-plain\\\\\\\\\\\\\\[validate\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_int()\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='a', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" assert Model.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema() == { 'properties': { 'third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type': {'title': 'Third Party Type', 'type': 'integer'} }, 'required': \\\\\\\\\\\\\\['third\\\\\\\\\\\\\\_party\\\\\\\\\\\\\\_type'\\\\\\\\\\\\\\], 'title': 'Model', 'type': 'object', } You can use this approach to e.g. define behavior for Pandas or Numpy types. Using GetPydanticSchema to reduce boilerplate¶ API Documentation You may notice that the above examples where we create a marker class require a good amount of boilerplate. For many simple cases you can greatly minimize this by using pydantic.GetPydanticSchema: from pydantic\\\\\\\\\\\\\\_core import core\\\\\\\\\\\\\\_schema from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, GetPydanticSchema class Model(BaseModel): y: Annotated\\\\\\\\\\\\\\[ str, GetPydanticSchema( lambda tp, handler: core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( lambda x: x \\\\\\\\\\\\\\* 2, handler(tp) ) ), \\\\\\\\\\\\\\] assert Model(y='ab').y == 'abab' Summary¶ Let's recap: Pydantic provides high level hooks to customize types via Annotated like AfterValidator and Field. Use these when possible. Under the hood these use pydantic-core to customize validation, and you can hook into that directly using GetPydanticSchema or a marker class with \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. If you really want a custom type you can implement \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ on the type itself. Handling custom generic classes¶ Warning This is an advanced technique that you might not need in the beginning. In most of the cases you will probably be fine with standard Pydantic models. You can use Generic Classes as field types and perform custom validation based on the \"type parameters\" (or sub-types) with \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. If the Generic class that you are using as a sub-type has a classmethod \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, you don't need to use arbitrary\\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_allowed for it to work. Because the source\\\\\\\\\\\\\\_type parameter is not the same as the cls parameter, you can use typing.get\\\\\\\\\\\\\\_args (or typing\\\\\\\\\\\\\\_extensions.get\\\\\\\\\\\\\\_args) to extract the generic parameters. Then you can use the handler to generate a schema for them by calling handler.generate\\\\\\\\\\\\\\_schema. Note that we do not do something like handler(get\\\\\\\\\\\\\\_args(source\\\\\\\\\\\\\\_type)\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]) because we want to generate an unrelated schema for that generic parameter, not one that is influenced by the current context of Annotated metadata and such. This is less important for custom types, but crucial for annotated metadata that modifies schema building. from dataclasses import dataclass from typing import Any, Generic, TypeVar from pydantic\\\\\\\\\\\\\\_core import CoreSchema, core\\\\\\\\\\\\\\_schema from typing\\\\\\\\\\\\\\_extensions import get\\\\\\\\\\\\\\_args, get\\\\\\\\\\\\\\_origin from pydantic import ( BaseModel, GetCoreSchemaHandler, ValidationError, ValidatorFunctionWrapHandler, ) ItemType = TypeVar('ItemType') # This is not a pydantic model, it's an arbitrary generic class @dataclass class Owner(Generic\\\\\\\\\\\\\\[ItemType\\\\\\\\\\\\\\]): name: str item: ItemType @classmethod def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( cls, source\\\\\\\\\\\\\\_type: Any, handler: GetCoreSchemaHandler ) -> CoreSchema: origin = get\\\\\\\\\\\\\\_origin(source\\\\\\\\\\\\\\_type) if origin is None: # used as \\\\\\\\\\\\\\`x: Owner\\\\\\\\\\\\\\` without params origin = source\\\\\\\\\\\\\\_type item\\\\\\\\\\\\\\_tp = Any else: item\\\\\\\\\\\\\\_tp = get\\\\\\\\\\\\\\_args(source\\\\\\\\\\\\\\_type)\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\] # both calling handler(...) and handler.generate\\\\\\\\\\\\\\_schema(...) # would work, but prefer the latter for conceptual and consistency reasons item\\\\\\\\\\\\\\_schema = handler.generate\\\\\\\\\\\\\\_schema(item\\\\\\\\\\\\\\_tp) def val\\\\\\\\\\\\\\_item( v: Owner\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], handler: ValidatorFunctionWrapHandler ) -> Owner\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\]: v.item = handler(v.item) return v python\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.chain\\\\\\\\\\\\\\_schema( # \\\\\\\\\\\\\\`chain\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\` means do the following steps in order: \\\\\\\\\\\\\\[ # Ensure the value is an instance of Owner core\\\\\\\\\\\\\\_schema.is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_schema(cls), # Use the item\\\\\\\\\\\\\\_schema to validate \\\\\\\\\\\\\\`items\\\\\\\\\\\\\\` core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_wrap\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( val\\\\\\\\\\\\\\_item, item\\\\\\\\\\\\\\_schema ), \\\\\\\\\\\\\\] ) return core\\\\\\\\\\\\\\_schema.json\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_python\\\\\\\\\\\\\\_schema( # for JSON accept an object with name and item keys json\\\\\\\\\\\\\\_schema=core\\\\\\\\\\\\\\_schema.chain\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\[ core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_schema( { 'name': core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field( core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema() ), 'item': core\\\\\\\\\\\\\\_schema.typed\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_field(item\\\\\\\\\\\\\\_schema), } ), # after validating the json data convert it to python core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_before\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( lambda data: Owner( name=data\\\\\\\\\\\\\\['name'\\\\\\\\\\\\\\], item=data\\\\\\\\\\\\\\['item'\\\\\\\\\\\\\\] ), # note that we re-use the same schema here as below python\\\\\\\\\\\\\\_schema, ), \\\\\\\\\\\\\\] ), python\\\\\\\\\\\\\\_schema=python\\\\\\\\\\\\\\_schema, ) class Car(BaseModel): color: str class House(BaseModel): rooms: int class Model(BaseModel): car\\\\\\\\\\\\\\_owner: Owner\\\\\\\\\\\\\\[Car\\\\\\\\\\\\\\] home\\\\\\\\\\\\\\_owner: Owner\\\\\\\\\\\\\\[House\\\\\\\\\\\\\\] model = Model( car\\\\\\\\\\\\\\_owner=Owner(name='John', item=Car(color='black')), home\\\\\\\\\\\\\\_owner=Owner(name='James', item=House(rooms=3)), ) print(model) \"\"\" car\\\\\\\\\\\\\\_owner=Owner(name='John', item=Car(color='black')) home\\\\\\\\\\\\\\_owner=Owner(name='James', item=House(rooms=3)) \"\"\" try: # If the values of the sub-types are invalid, we get an error Model( car\\\\\\\\\\\\\\_owner=Owner(name='John', item=House(rooms=3)), home\\\\\\\\\\\\\\_owner=Owner(name='James', item=Car(color='black')), ) except ValidationError as e: print(e) \"\"\" 2 validation errors for Model wine Input should be a valid number, unable to parse string as a number \\\\\\\\\\\\\\[type=float\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='Kinda good', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] cheese Input should be a valid boolean, unable to interpret input \\\\\\\\\\\\\\[type=bool\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='yeah', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" # Similarly with JSON model = Model.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json( '{\"car\\\\\\\\\\\\\\_owner\":{\"name\":\"John\",\"item\":{\"color\":\"black\"}},\"home\\\\\\\\\\\\\\_owner\":{\"name\":\"James\",\"item\":{\"rooms\":3}}}' ) print(model) \"\"\" car\\\\\\\\\\\\\\_owner=Owner(name='John', item=Car(color='black')) home\\\\\\\\\\\\\\_owner=Owner(name='James', item=House(rooms=3)) \"\"\" try: Model.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json( '{\"car\\\\\\\\\\\\\\_owner\":{\"name\":\"John\",\"item\":{\"rooms\":3}},\"home\\\\\\\\\\\\\\_owner\":{\"name\":\"James\",\"item\":{\"color\":\"black\"}}}' ) except ValidationError as e: print(e) \"\"\" 2 validation errors for Model car\\\\\\\\\\\\\\_owner.item.color Field required \\\\\\\\\\\\\\[type=missing, input\\\\\\\\\\\\\\_value={'rooms': 3}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] home\\\\\\\\\\\\\\_owner.item.rooms Field required \\\\\\\\\\\\\\[type=missing, input\\\\\\\\\\\\\\_value={'color': 'black'}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] \"\"\" Generic containers¶ The same idea can be applied to create generic container types, like a custom Sequence type: from typing import Any, Sequence, TypeVar from pydantic\\\\\\\\\\\\\\_core import ValidationError, core\\\\\\\\\\\\\\_schema from typing\\\\\\\\\\\\\\_extensions import get\\\\\\\\\\\\\\_args from pydantic import BaseModel, GetCoreSchemaHandler T = TypeVar('T') class MySequence(Sequence\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\]): def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, v: Sequence\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\]): self.v = v def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_getitem\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, i): return self.v\\\\\\\\\\\\\\[i\\\\\\\\\\\\\\] def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_len\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self): return len(self.v) @classmethod def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( cls, source: Any, handler: GetCoreSchemaHandler ) -> core\\\\\\\\\\\\\\_schema.CoreSchema: instance\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_schema(cls) args = get\\\\\\\\\\\\\\_args(source) if args: # replace the type and rely on Pydantic to generate the right schema # for \\\\\\\\\\\\\\`Sequence\\\\\\\\\\\\\\` sequence\\\\\\\\\\\\\\_t\\\\\\\\\\\\\\_schema = handler.generate\\\\\\\\\\\\\\_schema(Sequence\\\\\\\\\\\\\\[args\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]) else: sequence\\\\\\\\\\\\\\_t\\\\\\\\\\\\\\_schema = handler.generate\\\\\\\\\\\\\\_schema(Sequence) non\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_schema = core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( MySequence, sequence\\\\\\\\\\\\\\_t\\\\\\\\\\\\\\_schema ) return core\\\\\\\\\\\\\\_schema.union\\\\\\\\\\\\\\_schema(\\\\\\\\\\\\\\[instance\\\\\\\\\\\\\\_schema, non\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\]) class M(BaseModel): model\\\\\\\\\\\\\\_config = dict(validate\\\\\\\\\\\\\\_default=True) s1: MySequence = \\\\\\\\\\\\\\[3\\\\\\\\\\\\\\] m = M() print(m) #> s1=<\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_main\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.MySequence object at 0x0123456789ab> print(m.s1.v) #> \\\\\\\\\\\\\\[3\\\\\\\\\\\\\\] class M(BaseModel): s1: MySequence\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] M(s1=\\\\\\\\\\\\\\[1\\\\\\\\\\\\\\]) try: M(s1=\\\\\\\\\\\\\\['a'\\\\\\\\\\\\\\]) except ValidationError as exc: print(exc) \"\"\" 2 validation errors for M s1.is-instance\\\\\\\\\\\\\\[MySequence\\\\\\\\\\\\\\] Input should be an instance of MySequence \\\\\\\\\\\\\\[type=is\\\\\\\\\\\\\\_instance\\\\\\\\\\\\\\_of, input\\\\\\\\\\\\\\_value=\\\\\\\\\\\\\\['a'\\\\\\\\\\\\\\], input\\\\\\\\\\\\\\_type=list\\\\\\\\\\\\\\] s1.function-after\\\\\\\\\\\\\\[MySequence(), json-or-python\\\\\\\\\\\\\\[json=list\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\],python=chain\\\\\\\\\\\\\\[is-instance\\\\\\\\\\\\\\[Sequence\\\\\\\\\\\\\\],function-wrap\\\\\\\\\\\\\\[sequence\\\\\\\\\\\\\\_validator()\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]\\\\\\\\\\\\\\].0 Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='a', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Access to field name¶ Note This was not possible with Pydantic V2 to V2.3, it was re-added in Pydantic V2.4. As of Pydantic V2.4, you can access the field name via the handler.field\\\\\\\\\\\\\\_name within \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and thereby set the field name which will be available from info.field\\\\\\\\\\\\\\_name. from typing import Any from pydantic\\\\\\\\\\\\\\_core import core\\\\\\\\\\\\\\_schema from pydantic import BaseModel, GetCoreSchemaHandler, ValidationInfo class CustomType: \"\"\"Custom type that stores the field it was used in.\"\"\" def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, value: int, field\\\\\\\\\\\\\\_name: str): self.value = value self.field\\\\\\\\\\\\\\_name = field\\\\\\\\\\\\\\_name def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_repr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self): return f'CustomType<{self.value} {self.field\\\\\\\\\\\\\\_name!r}>' @classmethod def validate(cls, value: int, info: ValidationInfo): return cls(value, info.field\\\\\\\\\\\\\\_name) @classmethod def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( cls, source\\\\\\\\\\\\\\_type: Any, handler: GetCoreSchemaHandler ) -> core\\\\\\\\\\\\\\_schema.CoreSchema: return core\\\\\\\\\\\\\\_schema.with\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( cls.validate, handler(int), field\\\\\\\\\\\\\\_name=handler.field\\\\\\\\\\\\\\_name ) class MyModel(BaseModel): my\\\\\\\\\\\\\\_field: CustomType m = MyModel(my\\\\\\\\\\\\\\_field=1) print(m.my\\\\\\\\\\\\\\_field) #> CustomType<1 'my\\\\\\\\\\\\\\_field'> You can also access field\\\\\\\\\\\\\\_name from the markers used with Annotated, like AfterValidator. from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import AfterValidator, BaseModel, ValidationInfo def my\\\\\\\\\\\\\\_validators(value: int, info: ValidationInfo): return f'<{value} {info.field\\\\\\\\\\\\\\_name!r}>' class MyModel(BaseModel): my\\\\\\\\\\\\\\_field: Annotated\\\\\\\\\\\\\\[int, AfterValidator(my\\\\\\\\\\\\\\_validators)\\\\\\\\\\\\\\] m = MyModel(my\\\\\\\\\\\\\\_field=1) print(m.my\\\\\\\\\\\\\\_field) #> <1 'my\\\\\\\\\\\\\\_field'> Made with Material for MkDocs Insiders"
  },
  {
    "title": "Unions - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/unions/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Unions Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Union Modes Left to Right Mode Smart Mode Discriminated Unions Discriminated Unions with str discriminators Discriminated Unions with callable Discriminator Nested Discriminated Unions Union Validation Errors Unions Unions are fundamentally different to all other types Pydantic validates - instead of requiring all fields/items/values to be valid, unions require only one member to be valid. This leads to some nuance around how to validate unions: which member(s) of the union should you validate data against, and in which order? which errors to raise when validation fails? Validating unions feels like adding another orthogonal dimension to the validation process. To solve these problems, Pydantic supports three fundamental approaches to validating unions: left to right mode - the simplest approach, each member of the union is tried in order and the first match is returned smart mode - similar to \"left to right mode\" members are tried in order; however, validation will proceed past the first match to attempt to find a better match, this is the default mode for most union validation discriminated unions - only one member of the union is tried, based on a discriminator Union Modes¶ Left to Right Mode¶ Note Because this mode often leads to unexpected validation results, it is not the default in Pydantic >=2, instead union\\\\\\\\\\\\\\_mode='smart' is the default. With this approach, validation is attempted against each member of the union in their order they're defined, and the first successful validation is accepted as input. If validation fails on all members, the validation error includes the errors from all members of the union. union\\\\\\\\\\\\\\_mode='left\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_right' must be set as a Field parameter on union fields where you want to use it. Union with left to right mode from typing import Union from pydantic import BaseModel, Field, ValidationError class User(BaseModel): id: Union\\\\\\\\\\\\\\[str, int\\\\\\\\\\\\\\] = Field(union\\\\\\\\\\\\\\_mode='left\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_right') print(User(id=123)) #> id=123 print(User(id='hello')) #> id='hello' try: User(id=\\\\\\\\\\\\\\[\\\\\\\\\\\\\\]) except ValidationError as e: print(e) \"\"\" 2 validation errors for User id.str Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=\\\\\\\\\\\\\\[\\\\\\\\\\\\\\], input\\\\\\\\\\\\\\_type=list\\\\\\\\\\\\\\] id.int Input should be a valid integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=\\\\\\\\\\\\\\[\\\\\\\\\\\\\\], input\\\\\\\\\\\\\\_type=list\\\\\\\\\\\\\\] \"\"\" The order of members is very important in this case, as demonstrated by tweak the above example: Union with left to right - unexpected results from typing import Union from pydantic import BaseModel, Field class User(BaseModel): id: Union\\\\\\\\\\\\\\[int, str\\\\\\\\\\\\\\] = Field(union\\\\\\\\\\\\\\_mode='left\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_right') print(User(id=123)) # As expected the input is validated against the int member and the result is as expected. #> id=123 print(User(id='456')) # We're in lax mode and the numeric string '123' is valid as input to the first member of the union, int. Since that is tried first, we get the surprising result of id being an int instead of a str. #> id=456 Smart Mode¶ Because of the surprising side effects of union\\\\\\\\\\\\\\_mode='left\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_right', in Pydantic >=2 the default mode for Union validation is union\\\\\\\\\\\\\\_mode='smart'. In this mode, pydantic scores a match of a union member into one of the following three groups (from highest score to lowest score): An exact type match, for example an int input to a float | int union validation is an exact type match for the int member Validation would have succeeded in strict mode Validation would have succeeded in lax mode The union match which produced the highest score will be selected as the best match. In this mode, the following steps are taken to try to select the best match for the input: Union members are attempted left to right, with any successful matches scored into one of the three categories described above. If validation succeeds with an exact type match, that member is returned immediately and following members will not be attempted. If validation succeeded on at least one member as a \"strict\" match, the leftmost of those \"strict\" matches is returned. If validation succeeded on at least one member in \"lax\" mode, the leftmost match is returned. Validation failed on all the members, return all the errors. from typing import Union from uuid import UUID from pydantic import BaseModel class User(BaseModel): id: Union\\\\\\\\\\\\\\[int, str, UUID\\\\\\\\\\\\\\] name: str user\\\\\\\\\\\\\\_01 = User(id=123, name='John Doe') print(user\\\\\\\\\\\\\\_01) #> id=123 name='John Doe' print(user\\\\\\\\\\\\\\_01.id) #> 123 user\\\\\\\\\\\\\\_02 = User(id='1234', name='John Doe') print(user\\\\\\\\\\\\\\_02) #> id='1234' name='John Doe' print(user\\\\\\\\\\\\\\_02.id) #> 1234 user\\\\\\\\\\\\\\_03\\\\\\\\\\\\\\_uuid = UUID('cf57432e-809e-4353-adbd-9d5c0d733868') user\\\\\\\\\\\\\\_03 = User(id=user\\\\\\\\\\\\\\_03\\\\\\\\\\\\\\_uuid, name='John Doe') print(user\\\\\\\\\\\\\\_03) #> id=UUID('cf57432e-809e-4353-adbd-9d5c0d733868') name='John Doe' print(user\\\\\\\\\\\\\\_03.id) #> cf57432e-809e-4353-adbd-9d5c0d733868 print(user\\\\\\\\\\\\\\_03\\\\\\\\\\\\\\_uuid.int) #> 275603287559914445491632874575877060712 Tip The type Optional\\\\\\\\\\\\\\[x\\\\\\\\\\\\\\] is a shorthand for Union\\\\\\\\\\\\\\[x, None\\\\\\\\\\\\\\]. See more details in Required fields. Discriminated Unions¶ Discriminated unions are sometimes referred to as \"Tagged Unions\". We can use discriminated unions to more efficiently validate Union types, by choosing which member of the union to validate against. This makes validation more efficient and also avoids a proliferation of errors when validation fails. Adding discriminator to unions also means the generated JSON schema implements the associated OpenAPI specification. Discriminated Unions with str discriminators¶ Frequently, in the case of a Union with multiple models, there is a common field to all members of the union that can be used to distinguish which union case the data should be validated against; this is referred to as the \"discriminator\" in OpenAPI. To validate models based on that information you can set the same field - let's call it my\\\\\\\\\\\\\\_discriminator - in each of the models with a discriminated value, which is one (or many) Literal value(s). For your Union, you can set the discriminator in its value: Field(discriminator='my\\\\\\\\\\\\\\_discriminator'). from typing import Literal, Union from pydantic import BaseModel, Field, ValidationError class Cat(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['cat'\\\\\\\\\\\\\\] meows: int class Dog(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['dog'\\\\\\\\\\\\\\] barks: float class Lizard(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['reptile', 'lizard'\\\\\\\\\\\\\\] scales: bool class Model(BaseModel): pet: Union\\\\\\\\\\\\\\[Cat, Dog, Lizard\\\\\\\\\\\\\\] = Field(..., discriminator='pet\\\\\\\\\\\\\\_type') n: int print(Model(pet={'pet\\\\\\\\\\\\\\_type': 'dog', 'barks': 3.14}, n=1)) #> pet=Dog(pet\\\\\\\\\\\\\\_type='dog', barks=3.14) n=1 try: Model(pet={'pet\\\\\\\\\\\\\\_type': 'dog'}, n=1) except ValidationError as e: print(e) \"\"\" 1 validation error for Model pet.dog.barks Field required \\\\\\\\\\\\\\[type=missing, input\\\\\\\\\\\\\\_value={'pet\\\\\\\\\\\\\\_type': 'dog'}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] \"\"\" Discriminated Unions with callable Discriminator¶ API Documentation In the case of a Union with multiple models, sometimes there isn't a single uniform field across all models that you can use as a discriminator. This is the perfect use case for a callable Discriminator. from typing import Any, Literal, Union from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, Discriminator, Tag class Pie(BaseModel): time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook: int num\\\\\\\\\\\\\\_ingredients: int class ApplePie(Pie): fruit: Literal\\\\\\\\\\\\\\['apple'\\\\\\\\\\\\\\] = 'apple' class PumpkinPie(Pie): filling: Literal\\\\\\\\\\\\\\['pumpkin'\\\\\\\\\\\\\\] = 'pumpkin' def get\\\\\\\\\\\\\\_discriminator\\\\\\\\\\\\\\_value(v: Any) -> str: if isinstance(v, dict): return v.get('fruit', v.get('filling')) return getattr(v, 'fruit', getattr(v, 'filling', None)) class ThanksgivingDinner(BaseModel): dessert: Annotated\\\\\\\\\\\\\\[ Union\\\\\\\\\\\\\\[ Annotated\\\\\\\\\\\\\\[ApplePie, Tag('apple')\\\\\\\\\\\\\\], Annotated\\\\\\\\\\\\\\[PumpkinPie, Tag('pumpkin')\\\\\\\\\\\\\\], \\\\\\\\\\\\\\], Discriminator(get\\\\\\\\\\\\\\_discriminator\\\\\\\\\\\\\\_value), \\\\\\\\\\\\\\] apple\\\\\\\\\\\\\\_variation = ThanksgivingDinner.model\\\\\\\\\\\\\\_validate( {'dessert': {'fruit': 'apple', 'time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook': 60, 'num\\\\\\\\\\\\\\_ingredients': 8}} ) print(repr(apple\\\\\\\\\\\\\\_variation)) \"\"\" ThanksgivingDinner(dessert=ApplePie(time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook=60, num\\\\\\\\\\\\\\_ingredients=8, fruit='apple')) \"\"\" pumpkin\\\\\\\\\\\\\\_variation = ThanksgivingDinner.model\\\\\\\\\\\\\\_validate( { 'dessert': { 'filling': 'pumpkin', 'time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook': 40, 'num\\\\\\\\\\\\\\_ingredients': 6, } } ) print(repr(pumpkin\\\\\\\\\\\\\\_variation)) \"\"\" ThanksgivingDinner(dessert=PumpkinPie(time\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_cook=40, num\\\\\\\\\\\\\\_ingredients=6, filling='pumpkin')) \"\"\" Discriminators can also be used to validate Union types with combinations of models and primitive types. For example: from typing import Any, Union from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, Discriminator, Tag, ValidationError def model\\\\\\\\\\\\\\_x\\\\\\\\\\\\\\_discriminator(v: Any) -> str: if isinstance(v, int): return 'int' if isinstance(v, (dict, BaseModel)): return 'model' else: # return None if the discriminator value isn't found return None class SpecialValue(BaseModel): value: int class DiscriminatedModel(BaseModel): value: Annotated\\\\\\\\\\\\\\[ Union\\\\\\\\\\\\\\[ Annotated\\\\\\\\\\\\\\[int, Tag('int')\\\\\\\\\\\\\\], Annotated\\\\\\\\\\\\\\['SpecialValue', Tag('model')\\\\\\\\\\\\\\], \\\\\\\\\\\\\\], Discriminator(model\\\\\\\\\\\\\\_x\\\\\\\\\\\\\\_discriminator), \\\\\\\\\\\\\\] model\\\\\\\\\\\\\\_data = {'value': {'value': 1}} m = DiscriminatedModel.model\\\\\\\\\\\\\\_validate(model\\\\\\\\\\\\\\_data) print(m) #> value=SpecialValue(value=1) int\\\\\\\\\\\\\\_data = {'value': 123} m = DiscriminatedModel.model\\\\\\\\\\\\\\_validate(int\\\\\\\\\\\\\\_data) print(m) #> value=123 try: DiscriminatedModel.model\\\\\\\\\\\\\\_validate({'value': 'not an int or a model'}) except ValidationError as e: print(e) Notice the callable discriminator function returns None if a discriminator value is not found. When None is returned, this union\\\\\\\\\\\\\\_tag\\\\\\\\\\\\\\_not\\\\\\\\\\\\\\_found error is raised. \"\"\" 1 validation error for DiscriminatedModel value Unable to extract tag using discriminator model\\\\\\\\\\\\\\_x\\\\\\\\\\\\\\_discriminator() \\\\\\\\\\\\\\[type=union\\\\\\\\\\\\\\_tag\\\\\\\\\\\\\\_not\\\\\\\\\\\\\\_found, input\\\\\\\\\\\\\\_value='not an int or a model', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Note Using the typing.Annotated fields syntax can be handy to regroup the Union and discriminator information. See the next example for more details. There are a few ways to set a discriminator for a field, all varying slightly in syntax. For str discriminators: some\\\\\\\\\\\\\\_field: Union\\\\\\\\\\\\\\[...\\\\\\\\\\\\\\] = Field(discriminator='my\\\\\\\\\\\\\\_discriminator' some\\\\\\\\\\\\\\_field: Annotated\\\\\\\\\\\\\\[Union\\\\\\\\\\\\\\[...\\\\\\\\\\\\\\], Field(discriminator='my\\\\\\\\\\\\\\_discriminator')\\\\\\\\\\\\\\] For callable Discriminators: some\\\\\\\\\\\\\\_field: Union\\\\\\\\\\\\\\[...\\\\\\\\\\\\\\] = Field(discriminator=Discriminator(...)) some\\\\\\\\\\\\\\_field: Annotated\\\\\\\\\\\\\\[Union\\\\\\\\\\\\\\[...\\\\\\\\\\\\\\], Discriminator(...)\\\\\\\\\\\\\\] some\\\\\\\\\\\\\\_field: Annotated\\\\\\\\\\\\\\[Union\\\\\\\\\\\\\\[...\\\\\\\\\\\\\\], Field(discriminator=Discriminator(...))\\\\\\\\\\\\\\] Warning Discriminated unions cannot be used with only a single variant, such as Union\\\\\\\\\\\\\\[Cat\\\\\\\\\\\\\\]. Python changes Union\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\] into T at interpretation time, so it is not possible for pydantic to distinguish fields of Union\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\] from T. Nested Discriminated Unions¶ Only one discriminator can be set for a field but sometimes you want to combine multiple discriminators. You can do it by creating nested Annotated types, e.g.: from typing import Literal, Union from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, Field, ValidationError class BlackCat(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['cat'\\\\\\\\\\\\\\] color: Literal\\\\\\\\\\\\\\['black'\\\\\\\\\\\\\\] black\\\\\\\\\\\\\\_name: str class WhiteCat(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['cat'\\\\\\\\\\\\\\] color: Literal\\\\\\\\\\\\\\['white'\\\\\\\\\\\\\\] white\\\\\\\\\\\\\\_name: str Cat = Annotated\\\\\\\\\\\\\\[Union\\\\\\\\\\\\\\[BlackCat, WhiteCat\\\\\\\\\\\\\\], Field(discriminator='color')\\\\\\\\\\\\\\] class Dog(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['dog'\\\\\\\\\\\\\\] name: str Pet = Annotated\\\\\\\\\\\\\\[Union\\\\\\\\\\\\\\[Cat, Dog\\\\\\\\\\\\\\], Field(discriminator='pet\\\\\\\\\\\\\\_type')\\\\\\\\\\\\\\] class Model(BaseModel): pet: Pet n: int m = Model(pet={'pet\\\\\\\\\\\\\\_type': 'cat', 'color': 'black', 'black\\\\\\\\\\\\\\_name': 'felix'}, n=1) print(m) #> pet=BlackCat(pet\\\\\\\\\\\\\\_type='cat', color='black', black\\\\\\\\\\\\\\_name='felix') n=1 try: Model(pet={'pet\\\\\\\\\\\\\\_type': 'cat', 'color': 'red'}, n='1') except ValidationError as e: print(e) \"\"\" 1 validation error for Model pet.cat Input tag 'red' found using 'color' does not match any of the expected tags: 'black', 'white' \\\\\\\\\\\\\\[type=union\\\\\\\\\\\\\\_tag\\\\\\\\\\\\\\_invalid, input\\\\\\\\\\\\\\_value={'pet\\\\\\\\\\\\\\_type': 'cat', 'color': 'red'}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] \"\"\" try: Model(pet={'pet\\\\\\\\\\\\\\_type': 'cat', 'color': 'black'}, n='1') except ValidationError as e: print(e) \"\"\" 1 validation error for Model pet.cat.black.black\\\\\\\\\\\\\\_name Field required \\\\\\\\\\\\\\[type=missing, input\\\\\\\\\\\\\\_value={'pet\\\\\\\\\\\\\\_type': 'cat', 'color': 'black'}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] \"\"\" Union Validation Errors¶ When Union validation fails, error messages can be quite verbose, as they will produce validation errors for each case in the union. This is especially noticeable when dealing with recursive models, where reasons may be generated at each level of recursion. Discriminated unions help to simplify error messages in this case, as validation errors are only produced for the case with a matching discriminator value. You can also customize the error type, message, and context for a Discriminator by passing these specifications as parameters to the Discriminator constructor, as seen in the example below. from typing import Union from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, Discriminator, Tag, ValidationError # Errors are quite verbose with a normal Union: class Model(BaseModel): x: Union\\\\\\\\\\\\\\[str, 'Model'\\\\\\\\\\\\\\] try: Model.model\\\\\\\\\\\\\\_validate({'x': {'x': {'x': 1}}}) except ValidationError as e: print(e) \"\"\" 4 validation errors for Model x.str Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value={'x': {'x': 1}}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] x.Model.x.str Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value={'x': 1}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] x.Model.x.Model.x.str Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=1, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] x.Model.x.Model.x.Model Input should be a valid dictionary or instance of Model \\\\\\\\\\\\\\[type=model\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=1, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] \"\"\" try: Model.model\\\\\\\\\\\\\\_validate({'x': {'x': {'x': {}}}}) except ValidationError as e: print(e) \"\"\" 4 validation errors for Model x.str Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value={'x': {'x': {}}}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] x.Model.x.str Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value={'x': {}}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] x.Model.x.Model.x.str Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value={}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] x.Model.x.Model.x.Model.x Field required \\\\\\\\\\\\\\[type=missing, input\\\\\\\\\\\\\\_value={}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] \"\"\" # Errors are much simpler with a discriminated union: def model\\\\\\\\\\\\\\_x\\\\\\\\\\\\\\_discriminator(v): if isinstance(v, str): return 'str' if isinstance(v, (dict, BaseModel)): return 'model' class DiscriminatedModel(BaseModel): x: Annotated\\\\\\\\\\\\\\[ Union\\\\\\\\\\\\\\[ Annotated\\\\\\\\\\\\\\[str, Tag('str')\\\\\\\\\\\\\\], Annotated\\\\\\\\\\\\\\['DiscriminatedModel', Tag('model')\\\\\\\\\\\\\\], \\\\\\\\\\\\\\], Discriminator( model\\\\\\\\\\\\\\_x\\\\\\\\\\\\\\_discriminator, custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_type='invalid\\\\\\\\\\\\\\_union\\\\\\\\\\\\\\_member', custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_type is the type attribute of the ValidationError raised when validation fails. custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_message='Invalid union member', custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_message is the msg attribute of the ValidationError raised when validation fails. custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_context={'discriminator': 'str\\\\\\\\\\\\\\_or\\\\\\\\\\\\\\_model'}, custom\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_context is the ctx attribute of the ValidationError raised when validation fails. ), \\\\\\\\\\\\\\] try: DiscriminatedModel.model\\\\\\\\\\\\\\_validate({'x': {'x': {'x': 1}}}) except ValidationError as e: print(e) \"\"\" 1 validation error for DiscriminatedModel x.model.x.model.x Invalid union member \\\\\\\\\\\\\\[type=invalid\\\\\\\\\\\\\\_union\\\\\\\\\\\\\\_member, input\\\\\\\\\\\\\\_value=1, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] \"\"\" try: DiscriminatedModel.model\\\\\\\\\\\\\\_validate({'x': {'x': {'x': {}}}}) except ValidationError as e: print(e) \"\"\" 1 validation error for DiscriminatedModel x.model.x.model.x.model.x Field required \\\\\\\\\\\\\\[type=missing, input\\\\\\\\\\\\\\_value={}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] \"\"\" # The data is still handled properly when valid: data = {'x': {'x': {'x': 'a'}}} m = DiscriminatedModel.model\\\\\\\\\\\\\\_validate(data) print(m.model\\\\\\\\\\\\\\_dump()) #> {'x': {'x': {'x': 'a'}}} You can also simplify error messages by labeling each case with a Tag. This is especially useful when you have complex types like those in this example: from typing import Dict, List, Union from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import AfterValidator, Tag, TypeAdapter, ValidationError DoubledList = Annotated\\\\\\\\\\\\\\[List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\], AfterValidator(lambda x: x \\\\\\\\\\\\\\* 2)\\\\\\\\\\\\\\] StringsMap = Dict\\\\\\\\\\\\\\[str, str\\\\\\\\\\\\\\] # Not using any \\\\\\\\\\\\\\`Tag\\\\\\\\\\\\\\`s for each union case, the errors are not so nice to look at adapter = TypeAdapter(Union\\\\\\\\\\\\\\[DoubledList, StringsMap\\\\\\\\\\\\\\]) try: adapter.validate\\\\\\\\\\\\\\_python(\\\\\\\\\\\\\\['a'\\\\\\\\\\\\\\]) except ValidationError as exc\\\\\\\\\\\\\\_info: print(exc\\\\\\\\\\\\\\_info) \"\"\" 2 validation errors for union\\\\\\\\\\\\\\[function-after\\\\\\\\\\\\\\[(), list\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\],dict\\\\\\\\\\\\\\[str,str\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] function-after\\\\\\\\\\\\\\[(), list\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\].0 Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='a', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] dict\\\\\\\\\\\\\\[str,str\\\\\\\\\\\\\\] Input should be a valid dictionary \\\\\\\\\\\\\\[type=dict\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=\\\\\\\\\\\\\\['a'\\\\\\\\\\\\\\], input\\\\\\\\\\\\\\_type=list\\\\\\\\\\\\\\] \"\"\" tag\\\\\\\\\\\\\\_adapter = TypeAdapter( Union\\\\\\\\\\\\\\[ Annotated\\\\\\\\\\\\\\[DoubledList, Tag('DoubledList')\\\\\\\\\\\\\\], Annotated\\\\\\\\\\\\\\[StringsMap, Tag('StringsMap')\\\\\\\\\\\\\\], \\\\\\\\\\\\\\] ) try: tag\\\\\\\\\\\\\\_adapter.validate\\\\\\\\\\\\\\_python(\\\\\\\\\\\\\\['a'\\\\\\\\\\\\\\]) except ValidationError as exc\\\\\\\\\\\\\\_info: print(exc\\\\\\\\\\\\\\_info) \"\"\" 2 validation errors for union\\\\\\\\\\\\\\[DoubledList,StringsMap\\\\\\\\\\\\\\] DoubledList.0 Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='a', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] StringsMap Input should be a valid dictionary \\\\\\\\\\\\\\[type=dict\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=\\\\\\\\\\\\\\['a'\\\\\\\\\\\\\\], input\\\\\\\\\\\\\\_type=list\\\\\\\\\\\\\\] \"\"\" Made with Material for MkDocs Insiders"
  },
  {
    "title": "JSON Schema - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/json_schema/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 JSON Schema Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents General notes on JSON schema generation Getting schema of a specified type Field customization Unenforced Field constraints typing.Annotated Fields Modifying the schema JSON schema types Top-level schema generation Schema customization Customizing the JSON schema generation process JSON Schema API Documentation Pydantic allows automatic creation of JSON schemas from models. Using Pydantic, there are several ways to generate JSON schemas or JSON representations from fields or models: BaseModel.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema returns a jsonable dict of the schema. BaseModel.model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json returns a JSON string representation of the dict of the schema. TypeAdapter.dump\\\\\\\\\\\\\\_json serializes an instance of the adapted type to JSON. TypeAdapter.json\\\\\\\\\\\\\\_schema generates a JSON schema for the adapted type. The generated JSON schemas are compliant with the following specifications: JSON Schema Draft 2020-12 OpenAPI extensions. import json from enum import Enum from typing import Union from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, Field from pydantic.config import ConfigDict class FooBar(BaseModel): count: int size: Union\\\\\\\\\\\\\\[float, None\\\\\\\\\\\\\\] = None class Gender(str, Enum): male = 'male' female = 'female' other = 'other' not\\\\\\\\\\\\\\_given = 'not\\\\\\\\\\\\\\_given' class MainModel(BaseModel): \"\"\" This is the description of the main model \"\"\" model\\\\\\\\\\\\\\_config = ConfigDict(title='Main') foo\\\\\\\\\\\\\\_bar: FooBar gender: Annotated\\\\\\\\\\\\\\[Union\\\\\\\\\\\\\\[Gender, None\\\\\\\\\\\\\\], Field(alias='Gender')\\\\\\\\\\\\\\] = None snap: int = Field( 42, title='The Snap', description='this is the value of snap', gt=30, lt=50, ) print(json.dumps(MainModel.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema(), indent=2)) JSON output: { \"$defs\": { \"FooBar\": { \"properties\": { \"count\": { \"title\": \"Count\", \"type\": \"integer\" }, \"size\": { \"anyOf\": \\\\\\\\\\\\\\[ { \"type\": \"number\" }, { \"type\": \"null\" } \\\\\\\\\\\\\\], \"default\": null, \"title\": \"Size\" } }, \"required\": \\\\\\\\\\\\\\[ \"count\" \\\\\\\\\\\\\\], \"title\": \"FooBar\", \"type\": \"object\" }, \"Gender\": { \"enum\": \\\\\\\\\\\\\\[ \"male\", \"female\", \"other\", \"not\\\\\\\\\\\\\\_given\" \\\\\\\\\\\\\\], \"title\": \"Gender\", \"type\": \"string\" } }, \"description\": \"This is the description of the main model\", \"properties\": { \"foo\\\\\\\\\\\\\\_bar\": { \"$ref\": \"#/$defs/FooBar\" }, \"Gender\": { \"anyOf\": \\\\\\\\\\\\\\[ { \"$ref\": \"#/$defs/Gender\" }, { \"type\": \"null\" } \\\\\\\\\\\\\\], \"default\": null }, \"snap\": { \"default\": 42, \"description\": \"this is the value of snap\", \"exclusiveMaximum\": 50, \"exclusiveMinimum\": 30, \"title\": \"The Snap\", \"type\": \"integer\" } }, \"required\": \\\\\\\\\\\\\\[ \"foo\\\\\\\\\\\\\\_bar\" \\\\\\\\\\\\\\], \"title\": \"Main\", \"type\": \"object\" } General notes on JSON schema generation¶ The JSON schema for Optional fields indicates that the value null is allowed. The Decimal type is exposed in JSON schema (and serialized) as a string. The JSON schema does not preserve namedtuples as namedtuples. When they differ, you can specify whether you want the JSON schema to represent the inputs to validation or the outputs from serialization. Sub-models used are added to the $defs JSON attribute and referenced, as per the spec. Sub-models with modifications (via the Field class) like a custom title, description, or default value, are recursively included instead of referenced. The description for models is taken from either the docstring of the class or the argument description to the Field class. The schema is generated by default using aliases as keys, but it can be generated using model property names instead by calling model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema() or model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json() with the by\\\\\\\\\\\\\\_alias=False keyword argument. The format of $refs can be altered by calling model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema() or model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json()\\\\\\\\\\\\\\]\\\\\\\\\\\\\\[pydantic.main.BaseModel.model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\] with the ref\\\\\\\\\\\\\\_template keyword argument. Note Regarding the \"jsonable\" nature of the model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema results, calling json.dumps(m.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema())on some BaseModel m returns a valid JSON string. Getting schema of a specified type¶ The TypeAdapter class lets you create an object with methods for validating, serializing, and producing JSON schemas for arbitrary types. This serves as a complete replacement for schema\\\\\\\\\\\\\\_of in Pydantic V1 (which is now deprecated). from typing import List from pydantic import TypeAdapter adapter = TypeAdapter(List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]) print(adapter.json\\\\\\\\\\\\\\_schema()) #> {'items': {'type': 'integer'}, 'type': 'array'} Field customization¶ Optionally, the Field function can be used to provide extra information about the field and validations. See Customizing JSON Schema for details on field parameters that are used exclusively to customize the generated JSON schema. You can also use model config to customize JSON serialization and extra schema properties on a model. Specifically, the following config options are relevant: title use\\\\\\\\\\\\\\_enum\\\\\\\\\\\\\\_values json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_timedelta ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_bytes ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan Unenforced Field constraints¶ If Pydantic finds constraints which are not being enforced, an error will be raised. If you want to force the constraint to appear in the schema, even though it's not being checked upon parsing, you can use variadic arguments to Field with the raw schema attribute name: from pydantic import BaseModel, Field, PositiveInt try: # this won't work since \\\\\\\\\\\\\\`PositiveInt\\\\\\\\\\\\\\` takes precedence over the # constraints defined in \\\\\\\\\\\\\\`Field\\\\\\\\\\\\\\`, meaning they're ignored class Model(BaseModel): foo: PositiveInt = Field(..., lt=10) except ValueError as e: print(e) # if you find yourself needing this, an alternative is to declare # the constraints in \\\\\\\\\\\\\\`Field\\\\\\\\\\\\\\` (or you could use \\\\\\\\\\\\\\`conint()\\\\\\\\\\\\\\`) # here both constraints will be enforced: class ModelB(BaseModel): # Here both constraints will be applied and the schema # will be generated correctly foo: int = Field(..., gt=0, lt=10) print(ModelB.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema()) \"\"\" { 'properties': { 'foo': { 'exclusiveMaximum': 10, 'exclusiveMinimum': 0, 'title': 'Foo', 'type': 'integer', } }, 'required': \\\\\\\\\\\\\\['foo'\\\\\\\\\\\\\\], 'title': 'ModelB', 'type': 'object', } \"\"\" typing.Annotated Fields¶ Rather than assigning a Field value, it can be specified in the type hint with typing.Annotated: from uuid import uuid4 from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, Field class Foo(BaseModel): id: Annotated\\\\\\\\\\\\\\[str, Field(default\\\\\\\\\\\\\\_factory=lambda: uuid4().hex)\\\\\\\\\\\\\\] name: Annotated\\\\\\\\\\\\\\[str, Field(max\\\\\\\\\\\\\\_length=256)\\\\\\\\\\\\\\] = Field('Bar', title='te') print(Foo.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema()) \"\"\" { 'properties': { 'id': {'title': 'Id', 'type': 'string'}, 'name': { 'default': 'Bar', 'maxLength': 256, 'title': 'te', 'type': 'string', }, }, 'title': 'Foo', 'type': 'object', } \"\"\" Note Defaults can be set outside Annotated as the assigned value or with Field.default\\\\\\\\\\\\\\_factory inside Annotated. The Field.default argument is not supported inside Annotated. For versions of Python prior to 3.9, typing\\\\\\\\\\\\\\_extensions.Annotated can be used. Modifying the schema¶ Custom types (used as field\\\\\\\\\\\\\\_name: TheType or field\\\\\\\\\\\\\\_name: Annotated\\\\\\\\\\\\\\[TheType, ...\\\\\\\\\\\\\\]) as well as Annotated metadata (used as field\\\\\\\\\\\\\\_name: Annotated\\\\\\\\\\\\\\[int, SomeMetadata\\\\\\\\\\\\\\]) can modify or override the generated schema by implementing \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. This method receives two positional arguments: The type annotation that corresponds to this type (so in the case of TheType\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\]\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] it would be TheType\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]). A handler/callback to call the next implementer of \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. The handler system works just like mode='wrap' validators. In this case the input is the type and the output is a core\\\\\\\\\\\\\\_schema. Here is an example of a custom type that overrides the generated core\\\\\\\\\\\\\\_schema: from dataclasses import dataclass from typing import Any, Dict, List, Type from pydantic\\\\\\\\\\\\\\_core import core\\\\\\\\\\\\\\_schema from pydantic import BaseModel, GetCoreSchemaHandler @dataclass class CompressedString: dictionary: Dict\\\\\\\\\\\\\\[int, str\\\\\\\\\\\\\\] text: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] def build(self) -> str: return ' '.join(\\\\\\\\\\\\\\[self.dictionary\\\\\\\\\\\\\\[key\\\\\\\\\\\\\\] for key in self.text\\\\\\\\\\\\\\]) @classmethod def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( cls, source: Type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], handler: GetCoreSchemaHandler ) -> core\\\\\\\\\\\\\\_schema.CoreSchema: assert source is CompressedString return core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( cls.\\\\\\\\\\\\\\_validate, core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(), serialization=core\\\\\\\\\\\\\\_schema.plain\\\\\\\\\\\\\\_serializer\\\\\\\\\\\\\\_function\\\\\\\\\\\\\\_ser\\\\\\\\\\\\\\_schema( cls.\\\\\\\\\\\\\\_serialize, info\\\\\\\\\\\\\\_arg=False, return\\\\\\\\\\\\\\_schema=core\\\\\\\\\\\\\\_schema.str\\\\\\\\\\\\\\_schema(), ), ) @staticmethod def \\\\\\\\\\\\\\_validate(value: str) -> 'CompressedString': inverse\\\\\\\\\\\\\\_dictionary: Dict\\\\\\\\\\\\\\[str, int\\\\\\\\\\\\\\] = {} text: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] = \\\\\\\\\\\\\\[\\\\\\\\\\\\\\] for word in value.split(' '): if word not in inverse\\\\\\\\\\\\\\_dictionary: inverse\\\\\\\\\\\\\\_dictionary\\\\\\\\\\\\\\[word\\\\\\\\\\\\\\] = len(inverse\\\\\\\\\\\\\\_dictionary) text.append(inverse\\\\\\\\\\\\\\_dictionary\\\\\\\\\\\\\\[word\\\\\\\\\\\\\\]) return CompressedString( {v: k for k, v in inverse\\\\\\\\\\\\\\_dictionary.items()}, text ) @staticmethod def \\\\\\\\\\\\\\_serialize(value: 'CompressedString') -> str: return value.build() class MyModel(BaseModel): value: CompressedString print(MyModel.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema()) \"\"\" { 'properties': {'value': {'title': 'Value', 'type': 'string'}}, 'required': \\\\\\\\\\\\\\['value'\\\\\\\\\\\\\\], 'title': 'MyModel', 'type': 'object', } \"\"\" print(MyModel(value='fox fox fox dog fox')) \"\"\" value = CompressedString(dictionary={0: 'fox', 1: 'dog'}, text=\\\\\\\\\\\\\\[0, 0, 0, 1, 0\\\\\\\\\\\\\\]) \"\"\" print(MyModel(value='fox fox fox dog fox').model\\\\\\\\\\\\\\_dump(mode='json')) #> {'value': 'fox fox fox dog fox'} Since Pydantic would not know how to generate a schema for CompressedString, if you call handler(source) in its \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method you would get a pydantic.errors.PydanticSchemaGenerationError error. This will be the case for most custom types, so you almost never want to call into handler for custom types. The process for Annotated metadata is much the same except that you can generally call into handler to have Pydantic handle generating the schema. from dataclasses import dataclass from typing import Any, Sequence, Type from pydantic\\\\\\\\\\\\\\_core import core\\\\\\\\\\\\\\_schema from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, GetCoreSchemaHandler, ValidationError @dataclass class RestrictCharacters: alphabet: Sequence\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( self, source: Type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], handler: GetCoreSchemaHandler ) -> core\\\\\\\\\\\\\\_schema.CoreSchema: if not self.alphabet: raise ValueError('Alphabet may not be empty') schema = handler( source ) # get the CoreSchema from the type / inner constraints if schema\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\] != 'str': raise TypeError('RestrictCharacters can only be applied to strings') return core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_after\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function( self.validate, schema, ) def validate(self, value: str) -> str: if any(c not in self.alphabet for c in value): raise ValueError( f'{value!r} is not restricted to {self.alphabet!r}' ) return value class MyModel(BaseModel): value: Annotated\\\\\\\\\\\\\\[str, RestrictCharacters('ABC')\\\\\\\\\\\\\\] print(MyModel.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema()) \"\"\" { 'properties': {'value': {'title': 'Value', 'type': 'string'}}, 'required': \\\\\\\\\\\\\\['value'\\\\\\\\\\\\\\], 'title': 'MyModel', 'type': 'object', } \"\"\" print(MyModel(value='CBA')) #> value='CBA' try: MyModel(value='XYZ') except ValidationError as e: print(e) \"\"\" 1 validation error for MyModel value Value error, 'XYZ' is not restricted to 'ABC' \\\\\\\\\\\\\\[type=value\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='XYZ', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" So far we have been wrapping the schema, but if you just want to modify it or ignore it you can as well. To modify the schema, first call the handler, then mutate the result: from typing import Any, Type from pydantic\\\\\\\\\\\\\\_core import ValidationError, core\\\\\\\\\\\\\\_schema from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, GetCoreSchemaHandler class SmallString: def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( self, source: Type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], handler: GetCoreSchemaHandler, ) -> core\\\\\\\\\\\\\\_schema.CoreSchema: schema = handler(source) assert schema\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\] == 'str' schema\\\\\\\\\\\\\\['max\\\\\\\\\\\\\\_length'\\\\\\\\\\\\\\] = 10 # modify in place return schema class MyModel(BaseModel): value: Annotated\\\\\\\\\\\\\\[str, SmallString()\\\\\\\\\\\\\\] try: MyModel(value='too long!!!!!') except ValidationError as e: print(e) \"\"\" 1 validation error for MyModel value String should have at most 10 characters \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_too\\\\\\\\\\\\\\_long, input\\\\\\\\\\\\\\_value='too long!!!!!', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" To override the schema completely, do not call the handler and return your own CoreSchema: from typing import Any, Type from pydantic\\\\\\\\\\\\\\_core import ValidationError, core\\\\\\\\\\\\\\_schema from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, GetCoreSchemaHandler class AllowAnySubclass: def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( self, source: Type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], handler: GetCoreSchemaHandler ) -> core\\\\\\\\\\\\\\_schema.CoreSchema: # we can't call handler since it will fail for arbitrary types def validate(value: Any) -> Any: if not isinstance(value, source): raise ValueError( f'Expected an instance of {source}, got an instance of {type(value)}' ) return core\\\\\\\\\\\\\\_schema.no\\\\\\\\\\\\\\_info\\\\\\\\\\\\\\_plain\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_function(validate) class Foo: pass class Model(BaseModel): f: Annotated\\\\\\\\\\\\\\[Foo, AllowAnySubclass()\\\\\\\\\\\\\\] print(Model(f=Foo())) #> f=None class NotFoo: pass try: Model(f=NotFoo()) except ValidationError as e: print(e) \"\"\" 1 validation error for Model f Value error, Expected an instance of , got an instance of \\\\\\\\\\\\\\[type=value\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value=<\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_main\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.NotFoo object at 0x0123456789ab>, input\\\\\\\\\\\\\\_type=NotFoo\\\\\\\\\\\\\\] \"\"\" As seen above, annotating a field with a BaseModel type can be used to modify or override the generated json schema. However, if you want to take advantage of storing metadata via Annotated, but you don't want to override the generated JSON schema, you can use the following approach with a no-op version of \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ implemented on the metadata class: from typing import Type from pydantic\\\\\\\\\\\\\\_core import CoreSchema from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, GetCoreSchemaHandler class Metadata(BaseModel): foo: str = 'metadata!' bar: int = 100 @classmethod def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( cls, source\\\\\\\\\\\\\\_type: Type\\\\\\\\\\\\\\[BaseModel\\\\\\\\\\\\\\], handler: GetCoreSchemaHandler ) -> CoreSchema: if cls is not source\\\\\\\\\\\\\\_type: return handler(source\\\\\\\\\\\\\\_type) return super().\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(source\\\\\\\\\\\\\\_type, handler) class Model(BaseModel): state: Annotated\\\\\\\\\\\\\\[int, Metadata()\\\\\\\\\\\\\\] m = Model.model\\\\\\\\\\\\\\_validate({'state': 2}) print(repr(m)) #> Model(state=2) print(m.model\\\\\\\\\\\\\\_fields) \"\"\" { 'state': FieldInfo( annotation=int, required=True, metadata=\\\\\\\\\\\\\\[Metadata(foo='metadata!', bar=100)\\\\\\\\\\\\\\], ) } \"\"\" JSON schema types¶ Types, custom field types, and constraints (like max\\\\\\\\\\\\\\_length) are mapped to the corresponding spec formats in the following priority order (when there is an equivalent available): JSON Schema Core JSON Schema Validation OpenAPI Data Types The standard format JSON field is used to define Pydantic extensions for more complex string sub-types. The field schema mapping from Python or Pydantic to JSON schema is done as follows: Top-level schema generation¶ You can also generate a top-level JSON schema that only includes a list of models and related sub-models in its $defs: import json from pydantic import BaseModel from pydantic.json\\\\\\\\\\\\\\_schema import models\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema class Foo(BaseModel): a: str = None class Model(BaseModel): b: Foo class Bar(BaseModel): c: int \\\\\\\\\\\\\\_, top\\\\\\\\\\\\\\_level\\\\\\\\\\\\\\_schema = models\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema( \\\\\\\\\\\\\\[(Model, 'validation'), (Bar, 'validation')\\\\\\\\\\\\\\], title='My Schema' ) print(json.dumps(top\\\\\\\\\\\\\\_level\\\\\\\\\\\\\\_schema, indent=2)) JSON output: { \"$defs\": { \"Bar\": { \"properties\": { \"c\": { \"title\": \"C\", \"type\": \"integer\" } }, \"required\": \\\\\\\\\\\\\\[ \"c\" \\\\\\\\\\\\\\], \"title\": \"Bar\", \"type\": \"object\" }, \"Foo\": { \"properties\": { \"a\": { \"default\": null, \"title\": \"A\", \"type\": \"string\" } }, \"title\": \"Foo\", \"type\": \"object\" }, \"Model\": { \"properties\": { \"b\": { \"$ref\": \"#/$defs/Foo\" } }, \"required\": \\\\\\\\\\\\\\[ \"b\" \\\\\\\\\\\\\\], \"title\": \"Model\", \"type\": \"object\" } }, \"title\": \"My Schema\" } Schema customization¶ You can customize the generated $ref JSON location: the definitions are always stored under the key $defs, but a specified prefix can be used for the references. This is useful if you need to extend or modify the JSON schema default definitions location. For example, with OpenAPI: import json from pydantic import BaseModel from pydantic.type\\\\\\\\\\\\\\_adapter import TypeAdapter class Foo(BaseModel): a: int class Model(BaseModel): a: Foo adapter = TypeAdapter(Model) print( json.dumps( adapter.json\\\\\\\\\\\\\\_schema(ref\\\\\\\\\\\\\\_template='#/components/schemas/{model}'), indent=2, ) ) JSON output: { \"$defs\": { \"Foo\": { \"properties\": { \"a\": { \"title\": \"A\", \"type\": \"integer\" } }, \"required\": \\\\\\\\\\\\\\[ \"a\" \\\\\\\\\\\\\\], \"title\": \"Foo\", \"type\": \"object\" } }, \"properties\": { \"a\": { \"$ref\": \"#/components/schemas/Foo\" } }, \"required\": \\\\\\\\\\\\\\[ \"a\" \\\\\\\\\\\\\\], \"title\": \"Model\", \"type\": \"object\" } It's also possible to extend or override the generated JSON schema in a model by implementing \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ on your model. For example, you could add examples to the JSON schema: import json from pydantic\\\\\\\\\\\\\\_core import CoreSchema from pydantic import BaseModel, GetJsonSchemaHandler from pydantic.json\\\\\\\\\\\\\\_schema import JsonSchemaValue class Person(BaseModel): name: str age: int @classmethod def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_( cls, core\\\\\\\\\\\\\\_schema: CoreSchema, handler: GetJsonSchemaHandler ) -> JsonSchemaValue: json\\\\\\\\\\\\\\_schema = handler(core\\\\\\\\\\\\\\_schema) json\\\\\\\\\\\\\\_schema = handler.resolve\\\\\\\\\\\\\\_ref\\\\\\\\\\\\\\_schema(json\\\\\\\\\\\\\\_schema) json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\['examples'\\\\\\\\\\\\\\] = \\\\\\\\\\\\\\[ { 'name': 'John Doe', 'age': 25, } \\\\\\\\\\\\\\] return json\\\\\\\\\\\\\\_schema print(json.dumps(Person.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema(), indent=2)) JSON output: { \"examples\": \\\\\\\\\\\\\\[ { \"age\": 25, \"name\": \"John Doe\" } \\\\\\\\\\\\\\], \"properties\": { \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"age\": { \"title\": \"Age\", \"type\": \"integer\" } }, \"required\": \\\\\\\\\\\\\\[ \"name\", \"age\" \\\\\\\\\\\\\\], \"title\": \"Person\", \"type\": \"object\" } Note that you must return a schema, even if you are just mutating it in place. Customizing the JSON schema generation process¶ API Documentation If you need custom schema generation, you can use a schema\\\\\\\\\\\\\\_generator, modifying the GenerateJsonSchema class as necessary for your application. The various methods that can be used to produce JSON schema accept a keyword argument schema\\\\\\\\\\\\\\_generator: type\\\\\\\\\\\\\\[GenerateJsonSchema\\\\\\\\\\\\\\] = GenerateJsonSchema, and you can pass your custom subclass to these methods in order to use your own approach to generating JSON schema. GenerateJsonSchema implements the translation of a type's pydantic-core schema into a JSON schema. By design, this class breaks the JSON schema generation process into smaller methods that can be easily overridden in subclasses to modify the \"global\" approach to generating JSON schema. from pydantic import BaseModel from pydantic.json\\\\\\\\\\\\\\_schema import GenerateJsonSchema class MyGenerateJsonSchema(GenerateJsonSchema): def generate(self, schema, mode='validation'): json\\\\\\\\\\\\\\_schema = super().generate(schema, mode=mode) json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\['title'\\\\\\\\\\\\\\] = 'Customize title' json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\['$schema'\\\\\\\\\\\\\\] = self.schema\\\\\\\\\\\\\\_dialect return json\\\\\\\\\\\\\\_schema class MyModel(BaseModel): x: int print(MyModel.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema(schema\\\\\\\\\\\\\\_generator=MyGenerateJsonSchema)) \"\"\" { 'properties': {'x': {'title': 'X', 'type': 'integer'}}, 'required': \\\\\\\\\\\\\\['x'\\\\\\\\\\\\\\], 'title': 'Customize title', 'type': 'object', '$schema': 'https://json-schema.org/draft/2020-12/schema', } \"\"\" Below is an approach you can use to exclude any fields from the schema that don't have valid json schemas: from typing import Callable from pydantic\\\\\\\\\\\\\\_core import PydanticOmit, core\\\\\\\\\\\\\\_schema from pydantic import BaseModel from pydantic.json\\\\\\\\\\\\\\_schema import GenerateJsonSchema, JsonSchemaValue class MyGenerateJsonSchema(GenerateJsonSchema): def handle\\\\\\\\\\\\\\_invalid\\\\\\\\\\\\\\_for\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema( self, schema: core\\\\\\\\\\\\\\_schema.CoreSchema, error\\\\\\\\\\\\\\_info: str ) -> JsonSchemaValue: raise PydanticOmit def example\\\\\\\\\\\\\\_callable(): return 1 class Example(BaseModel): name: str = 'example' function: Callable = example\\\\\\\\\\\\\\_callable instance\\\\\\\\\\\\\\_example = Example() validation\\\\\\\\\\\\\\_schema = instance\\\\\\\\\\\\\\_example.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema( schema\\\\\\\\\\\\\\_generator=MyGenerateJsonSchema, mode='validation' ) print(validation\\\\\\\\\\\\\\_schema) \"\"\" { 'properties': { 'name': {'default': 'example', 'title': 'Name', 'type': 'string'} }, 'title': 'Example', 'type': 'object', } \"\"\" Made with Material for MkDocs Insiders"
  },
  {
    "title": "JSON - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/json/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 JSON Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Json Parsing JSON Serialization 🚧 Work in Progress This page is a work in progress. JSON¶ Json Parsing¶ API Documentation Pydantic provides builtin JSON parsing, which helps achieve: Significant performance improvements without the cost of using a 3rd party library Support for custom errors Support for strict specifications Here's an example of Pydantic's builtin JSON parsing via the model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json method, showcasing the support for strict specifications while parsing JSON data that doesn't match the model's type annotations: Python 3.7 and above Python 3.9 and above from datetime import date from typing import Tuple from pydantic import BaseModel, ConfigDict, ValidationError class Event(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(strict=True) when: date where: Tuple\\\\\\\\\\\\\\[int, int\\\\\\\\\\\\\\] json\\\\\\\\\\\\\\_data = '{\"when\": \"1987-01-28\", \"where\": \\\\\\\\\\\\\\[51, -1\\\\\\\\\\\\\\]}' print(Event.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json(json\\\\\\\\\\\\\\_data)) JSON has no date or tuple types, but Pydantic knows that so allows strings and arrays as inputs respectively when parsing JSON directly. #> when=datetime.date(1987, 1, 28) where=(51, -1) try: Event.model\\\\\\\\\\\\\\_validate({'when': '1987-01-28', 'where': \\\\\\\\\\\\\\[51, -1\\\\\\\\\\\\\\]}) If you pass the same values to the model\\\\\\\\\\\\\\_validate method, Pydantic will raise a validation error because the strict configuration is enabled. except ValidationError as e: print(e) \"\"\" 2 validation errors for Event when Input should be a valid date \\\\\\\\\\\\\\[type=date\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value='1987-01-28', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] where Input should be a valid tuple \\\\\\\\\\\\\\[type=tuple\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=\\\\\\\\\\\\\\[51, -1\\\\\\\\\\\\\\], input\\\\\\\\\\\\\\_type=list\\\\\\\\\\\\\\] \"\"\" In v2.5.0 and above, Pydantic uses jiter, a fast and iterable JSON parser, to parse JSON data. Using jiter compared to serde results in modest performance improvements that will get even better in the future. The jiter JSON parser is almost entirely compatible with the serde JSON parser, with one noticeable enhancement being that jiter supports deserialization of inf and NaN values. In the future, jiter is intended to enable support validation errors to include the location in the original JSON input which contained the invalid value. JSON Serialization¶ API Documentation For more information on JSON serialization, see the Serialization Concepts page. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Fields - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/fields/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Fields Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents Default values Using Annotated Field aliases Validation Alias AliasPath and AliasChoices Numeric Constraints String Constraints Decimal Constraints Dataclass Constraints Validate Default Values Field Representation Discriminator Strict Mode Immutability Exclude Customizing JSON Schema Fields API Documentation The Field function is used to customize and add metadata to fields of models. Default values¶ The default parameter is used to define a default value for a field. from pydantic import BaseModel, Field class User(BaseModel): name: str = Field(default='John Doe') user = User() print(user) #> name='John Doe' You can also use default\\\\\\\\\\\\\\_factory to define a callable that will be called to generate a default value. from uuid import uuid4 from pydantic import BaseModel, Field class User(BaseModel): id: str = Field(default\\\\\\\\\\\\\\_factory=lambda: uuid4().hex) Info The default and default\\\\\\\\\\\\\\_factory parameters are mutually exclusive. Note If you use typing.Optional, it doesn't mean that the field has a default value of None! Using Annotated¶ The Field function can also be used together with Annotated. from uuid import uuid4 from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, Field class User(BaseModel): id: Annotated\\\\\\\\\\\\\\[str, Field(default\\\\\\\\\\\\\\_factory=lambda: uuid4().hex)\\\\\\\\\\\\\\] Field aliases¶ For validation and serialization, you can define an alias for a field. There are three ways to define an alias: Field(..., alias='foo') Field(..., validation\\\\\\\\\\\\\\_alias='foo') Field(..., serialization\\\\\\\\\\\\\\_alias='foo') The alias parameter is used for both validation and serialization. If you want to use different aliases for validation and serialization respectively, you can use thevalidation\\\\\\\\\\\\\\_alias and serialization\\\\\\\\\\\\\\_alias parameters, which will apply only in their respective use cases. Here is some example usage of the alias parameter: from pydantic import BaseModel, Field class User(BaseModel): name: str = Field(..., alias='username') user = User(username='johndoe') The alias 'username' is used for instance creation and validation. print(user) #> name='johndoe' print(user.model\\\\\\\\\\\\\\_dump(by\\\\\\\\\\\\\\_alias=True)) We are using model\\\\\\\\\\\\\\_dump to convert the model into a serializable format. You can see more details about model\\\\\\\\\\\\\\_dump in the API reference. Note that the by\\\\\\\\\\\\\\_alias keyword argument defaults to False, and must be specified explicitly to dump models using the field (serialization) aliases. When by\\\\\\\\\\\\\\_alias=True, the alias 'username' is also used during serialization. #> {'username': 'johndoe'} If you want to use an alias only for validation, you can use the validation\\\\\\\\\\\\\\_alias parameter: from pydantic import BaseModel, Field class User(BaseModel): name: str = Field(..., validation\\\\\\\\\\\\\\_alias='username') user = User(username='johndoe') The validation alias 'username' is used during validation. print(user) #> name='johndoe' print(user.model\\\\\\\\\\\\\\_dump(by\\\\\\\\\\\\\\_alias=True)) The field name 'name' is used during serialization. #> {'name': 'johndoe'} If you only want to define an alias for serialization, you can use the serialization\\\\\\\\\\\\\\_alias parameter: from pydantic import BaseModel, Field class User(BaseModel): name: str = Field(..., serialization\\\\\\\\\\\\\\_alias='username') user = User(name='johndoe') The field name 'name' is used for validation. print(user) #> name='johndoe' print(user.model\\\\\\\\\\\\\\_dump(by\\\\\\\\\\\\\\_alias=True)) The serialization alias 'username' is used for serialization. #> {'username': 'johndoe'} Alias precedence and priority In case you use alias together with validation\\\\\\\\\\\\\\_alias or serialization\\\\\\\\\\\\\\_alias at the same time, the validation\\\\\\\\\\\\\\_alias will have priority over alias for validation, and serialization\\\\\\\\\\\\\\_alias will have priority over alias for serialization. You may also set alias\\\\\\\\\\\\\\_priority on a field to change this behavior. You can read more about Alias Precedence in the Model Config documentation. VSCode and Pyright users AliasPath and AliasChoices¶ API Documentation Pydantic provides two special types for convenience when using validation\\\\\\\\\\\\\\_alias: AliasPath and AliasChoices. The AliasPath is used to specify a path to a field using aliases. For example: from pydantic import BaseModel, Field, AliasPath class User(BaseModel): first\\\\\\\\\\\\\\_name: str = Field(validation\\\\\\\\\\\\\\_alias=AliasPath('names', 0)) last\\\\\\\\\\\\\\_name: str = Field(validation\\\\\\\\\\\\\\_alias=AliasPath('names', 1)) user = User.model\\\\\\\\\\\\\\_validate({'names': \\\\\\\\\\\\\\['John', 'Doe'\\\\\\\\\\\\\\]}) We are using model\\\\\\\\\\\\\\_validate to validate a dictionary using the field aliases. You can see more details about model\\\\\\\\\\\\\\_validate in the API reference. print(user) #> first\\\\\\\\\\\\\\_name='John' last\\\\\\\\\\\\\\_name='Doe' In the 'first\\\\\\\\\\\\\\_name' field, we are using the alias 'names' and the index 0 to specify the path to the first name. In the 'last\\\\\\\\\\\\\\_name' field, we are using the alias 'names' and the index 1 to specify the path to the last name. AliasChoices is used to specify a choice of aliases. For example: from pydantic import BaseModel, Field, AliasChoices class User(BaseModel): first\\\\\\\\\\\\\\_name: str = Field(validation\\\\\\\\\\\\\\_alias=AliasChoices('first\\\\\\\\\\\\\\_name', 'fname')) last\\\\\\\\\\\\\\_name: str = Field(validation\\\\\\\\\\\\\\_alias=AliasChoices('last\\\\\\\\\\\\\\_name', 'lname')) user = User.model\\\\\\\\\\\\\\_validate({'fname': 'John', 'lname': 'Doe'}) We are using the second alias choice for both fields. print(user) #> first\\\\\\\\\\\\\\_name='John' last\\\\\\\\\\\\\\_name='Doe' user = User.model\\\\\\\\\\\\\\_validate({'first\\\\\\\\\\\\\\_name': 'John', 'lname': 'Doe'}) We are using the first alias choice for the field 'first\\\\\\\\\\\\\\_name' and the second alias choice for the field 'last\\\\\\\\\\\\\\_name'. print(user) #> first\\\\\\\\\\\\\\_name='John' last\\\\\\\\\\\\\\_name='Doe' You can also use AliasChoices with AliasPath: from pydantic import BaseModel, Field, AliasPath, AliasChoices class User(BaseModel): first\\\\\\\\\\\\\\_name: str = Field(validation\\\\\\\\\\\\\\_alias=AliasChoices('first\\\\\\\\\\\\\\_name', AliasPath('names', 0))) last\\\\\\\\\\\\\\_name: str = Field(validation\\\\\\\\\\\\\\_alias=AliasChoices('last\\\\\\\\\\\\\\_name', AliasPath('names', 1))) user = User.model\\\\\\\\\\\\\\_validate({'first\\\\\\\\\\\\\\_name': 'John', 'last\\\\\\\\\\\\\\_name': 'Doe'}) print(user) #> first\\\\\\\\\\\\\\_name='John' last\\\\\\\\\\\\\\_name='Doe' user = User.model\\\\\\\\\\\\\\_validate({'names': \\\\\\\\\\\\\\['John', 'Doe'\\\\\\\\\\\\\\]}) print(user) #> first\\\\\\\\\\\\\\_name='John' last\\\\\\\\\\\\\\_name='Doe' user = User.model\\\\\\\\\\\\\\_validate({'names': \\\\\\\\\\\\\\['John'\\\\\\\\\\\\\\], 'last\\\\\\\\\\\\\\_name': 'Doe'}) print(user) #> first\\\\\\\\\\\\\\_name='John' last\\\\\\\\\\\\\\_name='Doe' Numeric Constraints¶ There are some keyword arguments that can be used to constrain numeric values: gt - greater than lt - less than ge - greater than or equal to le - less than or equal to multiple\\\\\\\\\\\\\\_of - a multiple of the given number allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan - allow 'inf', '-inf', 'nan' values Here's an example: from pydantic import BaseModel, Field class Foo(BaseModel): positive: int = Field(gt=0) non\\\\\\\\\\\\\\_negative: int = Field(ge=0) negative: int = Field(lt=0) non\\\\\\\\\\\\\\_positive: int = Field(le=0) even: int = Field(multiple\\\\\\\\\\\\\\_of=2) love\\\\\\\\\\\\\\_for\\\\\\\\\\\\\\_pydantic: float = Field(allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan=True) foo = Foo( positive=1, non\\\\\\\\\\\\\\_negative=0, negative=-1, non\\\\\\\\\\\\\\_positive=0, even=2, love\\\\\\\\\\\\\\_for\\\\\\\\\\\\\\_pydantic=float('inf'), ) print(foo) \"\"\" positive=1 non\\\\\\\\\\\\\\_negative=0 negative=-1 non\\\\\\\\\\\\\\_positive=0 even=2 love\\\\\\\\\\\\\\_for\\\\\\\\\\\\\\_pydantic=inf \"\"\" JSON Schema Constraints on compound types In case you use field constraints with compound types, an error can happen in some cases. To avoid potential issues, you can use Annotated: from typing import Optional from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, Field class Foo(BaseModel): positive: Optional\\\\\\\\\\\\\\[Annotated\\\\\\\\\\\\\\[int, Field(gt=0)\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] # Can error in some cases, not recommended: non\\\\\\\\\\\\\\_negative: Optional\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] = Field(ge=0) String Constraints¶ API Documentation There are fields that can be used to constrain strings: min\\\\\\\\\\\\\\_length: Minimum length of the string. max\\\\\\\\\\\\\\_length: Maximum length of the string. pattern: A regular expression that the string must match. Here's an example: from pydantic import BaseModel, Field class Foo(BaseModel): short: str = Field(min\\\\\\\\\\\\\\_length=3) long: str = Field(max\\\\\\\\\\\\\\_length=10) regex: str = Field(pattern=r'^\\\\\\\\\\\\\\\\d\\\\\\\\\\\\\\*$') Only digits are allowed. foo = Foo(short='foo', long='foobarbaz', regex='123') print(foo) #> short='foo' long='foobarbaz' regex='123' JSON Schema Decimal Constraints¶ There are fields that can be used to constrain decimals: max\\\\\\\\\\\\\\_digits: Maximum number of digits within the Decimal. It does not include a zero before the decimal point or trailing decimal zeroes. decimal\\\\\\\\\\\\\\_places: Maximum number of decimal places allowed. It does not include trailing decimal zeroes. Here's an example: from decimal import Decimal from pydantic import BaseModel, Field class Foo(BaseModel): precise: Decimal = Field(max\\\\\\\\\\\\\\_digits=5, decimal\\\\\\\\\\\\\\_places=2) foo = Foo(precise=Decimal('123.45')) print(foo) #> precise=Decimal('123.45') Dataclass Constraints¶ There are fields that can be used to constrain dataclasses: init\\\\\\\\\\\\\\_var: Whether the field should be seen as an init-only field in the dataclass. kw\\\\\\\\\\\\\\_only: Whether the field should be a keyword-only argument in the constructor of the dataclass. Here's an example: from pydantic import BaseModel, Field from pydantic.dataclasses import dataclass @dataclass class Foo: bar: str baz: str = Field(init\\\\\\\\\\\\\\_var=True) qux: str = Field(kw\\\\\\\\\\\\\\_only=True) class Model(BaseModel): foo: Foo model = Model(foo=Foo('bar', baz='baz', qux='qux')) print(model.model\\\\\\\\\\\\\\_dump()) The baz field is not included in the model\\\\\\\\\\\\\\_dump() output, since it is an init-only field. #> {'foo': {'bar': 'bar', 'qux': 'qux'}} Validate Default Values¶ The parameter validate\\\\\\\\\\\\\\_default can be used to control whether the default value of the field should be validated. By default, the default value of the field is not validated. from pydantic import BaseModel, Field, ValidationError class User(BaseModel): age: int = Field(default='twelve', validate\\\\\\\\\\\\\\_default=True) try: user = User() except ValidationError as e: print(e) \"\"\" 1 validation error for User age Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='twelve', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Field Representation¶ The parameter repr can be used to control whether the field should be included in the string representation of the model. from pydantic import BaseModel, Field class User(BaseModel): name: str = Field(repr=True) This is the default value. age: int = Field(repr=False) user = User(name='John', age=42) print(user) #> name='John' Discriminator¶ The parameter discriminator can be used to control the field that will be used to discriminate between different models in a union. It takes either the name of a field or a Discriminator instance. The Discriminator approach can be useful when the discriminator fields aren't the same for all the models in the Union. The following example shows how to use discriminator with a field name: Python 3.8 and above Python 3.10 and above from typing import Literal, Union from pydantic import BaseModel, Field class Cat(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['cat'\\\\\\\\\\\\\\] age: int class Dog(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['dog'\\\\\\\\\\\\\\] age: int class Model(BaseModel): pet: Union\\\\\\\\\\\\\\[Cat, Dog\\\\\\\\\\\\\\] = Field(discriminator='pet\\\\\\\\\\\\\\_type') print(Model.model\\\\\\\\\\\\\\_validate({'pet': {'pet\\\\\\\\\\\\\\_type': 'cat', 'age': 12}})) See more about Helper Functions in the Models page. #> pet=Cat(pet\\\\\\\\\\\\\\_type='cat', age=12) The following example shows how to use the discriminator keyword argument with a Discriminator instance: from typing import Literal, Union from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, Discriminator, Field, Tag class Cat(BaseModel): pet\\\\\\\\\\\\\\_type: Literal\\\\\\\\\\\\\\['cat'\\\\\\\\\\\\\\] age: int class Dog(BaseModel): pet\\\\\\\\\\\\\\_kind: Literal\\\\\\\\\\\\\\['dog'\\\\\\\\\\\\\\] age: int def pet\\\\\\\\\\\\\\_discriminator(v): if isinstance(v, dict): return v.get('pet\\\\\\\\\\\\\\_type', v.get('pet\\\\\\\\\\\\\\_kind')) return getattr(v, 'pet\\\\\\\\\\\\\\_type', getattr(v, 'pet\\\\\\\\\\\\\\_kind', None)) class Model(BaseModel): pet: Union\\\\\\\\\\\\\\[Annotated\\\\\\\\\\\\\\[Cat, Tag('cat')\\\\\\\\\\\\\\], Annotated\\\\\\\\\\\\\\[Dog, Tag('dog')\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = Field( discriminator=Discriminator(pet\\\\\\\\\\\\\\_discriminator) ) print(repr(Model.model\\\\\\\\\\\\\\_validate({'pet': {'pet\\\\\\\\\\\\\\_type': 'cat', 'age': 12}}))) #> Model(pet=Cat(pet\\\\\\\\\\\\\\_type='cat', age=12)) print(repr(Model.model\\\\\\\\\\\\\\_validate({'pet': {'pet\\\\\\\\\\\\\\_kind': 'dog', 'age': 12}}))) #> Model(pet=Dog(pet\\\\\\\\\\\\\\_kind='dog', age=12)) You can also take advantage of Annotated to define your discriminated unions. See the Discriminated Unions docs for more details. Strict Mode¶ The strict parameter on a Field specifies whether the field should be validated in \"strict mode\". In strict mode, Pydantic throws an error during validation instead of coercing data on the field where strict=True. from pydantic import BaseModel, Field class User(BaseModel): name: str = Field(strict=True) This is the default value. age: int = Field(strict=False) user = User(name='John', age='42') The age field is not validated in the strict mode. Therefore, it can be assigned a string. print(user) #> name='John' age=42 See Strict Mode for more details. See Conversion Table for more details on how Pydantic converts data in both strict and lax modes. Immutability¶ The parameter frozen is used to emulate the frozen dataclass behaviour. It is used to prevent the field from being assigned a new value after the model is created (immutability). See the frozen dataclass documentation for more details. from pydantic import BaseModel, Field, ValidationError class User(BaseModel): name: str = Field(frozen=True) age: int user = User(name='John', age=42) try: user.name = 'Jane' Since name field is frozen, the assignment is not allowed. except ValidationError as e: print(e) \"\"\" 1 validation error for User name Field is frozen \\\\\\\\\\\\\\[type=frozen\\\\\\\\\\\\\\_field, input\\\\\\\\\\\\\\_value='Jane', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Exclude¶ The exclude parameter can be used to control which fields should be excluded from the model when exporting the model. See the following example: from pydantic import BaseModel, Field class User(BaseModel): name: str age: int = Field(exclude=True) user = User(name='John', age=42) print(user.model\\\\\\\\\\\\\\_dump()) The age field is not included in the model\\\\\\\\\\\\\\_dump() output, since it is excluded. #> {'name': 'John'} See the Serialization section for more details. Customizing JSON Schema¶ There are fields that exclusively to customise the generated JSON Schema: title: The title of the field. description: The description of the field. examples: The examples of the field. json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra: Extra JSON Schema properties to be added to the field. Here's an example: from pydantic import BaseModel, EmailStr, Field, SecretStr class User(BaseModel): age: int = Field(description='Age of the user') email: EmailStr = Field(examples=\\\\\\\\\\\\\\['marcelo@mail.com'\\\\\\\\\\\\\\]) name: str = Field(title='Username') password: SecretStr = Field( json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra={ 'title': 'Password', 'description': 'Password of the user', 'examples': \\\\\\\\\\\\\\['123456'\\\\\\\\\\\\\\], } ) print(User.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema()) \"\"\" { 'properties': { 'age': { 'description': 'Age of the user', 'title': 'Age', 'type': 'integer', }, 'email': { 'examples': \\\\\\\\\\\\\\['marcelo@mail.com'\\\\\\\\\\\\\\], 'format': 'email', 'title': 'Email', 'type': 'string', }, 'name': {'title': 'Username', 'type': 'string'}, 'password': { 'description': 'Password of the user', 'examples': \\\\\\\\\\\\\\['123456'\\\\\\\\\\\\\\], 'format': 'password', 'title': 'Password', 'type': 'string', 'writeOnly': True, }, }, 'required': \\\\\\\\\\\\\\['age', 'email', 'name', 'password'\\\\\\\\\\\\\\], 'title': 'User', 'type': 'object', } \"\"\" Made with Material for MkDocs Insiders"
  },
  {
    "title": "Changelog - Pydantic",
    "url": "https://docs.pydantic.dev/latest/changelog/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Changelog Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Get Started Welcome to Pydantic Why use Pydantic Help with Pydantic Installation Migration Guide Version Policy Contributing Changelog Page contents v2.5.2 (2023-11-122) What's Changed Packaging New Features Fixes v2.5.1 (2023-11-15) What's Changed Packaging Fixes v2.5.0 (2023-11-13) What's Changed Packaging New Features Changes Performance Fixes New Contributors pydantic pydantic-core v2.5.0b1 (2023-11-09) v2.4.2 (2023-09-27) What's Changed Fixes New Contributors v2.4.1 (2023-09-26) What's Changed Packaging Fixes v2.4.0 (2023-09-22) What's Changed Packaging New Features Changes Performance Fixes New Contributors v2.3.0 (2023-08-23) v2.2.1 (2023-08-18) v2.2.0 (2023-08-17) v2.1.1 (2023-07-25) v2.1.0 (2023-07-25) v2.0.3 (2023-07-05) v2.0.2 (2023-07-05) v2.0.1 (2023-07-04) v2.0 (2023-06-30) v2.0b3 (2023-06-16) v2.0b2 (2023-06-03) v2.0b1 (2023-06-01) v2.0a4 (2023-05-05) v2.0a3 (2023-04-20) v2.0a2 (2023-04-12) v2.0a1 (2023-04-03) v1.10.13 (2023-09-27) v1.10.12 (2023-07-24) v1.10.11 (2023-07-04) v1.10.10 (2023-06-30) v1.10.9 (2023-06-07) v1.10.8 (2023-05-23) v1.10.7 (2023-03-22) v1.10.6 (2023-03-08) v1.10.5 (2023-02-15) v1.10.4 (2022-12-30) v1.10.3 (2022-12-29) v1.10.2 (2022-09-05) v1.10.1 (2022-08-31) v1.10.0 (2022-08-30) v1.10.0b1 (2022-08-24) v1.10.0a2 (2022-08-24) v1.10.0a1 (2022-08-22) v1.9.2 (2022-08-11) v1.9.1 (2022-05-19) v1.9.0 (2021-12-31) Highlights v1.9.0 (2021-12-31) Changes v1.9.0a2 (2021-12-24) Changes v1.9.0a1 (2021-12-18) Changes v1.8.2 (2021-05-11) v1.8.1 (2021-03-03) v1.8 (2021-02-26) Highlights Changes v1.7.4 (2021-05-11) v1.7.3 (2020-11-30) v1.7.2 (2020-11-01) v1.7.1 (2020-10-28) v1.7 (2020-10-26) Highlights Changes v1.6.2 (2021-05-11) v1.6.1 (2020-07-15) v1.6 (2020-07-11) v1.5.1 (2020-04-23) v1.5 (2020-04-18) v1.4 (2020-01-24) v1.3 (2019-12-21) v1.2 (2019-11-28) v1.1.1 (2019-11-20) v1.1 (2019-11-07) v1.0 (2019-10-23) v1.0b2 (2019-10-07) v1.0b1 (2019-10-01) v0.32.2 (2019-08-17) v0.32.1 (2019-08-08) v0.32 (2019-08-06) v0.31.1 (2019-07-31) v0.31 (2019-07-24) v0.30.1 (2019-07-15) v0.30 (2019-07-07) v0.29 (2019-06-19) v0.28 (2019-06-06) v0.27 (2019-05-30) v0.27.0a1 (2019-05-26) v0.26 (2019-05-22) v0.25 (2019-05-05) v0.24 (2019-04-23) v0.23 (2019-04-04) v0.22 (2019-03-29) v0.21.0 (2019-03-15) v0.20.1 (2019-02-26) v0.20.0 (2019-02-18) v0.20.0a1 (2019-02-13) v0.19.0 (2019-02-04) v0.18.2 (2019-01-22) v0.18.1 (2019-01-17) v0.18.0 (2019-01-13) v0.17.0 (2018-12-27) v0.16.1 (2018-12-10) v0.16.0 (2018-12-03) v0.15.0 (2018-11-18) v0.14.0 (2018-10-02) v0.13.1 (2018-09-21) v0.13.0 (2018-08-25) v0.12.1 (2018-07-31) v0.12.0 (2018-07-31) v0.11.2 (2018-07-05) v0.11.1 (2018-07-02) v0.11.0 (2018-06-28) v0.10.0 (2018-06-11) v0.9.1 (2018-05-10) v0.9.0 (2018-04-28) v0.8.0 (2018-03-25) v0.7.1 (2018-02-07) v0.7.0 (2018-02-06) v0.6.4 (2018-02-01) v0.6.3 (2017-11-26) v0.6.2 (2017-11-13) v0.6.1 (2017-11-08) v0.6.0 (2017-11-07) v0.5.0 (2017-10-23) v0.4.0 (2017-07-08) v0.3.0 (2017-06-21) v0.2.1 (2017-06-07) v0.2.0 (2017-06-07) v0.1.0 (2017-06-03) Changelog v2.5.2 (2023-11-122)¶ GitHub release What's Changed¶ Packaging¶ uprev pydantic-core to 2.14.5 New Features¶ Add ConfigDict.ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan by @davidhewitt in #8159 Fixes¶ Fix validation of Literal from JSON keys when used as dict key by @sydney-runkle in pydantic/pydantic-core#1075 Fix bug re custom\\\\\\\\\\\\\\_init on members of Union by @sydney-runkle in pydantic/pydantic-core#1076 Fix JsonValue bool serialization by @sydney-runkle in #8190 Fix handling of unhashable inputs with Literal in Unions by @sydney-runkle in pydantic/pydantic-core#1089 v2.5.1 (2023-11-15)¶ GitHub release What's Changed¶ Packaging¶ uprev pydantic-core to 2.14.3 by @samuelcolvin in #8120 Fixes¶ Fix package description limit by @dmontagu in #8097 Fix ValidateCallWrapper error when creating a model which has a @validate\\\\\\\\\\\\\\_call wrapped field annotation by @sydney-runkle in #8110 v2.5.0 (2023-11-13)¶ GitHub release The code released in v2.5.0 is functionally identical to that of v2.5.0b1. What's Changed¶ Packaging¶ Update pydantic-core from 2.10.1 to 2.14.1, significant changes from these updates are described below, full changelog here Update to pyright==1.1.335 by @Viicos in #8075 New Features¶ Allow plugins to catch non ValidationError errors by @adriangb in #7806 Support \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_doc\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ argument in create\\\\\\\\\\\\\\_model() by @chris-spann in #7863 Expose regex\\\\\\\\\\\\\\_engine flag - meaning you can use with the Rust or Python regex libraries in constraints by @utkini in #7768 Save return type generated from type annotation in ComputedFieldInfo by @alexmojaki in #7889 Adopting ruff formatter by @Luca-Blight in #7930 Added validation\\\\\\\\\\\\\\_error\\\\\\\\\\\\\\_cause to config by @zakstucke in #7626 Make path of the item to validate available in plugin by @hramezani in #7861 Add CallableDiscriminator and Tag by @dmontagu in #7983 CallableDiscriminator renamed to Discriminator by @dmontagu in #8047 Make union case tags affect union error messages by @dmontagu in #8001 Add examples and json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra to @computed\\\\\\\\\\\\\\_field by @alexmojaki in #8013 Add JsonValue type by @dmontagu in #7998 Allow str as argument to Discriminator by @dmontagu in #8047 Add SchemaSerializer.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_reduce\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method to enable pickle serialization by @edoakes in pydantic/pydantic-core#1006 Changes¶ Significant Change: replace ultra\\\\\\\\\\\\\\_strict with new smart union implementation, the way unions are validated has changed significantly to improve performance and correctness, we have worked hard to absolutely minimise the number of cases where behaviour has changed, see the PR for details - by @davidhewitt in pydantic/pydantic-core#867 Add support for instance method reassignment when extra='allow' by @sydney-runkle in #7683 Support JSON schema generation for Enum types with no cases by @sydney-runkle in #7927 Warn if a class inherits from Generic before BaseModel by @alexmojaki in #7891 Performance¶ New custom JSON parser, jiter by @samuelcolvin in pydantic/pydantic-core#974 PGO build for MacOS M1 by @samuelcolvin in pydantic/pydantic-core#1063 Use \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_getattr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ for all package imports, improve import time by @samuelcolvin in #7947 Fixes¶ Fix mypy issue with subclasses of RootModel by @sydney-runkle in #7677 Properly rebuild the FieldInfo when a forward ref gets evaluated by @dmontagu in #7698 Fix failure to load SecretStr from JSON (regression in v2.4) by @sydney-runkle in #7729 Fix defer\\\\\\\\\\\\\\_build behavior with TypeAdapter by @sydney-runkle in #7736 Improve compatibility with legacy mypy versions by @dmontagu in #7742 Fix: update TypeVar handling when default is not set by @pmmmwh in #7719 Support specification of strict on Enum type fields by @sydney-runkle in #7761 Wrap weakref.ref instead of subclassing to fix cloudpickle serialization by @edoakes in #7780 Keep values of private attributes set within model\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init in subclasses by @alexmojaki in #7775 Add more specific type for non-callable json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra by @alexmojaki in #7803 Raise an error when deleting frozen (model) fields by @alexmojaki in #7800 Fix schema sorting bug with default values by @sydney-runkle in #7817 Use generated alias for aliases that are not specified otherwise by @alexmojaki in #7802 Support strict specification for UUID types by @sydney-runkle in #7865 JSON schema: fix extra parameter handling by @me-and in #7810 Fix: support pydantic.Field(kw\\\\\\\\\\\\\\_only=True) with inherited dataclasses by @PrettyWood in #7827 Support validate\\\\\\\\\\\\\\_call decorator for methods in classes with \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_slots\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ by @sydney-runkle in #7883 Fix pydantic dataclass problem with dataclasses.field default by @hramezani in #7898 Fix schema generation for generics with union type bounds by @sydney-runkle in #7899 Fix version for importlib\\\\\\\\\\\\\\_metadata on python 3.7 by @sydney-runkle in #7904 Support | operator (Union) in PydanticRecursiveRef by @alexmojaki in #7892 Fix display\\\\\\\\\\\\\\_as\\\\\\\\\\\\\\_type for TypeAliasType in python 3.12 by @dmontagu in #7929 Add support for NotRequired generics in TypedDict by @sydney-runkle in #7932 Make generic TypeAliasType specifications produce different schema definitions by @alexdrydew in #7893 Added fix for signature of inherited dataclass by @howsunjow in #7925 Make the model name generation more robust in JSON schema by @joakimnordling in #7881 Fix plurals in validation error messages (in tests) by @Iipin in #7972 PrivateAttr is passed from Annotated default position by @tabassco in #8004 Don't decode bytes (which may not be UTF8) when displaying SecretBytes by @alexmojaki in #8012 Use classmethod instead of classmethod\\\\\\\\\\\\\\[Any, Any, Any\\\\\\\\\\\\\\] by @Mr-Pepe in #7979 Clearer error on invalid Plugin by @samuelcolvin in #8023 Correct pydantic dataclasses import by @samuelcolvin in #8027 Fix misbehavior for models referencing redefined type aliases by @dmontagu in #8050 Fix Optional field with validate\\\\\\\\\\\\\\_default only performing one field validation by @sydney-runkle in pydantic/pydantic-core#1002 Fix definition-ref bug with Dict keys by @sydney-runkle in pydantic/pydantic-core#1014 Fix bug allowing validation of bool types with coerce\\\\\\\\\\\\\\_numbers\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_str=True by @sydney-runkle in pydantic/pydantic-core#1017 Don't accept NaN in float and decimal constraints by @davidhewitt in pydantic/pydantic-core#1037 Add lax\\\\\\\\\\\\\\_str and lax\\\\\\\\\\\\\\_int support for enum values not inherited from str/int by @michaelhly in pydantic/pydantic-core#1015 Support subclasses in lists in Union of List types by @sydney-runkle in pydantic/pydantic-core#1039 Allow validation against max\\\\\\\\\\\\\\_digits and decimals to pass if normalized or non-normalized input is valid by @sydney-runkle in pydantic/pydantic-core#1049 Fix: proper pluralization in ValidationError messages by @Iipin in pydantic/pydantic-core#1050 Disallow the string '-' as datetime input by @davidhewitt in pydantic/speedate#52 & pydantic/pydantic-core#1060 Fix: NaN and Inf float serialization by @davidhewitt in pydantic/pydantic-core#1062 Restore manylinux-compatible PGO builds by @davidhewitt in pydantic/pydantic-core#1068 New Contributors¶ pydantic¶ @schneebuzz made their first contribution in #7699 @edoakes made their first contribution in #7780 @alexmojaki made their first contribution in #7775 @NickG123 made their first contribution in #7751 @gowthamgts made their first contribution in #7830 @jamesbraza made their first contribution in #7848 @laundmo made their first contribution in #7850 @rahmatnazali made their first contribution in #7870 @waterfountain1996 made their first contribution in #7878 @chris-spann made their first contribution in #7863 @me-and made their first contribution in #7810 @utkini made their first contribution in #7768 @bn-l made their first contribution in #7744 @alexdrydew made their first contribution in #7893 @Luca-Blight made their first contribution in #7930 @howsunjow made their first contribution in #7925 @joakimnordling made their first contribution in #7881 @icfly2 made their first contribution in #7976 @Yummy-Yums made their first contribution in #8003 @Iipin made their first contribution in #7972 @tabassco made their first contribution in #8004 @Mr-Pepe made their first contribution in #7979 @0x00cl made their first contribution in #8010 @barraponto made their first contribution in #8032 pydantic-core¶ @sisp made their first contribution in pydantic/pydantic-core#995 @michaelhly made their first contribution in pydantic/pydantic-core#1015 v2.5.0b1 (2023-11-09)¶ Pre-release, see the GitHub release for details. v2.4.2 (2023-09-27)¶ GitHub release What's Changed¶ Fixes¶ Fix bug with JSON schema for sequence of discriminated union by @dmontagu in #7647 Fix schema references in discriminated unions by @adriangb in #7646 Fix json schema generation for recursive models by @adriangb in #7653 Fix models\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema for generic models by @adriangb in #7654 Fix xfailed test for generic model signatures by @adriangb in #7658 New Contributors¶ @austinorr made their first contribution in #7657 @peterHoburg made their first contribution in #7670 v2.4.1 (2023-09-26)¶ GitHub release What's Changed¶ Packaging¶ Update pydantic-core to 2.10.1 by @davidhewitt in #7633 Fixes¶ Serialize unsubstituted type vars as Any by @adriangb in #7606 Remove schema building caches by @adriangb in #7624 Fix an issue where JSON schema extras weren't JSON encoded by @dmontagu in #7625 v2.4.0 (2023-09-22)¶ GitHub release What's Changed¶ Packaging¶ Update pydantic-core to 2.10.0 by @samuelcolvin in #7542 New Features¶ Add Base64Url types by @dmontagu in #7286 Implement optional number to str coercion by @lig in #7508 Allow access to field\\\\\\\\\\\\\\_name and data in all validators if there is data and a field name by @samuelcolvin in #7542 Add BaseModel.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_strings and TypeAdapter.validate\\\\\\\\\\\\\\_strings by @hramezani in #7552 Add Pydantic plugins experimental implementation by @lig @samuelcolvin and @Kludex in #6820 Changes¶ Do not override model\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init in subclass with private attrs by @Viicos in #7302 Make fields with defaults not required in the serialization schema by default by @dmontagu in #7275 Mark Extra as deprecated by @disrupted in #7299 Make EncodedStr a dataclass by @Kludex in #7396 Move annotated\\\\\\\\\\\\\\_handlers to be public by @samuelcolvin in #7569 Performance¶ Simplify flattening and inlining of CoreSchema by @adriangb in #7523 Remove unused copies in CoreSchema walking by @adriangb in #7528 Add caches for collecting definitions and invalid schemas from a CoreSchema by @adriangb in #7527 Eagerly resolve discriminated unions and cache cases where we can't by @adriangb in #7529 Replace dict.get and dict.setdefault with more verbose versions in CoreSchema building hot paths by @adriangb in #7536 Cache invalid CoreSchema discovery by @adriangb in #7535 Allow disabling CoreSchema validation for faster startup times by @adriangb in #7565 Fixes¶ Fix config detection for TypedDict from grandparent classes by @dmontagu in #7272 Fix hash function generation for frozen models with unusual MRO by @dmontagu in #7274 Make strict config overridable in field for Path by @hramezani in #7281 Use ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_ on default in GenerateJsonSchema by @Kludex in #7269 Adding a check that alias is validated as an identifier for Python by @andree0 in #7319 Raise an error when computed field overrides field by @sydney-runkle in #7346 Fix applying SkipValidation to referenced schemas by @adriangb in #7381 Enforce behavior of private attributes having double leading underscore by @lig in #7265 Standardize \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ signature by @hramezani in #7415 Fix generic dataclass fields mutation bug (when using TypeAdapter) by @sydney-runkle in #7435 Fix TypeError on model\\\\\\\\\\\\\\_validator in wrap mode by @pmmmwh in #7496 Improve enum error message by @hramezani in #7506 Make repr work for instances that failed initialization when handling ValidationErrors by @dmontagu in #7439 Fixed a regular expression denial of service issue by limiting whitespaces by @prodigysml in #7360 Fix handling of UUID values having UUID.version=None by @lig in #7566 Fix \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_iter\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ returning private cached\\\\\\\\\\\\\\_property info by @sydney-runkle in #7570 Improvements to version info message by @samuelcolvin in #7594 New Contributors¶ @15498th made their first contribution in #7238 @GabrielCappelli made their first contribution in #7213 @tobni made their first contribution in #7184 @redruin1 made their first contribution in #7282 @FacerAin made their first contribution in #7288 @acdha made their first contribution in #7297 @andree0 made their first contribution in #7319 @gordonhart made their first contribution in #7375 @pmmmwh made their first contribution in #7496 @disrupted made their first contribution in #7299 @prodigysml made their first contribution in #7360 v2.3.0 (2023-08-23)¶ GitHub release 🔥 Remove orphaned changes file from repo by @lig in #7168 Add copy button on documentation by @Kludex in #7190 Fix docs on JSON type by @Kludex in #7189 Update mypy 1.5.0 to 1.5.1 in CI by @hramezani in #7191 fix download links badge by @samuelcolvin in #7200 add 2.2.1 to changelog by @samuelcolvin in #7212 Make ModelWrapValidator protocols generic by @dmontagu in #7154 Correct Field(..., exclude: bool) docs by @samuelcolvin in #7214 Make shadowing attributes a warning instead of an error by @adriangb in #7193 Document Base64Str and Base64Bytes by @Kludex in #7192 Fix config.defer\\\\\\\\\\\\\\_build for serialization first cases by @samuelcolvin in #7024 clean Model docstrings in JSON Schema by @samuelcolvin in #7210 fix #7228 (typo): docs in validators.md to correct validate\\\\\\\\\\\\\\_default kwarg by @lmmx in #7229 ✅ Implement tzinfo.fromutc method for TzInfo in pydantic-core by @lig in #7019 Support \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ by @hramezani in #7197 v2.2.1 (2023-08-18)¶ GitHub release Make xfailing test for root model extra stop xfailing by @dmontagu in #6937 Optimize recursion detection by stopping on the second visit for the same object by @mciucu in #7160 fix link in docs by @tlambert03 in #7166 Replace MiMalloc w/ default allocator by @adriangb in pydantic/pydantic-core#900 Bump pydantic-core to 2.6.1 and prepare 2.2.1 release by @adriangb in #7176 v2.2.0 (2023-08-17)¶ GitHub release Split \"pipx install\" setup command into two commands on the documentation site by @nomadmtb in #6869 Deprecate Field.include by @hramezani in #6852 Fix typo in default factory error msg by @hramezani in #6880 Simplify handling of typing.Annotated in GenerateSchema by @dmontagu in #6887 Re-enable fastapi tests in CI by @dmontagu in #6883 Make it harder to hit collisions with json schema defrefs by @dmontagu in #6566 Cleaner error for invalid input to Path fields by @samuelcolvin in #6903 support Coordinate Type by @yezz123 in #6906 Fix ForwardRef wrapper for py 3.10.0 (shim until bpo-45166) by @randomir in #6919 Fix misbehavior related to copying of RootModel by @dmontagu in #6918 Fix issue with recursion error caused by ParamSpec by @dmontagu in #6923 Add section about Constrained classes to the Migration Guide by @Kludex in #6924 Use main branch for badge links by @Viicos in #6925 Add test for v1/v2 Annotated discrepancy by @carlbordum in #6926 Make the v1 mypy plugin work with both v1 and v2 by @dmontagu in #6921 Fix issue where generic models couldn't be parametrized with BaseModel by @dmontagu in #6933 Remove xfail for discriminated union with alias by @dmontagu in #6938 add field\\\\\\\\\\\\\\_serializer to computed\\\\\\\\\\\\\\_field by @andresliszt in #6965 Use union\\\\\\\\\\\\\\_schema with Type\\\\\\\\\\\\\\[Union\\\\\\\\\\\\\\[...\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] by @JeanArhancet in #6952 Fix inherited typeddict attributes / config by @adriangb in #6981 fix dataclass annotated before validator called twice by @davidhewitt in #6998 Update test-fastapi deselected tests by @hramezani in #7014 Fix validator doc format by @hramezani in #7015 Fix typo in docstring of model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema by @AdamVinch-Federated in #7032 remove unused \"type ignores\" with pyright by @samuelcolvin in #7026 Add benchmark representing FastAPI startup time by @adriangb in #7030 Fix json\\\\\\\\\\\\\\_encoders for Enum subclasses by @adriangb in #7029 Update docstring of ser\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_bytes regarding base64 encoding by @Viicos in #7052 Allow @validate\\\\\\\\\\\\\\_call to work on async methods by @adriangb in #7046 Fix: mypy error with Settings and SettingsConfigDict by @JeanArhancet in #7002 Fix some typos (repeated words and it's/its) by @eumiro in #7063 Fix the typo in docstring by @harunyasar in #7062 Docs: Fix broken URL in the pydantic-settings package recommendation by @swetjen in #6995 Handle constraints being applied to schemas that don't accept it by @adriangb in #6951 Replace almost\\\\\\\\\\\\\\_equal\\\\\\\\\\\\\\_floats with math.isclose by @eumiro in #7082 bump pydantic-core to 2.5.0 by @davidhewitt in #7077 Add short\\\\\\\\\\\\\\_version and use it in links by @hramezani in #7115 📝 Add usage link to RootModel by @Kludex in #7113 Revert \"Fix default port for mongosrv DSNs (#6827)\" by @Kludex in #7116 Clarify validate\\\\\\\\\\\\\\_default and \\\\\\\\\\\\\\_Unset handling in usage docs and migration guide by @benbenbang in #6950 Tweak documentation of Field.exclude by @Viicos in #7086 Do not require validate\\\\\\\\\\\\\\_assignment to use Field.frozen by @Viicos in #7103 tweaks to \\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_utils by @samuelcolvin in #7040 Make DefaultDict working with set by @hramezani in #7126 Don't always require typing.Generic as a base for partially parametrized models by @dmontagu in #7119 Fix issue with JSON schema incorrectly using parent class core schema by @dmontagu in #7020 Fix xfailed test related to TypedDict and alias\\\\\\\\\\\\\\_generator by @dmontagu in #6940 Improve error message for NameEmail by @dmontagu in #6939 Fix generic computed fields by @dmontagu in #6988 Reflect namedtuple default values during validation by @dmontagu in #7144 Update dependencies, fix pydantic-core usage, fix CI issues by @dmontagu in #7150 Add mypy 1.5.0 by @hramezani in #7118 Handle non-json native enum values by @adriangb in #7056 document round\\\\\\\\\\\\\\_trip in Json type documentation by @jc-louis in #7137 Relax signature checks to better support builtins and C extension functions as validators by @adriangb in #7101 add union\\\\\\\\\\\\\\_mode='left\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_right' by @davidhewitt in #7151 Include an error message hint for inherited ordering by @yvalencia91 in #7124 Fix one docs link and resolve some warnings for two others by @dmontagu in #7153 Include Field extra keys name in warning by @hramezani in #7136 v2.1.1 (2023-07-25)¶ GitHub release Skip FieldInfo merging when unnecessary by @dmontagu in #6862 v2.1.0 (2023-07-25)¶ GitHub release Add StringConstraints for use as Annotated metadata by @adriangb in #6605 Try to fix intermittently failing CI by @adriangb in #6683 Remove redundant example of optional vs default. by @ehiggs-deliverect in #6676 Docs update by @samuelcolvin in #6692 Remove the Validate always section in validator docs by @adriangb in #6679 Fix recursion error in json schema generation by @adriangb in #6720 Fix incorrect subclass check for secretstr by @AlexVndnblcke in #6730 update pdm / pdm lockfile to 2.8.0 by @davidhewitt in #6714 unpin pdm on more CI jobs by @davidhewitt in #6755 improve source locations for auxiliary packages in docs by @davidhewitt in #6749 Assume builtins don't accept an info argument by @adriangb in #6754 Fix bug where calling help(BaseModelSubclass) raises errors by @hramezani in #6758 Fix mypy plugin handling of @model\\\\\\\\\\\\\\_validator(mode=\"after\") by @ljodal in #6753 update pydantic-core to 2.3.1 by @davidhewitt in #6756 Mypy plugin for settings by @hramezani in #6760 Use contentSchema keyword for JSON schema by @dmontagu in #6715 fast-path checking finite decimals by @davidhewitt in #6769 Docs update by @samuelcolvin in #6771 Improve json schema doc by @hramezani in #6772 Update validator docs by @adriangb in #6695 Fix typehint for wrap validator by @dmontagu in #6788 🐛 Fix validation warning for unions of Literal and other type by @lig in #6628 Update documentation for generics support in V2 by @tpdorsey in #6685 add pydantic-core build info to version\\\\\\\\\\\\\\_info() by @samuelcolvin in #6785 Fix pydantic dataclasses that use slots with default values by @dmontagu in #6796 Fix inheritance of hash function for frozen models by @dmontagu in #6789 ✨ Add SkipJsonSchema annotation by @Kludex in #6653 Error if an invalid field name is used with Field by @dmontagu in #6797 Add GenericModel to MOVED\\\\\\\\\\\\\\_IN\\\\\\\\\\\\\\_V2 by @adriangb in #6776 Remove unused code from docs/usage/types/custom.md by @hramezani in #6803 Fix float -> Decimal coercion precision loss by @adriangb in #6810 remove email validation from the north star benchmark by @davidhewitt in #6816 Fix link to mypy by @progsmile in #6824 Improve initialization hooks example by @hramezani in #6822 Fix default port for mongosrv DSNs by @dmontagu in #6827 Improve API documentation, in particular more links between usage and API docs by @samuelcolvin in #6780 update pydantic-core to 2.4.0 by @davidhewitt in #6831 Fix annotated\\\\\\\\\\\\\\_types.MaxLen validator for custom sequence types by @ImogenBits in #6809 Update V1 by @hramezani in #6833 Make it so callable JSON schema extra works by @dmontagu in #6798 Fix serialization issue with InstanceOf by @dmontagu in #6829 Add back support for json\\\\\\\\\\\\\\_encoders by @adriangb in #6811 Update field annotations when building the schema by @dmontagu in #6838 Use WeakValueDictionary to fix generic memory leak by @dmontagu in #6681 Add config.defer\\\\\\\\\\\\\\_build to optionally make model building lazy by @samuelcolvin in #6823 delegate UUID serialization to pydantic-core by @davidhewitt in #6850 Update json\\\\\\\\\\\\\\_encoders docs by @adriangb in #6848 Fix error message for staticmethod/classmethod order with validate\\\\\\\\\\\\\\_call by @dmontagu in #6686 Improve documentation for Config by @samuelcolvin in #6847 Update serialization doc to mention Field.exclude takes priority over call-time include/exclude by @hramezani in #6851 Allow customizing core schema generation by making GenerateSchema public by @adriangb in #6737 v2.0.3 (2023-07-05)¶ GitHub release Mention PyObject (v1) moving to ImportString (v2) in migration doc by @slafs in #6456 Fix release-tweet CI by @Kludex in #6461 Revise the section on required / optional / nullable fields. by @ybressler in #6468 Warn if a type hint is not in fact a type by @adriangb in #6479 Replace TransformSchema with GetPydanticSchema by @dmontagu in #6484 Fix the un-hashability of various annotation types, for use in caching generic containers by @dmontagu in #6480 PYD-164: Rework custom types docs by @adriangb in #6490 Fix ci by @adriangb in #6507 Fix forward ref in generic by @adriangb in #6511 Fix generation of serialization JSON schemas for core\\\\\\\\\\\\\\_schema.ChainSchema by @dmontagu in #6515 Document the change in Field.alias behavior in Pydantic V2 by @hramezani in #6508 Give better error message attempting to compute the json schema of a model with undefined fields by @dmontagu in #6519 Document alias\\\\\\\\\\\\\\_priority by @tpdorsey in #6520 Add redirect for types documentation by @tpdorsey in #6513 Allow updating docs without release by @samuelcolvin in #6551 Ensure docs tests always run in the right folder by @dmontagu in #6487 Defer evaluation of return type hints for serializer functions by @dmontagu in #6516 Disable E501 from Ruff and rely on just Black by @adriangb in #6552 Update JSON Schema documentation for V2 by @tpdorsey in #6492 Add documentation of cyclic reference handling by @dmontagu in #6493 Remove the need for change files by @samuelcolvin in #6556 add \"north star\" benchmark by @davidhewitt in #6547 Update Dataclasses docs by @tpdorsey in #6470 ♻️ Use different error message on v1 redirects by @Kludex in #6595 ⬆ Upgrade pydantic-core to v2.2.0 by @lig in #6589 Fix serialization for IPvAny by @dmontagu in #6572 Improve CI by using PDM instead of pip to install typing-extensions by @adriangb in #6602 Add enum error type docs by @lig in #6603 🐛 Fix max\\\\\\\\\\\\\\_length for unicode strings by @lig in #6559 Add documentation for accessing features via pydantic.v1 by @tpdorsey in #6604 Include extra when iterating over a model by @adriangb in #6562 Fix typing of model\\\\\\\\\\\\\\_validator by @adriangb in #6514 Touch up Decimal validator by @adriangb in #6327 Fix various docstrings using fixed pytest-examples by @dmontagu in #6607 Handle function validators in a discriminated union by @dmontagu in #6570 Review json\\\\\\\\\\\\\\_schema.md by @tpdorsey in #6608 Make validate\\\\\\\\\\\\\\_call work on basemodel methods by @dmontagu in #6569 add test for big int json serde by @davidhewitt in #6614 Fix pydantic dataclass problem with dataclasses.field default\\\\\\\\\\\\\\_factory by @hramezani in #6616 Fixed mypy type inference for TypeAdapter by @zakstucke in #6617 Make it work to use None as a generic parameter by @dmontagu in #6609 Make it work to use $ref as an alias by @dmontagu in #6568 add note to migration guide about changes to AnyUrl etc by @davidhewitt in #6618 🐛 Support defining json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra on RootModel using Field by @lig in #6622 Update pre-commit to prevent commits to main branch on accident by @dmontagu in #6636 Fix PDM CI for python 3.7 on MacOS/windows by @dmontagu in #6627 Produce more accurate signatures for pydantic dataclasses by @dmontagu in #6633 Updates to Url types for Pydantic V2 by @tpdorsey in #6638 Fix list markdown in transform docstring by @StefanBRas in #6649 simplify slots\\\\\\\\\\\\\\_dataclass construction to appease mypy by @davidhewitt in #6639 Update TypedDict schema generation docstring by @adriangb in #6651 Detect and lint-error for prints by @dmontagu in #6655 Add xfailing test for pydantic-core PR 766 by @dmontagu in #6641 Ignore unrecognized fields from dataclasses metadata by @dmontagu in #6634 Make non-existent class getattr a mypy error by @dmontagu in #6658 Update pydantic-core to 2.3.0 by @hramezani in #6648 Use OrderedDict from typing\\\\\\\\\\\\\\_extensions by @dmontagu in #6664 Fix typehint for JSON schema extra callable by @dmontagu in #6659 v2.0.2 (2023-07-05)¶ GitHub release Fix bug where round-trip pickling/unpickling a RootModel would change the value of \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, #6457 by @dmontagu Allow single-item discriminated unions, #6405 by @dmontagu Fix issue with union parsing of enums, #6440 by @dmontagu Docs: Fixed constr documentation, renamed old regex to new pattern, #6452 by @miili Change GenerateJsonSchema.generate\\\\\\\\\\\\\\_definitions signature, #6436 by @dmontagu See the full changelog here v2.0.1 (2023-07-04)¶ GitHub release First patch release of Pydantic V2 Extra fields added via setattr (i.e. m.some\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_field = 'extra\\\\\\\\\\\\\\_value') are added to .model\\\\\\\\\\\\\\_extra if model\\\\\\\\\\\\\\_config extra='allowed'. Fixed #6333, #6365 by @aaraney Automatically unpack JSON schema '$ref' for custom types, #6343 by @adriangb Fix tagged unions multiple processing in submodels, #6340 by @suharnikov See the full changelog here v2.0 (2023-06-30)¶ GitHub release Pydantic V2 is here! See this post for more details. v2.0b3 (2023-06-16)¶ Third beta pre-release of Pydantic V2 See the full changelog here v2.0b2 (2023-06-03)¶ Add from\\\\\\\\\\\\\\_attributes runtime flag to TypeAdapter.validate\\\\\\\\\\\\\\_python and BaseModel.model\\\\\\\\\\\\\\_validate. See the full changelog here v2.0b1 (2023-06-01)¶ First beta pre-release of Pydantic V2 See the full changelog here v2.0a4 (2023-05-05)¶ Fourth pre-release of Pydantic V2 See the full changelog here v2.0a3 (2023-04-20)¶ Third pre-release of Pydantic V2 See the full changelog here v2.0a2 (2023-04-12)¶ Second pre-release of Pydantic V2 See the full changelog here v2.0a1 (2023-04-03)¶ First pre-release of Pydantic V2! See this post for more details. v1.10.13 (2023-09-27)¶ Fix: Add max length check to pydantic.validate\\\\\\\\\\\\\\_email, #7673 by @hramezani Docs: Fix pip commands to install v1, #6930 by @chbndrhnns v1.10.12 (2023-07-24)¶ Fixes the maxlen property being dropped on deque validation. Happened only if the deque item has been typed. Changes the \\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_sequence\\\\\\\\\\\\\\_like func, #6581 by @maciekglowka v1.10.11 (2023-07-04)¶ Importing create\\\\\\\\\\\\\\_model in tools.py through relative path instead of absolute path - so that it doesn't import V2 code when copied over to V2 branch, #6361 by @SharathHuddar v1.10.10 (2023-06-30)¶ Add Pydantic Json field support to settings management, #6250 by @hramezani Fixed literal validator errors for unhashable values, #6188 by @markus1978 Fixed bug with generics receiving forward refs, #6130 by @mark-todd Update install method of FastAPI for internal tests in CI, #6117 by @Kludex v1.10.9 (2023-06-07)¶ Fix trailing zeros not ignored in Decimal validation, #5968 by @hramezani Fix mypy plugin for v1.4.0, #5928 by @cdce8p Add future and past date hypothesis strategies, #5850 by @bschoenmaeckers Discourage usage of Cython 3 with Pydantic 1.x, #5845 by @lig v1.10.8 (2023-05-23)¶ Fix a bug in Literal usage with typing-extension==4.6.0, #5826 by @hramezani This solves the (closed) issue #3849 where aliased fields that use discriminated union fail to validate when the data contains the non-aliased field name, #5736 by @benwah Update email-validator dependency to >=2.0.0post2, #5627 by @adriangb update AnyClassMethod for changes in python/typeshed#9771, #5505 by @ITProKyle v1.10.7 (2023-03-22)¶ Fix creating schema from model using ConstrainedStr with regex as dict key, #5223 by @matejetz Address bug in mypy plugin caused by explicit\\\\\\\\\\\\\\_package\\\\\\\\\\\\\\_bases=True, #5191 by @dmontagu Add implicit defaults in the mypy plugin for Field with no default argument, #5190 by @dmontagu Fix schema generated for Enum values used as Literals in discriminated unions, #5188 by @javibookline Fix mypy failures caused by the pydantic mypy plugin when users define from\\\\\\\\\\\\\\_orm in their own classes, #5187 by @dmontagu Fix InitVar usage with pydantic dataclasses, mypy version 1.1.1 and the custom mypy plugin, #5162 by @cdce8p v1.10.6 (2023-03-08)¶ Implement logic to support creating validators from non standard callables by using defaults to identify them and unwrapping functools.partial and functools.partialmethod when checking the signature, #5126 by @JensHeinrich Fix mypy plugin for v1.1.1, and fix dataclass\\\\\\\\\\\\\\_transform decorator for pydantic dataclasses, #5111 by @cdce8p Raise ValidationError, not ConfigError, when a discriminator value is unhashable, #4773 by @kurtmckee v1.10.5 (2023-02-15)¶ Fix broken parametrized bases handling with GenericModels with complex sets of models, #5052 by @MarkusSintonen Invalidate mypy cache if plugin config changes, #5007 by @cdce8p Fix RecursionError when deep-copying dataclass types wrapped by pydantic, #4949 by @mbillingr Fix X | Y union syntax breaking GenericModel, #4146 by @thenx Switch coverage badge to show coverage for this branch/release, #5060 by @samuelcolvin v1.10.4 (2022-12-30)¶ Change dependency to typing-extensions>=4.2.0, #4885 by @samuelcolvin v1.10.3 (2022-12-29)¶ NOTE: v1.10.3 was \"yanked\" from PyPI due to #4885 which is fixed in v1.10.4 fix parsing of custom root models, #4883 by @gou177 fix: use dataclass proxy for frozen or empty dataclasses, #4878 by @PrettyWood Fix schema and schema\\\\\\\\\\\\\\_json on models where a model instance is a one of default values, #4781 by @Bobronium Add Jina AI to sponsors on docs index page, #4767 by @samuelcolvin fix: support assignment on DataclassProxy, #4695 by @PrettyWood Add postgresql+psycopg as allowed scheme for PostgreDsn to make it usable with SQLAlchemy 2, #4689 by @morian Allow dict schemas to have both patternProperties and additionalProperties, #4641 by @jparise Fixes error passing None for optional lists with unique\\\\\\\\\\\\\\_items, #4568 by @mfulgo Fix GenericModel with Callable param raising a TypeError, #4551 by @mfulgo Fix field regex with StrictStr type annotation, #4538 by @sisp Correct dataclass\\\\\\\\\\\\\\_transform keyword argument name from field\\\\\\\\\\\\\\_descriptors to field\\\\\\\\\\\\\\_specifiers, #4500 by @samuelcolvin fix: avoid multiple calls of \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ when dataclasses are inherited, #4487 by @PrettyWood Reduce the size of binary wheels, #2276 by @samuelcolvin v1.10.2 (2022-09-05)¶ Revert Change: Revert percent encoding of URL parts which was originally added in #4224, #4470 by @samuelcolvin Prevent long (length > 4\\\\\\\\\\\\\\_300) strings/bytes as input to int fields, see python/cpython#95778 and CVE-2020-10735, #1477 by @samuelcolvin fix: dataclass wrapper was not always called, #4477 by @PrettyWood Use tomllib on Python 3.11 when parsing mypy configuration, #4476 by @hauntsaninja Basic fix of GenericModel cache to detect order of arguments in Union models, #4474 by @sveinugu Fix mypy plugin when using bare types like list and dict as default\\\\\\\\\\\\\\_factory, #4457 by @samuelcolvin v1.10.1 (2022-08-31)¶ Add \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_hash\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method to pydancic.color.Color class, #4454 by @czaki v1.10.0 (2022-08-30)¶ Refactor the whole pydantic dataclass decorator to really act like its standard lib equivalent. It hence keeps \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_eq\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_hash\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, ... and makes comparison with its non-validated version possible. It also fixes usage of frozen dataclasses in fields and usage of default\\\\\\\\\\\\\\_factory in nested dataclasses. The support of Config.extra has been added. Finally, config customization directly via a dict is now possible, #2557 by @PrettyWood BREAKING CHANGES: The compiled boolean (whether pydantic is compiled with cython) has been moved from main.py to version.py Now that Config.extra is supported, dataclass ignores by default extra arguments (like BaseModel) Fix PEP487 \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_set\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ protocol in BaseModel for PrivateAttrs, #4407 by @tlambert03 Allow for custom parsing of environment variables via parse\\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_var in Config, #4406 by @acmiyaguchi Rename master to main, #4405 by @hramezani Fix StrictStr does not raise ValidationError when max\\\\\\\\\\\\\\_length is present in Field, #4388 by @hramezani Make SecretStr and SecretBytes hashable, #4387 by @chbndrhnns Fix StrictBytes does not raise ValidationError when max\\\\\\\\\\\\\\_length is present in Field, #4380 by @JeanArhancet Add support for bare type, #4375 by @hramezani Support Python 3.11, including binaries for 3.11 in PyPI, #4374 by @samuelcolvin Add support for re.Pattern, #4366 by @hramezani Fix \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_parse\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ is incorrectly passed keyword arguments when no \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ is defined, #4361 by @hramezani Fix implicitly importing ForwardRef and Callable from pydantic.typing instead of typing and also expose MappingIntStrAny, #4358 by @aminalaee remove Any types from the dataclass decorator so it can be used with the disallow\\\\\\\\\\\\\\_any\\\\\\\\\\\\\\_expr mypy option, #4356 by @DetachHead moved repo to pydantic/pydantic, #4348 by @yezz123 fix \"extra fields not permitted\" error when dataclass with Extra.forbid is validated multiple times, #4343 by @detachhead Add Python 3.9 and 3.10 examples to docs, #4339 by @Bobronium Discriminated union models now use oneOf instead of anyOf when generating OpenAPI schema definitions, #4335 by @MaxwellPayne Allow type checkers to infer inner type of Json type. Json\\\\\\\\\\\\\\[list\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] will be now inferred as list\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\], Json\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] should be used instead of plain Json. Runtime behaviour is not changed, #4332 by @Bobronium Allow empty string aliases by using a alias is not None check, rather than bool(alias), #4253 by @sergeytsaplin Update ForwardRefs in Field.outer\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_, #4249 by @JacobHayes The use of \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dataclass\\\\\\\\\\\\\\_transform\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ has been replaced by typing\\\\\\\\\\\\\\_extensions.dataclass\\\\\\\\\\\\\\_transform, which is the preferred way to mark pydantic models as a dataclass under PEP 681, #4241 by @multimeric Use parent model's Config when validating nested NamedTuple fields, #4219 by @synek Update BaseModel.construct to work with aliased Fields, #4192 by @kylebamos Catch certain raised errors in smart\\\\\\\\\\\\\\_deepcopy and revert to deepcopy if so, #4184 by @coneybeare Add Config.anystr\\\\\\\\\\\\\\_upper and to\\\\\\\\\\\\\\_upper kwarg to constr and conbytes, #4165 by @satheler Fix JSON schema for set and frozenset when they include default values, #4155 by @aminalaee Teach the mypy plugin that methods decorated by @validator are classmethods, #4102 by @DMRobertson Improve mypy plugin's ability to detect required fields, #4086 by @richardxia Support fields of type Type\\\\\\\\\\\\\\[\\\\\\\\\\\\\\] in schema, #4051 by @aminalaee Add default value in JSON Schema when const=True, #4031 by @aminalaee Adds reserved word check to signature generation logic, #4011 by @strue36 Fix Json strategy failure for the complex nested field, #4005 by @sergiosim Add JSON-compatible float constraint allow\\\\\\\\\\\\\\_inf\\\\\\\\\\\\\\_nan, #3994 by @tiangolo Remove undefined behaviour when env\\\\\\\\\\\\\\_prefix had characters in common with env\\\\\\\\\\\\\\_nested\\\\\\\\\\\\\\_delimiter, #3975 by @arsenron Support generics model with create\\\\\\\\\\\\\\_model, #3945 by @hot123s allow submodels to overwrite extra field info, #3934 by @PrettyWood Document and test structural pattern matching (PEP 636) on BaseModel, #3920 by @irgolic Fix incorrect deserialization of python timedelta object to ISO 8601 for negative time deltas. Minus was serialized in incorrect place (\"P-1DT23H59M59.888735S\" instead of correct \"-P1DT23H59M59.888735S\"), #3899 by @07pepa Fix validation of discriminated union fields with an alias when passing a model instance, #3846 by @chornsby Add a CockroachDsn type to validate CockroachDB connection strings. The type supports the following schemes: cockroachdb, cockroachdb+psycopg2 and cockroachdb+asyncpg, #3839 by @blubber Fix MyPy plugin to not override pre-existing \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method in models, #3824 by @patrick91 Fix mypy version checking, #3783 by @KotlinIsland support overwriting dunder attributes of BaseModel instances, #3777 by @PrettyWood Added ConstrainedDate and condate, #3740 by @hottwaj Support kw\\\\\\\\\\\\\\_only in dataclasses, #3670 by @detachhead Add comparison method for Color class, #3646 by @aminalaee Drop support for python3.6, associated cleanup, #3605 by @samuelcolvin created new function to\\\\\\\\\\\\\\_lower\\\\\\\\\\\\\\_camel() for \"non pascal case\" camel case, #3463 by @schlerp Add checks to default and default\\\\\\\\\\\\\\_factory arguments in Mypy plugin, #3430 by @klaa97 fix mangling of inspect.signature for BaseModel, #3413 by @fix-inspect-signature Adds the SecretField abstract class so that all the current and future secret fields like SecretStr and SecretBytes will derive from it, #3409 by @expobrain Support multi hosts validation in PostgresDsn, #3337 by @rglsk Fix parsing of very small numeric timedelta values, #3315 by @samuelcolvin Update SecretsSettingsSource to respect config.case\\\\\\\\\\\\\\_sensitive, #3273 by @JeanArhancet Add MongoDB network data source name (DSN) schema, #3229 by @snosratiershad Add support for multiple dotenv files, #3222 by @rekyungmin Raise an explicit ConfigError when multiple fields are incorrectly set for a single validator, #3215 by @SunsetOrange Allow ellipsis on Fields inside Annotated for TypedDicts required, #3133 by @ezegomez Catch overflow errors in int\\\\\\\\\\\\\\_validator, #3112 by @ojii Adds a \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_rich\\\\\\\\\\\\\\_repr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method to Representation class which enables pretty printing with Rich, #3099 by @willmcgugan Add percent encoding in AnyUrl and descendent types, #3061 by @FaresAhmedb validate\\\\\\\\\\\\\\_arguments decorator now supports alias, #3019 by @MAD-py Avoid \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_weakref\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ attributes in AnyUrl and IP address fields, #2890 by @nuno-andre Add ability to use Final in a field type annotation, #2766 by @uriyyo Update requirement to typing\\\\\\\\\\\\\\_extensions>=4.1.0 to guarantee dataclass\\\\\\\\\\\\\\_transform is available, #4424 by @commonism Add Explosion and AWS to main sponsors, #4413 by @samuelcolvin Update documentation for copy\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_validation to reflect recent changes, #4369 by @samuelcolvin Runtime warning if \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_slots\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ is passed to create\\\\\\\\\\\\\\_model, \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_slots\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ is then ignored, #4432 by @samuelcolvin Add type hints to BaseSettings.Config to avoid mypy errors, also correct mypy version compatibility notice in docs, #4450 by @samuelcolvin v1.10.0b1 (2022-08-24)¶ Pre-release, see the GitHub release for details. v1.10.0a2 (2022-08-24)¶ Pre-release, see the GitHub release for details. v1.10.0a1 (2022-08-22)¶ Pre-release, see the GitHub release for details. v1.9.2 (2022-08-11)¶ Revert Breaking Change: v1.9.1 introduced a breaking change where model fields were deep copied by default, this release reverts the default behaviour to match v1.9.0 and before, while also allow deep-copy behaviour via copy\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_validation = 'deep'. See #4092 for more information. Allow for shallow copies of model fields, Config.copy\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_validation is now a str which must be 'none', 'deep', or 'shallow' corresponding to not copying, deep copy & shallow copy; default 'shallow', #4093 by @timkpaine v1.9.1 (2022-05-19)¶ Thank you to pydantic's sponsors: @tiangolo, @stellargraph, @JonasKs, @grillazz, @Mazyod, @kevinalh, @chdsbd, @povilasb, @povilasb, @jina-ai, @mainframeindustries, @robusta-dev, @SendCloud, @rszamszur, @jodal, @hardbyte, @corleyma, @daddycocoaman, @Rehket, @jokull, @reillysiemens, @westonsteimel, @primer-io, @koxudaxi, @browniebroke, @stradivari96, @adriangb, @kamalgill, @jqueguiner, @dev-zero, @datarootsio, @RedCarpetUp for their kind support. Limit the size of generics.\\\\\\\\\\\\\\_generic\\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_cache and generics.\\\\\\\\\\\\\\_assigned\\\\\\\\\\\\\\_parameters to avoid unlimited increase in memory usage, #4083 by @samuelcolvin Add Jupyverse and FPS as Jupyter projects using pydantic, #4082 by @davidbrochart Speedup \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_isinstancecheck\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ on pydantic models when the type is not a model, may also avoid memory \"leaks\", #4081 by @samuelcolvin Fix in-place modification of FieldInfo that caused problems with PEP 593 type aliases, #4067 by @adriangb Add support for autocomplete in VS Code via \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dataclass\\\\\\\\\\\\\\_transform\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ when using pydantic.dataclasses.dataclass, #4006 by @giuliano-oliveira Remove benchmarks from codebase and docs, #3973 by @samuelcolvin Typing checking with pyright in CI, improve docs on vscode/pylance/pyright, #3972 by @samuelcolvin Fix nested Python dataclass schema regression, #3819 by @himbeles Update documentation about lazy evaluation of sources for Settings, #3806 by @garyd203 Prevent subclasses of bytes being converted to bytes, #3706 by @samuelcolvin Fixed \"error checking inheritance of\" when using PEP585 and PEP604 type hints, #3681 by @aleksul Allow self referencing ClassVars in models, #3679 by @samuelcolvin Breaking Change, see #4106: Fix issue with self-referencing dataclass, #3675 by @uriyyo Include non-standard port numbers in rendered URLs, #3652 by @dolfinus Config.copy\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_validation does a deep copy and not a shallow one, #3641 by @PrettyWood fix: clarify that discriminated unions do not support singletons, #3636 by @tommilligan Add read\\\\\\\\\\\\\\_text(encoding='utf-8') for setup.py, #3625 by @hswong3i Fix JSON Schema generation for Discriminated Unions within lists, #3608 by @samuelcolvin v1.9.0 (2021-12-31)¶ Thank you to pydantic's sponsors: @sthagen, @timdrijvers, @toinbis, @koxudaxi, @ginomempin, @primer-io, @and-semakin, @westonsteimel, @reillysiemens, @es3n1n, @jokull, @JonasKs, @Rehket, @corleyma, @daddycocoaman, @hardbyte, @datarootsio, @jodal, @aminalaee, @rafsaf, @jqueguiner, @chdsbd, @kevinalh, @Mazyod, @grillazz, @JonasKs, @simw, @leynier, @xfenix for their kind support. Highlights¶ add Python 3.10 support, #2885 by @PrettyWood Discriminated unions, #619 by @PrettyWood Config.smart\\\\\\\\\\\\\\_union for better union logic, #2092 by @PrettyWood Binaries for Macos M1 CPUs, #3498 by @samuelcolvin Complex types can be set via nested environment variables, e.g. foo\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_bar, #3159 by @Air-Mark add a dark mode to pydantic documentation, #2913 by @gbdlin Add support for autocomplete in VS Code via \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dataclass\\\\\\\\\\\\\\_transform\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, #2721 by @tiangolo Add \"exclude\" as a field parameter so that it can be configured using model config, #660 by @daviskirk v1.9.0 (2021-12-31) Changes¶ Apply update\\\\\\\\\\\\\\_forward\\\\\\\\\\\\\\_refs to Config.json\\\\\\\\\\\\\\_encodes prevent name clashes in types defined via strings, #3583 by @samuelcolvin Extend pydantic's mypy plugin to support mypy versions 0.910, 0.920, 0.921 & 0.930, #3573 & #3594 by @PrettyWood, @christianbundy, @samuelcolvin v1.9.0a2 (2021-12-24) Changes¶ support generic models with discriminated union, #3551 by @PrettyWood keep old behaviour of json() by default, #3542 by @PrettyWood Removed typing-only \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ attribute from BaseModel, #3540 by @layday Build Python 3.10 wheels, #3539 by @mbachry Fix display of extra fields with model \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_repr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, #3234 by @cocolman models copied via Config.copy\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_validation always have all fields, #3201 by @PrettyWood nested ORM from nested dictionaries, #3182 by @PrettyWood fix link to discriminated union section by @PrettyWood v1.9.0a1 (2021-12-18) Changes¶ Add support for Decimal-specific validation configurations in Field(), additionally to using condecimal(), to allow better support from editors and tooling, #3507 by @tiangolo Add arm64 binaries suitable for MacOS with an M1 CPU to PyPI, #3498 by @samuelcolvin Fix issue where None was considered invalid when using a Union type containing Any or object, #3444 by @tharradine When generating field schema, pass optional field argument (of type pydantic.fields.ModelField) to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_modify\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_() if present, #3434 by @jasujm Fix issue when pydantic fail to parse typing.ClassVar string type annotation, #3401 by @uriyyo Mention Python >= 3.9.2 as an alternative to typing\\\\\\\\\\\\\\_extensions.TypedDict, #3374 by @BvB93 Changed the validator method name in the Custom Errors example to more accurately describe what the validator is doing; changed from name\\\\\\\\\\\\\\_must\\\\\\\\\\\\\\_contain\\\\\\\\\\\\\\_space to value\\\\\\\\\\\\\\_must\\\\\\\\\\\\\\_equal\\\\\\\\\\\\\\_bar, #3327 by @michaelrios28 Add AmqpDsn class, #3254 by @kludex Always use Enum value as default in generated JSON schema, #3190 by @joaommartins Add support for Mypy 0.920, #3175 by @christianbundy validate\\\\\\\\\\\\\\_arguments now supports extra customization (used to always be Extra.forbid), #3161 by @PrettyWood Complex types can be set by nested environment variables, #3159 by @Air-Mark Fix mypy plugin to collect fields based on pydantic.utils.is\\\\\\\\\\\\\\_valid\\\\\\\\\\\\\\_field so that it ignores untyped private variables, #3146 by @hi-ogawa fix validate\\\\\\\\\\\\\\_arguments issue with Config.validate\\\\\\\\\\\\\\_all, #3135 by @PrettyWood avoid dict coercion when using dict subclasses as field type, #3122 by @PrettyWood add support for object type, #3062 by @PrettyWood Updates pydantic dataclasses to keep \\\\\\\\\\\\\\_special properties on parent classes, #3043 by @zulrang Add a TypedDict class for error objects, #3038 by @matthewhughes934 Fix support for using a subclass of an annotation as a default, #3018 by @JacobHayes make create\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_typeddict mypy compliant, #3008 by @PrettyWood Make multiple inheritance work when using PrivateAttr, #2989 by @hmvp Parse environment variables as JSON, if they have a Union type with a complex subfield, #2936 by @cbartz Prevent StrictStr permitting Enum values where the enum inherits from str, #2929 by @samuelcolvin Make SecretsSettingsSource parse values being assigned to fields of complex types when sourced from a secrets file, just as when sourced from environment variables, #2917 by @davidmreed add a dark mode to pydantic documentation, #2913 by @gbdlin Make pydantic-mypy plugin compatible with pyproject.toml configuration, consistent with mypy changes. See the doc for more information, #2908 by @jrwalk add Python 3.10 support, #2885 by @PrettyWood Correctly parse generic models with Json\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\], #2860 by @geekingfrog Update contrib docs re: Python version to use for building docs, #2856 by @paxcodes Clarify documentation about pydantic's support for custom validation and strict type checking, despite pydantic being primarily a parsing library, #2855 by @paxcodes Fix schema generation for Deque fields, #2810 by @sergejkozin fix an edge case when mixing constraints and Literal, #2794 by @PrettyWood Fix postponed annotation resolution for NamedTuple and TypedDict when they're used directly as the type of fields within Pydantic models, #2760 by @jameysharp Fix bug when mypy plugin fails on construct method call for BaseSettings derived classes, #2753 by @uriyyo Add function overloading for a pydantic.create\\\\\\\\\\\\\\_model function, #2748 by @uriyyo Fix mypy plugin issue with self field declaration, #2743 by @uriyyo The colon at the end of the line \"The fields which were supplied when user was initialised:\" suggests that the code following it is related. Changed it to a period, #2733 by @krisaoe Renamed variable schema to schema\\\\\\\\\\\\\\_ to avoid shadowing of global variable name, #2724 by @shahriyarr Add support for autocomplete in VS Code via \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dataclass\\\\\\\\\\\\\\_transform\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, #2721 by @tiangolo add missing type annotations in BaseConfig and handle max\\\\\\\\\\\\\\_length = 0, #2719 by @PrettyWood Change orm\\\\\\\\\\\\\\_mode checking to allow recursive ORM mode parsing with dicts, #2718 by @nuno-andre Add episode 313 of the Talk Python To Me podcast, where Michael Kennedy and Samuel Colvin discuss Pydantic, to the docs, #2712 by @RatulMaharaj fix JSON schema generation when a field is of type NamedTuple and has a default value, #2707 by @PrettyWood Enum fields now properly support extra kwargs in schema generation, #2697 by @sammchardy Breaking Change, see #3780: Make serialization of referenced pydantic models possible, #2650 by @PrettyWood Add uniqueItems option to ConstrainedList, #2618 by @nuno-andre Try to evaluate forward refs automatically at model creation, #2588 by @uriyyo Switch docs preview and coverage display to use smokeshow, #2580 by @samuelcolvin Add \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_version\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ attribute to pydantic module, #2572 by @paxcodes Add postgresql+asyncpg, postgresql+pg8000, postgresql+psycopg2, postgresql+psycopg2cffi, postgresql+py-postgresql and postgresql+pygresql schemes for PostgresDsn, #2567 by @postgres-asyncpg Enable the Hypothesis plugin to generate a constrained decimal when the decimal\\\\\\\\\\\\\\_places argument is specified, #2524 by @cwe5590 Allow collections.abc.Callable to be used as type in Python 3.9, #2519 by @daviskirk Documentation update how to custom compile pydantic when using pip install, small change in setup.py to allow for custom CFLAGS when compiling, #2517 by @peterroelants remove side effect of default\\\\\\\\\\\\\\_factory to run it only once even if Config.validate\\\\\\\\\\\\\\_all is set, #2515 by @PrettyWood Add lookahead to ip regexes for AnyUrl hosts. This allows urls with DNS labels looking like IPs to validate as they are perfectly valid host names, #2512 by @sbv-csis Set minItems and maxItems in generated JSON schema for fixed-length tuples, #2497 by @PrettyWood Add strict argument to conbytes, #2489 by @koxudaxi Support user defined generic field types in generic models, #2465 by @daviskirk Add an example and a short explanation of subclassing GetterDict to docs, #2463 by @nuno-andre add KafkaDsn type, HttpUrl now has default port 80 for http and 443 for https, #2447 by @MihanixA Add PastDate and FutureDate types, #2425 by @Kludex Support generating schema for Generic fields with subtypes, #2375 by @maximberg fix(encoder): serialize NameEmail to str, #2341 by @alecgerona add Config.smart\\\\\\\\\\\\\\_union to prevent coercion in Union if possible, see the doc for more information, #2092 by @PrettyWood Add ability to use typing.Counter as a model field type, #2060 by @uriyyo Add parameterised subclasses to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_bases\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ when constructing new parameterised classes, so that A <: B => A\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] <: B\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\], #2007 by @diabolo-dan Create FileUrl type that allows URLs that conform to RFC 8089. Add host\\\\\\\\\\\\\\_required parameter, which is True by default (AnyUrl and subclasses), False in RedisDsn, FileUrl, #1983 by @vgerak add confrozenset(), analogous to conset() and conlist(), #1897 by @PrettyWood stop calling parent class root\\\\\\\\\\\\\\_validator if overridden, #1895 by @PrettyWood Add repr (defaults to True) parameter to Field, to hide it from the default representation of the BaseModel, #1831 by @fnep Accept empty query/fragment URL parts, #1807 by @xavier v1.8.2 (2021-05-11)¶ Warning A security vulnerability, level \"moderate\" is fixed in v1.8.2. Please upgrade ASAP. See security advisory CVE-2021-29510 Security fix: Fix date and datetime parsing so passing either 'infinity' or float('inf') (or their negative values) does not cause an infinite loop, see security advisory CVE-2021-29510 fix schema generation with Enum by generating a valid name, #2575 by @PrettyWood fix JSON schema generation with a Literal of an enum member, #2536 by @PrettyWood Fix bug with configurations declarations that are passed as keyword arguments during class creation, #2532 by @uriyyo Allow passing json\\\\\\\\\\\\\\_encoders in class kwargs, #2521 by @layday support arbitrary types with custom \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_eq\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, #2483 by @PrettyWood support Annotated in validate\\\\\\\\\\\\\\_arguments and in generic models with Python 3.9, #2483 by @PrettyWood v1.8.1 (2021-03-03)¶ Bug fixes for regressions and new features from v1.8 allow elements of Config.field to update elements of a Field, #2461 by @samuelcolvin fix validation with a BaseModel field and a custom root type, #2449 by @PrettyWood expose Pattern encoder to fastapi, #2444 by @PrettyWood enable the Hypothesis plugin to generate a constrained float when the multiple\\\\\\\\\\\\\\_of argument is specified, #2442 by @tobi-lipede-oodle Avoid RecursionError when using some types like Enum or Literal with generic models, #2436 by @PrettyWood do not overwrite declared \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_hash\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ in subclasses of a model, #2422 by @PrettyWood fix mypy complaints on Path and UUID related custom types, #2418 by @PrettyWood Support properly variable length tuples of compound types, #2416 by @PrettyWood v1.8 (2021-02-26)¶ Thank you to pydantic's sponsors: @jorgecarleitao, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @koxudaxi, @timdrijvers, @mkeen, @meadsteve, @ginomempin, @primer-io, @and-semakin, @tomthorogood, @AjitZK, @westonsteimel, @Mazyod, @christippett, @CarlosDomingues, @Kludex, @r-m-n for their kind support. Highlights¶ Hypothesis plugin for testing, #2097 by @Zac-HD support for NamedTuple and TypedDict, #2216 by @PrettyWood Support Annotated hints on model fields, #2147 by @JacobHayes frozen parameter on Config to allow models to be hashed, #1880 by @rhuille Changes¶ Breaking Change, remove old deprecation aliases from v1, #2415 by @samuelcolvin: remove notes on migrating to v1 in docs remove Schema which was replaced by Field remove Config.case\\\\\\\\\\\\\\_insensitive which was replaced by Config.case\\\\\\\\\\\\\\_sensitive (default False) remove Config.allow\\\\\\\\\\\\\\_population\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_alias which was replaced by Config.allow\\\\\\\\\\\\\\_population\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_name remove model.fields which was replaced by model.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ remove model.to\\\\\\\\\\\\\\_string() which was replaced by str(model) remove model.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_values\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ which was replaced by model.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ Breaking Change: always validate only first sublevel items with each\\\\\\\\\\\\\\_item. There were indeed some edge cases with some compound types where the validated items were the last sublevel ones, #1933 by @PrettyWood Update docs extensions to fix local syntax highlighting, #2400 by @daviskirk fix: allow utils.lenient\\\\\\\\\\\\\\_issubclass to handle typing.GenericAlias objects like list\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] in Python >= 3.9, #2399 by @daviskirk Improve field declaration for pydantic dataclass by allowing the usage of pydantic Field or 'metadata' kwarg of dataclasses.field, #2384 by @PrettyWood Making typing-extensions a required dependency, #2368 by @samuelcolvin Make resolve\\\\\\\\\\\\\\_annotations more lenient, allowing for missing modules, #2363 by @samuelcolvin Allow configuring models through class kwargs, #2356 by @Bobronium Prevent Mapping subclasses from always being coerced to dict, #2325 by @ofek fix: allow None for type Optional\\\\\\\\\\\\\\[conset / conlist\\\\\\\\\\\\\\], #2320 by @PrettyWood Support empty tuple type, #2318 by @PrettyWood fix: python\\\\\\\\\\\\\\_requires metadata to require >=3.6.1, #2306 by @hukkinj1 Properly encode Decimal with, or without any decimal places, #2293 by @hultner fix: update \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ in BaseModel.copy(update=…), #2290 by @PrettyWood fix: keep order of fields with BaseModel.construct(), #2281 by @PrettyWood Support generating schema for Generic fields, #2262 by @maximberg Fix validate\\\\\\\\\\\\\\_decorator so \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*kwargs doesn't exclude values when the keyword has the same name as the \\\\\\\\\\\\\\*args or \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*kwargs names, #2251 by @cybojenix Prevent overriding positional arguments with keyword arguments in validate\\\\\\\\\\\\\\_arguments, as per behaviour with native functions, #2249 by @cybojenix add documentation for con\\\\\\\\\\\\\\* type functions, #2242 by @tayoogunbiyi Support custom root type (aka \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_) when using parse\\\\\\\\\\\\\\_obj() with nested models, #2238 by @PrettyWood Support custom root type (aka \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_) with from\\\\\\\\\\\\\\_orm(), #2237 by @PrettyWood ensure cythonized functions are left untouched when creating models, based on #1944 by @kollmats, #2228 by @samuelcolvin Resolve forward refs for stdlib dataclasses converted into pydantic ones, #2220 by @PrettyWood Add support for NamedTuple and TypedDict types. Those two types are now handled and validated when used inside BaseModel or pydantic dataclass. Two utils are also added create\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_namedtuple and create\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_typeddict, #2216 by @PrettyWood Do not ignore annotated fields when type is Union\\\\\\\\\\\\\\[Type\\\\\\\\\\\\\\[...\\\\\\\\\\\\\\], ...\\\\\\\\\\\\\\], #2213 by @PrettyWood Raise a user-friendly TypeError when a root\\\\\\\\\\\\\\_validator does not return a dict (e.g. None), #2209 by @masalim2 Add a FrozenSet\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] type annotation to the allowed\\\\\\\\\\\\\\_schemes argument on the strict\\\\\\\\\\\\\\_url field type, #2198 by @Midnighter add allow\\\\\\\\\\\\\\_mutation constraint to Field, #2195 by @sblack-usu Allow Field with a default\\\\\\\\\\\\\\_factory to be used as an argument to a function decorated with validate\\\\\\\\\\\\\\_arguments, #2176 by @thomascobb Allow non-existent secrets directory by only issuing a warning, #2175 by @davidolrik fix URL regex to parse fragment without query string, #2168 by @andrewmwhite fix: ensure to always return one of the values in Literal field type, #2166 by @PrettyWood Support typing.Annotated hints on model fields. A Field may now be set in the type hint with Annotated\\\\\\\\\\\\\\[..., Field(...); all other annotations are ignored but still visible with get\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_hints(..., include\\\\\\\\\\\\\\_extras=True), #2147 by @JacobHayes Added StrictBytes type as well as strict=False option to ConstrainedBytes, #2136 by @rlizzo added Config.anystr\\\\\\\\\\\\\\_lower and to\\\\\\\\\\\\\\_lower kwarg to constr and conbytes, #2134 by @tayoogunbiyi Support plain typing.Tuple type, #2132 by @PrettyWood Add a bound method validate to functions decorated with validate\\\\\\\\\\\\\\_arguments to validate parameters without actually calling the function, #2127 by @PrettyWood Add the ability to customize settings sources (add / disable / change priority order), #2107 by @kozlek Fix mypy complaints about most custom pydantic types, #2098 by @PrettyWood Add a Hypothesis plugin for easier property-based testing with Pydantic's custom types - usage details here, #2097 by @Zac-HD add validator for None, NoneType or Literal\\\\\\\\\\\\\\[None\\\\\\\\\\\\\\], #2095 by @PrettyWood Handle properly fields of type Callable with a default value, #2094 by @PrettyWood Updated create\\\\\\\\\\\\\\_model return type annotation to return type which inherits from \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_base\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ argument, #2071 by @uriyyo Add merged json\\\\\\\\\\\\\\_encoders inheritance, #2064 by @art049 allow overwriting ClassVars in sub-models without having to re-annotate them, #2061 by @layday add default encoder for Pattern type, #2045 by @PrettyWood Add NonNegativeInt, NonPositiveInt, NonNegativeFloat, NonPositiveFloat, #1975 by @mdavis-xyz Use % for percentage in string format of colors, #1960 by @EdwardBetts Fixed issue causing KeyError to be raised when building schema from multiple BaseModel with the same names declared in separate classes, #1912 by @JSextonn Add rediss (Redis over SSL) protocol to RedisDsn Allow URLs without user part (e.g., rediss://:pass@localhost), #1911 by @TrDex Add a new frozen boolean parameter to Config (default: False). Setting frozen=True does everything that allow\\\\\\\\\\\\\\_mutation=False does, and also generates a \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_hash\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_() method for the model. This makes instances of the model potentially hashable if all the attributes are hashable, #1880 by @rhuille fix schema generation with multiple Enums having the same name, #1857 by @PrettyWood Added support for 13/19 digits VISA credit cards in PaymentCardNumber type, #1416 by @AlexanderSov fix: prevent RecursionError while using recursive GenericModels, #1370 by @xppt use enum for typing.Literal in JSON schema, #1350 by @PrettyWood Fix: some recursive models did not require update\\\\\\\\\\\\\\_forward\\\\\\\\\\\\\\_refs and silently behaved incorrectly, #1201 by @PrettyWood Fix bug where generic models with fields where the typevar is nested in another type a: List\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\] are considered to be concrete. This allows these models to be subclassed and composed as expected, #947 by @daviskirk Add Config.copy\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_validation flag. When set to False, pydantic will keep models used as fields untouched on validation instead of reconstructing (copying) them, #265 by @PrettyWood v1.7.4 (2021-05-11)¶ Security fix: Fix date and datetime parsing so passing either 'infinity' or float('inf') (or their negative values) does not cause an infinite loop, See security advisory CVE-2021-29510 v1.7.3 (2020-11-30)¶ Thank you to pydantic's sponsors: @timdrijvers, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @jorgecarleitao, @koxudaxi, @primer-api, @mkeen, @meadsteve for their kind support. fix: set right default value for required (optional) fields, #2142 by @PrettyWood fix: support underscore\\\\\\\\\\\\\\_attrs\\\\\\\\\\\\\\_are\\\\\\\\\\\\\\_private with generic models, #2138 by @PrettyWood fix: update all modified field values in root\\\\\\\\\\\\\\_validator when validate\\\\\\\\\\\\\\_assignment is on, #2116 by @PrettyWood Allow pickling of pydantic.dataclasses.dataclass dynamically created from a built-in dataclasses.dataclass, #2111 by @aimestereo Fix a regression where Enum fields would not propagate keyword arguments to the schema, #2109 by @bm424 Ignore \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_doc\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ as private attribute when Config.underscore\\\\\\\\\\\\\\_attrs\\\\\\\\\\\\\\_are\\\\\\\\\\\\\\_private is set, #2090 by @PrettyWood v1.7.2 (2020-11-01)¶ fix slow GenericModel concrete model creation, allow GenericModel concrete name reusing in module, #2078 by @Bobronium keep the order of the fields when validate\\\\\\\\\\\\\\_assignment is set, #2073 by @PrettyWood forward all the params of the stdlib dataclass when converted into pydantic dataclass, #2065 by @PrettyWood v1.7.1 (2020-10-28)¶ Thank you to pydantic's sponsors: @timdrijvers, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @jorgecarleitao, @koxudaxi, @primer-api, @mkeen for their kind support. fix annotation of validate\\\\\\\\\\\\\\_arguments when passing configuration as argument, #2055 by @layday Fix mypy assignment error when using PrivateAttr, #2048 by @aphedges fix underscore\\\\\\\\\\\\\\_attrs\\\\\\\\\\\\\\_are\\\\\\\\\\\\\\_private causing TypeError when overriding \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, #2047 by @samuelcolvin Fixed regression introduced in v1.7 involving exception handling in field validators when validate\\\\\\\\\\\\\\_assignment=True, #2044 by @johnsabath fix: pydantic dataclass can inherit from stdlib dataclass and Config.arbitrary\\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_allowed is supported, #2042 by @PrettyWood v1.7 (2020-10-26)¶ Thank you to pydantic's sponsors: @timdrijvers, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @jorgecarleitao, @koxudaxi, @primer-api for their kind support. Highlights¶ Python 3.9 support, thanks @PrettyWood Private model attributes, thanks @Bobronium \"secrets files\" support in BaseSettings, thanks @mdgilene convert stdlib dataclasses to pydantic dataclasses and use stdlib dataclasses in models, thanks @PrettyWood Changes¶ Breaking Change: remove \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_defaults\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, add default\\\\\\\\\\\\\\_factory support with BaseModel.construct. Use .get\\\\\\\\\\\\\\_default() method on fields in \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ attribute instead, #1732 by @PrettyWood Rearrange CI to run linting as a separate job, split install recipes for different tasks, #2020 by @samuelcolvin Allows subclasses of generic models to make some, or all, of the superclass's type parameters concrete, while also defining new type parameters in the subclass, #2005 by @choogeboom Call validator with the correct values parameter type in BaseModel.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_setattr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, when validate\\\\\\\\\\\\\\_assignment = True in model config, #1999 by @me-ransh Force fields.Undefined to be a singleton object, fixing inherited generic model schemas, #1981 by @daviskirk Include tests in source distributions, #1976 by @sbraz Add ability to use min\\\\\\\\\\\\\\_length/max\\\\\\\\\\\\\\_length constraints with secret types, #1974 by @uriyyo Also check root\\\\\\\\\\\\\\_validators when validate\\\\\\\\\\\\\\_assignment is on, #1971 by @PrettyWood Fix const validators not running when custom validators are present, #1957 by @hmvp add deque to field types, #1935 by @wozniakty add basic support for Python 3.9, #1832 by @PrettyWood Fix typo in the anchor of exporting\\\\\\\\\\\\\\_models.md#modelcopy and incorrect description, #1821 by @KimMachineGun Added ability for BaseSettings to read \"secret files\", #1820 by @mdgilene add parse\\\\\\\\\\\\\\_raw\\\\\\\\\\\\\\_as utility function, #1812 by @PrettyWood Support home directory relative paths for dotenv files (e.g. ~/.env), #1803 by @PrettyWood Clarify documentation for parse\\\\\\\\\\\\\\_file to show that the argument should be a file path not a file-like object, #1794 by @mdavis-xyz Fix false positive from mypy plugin when a class nested within a BaseModel is named Model, #1770 by @selimb add basic support of Pattern type in schema generation, #1767 by @PrettyWood Support custom title, description and default in schema of enums, #1748 by @PrettyWood Properly represent Literal Enums when use\\\\\\\\\\\\\\_enum\\\\\\\\\\\\\\_values is True, #1747 by @noelevans Allows timezone information to be added to strings to be formatted as time objects. Permitted formats are Z for UTC or an offset for absolute positive or negative time shifts. Or the timezone data can be omitted, #1744 by @noelevans Add stub \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ with Python 3.6 signature for ForwardRef, #1738 by @sirtelemak Fix behaviour with forward refs and optional fields in nested models, #1736 by @PrettyWood add Enum and IntEnum as valid types for fields, #1735 by @PrettyWood Change default value of \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_module\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ argument of create\\\\\\\\\\\\\\_model from None to 'pydantic.main'. Set reference of created concrete model to it's module to allow pickling (not applied to models created in functions), #1686 by @Bobronium Add private attributes support, #1679 by @Bobronium add config to @validate\\\\\\\\\\\\\\_arguments, #1663 by @samuelcolvin Allow descendant Settings models to override env variable names for the fields defined in parent Settings models with env in their Config. Previously only env\\\\\\\\\\\\\\_prefix configuration option was applicable, #1561 by @ojomio Support ref\\\\\\\\\\\\\\_template when creating schema $refs, #1479 by @kilo59 Add a \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_call\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ stub to PyObject so that mypy will know that it is callable, #1352 by @brianmaissy pydantic.dataclasses.dataclass decorator now supports built-in dataclasses.dataclass. It is hence possible to convert an existing dataclass easily to add Pydantic validation. Moreover nested dataclasses are also supported, #744 by @PrettyWood v1.6.2 (2021-05-11)¶ Security fix: Fix date and datetime parsing so passing either 'infinity' or float('inf') (or their negative values) does not cause an infinite loop, See security advisory CVE-2021-29510 v1.6.1 (2020-07-15)¶ fix validation and parsing of nested models with default\\\\\\\\\\\\\\_factory, #1710 by @PrettyWood v1.6 (2020-07-11)¶ Thank you to pydantic's sponsors: @matin, @tiangolo, @chdsbd, @jorgecarleitao, and 1 anonymous sponsor for their kind support. Modify validators for conlist and conset to not have always=True, #1682 by @samuelcolvin add port check to AnyUrl (can't exceed 65536) ports are 16 insigned bits: 0 <= port <= 2\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*16-1 src: rfc793 header format, #1654 by @flapili Document default regex anchoring semantics, #1648 by @yurikhan Use chain.from\\\\\\\\\\\\\\_iterable in class\\\\\\\\\\\\\\_validators.py. This is a faster and more idiomatic way of using itertools.chain. Instead of computing all the items in the iterable and storing them in memory, they are computed one-by-one and never stored as a huge list. This can save on both runtime and memory space, #1642 by @cool-RR Add conset(), analogous to conlist(), #1623 by @patrickkwang make Pydantic errors (un)pickable, #1616 by @PrettyWood Allow custom encoding for dotenv files, #1615 by @PrettyWood Ensure SchemaExtraCallable is always defined to get type hints on BaseConfig, #1614 by @PrettyWood Update datetime parser to support negative timestamps, #1600 by @mlbiche Update mypy, remove AnyType alias for Type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], #1598 by @samuelcolvin Adjust handling of root validators so that errors are aggregated from all failing root validators, instead of reporting on only the first root validator to fail, #1586 by @beezee Make \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_modify\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ on Enums apply to the enum schema rather than fields that use the enum, #1581 by @therefromhere Fix behavior of \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_all\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ key when used in conjunction with index keys in advanced include/exclude of fields that are sequences, #1579 by @xspirus Subclass validators do not run when referencing a List field defined in a parent class when each\\\\\\\\\\\\\\_item=True. Added an example to the docs illustrating this, #1566 by @samueldeklund change schema.field\\\\\\\\\\\\\\_class\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_schema to support frozenset in schema, #1557 by @wangpeibao Call \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_modify\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ only for the field schema, #1552 by @PrettyWood Move the assignment of field.validate\\\\\\\\\\\\\\_always in fields.py so the always parameter of validators work on inheritance, #1545 by @dcHHH Added support for UUID instantiation through 16 byte strings such as b'\\\\\\\\\\\\\\\\x12\\\\\\\\\\\\\\\\x34\\\\\\\\\\\\\\\\x56\\\\\\\\\\\\\\\\x78' \\\\\\\\\\\\\\* 4. This was done to support BINARY(16) columns in sqlalchemy, #1541 by @shawnwall Add a test assertion that default\\\\\\\\\\\\\\_factory can return a singleton, #1523 by @therefromhere Add NameEmail.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_eq\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ so duplicate NameEmail instances are evaluated as equal, #1514 by @stephen-bunn Add datamodel-code-generator link in pydantic document site, #1500 by @koxudaxi Added a \"Discussion of Pydantic\" section to the documentation, with a link to \"Pydantic Introduction\" video by Alexander Hultnér, #1499 by @hultner Avoid some side effects of default\\\\\\\\\\\\\\_factory by calling it only once if possible and by not setting a default value in the schema, #1491 by @PrettyWood Added docs about dumping dataclasses to JSON, #1487 by @mikegrima Make BaseModel.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_signature\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ class-only, so getting \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_signature\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ from model instance will raise AttributeError, #1466 by @Bobronium include 'format': 'password' in the schema for secret types, #1424 by @atheuz Modify schema constraints on ConstrainedFloat so that exclusiveMinimum and minimum are not included in the schema if they are equal to -math.inf and exclusiveMaximum and maximum are not included if they are equal to math.inf, #1417 by @vdwees Squash internal \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ dicts in .dict() (and, by extension, in .json()), #1414 by @patrickkwang Move const validator to post-validators so it validates the parsed value, #1410 by @selimb Fix model validation to handle nested literals, e.g. Literal\\\\\\\\\\\\\\['foo', Literal\\\\\\\\\\\\\\['bar'\\\\\\\\\\\\\\]\\\\\\\\\\\\\\], #1364 by @DBCerigo Remove user\\\\\\\\\\\\\\_required = True from RedisDsn, neither user nor password are required, #1275 by @samuelcolvin Remove extra allOf from schema for fields with Union and custom Field, #1209 by @mostaphaRoudsari Updates OpenAPI schema generation to output all enums as separate models. Instead of inlining the enum values in the model schema, models now use a $ref property to point to the enum definition, #1173 by @calvinwyoung v1.5.1 (2020-04-23)¶ Signature generation with extra: allow never uses a field name, #1418 by @prettywood Avoid mutating Field default value, #1412 by @prettywood v1.5 (2020-04-18)¶ Make includes/excludes arguments for .dict(), .\\\\\\\\\\\\\\_iter(), ..., immutable, #1404 by @AlexECX Always use a field's real name with includes/excludes in model.\\\\\\\\\\\\\\_iter(), regardless of by\\\\\\\\\\\\\\_alias, #1397 by @AlexECX Update constr regex example to include start and end lines, #1396 by @lmcnearney Confirm that shallow model.copy() does make a shallow copy of attributes, #1383 by @samuelcolvin Renaming model\\\\\\\\\\\\\\_name argument of main.create\\\\\\\\\\\\\\_model() to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_name to allow using model\\\\\\\\\\\\\\_name as a field name, #1367 by @kittipatv Replace raising of exception to silent passing for non-Var attributes in mypy plugin, #1345 by @b0g3r Remove typing\\\\\\\\\\\\\\_extensions dependency for Python 3.8, #1342 by @prettywood Make SecretStr and SecretBytes initialization idempotent, #1330 by @atheuz document making secret types dumpable using the json method, #1328 by @atheuz Move all testing and build to github actions, add windows and macos binaries, thank you @StephenBrown2 for much help, #1326 by @samuelcolvin fix card number length check in PaymentCardNumber, PaymentCardBrand now inherits from str, #1317 by @samuelcolvin Have BaseModel inherit from Representation to make mypy happy when overriding \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_str\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, #1310 by @FuegoFro Allow None as input to all optional list fields, #1307 by @prettywood Add datetime field to default\\\\\\\\\\\\\\_factory example, #1301 by @StephenBrown2 Allow subclasses of known types to be encoded with superclass encoder, #1291 by @StephenBrown2 Exclude exported fields from all elements of a list/tuple of submodels/dicts with '\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_all\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_', #1286 by @masalim2 Add pydantic.color.Color objects as available input for Color fields, #1258 by @leosussan In examples, type nullable fields as Optional, so that these are valid mypy annotations, #1248 by @kokes Make pattern\\\\\\\\\\\\\\_validator() accept pre-compiled Pattern objects. Fix str\\\\\\\\\\\\\\_validator() return type to str, #1237 by @adamgreg Document how to manage Generics and inheritance, #1229 by @esadruhn update\\\\\\\\\\\\\\_forward\\\\\\\\\\\\\\_refs() method of BaseModel now copies \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ of class module instead of modyfying it, #1228 by @paul-ilyin Support instance methods and class methods with @validate\\\\\\\\\\\\\\_arguments, #1222 by @samuelcolvin Add default\\\\\\\\\\\\\\_factory argument to Field to create a dynamic default value by passing a zero-argument callable, #1210 by @prettywood add support for NewType of List, Optional, etc, #1207 by @Kazy fix mypy signature for root\\\\\\\\\\\\\\_validator, #1192 by @samuelcolvin Fixed parsing of nested 'custom root type' models, #1190 by @Shados Add validate\\\\\\\\\\\\\\_arguments function decorator which checks the arguments to a function matches type annotations, #1179 by @samuelcolvin Add \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_signature\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ to models, #1034 by @Bobronium Refactor .\\\\\\\\\\\\\\_iter() method, 10x speed boost for dict(model), #1017 by @Bobronium v1.4 (2020-01-24)¶ Breaking Change: alias precedence logic changed so aliases on a field always take priority over an alias from alias\\\\\\\\\\\\\\_generator to avoid buggy/unexpected behaviour, see here for details, #1178 by @samuelcolvin Add support for unicode and punycode in TLDs, #1182 by @jamescurtin Fix cls argument in validators during assignment, #1172 by @samuelcolvin completing Luhn algorithm for PaymentCardNumber, #1166 by @cuencandres add support for generics that implement \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ like a custom data type, #1159 by @tiangolo add support for infinite generators with Iterable, #1152 by @tiangolo fix url\\\\\\\\\\\\\\_regex to accept schemas with +, - and . after the first character, #1142 by @samuelcolvin move version\\\\\\\\\\\\\\_info() to version.py, suggest its use in issues, #1138 by @samuelcolvin Improve pydantic import time by roughly 50% by deferring some module loading and regex compilation, #1127 by @samuelcolvin Fix EmailStr and NameEmail to accept instances of themselves in cython, #1126 by @koxudaxi Pass model class to the Config.schema\\\\\\\\\\\\\\_extra callable, #1125 by @therefromhere Fix regex for username and password in URLs, #1115 by @samuelcolvin Add support for nested generic models, #1104 by @dmontagu add \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_all\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.py to prevent \"implicit reexport\" errors from mypy, #1072 by @samuelcolvin Add support for using \"dotenv\" files with BaseSettings, #1011 by @acnebs v1.3 (2019-12-21)¶ Change schema and schema\\\\\\\\\\\\\\_model to handle dataclasses by using their \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ feature, #792 by @aviramha Added option for root\\\\\\\\\\\\\\_validator to be skipped if values validation fails using keyword skip\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_failure=True, #1049 by @aviramha Allow Config.schema\\\\\\\\\\\\\\_extra to be a callable so that the generated schema can be post-processed, #1054 by @selimb Update mypy to version 0.750, #1057 by @dmontagu Trick Cython into allowing str subclassing, #1061 by @skewty Prevent type attributes being added to schema unless the attribute \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_attributes\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ is True, #1064 by @samuelcolvin Change BaseModel.parse\\\\\\\\\\\\\\_file to use Config.json\\\\\\\\\\\\\\_loads, #1067 by @kierandarcy Fix for optional Json fields, #1073 by @volker48 Change the default number of threads used when compiling with cython to one, allow override via the CYTHON\\\\\\\\\\\\\\_NTHREADS environment variable, #1074 by @samuelcolvin Run FastAPI tests during Pydantic's CI tests, #1075 by @tiangolo My mypy strictness constraints, and associated tweaks to type annotations, #1077 by @samuelcolvin Add \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_eq\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ to SecretStr and SecretBytes to allow \"value equals\", #1079 by @sbv-trueenergy Fix schema generation for nested None case, #1088 by @lutostag Consistent checks for sequence like objects, #1090 by @samuelcolvin Fix Config inheritance on BaseSettings when used with env\\\\\\\\\\\\\\_prefix, #1091 by @samuelcolvin Fix for \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_modify\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ when it conflicted with field\\\\\\\\\\\\\\_class\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\*, #1102 by @samuelcolvin docs: Fix explanation of case sensitive environment variable names when populating BaseSettings subclass attributes, #1105 by @tribals Rename django-rest-framework benchmark in documentation, #1119 by @frankie567 v1.2 (2019-11-28)¶ Possible Breaking Change: Add support for required Optional with name: Optional\\\\\\\\\\\\\\[AnyType\\\\\\\\\\\\\\] = Field(...) and refactor ModelField creation to preserve required parameter value, #1031 by @tiangolo; see here for details Add benchmarks for cattrs, #513 by @sebastianmika Add exclude\\\\\\\\\\\\\\_none option to dict() and friends, #587 by @niknetniko Add benchmarks for valideer, #670 by @gsakkis Add parse\\\\\\\\\\\\\\_obj\\\\\\\\\\\\\\_as and parse\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_as functions for ad-hoc parsing of data into arbitrary pydantic-compatible types, #934 by @dmontagu Add allow\\\\\\\\\\\\\\_reuse argument to validators, thus allowing validator reuse, #940 by @dmontagu Add support for mapping types for custom root models, #958 by @dmontagu Mypy plugin support for dataclasses, #966 by @koxudaxi Add support for dataclasses default factory, #968 by @ahirner Add a ByteSize type for converting byte string (1GB) to plain bytes, #977 by @dgasmith Fix mypy complaint about @root\\\\\\\\\\\\\\_validator(pre=True), #984 by @samuelcolvin Add manylinux binaries for Python 3.8 to pypi, also support manylinux2010, #994 by @samuelcolvin Adds ByteSize conversion to another unit, #995 by @dgasmith Fix \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_str\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_repr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ inheritance for models, #1022 by @samuelcolvin add testimonials section to docs, #1025 by @sullivancolin Add support for typing.Literal for Python 3.8, #1026 by @dmontagu v1.1.1 (2019-11-20)¶ Fix bug where use of complex fields on sub-models could cause fields to be incorrectly configured, #1015 by @samuelcolvin v1.1 (2019-11-07)¶ Add a mypy plugin for type checking BaseModel.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and more, #722 by @dmontagu Change return type typehint for GenericModel.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_class\\\\\\\\\\\\\\_getitem\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ to prevent PyCharm warnings, #936 by @dmontagu Fix usage of Any to allow None, also support TypeVar thus allowing use of un-parameterised collection types e.g. Dict and List, #962 by @samuelcolvin Set FieldInfo on subfields to fix schema generation for complex nested types, #965 by @samuelcolvin v1.0 (2019-10-23)¶ Breaking Change: deprecate the Model.fields property, use Model.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ instead, #883 by @samuelcolvin Breaking Change: Change the precedence of aliases so child model aliases override parent aliases, including using alias\\\\\\\\\\\\\\_generator, #904 by @samuelcolvin Breaking change: Rename skip\\\\\\\\\\\\\\_defaults to exclude\\\\\\\\\\\\\\_unset, and add ability to exclude actual defaults, #915 by @dmontagu Add \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*kwargs to pydantic.main.ModelMetaclass.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_new\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ so \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_subclass\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ can take custom parameters on extended BaseModel classes, #867 by @retnikt Fix field of a type that has a default value, #880 by @koxudaxi Use FutureWarning instead of DeprecationWarning when alias instead of env is used for settings models, #881 by @samuelcolvin Fix issue with BaseSettings inheritance and alias getting set to None, #882 by @samuelcolvin Modify \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_repr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_str\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ methods to be consistent across all public classes, add \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pretty\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ to support python-devtools, #884 by @samuelcolvin deprecation warning for case\\\\\\\\\\\\\\_insensitive on BaseSettings config, #885 by @samuelcolvin For BaseSettings merge environment variables and in-code values recursively, as long as they create a valid object when merged together, to allow splitting init arguments, #888 by @idmitrievsky change secret types example, #890 by @ashears Change the signature of Model.construct() to be more user-friendly, document construct() usage, #898 by @samuelcolvin Add example for the construct() method, #907 by @ashears Improve use of Field constraints on complex types, raise an error if constraints are not enforceable, also support tuples with an ellipsis Tuple\\\\\\\\\\\\\\[X, ...\\\\\\\\\\\\\\], Sequence and FrozenSet in schema, #909 by @samuelcolvin update docs for bool missing valid value, #911 by @trim21 Better str/repr logic for ModelField, #912 by @samuelcolvin Fix ConstrainedList, update schema generation to reflect min\\\\\\\\\\\\\\_items and max\\\\\\\\\\\\\\_items Field() arguments, #917 by @samuelcolvin Allow abstracts sets (eg. dict keys) in the include and exclude arguments of dict(), #921 by @samuelcolvin Fix JSON serialization errors on ValidationError.json() by using pydantic\\\\\\\\\\\\\\_encoder, #922 by @samuelcolvin Clarify usage of remove\\\\\\\\\\\\\\_untouched, improve error message for types with no validators, #926 by @retnikt v1.0b2 (2019-10-07)¶ Mark StrictBool typecheck as bool to allow for default values without mypy errors, #690 by @dmontagu Transfer the documentation build from sphinx to mkdocs, re-write much of the documentation, #856 by @samuelcolvin Add support for custom naming schemes for GenericModel subclasses, #859 by @dmontagu Add if TYPE\\\\\\\\\\\\\\_CHECKING: to the excluded lines for test coverage, #874 by @dmontagu Rename allow\\\\\\\\\\\\\\_population\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_alias to allow\\\\\\\\\\\\\\_population\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_name, remove unnecessary warning about it, #875 by @samuelcolvin v1.0b1 (2019-10-01)¶ Breaking Change: rename Schema to Field, make it a function to placate mypy, #577 by @samuelcolvin Breaking Change: modify parsing behavior for bool, #617 by @dmontagu Breaking Change: get\\\\\\\\\\\\\\_validators is no longer recognised, use \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. Config.ignore\\\\\\\\\\\\\\_extra and Config.allow\\\\\\\\\\\\\\_extra are no longer recognised, use Config.extra, #720 by @samuelcolvin Breaking Change: modify default config settings for BaseSettings; case\\\\\\\\\\\\\\_insensitive renamed to case\\\\\\\\\\\\\\_sensitive, default changed to case\\\\\\\\\\\\\\_sensitive = False, env\\\\\\\\\\\\\\_prefix default changed to '' - e.g. no prefix, #721 by @dmontagu Breaking change: Implement root\\\\\\\\\\\\\\_validator and rename root errors from \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_obj\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, #729 by @samuelcolvin Breaking Change: alter the behaviour of dict(model) so that sub-models are nolonger converted to dictionaries, #733 by @samuelcolvin Breaking change: Added initvars support to post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_parse, #748 by @Raphael-C-Almeida Breaking Change: Make BaseModel.json() only serialize the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ key for models with custom root, #752 by @dmontagu Breaking Change: complete rewrite of URL parsing logic, #755 by @samuelcolvin Breaking Change: preserve superclass annotations for field-determination when not provided in subclass, #757 by @dmontagu Breaking Change: BaseSettings now uses the special env settings to define which environment variables to read, not aliases, #847 by @samuelcolvin add support for assert statements inside validators, #653 by @abdusco Update documentation to specify the use of pydantic.dataclasses.dataclass and subclassing pydantic.BaseModel, #710 by @maddosaurus Allow custom JSON decoding and encoding via json\\\\\\\\\\\\\\_loads and json\\\\\\\\\\\\\\_dumps Config properties, #714 by @samuelcolvin make all annotated fields occur in the order declared, #715 by @dmontagu use pytest to test mypy integration, #735 by @dmontagu add \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_repr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method to ErrorWrapper, #738 by @samuelcolvin Added support for FrozenSet members in dataclasses, and a better error when attempting to use types from the typing module that are not supported by Pydantic, #745 by @djpetti add documentation for Pycharm Plugin, #750 by @koxudaxi fix broken examples in the docs, #753 by @dmontagu moving typing related objects into pydantic.typing, #761 by @samuelcolvin Minor performance improvements to ErrorWrapper, ValidationError and datetime parsing, #763 by @samuelcolvin Improvements to datetime/date/time/timedelta types: more descriptive errors, change errors to value\\\\\\\\\\\\\\_error not type\\\\\\\\\\\\\\_error, support bytes, #766 by @samuelcolvin fix error messages for Literal types with multiple allowed values, #770 by @dmontagu Improved auto-generated title field in JSON schema by converting underscore to space, #772 by @skewty support mypy --no-implicit-reexport for dataclasses, also respect --no-implicit-reexport in pydantic itself, #783 by @samuelcolvin add the PaymentCardNumber type, #790 by @matin Fix const validations for lists, #794 by @hmvp Set additionalProperties to false in schema for models with extra fields disallowed, #796 by @Code0x58 EmailStr validation method now returns local part case-sensitive per RFC 5321, #798 by @henriklindgren Added ability to validate strictness to ConstrainedFloat, ConstrainedInt and ConstrainedStr and added StrictFloat and StrictInt classes, #799 by @DerRidda Improve handling of None and Optional, replace whole with each\\\\\\\\\\\\\\_item (inverse meaning, default False) on validators, #803 by @samuelcolvin add support for Type\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\] type hints, #807 by @timonbimon Performance improvements from removing change\\\\\\\\\\\\\\_exceptions, change how pydantic error are constructed, #819 by @samuelcolvin Fix the error message arising when a BaseModel-type model field causes a ValidationError during parsing, #820 by @dmontagu allow getter\\\\\\\\\\\\\\_dict on Config, modify GetterDict to be more like a Mapping object and thus easier to work with, #821 by @samuelcolvin Only check TypeVar param on base GenericModel class, #842 by @zpencerq rename Model.\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_cache -> Model.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_cache\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, Model.\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_encoder -> Model.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_encoder\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, Model.\\\\\\\\\\\\\\_custom\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_type -> Model.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_custom\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, #851 by @samuelcolvin v0.32.2 (2019-08-17)¶ (Docs are available here) fix \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ usage with dataclass inheritance, fix #739 by @samuelcolvin fix required fields validation on GenericModels classes, #742 by @amitbl fix defining custom Schema on GenericModel fields, #754 by @amitbl v0.32.1 (2019-08-08)¶ do not validate extra fields when validate\\\\\\\\\\\\\\_assignment is on, #724 by @YaraslauZhylko v0.32 (2019-08-06)¶ add model name to ValidationError error message, #676 by @dmontagu breaking change: remove \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_getattr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and rename \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_values\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ on BaseModel, deprecation warning on use \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_values\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ attr, attributes access speed increased up to 14 times, #712 by @Bobronium support ForwardRef (without self-referencing annotations) in Python 3.6, #706 by @koxudaxi implement schema\\\\\\\\\\\\\\_extra in Config sub-class, #663 by @tiangolo v0.31.1 (2019-07-31)¶ fix json generation for EnumError, #697 by @dmontagu update numerous dependencies v0.31 (2019-07-24)¶ better support for floating point multiple\\\\\\\\\\\\\\_of values, #652 by @justindujardin fix schema generation for NewType and Literal, #649 by @dmontagu fix alias\\\\\\\\\\\\\\_generator and field config conflict, #645 by @gmetzker and #658 by @Bobronium more detailed message for EnumError, #673 by @dmontagu add advanced exclude support for dict, json and copy, #648 by @Bobronium fix bug in GenericModel for models with concrete parameterized fields, #672 by @dmontagu add documentation for Literal type, #651 by @dmontagu add Config.keep\\\\\\\\\\\\\\_untouched for custom descriptors support, #679 by @Bobronium use inspect.cleandoc internally to get model description, #657 by @tiangolo add Color to schema generation, by @euri10 add documentation for Literal type, #651 by @dmontagu v0.30.1 (2019-07-15)¶ fix so nested classes which inherit and change \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ are correctly processed while still allowing self as a parameter, #644 by @lnaden and @dgasmith v0.30 (2019-07-07)¶ enforce single quotes in code, #612 by @samuelcolvin fix infinite recursion with dataclass inheritance and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, #606 by @Hanaasagi fix default values for GenericModel, #610 by @dmontagu clarify that self-referencing models require Python 3.7+, #616 by @vlcinsky fix truncate for types, #611 by @dmontagu add alias\\\\\\\\\\\\\\_generator support, #622 by @Bobronium fix unparameterized generic type schema generation, #625 by @dmontagu fix schema generation with multiple/circular references to the same model, #621 by @tiangolo and @wongpat support custom root types, #628 by @koxudaxi support self as a field name in parse\\\\\\\\\\\\\\_obj, #632 by @samuelcolvin v0.29 (2019-06-19)¶ support dataclasses.InitVar, #592 by @pfrederiks Updated documentation to elucidate the usage of Union when defining multiple types under an attribute's annotation and showcase how the type-order can affect marshalling of provided values, #594 by @somada141 add conlist type, #583 by @hmvp add support for generics, #595 by @dmontagu v0.28 (2019-06-06)¶ fix support for JSON Schema generation when using models with circular references in Python 3.7, #572 by @tiangolo support \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_parse\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ on dataclasses, #567 by @sevaho allow dumping dataclasses to JSON, #575 by @samuelcolvin and @DanielOberg ORM mode, #562 by @samuelcolvin fix pydantic.compiled on ipython, #573 by @dmontagu and @samuelcolvin add StrictBool type, #579 by @cazgp v0.27 (2019-05-30)¶ breaking change \\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init to execute dataclass' original \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ before validation, #560 by @HeavenVolkoff fix handling of generic types without specified parameters, #550 by @dmontagu breaking change (maybe): this is the first release compiled with cython, see the docs and please submit an issue if you run into problems v0.27.0a1 (2019-05-26)¶ fix JSON Schema for list, tuple, and set, #540 by @tiangolo compiling with cython, manylinux binaries, some other performance improvements, #548 by @samuelcolvin v0.26 (2019-05-22)¶ fix to schema generation for IPvAnyAddress, IPvAnyInterface, IPvAnyNetwork #498 by @pilosus fix variable length tuples support, #495 by @pilosus fix return type hint for create\\\\\\\\\\\\\\_model, #526 by @dmontagu Breaking Change: fix .dict(skip\\\\\\\\\\\\\\_keys=True) skipping values set via alias (this involves changing validate\\\\\\\\\\\\\\_model() to always returns Tuple\\\\\\\\\\\\\\[Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\], Set\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\], Optional\\\\\\\\\\\\\\[ValidationError\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]), #517 by @sommd fix to schema generation for IPv4Address, IPv6Address, IPv4Interface, IPv6Interface, IPv4Network, IPv6Network #532 by @euri10 add Color type, #504 by @pilosus and @samuelcolvin v0.25 (2019-05-05)¶ Improve documentation on self-referencing models and annotations, #487 by @theenglishway fix .dict() with extra keys, #490 by @JaewonKim support const keyword in Schema, #434 by @Sean1708 v0.24 (2019-04-23)¶ fix handling ForwardRef in sub-types, like Union, #464 by @tiangolo fix secret serialization, #465 by @atheuz Support custom validators for dataclasses, #454 by @primal100 fix parse\\\\\\\\\\\\\\_obj to cope with dict-like objects, #472 by @samuelcolvin fix to schema generation in nested dataclass-based models, #474 by @NoAnyLove fix json for Path, FilePath, and DirectoryPath objects, #473 by @mikegoodspeed v0.23 (2019-04-04)¶ improve documentation for contributing section, #441 by @pilosus improve README.rst to include essential information about the package, #446 by @pilosus IntEnum support, #444 by @potykion fix PyObject callable value, #409 by @pilosus fix black deprecation warnings after update, #451 by @pilosus fix ForwardRef collection bug, #450 by @tigerwings Support specialized ClassVars, #455 by @tyrylu fix JSON serialization for ipaddress types, #333 by @pilosus add SecretStr and SecretBytes types, #452 by @atheuz v0.22 (2019-03-29)¶ add IPv{4,6,Any}Network and IPv{4,6,Any}Interface types from ipaddress stdlib, #333 by @pilosus add docs for datetime types, #386 by @pilosus fix to schema generation in dataclass-based models, #408 by @pilosus fix path in nested models, #437 by @kataev add Sequence support, #304 by @pilosus v0.21.0 (2019-03-15)¶ fix typo in NoneIsNotAllowedError message, #414 by @YaraslauZhylko add IPvAnyAddress, IPv4Address and IPv6Address types, #333 by @pilosus v0.20.1 (2019-02-26)¶ fix type hints of parse\\\\\\\\\\\\\\_obj and similar methods, #405 by @erosennin fix submodel validation, #403 by @samuelcolvin correct type hints for ValidationError.json, #406 by @layday v0.20.0 (2019-02-18)¶ fix tests for Python 3.8, #396 by @samuelcolvin Adds fields to the dir method for autocompletion in interactive sessions, #398 by @dgasmith support ForwardRef (and therefore from \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_future\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ import annotations) with dataclasses, #397 by @samuelcolvin v0.20.0a1 (2019-02-13)¶ breaking change (maybe): more sophisticated argument parsing for validators, any subset of values, config and field is now permitted, eg. (cls, value, field), however the variadic key word argument (\"\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*kwargs\") must be called kwargs, #388 by @samuelcolvin breaking change: Adds skip\\\\\\\\\\\\\\_defaults argument to BaseModel.dict() to allow skipping of fields that were not explicitly set, signature of Model.construct() changed, #389 by @dgasmith add py.typed marker file for PEP-561 support, #391 by @je-l Fix extra behaviour for multiple inheritance/mix-ins, #394 by @YaraslauZhylko v0.19.0 (2019-02-04)¶ Support Callable type hint, fix #279 by @proofit404 Fix schema for fields with validator decorator, fix #375 by @tiangolo Add multiple\\\\\\\\\\\\\\_of constraint to ConstrainedDecimal, ConstrainedFloat, ConstrainedInt and their related types condecimal, confloat, and conint #371, thanks @StephenBrown2 Deprecated ignore\\\\\\\\\\\\\\_extra and allow\\\\\\\\\\\\\\_extra Config fields in favor of extra, #352 by @liiight Add type annotations to all functions, test fully with mypy, #373 by @samuelcolvin fix for 'missing' error with validate\\\\\\\\\\\\\\_all or validate\\\\\\\\\\\\\\_always, #381 by @samuelcolvin Change the second/millisecond watershed for date/datetime parsing to 2e10, #385 by @samuelcolvin v0.18.2 (2019-01-22)¶ Fix to schema generation with Optional fields, fix #361 by @samuelcolvin v0.18.1 (2019-01-17)¶ add ConstrainedBytes and conbytes types, #315 @Gr1N adding MANIFEST.in to include license in package .tar.gz, #358 by @samuelcolvin v0.18.0 (2019-01-13)¶ breaking change: don't call validators on keys of dictionaries, #254 by @samuelcolvin Fix validators with always=True when the default is None or the type is optional, also prevent whole validators being called for sub-fields, fix #132 by @samuelcolvin improve documentation for settings priority and allow it to be easily changed, #343 by @samuelcolvin fix ignore\\\\\\\\\\\\\\_extra=False and allow\\\\\\\\\\\\\\_population\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_alias=True, fix #257 by @samuelcolvin breaking change: Set BaseConfig attributes min\\\\\\\\\\\\\\_anystr\\\\\\\\\\\\\\_length and max\\\\\\\\\\\\\\_anystr\\\\\\\\\\\\\\_length to None by default, fix #349 in #350 by @tiangolo add support for postponed annotations, #348 by @samuelcolvin v0.17.0 (2018-12-27)¶ fix schema for timedelta as number, #325 by @tiangolo prevent validators being called repeatedly after inheritance, #327 by @samuelcolvin prevent duplicate validator check in ipython, fix #312 by @samuelcolvin add \"Using Pydantic\" section to docs, #323 by @tiangolo & #326 by @samuelcolvin fix schema generation for fields annotated as : dict, : list, : tuple and : set, #330 & #335 by @nkonin add support for constrained strings as dict keys in schema, #332 by @tiangolo support for passing Config class in dataclasses decorator, #276 by @jarekkar (breaking change: this supersedes the validate\\\\\\\\\\\\\\_assignment argument with config) support for nested dataclasses, #334 by @samuelcolvin better errors when getting an ImportError with PyObject, #309 by @samuelcolvin rename get\\\\\\\\\\\\\\_validators to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, deprecation warning on use of old name, #338 by @samuelcolvin support ClassVar by excluding such attributes from fields, #184 by @samuelcolvin v0.16.1 (2018-12-10)¶ fix create\\\\\\\\\\\\\\_model to correctly use the passed \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, #320 by @hugoduncan v0.16.0 (2018-12-03)¶ breaking change: refactor schema generation to be compatible with JSON Schema and OpenAPI specs, #308 by @tiangolo add schema to schema module to generate top-level schemas from base models, #308 by @tiangolo add additional fields to Schema class to declare validation for str and numeric values, #311 by @tiangolo rename \\\\\\\\\\\\\\_schema to schema on fields, #318 by @samuelcolvin add case\\\\\\\\\\\\\\_insensitive option to BaseSettings Config, #277 by @jasonkuhrt v0.15.0 (2018-11-18)¶ move codebase to use black, #287 by @samuelcolvin fix alias use in settings, #286 by @jasonkuhrt and @samuelcolvin fix datetime parsing in parse\\\\\\\\\\\\\\_date, #298 by @samuelcolvin allow dataclass inheritance, fix #293 by @samuelcolvin fix PyObject = None, fix #305 by @samuelcolvin allow Pattern type, fix #303 by @samuelcolvin v0.14.0 (2018-10-02)¶ dataclasses decorator, #269 by @Gaunt and @samuelcolvin v0.13.1 (2018-09-21)¶ fix issue where int\\\\\\\\\\\\\\_validator doesn't cast a bool to an int #264 by @nphyatt add deep copy support for BaseModel.copy() #249, @gangefors v0.13.0 (2018-08-25)¶ raise an exception if a field's name shadows an existing BaseModel attribute #242 add UrlStr and urlstr types #236 timedelta json encoding ISO8601 and total seconds, custom json encoders #247, by @cfkanesan and @samuelcolvin allow timedelta objects as values for properties of type timedelta (matches datetime etc. behavior) #247 v0.12.1 (2018-07-31)¶ fix schema generation for fields defined using typing.Any #237 v0.12.0 (2018-07-31)¶ add by\\\\\\\\\\\\\\_alias argument in .dict() and .json() model methods #205 add Json type support #214 support tuples #227 major improvements and changes to schema #213 v0.11.2 (2018-07-05)¶ add NewType support #115 fix list, set & tuple validation #225 separate out validate\\\\\\\\\\\\\\_model method, allow errors to be returned along with valid values #221 v0.11.1 (2018-07-02)¶ support Python 3.7 #216, thanks @layday Allow arbitrary types in model #209, thanks @oldPadavan v0.11.0 (2018-06-28)¶ make list, tuple and set types stricter #86 breaking change: remove msgpack parsing #201 add FilePath and DirectoryPath types #10 model schema generation #190 JSON serialization of models and schemas #133 v0.10.0 (2018-06-11)¶ add Config.allow\\\\\\\\\\\\\\_population\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_alias #160, thanks @bendemaree breaking change: new errors format #179, thanks @Gr1N breaking change: removed Config.min\\\\\\\\\\\\\\_number\\\\\\\\\\\\\\_size and Config.max\\\\\\\\\\\\\\_number\\\\\\\\\\\\\\_size #183, thanks @Gr1N breaking change: correct behaviour of lt and gt arguments to conint etc. #188 for the old behaviour use le and ge #194, thanks @jaheba added error context and ability to redefine error message templates using Config.error\\\\\\\\\\\\\\_msg\\\\\\\\\\\\\\_templates #183, thanks @Gr1N fix typo in validator exception #150 copy defaults to model values, so different models don't share objects #154 v0.9.1 (2018-05-10)¶ allow custom get\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_config on config classes #159 add UUID1, UUID3, UUID4 and UUID5 types #167, thanks @Gr1N modify some inconsistent docstrings and annotations #173, thanks @YannLuo fix type annotations for exotic types #171, thanks @Gr1N re-use type validators in exotic types #171 scheduled monthly requirements updates #168 add Decimal, ConstrainedDecimal and condecimal types #170, thanks @Gr1N v0.9.0 (2018-04-28)¶ tweak email-validator import error message #145 fix parse error of parse\\\\\\\\\\\\\\_date() and parse\\\\\\\\\\\\\\_datetime() when input is 0 #144, thanks @YannLuo add Config.anystr\\\\\\\\\\\\\\_strip\\\\\\\\\\\\\\_whitespace and strip\\\\\\\\\\\\\\_whitespace kwarg to constr, by default values is False #163, thanks @Gr1N add ConstrainedFloat, confloat, PositiveFloat and NegativeFloat types #166, thanks @Gr1N v0.8.0 (2018-03-25)¶ fix type annotation for inherit\\\\\\\\\\\\\\_config #139 breaking change: check for invalid field names in validators #140 validate attributes of parent models #141 breaking change: email validation now uses email-validator #142 v0.7.1 (2018-02-07)¶ fix bug with create\\\\\\\\\\\\\\_model modifying the base class v0.7.0 (2018-02-06)¶ added compatibility with abstract base classes (ABCs) #123 add create\\\\\\\\\\\\\\_model method #113 #125 breaking change: rename .config to .\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ on a model breaking change: remove deprecated .values() on a model, use .dict() instead remove use of OrderedDict and use simple dict #126 add Config.use\\\\\\\\\\\\\\_enum\\\\\\\\\\\\\\_values #127 add wildcard validators of the form @validate('\\\\\\\\\\\\\\*') #128 v0.6.4 (2018-02-01)¶ allow Python date and times objects #122 v0.6.3 (2017-11-26)¶ fix direct install without README.rst present v0.6.2 (2017-11-13)¶ errors for invalid validator use safer check for complex models in Settings v0.6.1 (2017-11-08)¶ prevent duplicate validators, #101 add always kwarg to validators, #102 v0.6.0 (2017-11-07)¶ assignment validation #94, thanks petroswork! JSON in environment variables for complex types, #96 add validator decorators for complex validation, #97 depreciate values(...) and replace with .dict(...), #99 v0.5.0 (2017-10-23)¶ add UUID validation #89 remove index and track from error object (json) if they're null #90 improve the error text when a list is provided rather than a dict #90 add benchmarks table to docs #91 v0.4.0 (2017-07-08)¶ show length in string validation error fix aliases in config during inheritance #55 simplify error display use unicode ellipsis in truncate add parse\\\\\\\\\\\\\\_obj, parse\\\\\\\\\\\\\\_raw and parse\\\\\\\\\\\\\\_file helper functions #58 switch annotation only fields to come first in fields list not last v0.3.0 (2017-06-21)¶ immutable models via config.allow\\\\\\\\\\\\\\_mutation = False, associated cleanup and performance improvement #44 immutable helper methods construct() and copy() #53 allow pickling of models #53 setattr is removed as \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_setattr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ is now intelligent #44 raise\\\\\\\\\\\\\\_exception removed, Models now always raise exceptions #44 instance method validators removed django-restful-framework benchmarks added #47 fix inheritance bug #49 make str type stricter so list, dict etc are not coerced to strings. #52 add StrictStr which only always strings as input #52 v0.2.1 (2017-06-07)¶ pypi and travis together messed up the deploy of v0.2 this should fix it v0.2.0 (2017-06-07)¶ breaking change: values() on a model is now a method not a property, takes include and exclude arguments allow annotation only fields to support mypy add pretty to\\\\\\\\\\\\\\_string(pretty=True) method for models v0.1.0 (2017-06-03)¶ add docs add history Made with Material for MkDocs Insiders"
  },
  {
    "title": "Contributing - Pydantic",
    "url": "https://docs.pydantic.dev/latest/contributing/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Contributing Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Get Started Welcome to Pydantic Why use Pydantic Help with Pydantic Installation Migration Guide Version Policy Contributing Changelog Page contents Issues Pull Requests Prerequisites Installation and setup Check out a new branch and make your changes Run tests and linting Build documentation Commit and push your changes Code style and requirements Documentation style Code documentation Documentation Style Badges With Markdown With reStructuredText With HTML Contributing We'd love you to contribute to Pydantic! Issues¶ Questions, feature requests and bug reports are all welcome as discussions or issues. However, to report a security vulnerability, please see our security policy. To make it as simple as possible for us to help you, please include the output of the following call in your issue: python -c \"import pydantic.utils; print(pydantic.utils.version\\\\\\\\\\\\\\_info())\" If you're using Pydantic prior to v1.3 (when version\\\\\\\\\\\\\\_info() was added), please manually include OS, Python version and pydantic version. Please try to always include the above unless you're unable to install Pydantic or know it's not relevant to your question or feature request. Pull Requests¶ It should be extremely simple to get started and create a Pull Request. Pydantic is released regularly so you should see your improvements release in a matter of days or weeks. Unless your change is trivial (typo, docs tweak etc.), please create an issue to discuss the change before creating a pull request. Pydantic V1 is in maintenance mode Pydantic v1 is in maintenance mode, meaning that only bug fixes and security fixes will be accepted. New features should be targeted at Pydantic v2. To submit a fix to Pydantic v1, use the 1.10.X-fixes branch. If you're looking for something to get your teeth into, check out the \"help wanted\" label on github. To make contributing as easy and fast as possible, you'll want to run tests and linting locally. Luckily, Pydantic has few dependencies, doesn't require compiling and tests don't need access to databases, etc. Because of this, setting up and running the tests should be very simple. Tip tl;dr: use make format to fix formatting, make to run tests and linting & make docs to build the docs. Prerequisites¶ You'll need the following prerequisites: Any Python version between Python 3.7 and 3.11 virtualenv or other virtual environment tool git make PDM Installation and setup¶ Fork the repository on GitHub and clone your fork locally. # Clone your fork and cd into the repo directory git clone git@github.com:/pydantic.git cd pydantic # Install PDM and pre-commit # We use pipx here, for other options see: # https://pdm.fming.dev/latest/#installation # https://pre-commit.com/#install # To get pipx itself: # https://pypa.github.io/pipx/ pipx install pdm pipx install pre-commit # Install pydantic, dependencies, test dependencies and doc dependencies make install Check out a new branch and make your changes¶ Create a new branch for your changes. # Checkout a new branch and make your changes git checkout -b my-new-feature-branch # Make your changes... Run tests and linting¶ Run tests and linting locally to make sure everything is working as expected. # Run automated code formatting and linting make format # Pydantic uses ruff, an awesome Python linter written in rust # https://github.com/astral-sh/ruff # Run tests and linting make # There are a few sub-commands in Makefile like \\\\\\\\\\\\\\`test\\\\\\\\\\\\\\`, \\\\\\\\\\\\\\`testcov\\\\\\\\\\\\\\` and \\\\\\\\\\\\\\`lint\\\\\\\\\\\\\\` # which you might want to use, but generally just \\\\\\\\\\\\\\`make\\\\\\\\\\\\\\` should be all you need. # You can run \\\\\\\\\\\\\\`make help\\\\\\\\\\\\\\` to see more options. Build documentation¶ If you've made any changes to the documentation (including changes to function signatures, class definitions, or docstrings that will appear in the API documentation), make sure it builds successfully. # Build documentation make docs # If you have changed the documentation, make sure it builds successfully. # You can also use \\\\\\\\\\\\\\`make docs-serve\\\\\\\\\\\\\\` to serve the documentation at localhost:8000 Commit and push your changes¶ Commit your changes, push your branch to GitHub, and create a pull request. Please follow the pull request template and fill in as much information as possible. Link to any relevant issues and include a description of your changes. When your pull request is ready for review, add a comment with the message \"please review\" and we'll take a look as soon as we can. Code style and requirements¶ TODO Documentation style¶ Documentation is written in Markdown and built using Material for MkDocs. API documentation is build from docstrings using mkdocstrings. Code documentation¶ When contributing to Pydantic, please make sure that all code is well documented. The following should be documented using properly formatted docstrings: Modules Class definitions Function definitions Module-level variables Pydantic uses Google-style docstrings formatted according to PEP 257 guidelines. (See Example Google Style Python Docstrings for further examples.) pydocstyle is used for linting docstrings. You can run make format to check your docstrings. Where this is a conflict between Google-style docstrings and pydocstyle linting, follow the pydocstyle linting hints. Class attributes and function arguments should be documented in the format \"name: description.\" When applicable, a return type should be documented with just a description. Types are inferred from the signature. class Foo: \"\"\"A class docstring. Attributes: bar: A description of bar. Defaults to \"bar\". \"\"\" bar: str = 'bar' def bar(self, baz: int) -> str: \"\"\"A function docstring. Args: baz: A description of \\\\\\\\\\\\\\`baz\\\\\\\\\\\\\\`. Returns: A description of the return value. \"\"\" return 'bar' You may include example code in docstrings. This code should be complete, self-contained, and runnable. Docstring examples are tested using doctest, so make sure they are correct and complete. See FieldInfo.from\\\\\\\\\\\\\\_annotated\\\\\\\\\\\\\\_attribute() for an example. Class and instance attributes Class attributes should be documented in the class docstring. Instance attributes should be documented as \"Args\" in the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ docstring. Documentation Style¶ In general, documentation should be written in a friendly, approachable style. It should be easy to read and understand, and should be as concise as possible while still being complete. Code examples are encouraged, but should be kept short and simple. However, every code example should be complete, self-contained, and runnable. (If you're not sure how to do this, ask for help!) We prefer print output to naked asserts, but if you're testing something that doesn't have a useful print output, asserts are fine. Pydantic's unit test will test all code examples in the documentation, so it's important that they are correct and complete. When adding a new code example, use the following to test examples and update their formatting and output: # Run tests and update code examples pytest tests/test\\\\\\\\\\\\\\_docs.py --update-examples Badges¶ Pydantic has a badge that you can use to show that your project uses Pydantic. You can use this badge in your README.md: With Markdown¶ \\\\\\\\\\\\\\[!\\\\\\\\\\\\\\[Pydantic v1\\\\\\\\\\\\\\](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v1.json)\\\\\\\\\\\\\\](https://pydantic.dev) \\\\\\\\\\\\\\[!\\\\\\\\\\\\\\[Pydantic v2\\\\\\\\\\\\\\](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json)\\\\\\\\\\\\\\](https://pydantic.dev) With reStructuredText¶ .. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v1.json :target: https://pydantic.dev :alt: Pydantic .. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json :target: https://pydantic.dev :alt: Pydantic With HTML¶ \\\\\\[!\\\\\\[Pydantic Version 1\\\\\\](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v1.json)\\\\\\](https://pydantic.dev) \\\\\\[!\\\\\\[Pydantic Version 2\\\\\\](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json)\\\\\\](https://pydantic.dev) Made with Material for MkDocs Insiders"
  },
  {
    "title": "Migration Guide - Pydantic",
    "url": "https://docs.pydantic.dev/latest/migration/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Migration Guide Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Get Started Welcome to Pydantic Why use Pydantic Help with Pydantic Installation Migration Guide Version Policy Contributing Changelog Page contents Install Pydantic V2 Code transformation tool Continue using Pydantic V1 features Migration guide Changes to pydantic.BaseModel Changes to pydantic.generics.GenericModel Changes to pydantic.Field Changes to dataclasses Changes to config Changes to validators @validator and @root\\\\\\\\\\\\\\_validator are deprecated Changes to @validator's allowed signatures TypeError is no longer converted to ValidationError in validators Validator behavior changes The allow\\\\\\\\\\\\\\_reuse keyword argument is no longer necessary @validate\\\\\\\\\\\\\\_arguments has been renamed to @validate\\\\\\\\\\\\\\_call Input types are not preserved Changes to Handling of Standard Types Dicts Unions Required, optional, and nullable fields Patterns / regex on strings Introduction of TypeAdapter Defining custom types Changes to JSON schema generation BaseSettings has moved to pydantic-settings Color and Payment Card Numbers moved to pydantic-extra-types Url and Dsn types in pydantic.networks no longer inherit from str Constrained types Moved in Pydantic V2 Deprecated and moved in Pydantic V2 Removed in Pydantic V2 Migration Guide Pydantic V2 introduces a number of changes to the API, including some breaking changes. This page provides a guide highlighting the most important changes to help you migrate your code from Pydantic V1 to Pydantic V2. Install Pydantic V2¶ Pydantic V2 is now the current production release of Pydantic. You can install Pydantic V2 from PyPI: pip install -U pydantic If you encounter any issues, please create an issue in GitHub using the bug V2 label. This will help us to actively monitor and track errors, and to continue to improve the library's performance. If you need to use latest Pydantic V1 for any reason, see the Continue using Pydantic V1 features section below for details on installation and imports from pydantic.v1. Code transformation tool¶ We have created a tool to help you migrate your code. This tool is still in beta, but we hope it will help you to migrate your code more quickly. You can install the tool from PyPI: pip install bump-pydantic The usage is simple. If your project structure is: \\\\\\\\\\\\\\* repo\\\\\\\\\\\\\\_folder \\\\\\\\\\\\\\* my\\\\\\\\\\\\\\_package \\\\\\\\\\\\\\* ... Then you'll want to do: cd /path/to/repo\\\\\\\\\\\\\\_folder bump-pydantic my\\\\\\\\\\\\\\_package See more about it on the Bump Pydantic repository. Continue using Pydantic V1 features¶ Pydantic V1 is still available when you need it, though we recommend migrating to Pydantic V2 for its improvements and new features. If you need to use latest Pydantic V1, you can install it with: pip install \"pydantic==1.\\\\\\\\\\\\\\*\" The Pydantic V2 package also continues to provide access to the Pydantic V1 API by importing through pydantic.v1. For example, you can use the BaseModel class from Pydantic V1 instead of the Pydantic V2 pydantic.BaseModel class: from pydantic.v1 import BaseModel You can also import functions that have been removed from Pydantic V2, such as lenient\\\\\\\\\\\\\\_isinstance: from pydantic.v1.utils import lenient\\\\\\\\\\\\\\_isinstance Pydantic V1 documentation is available at https://docs.pydantic.dev/1.10/. Migration guide¶ The following sections provide details on the most important changes in Pydantic V2. Changes to pydantic.BaseModel¶ Various method names have been changed; all non-deprecated BaseModel methods now have names matching either the format model\\\\\\\\\\\\\\_.\\\\\\\\\\\\\\* or \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.\\\\\\\\\\\\\\*pydantic.\\\\\\\\\\\\\\*\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. Where possible, we have retained the deprecated methods with their old names to help ease migration, but calling them will emit DeprecationWarnings. Pydantic V1 Pydantic V2 \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ model\\\\\\\\\\\\\\_fields \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_private\\\\\\\\\\\\\\_attributes\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_private\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ construct() model\\\\\\\\\\\\\\_construct() copy() model\\\\\\\\\\\\\\_copy() dict() model\\\\\\\\\\\\\\_dump() json\\\\\\\\\\\\\\_schema() model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema() json() model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json() parse\\\\\\\\\\\\\\_obj() model\\\\\\\\\\\\\\_validate() update\\\\\\\\\\\\\\_forward\\\\\\\\\\\\\\_refs() model\\\\\\\\\\\\\\_rebuild() Some of the built-in data-loading functionality has been slated for removal. In particular, parse\\\\\\\\\\\\\\_raw and parse\\\\\\\\\\\\\\_file are now deprecated. In Pydantic V2, model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json works like parse\\\\\\\\\\\\\\_raw. Otherwise, you should load the data and then pass it to model\\\\\\\\\\\\\\_validate. The from\\\\\\\\\\\\\\_orm method has been deprecated; you can now just use model\\\\\\\\\\\\\\_validate (equivalent to parse\\\\\\\\\\\\\\_obj from Pydantic V1) to achieve something similar, as long as you've set from\\\\\\\\\\\\\\_attributes=True in the model config. The \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_eq\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method has changed for models. Models can only be equal to other BaseModel instances. For two model instances to be equal, they must have the same: Type (or, in the case of generic models, non-parametrized generic origin type) Field values Extra values (only relevant when model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['extra'\\\\\\\\\\\\\\] == 'allow') Private attribute values; models with different values of private attributes are no longer equal. Models are no longer equal to the dicts containing their data. Non-generic models of different types are never equal. Generic models with different origin types are never equal. We don't require exact type equality so that, for example, instances of MyGenericModel\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\] could be equal to instances of MyGenericModel\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]. We have replaced the use of the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ field to specify a \"custom root model\" with a new type called RootModel which is intended to replace the functionality of using a field called \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ in Pydantic V1. We have significantly expanded Pydantic's capabilities related to customizing serialization. In particular, we have added the @field\\\\\\\\\\\\\\_serializer, @model\\\\\\\\\\\\\\_serializer, and @computed\\\\\\\\\\\\\\_field decorators, which each address various shortcomings from Pydantic V1. See Custom serializers for the usage docs of these new decorators. Due to performance overhead and implementation complexity, we have now deprecated support for specifying json\\\\\\\\\\\\\\_encoders in the model config. This functionality was originally added for the purpose of achieving custom serialization logic, and we think the new serialization decorators are a better choice in most common scenarios. We have changed the behavior related to serializing subclasses of models when they occur as nested fields in a parent model. In V1, we would always include all fields from the subclass instance. In V2, when we dump a model, we only include the fields that are defined on the annotated type of the field. This helps prevent some accidental security bugs. You can read more about this (including how to opt out of this behavior) in the Subclass instances for fields of BaseModel, dataclasses, TypedDict section of the model exporting docs. GetterDict has been removed as it was just an implementation detail of orm\\\\\\\\\\\\\\_mode, which has been removed. In many cases, arguments passed to the constructor will be copied in order to perform validation and, where necessary, coercion. This is notable in the case of passing mutable objects as arguments to a constructor. You can see an example + more detail here. Changes to pydantic.generics.GenericModel¶ The pydantic.generics.GenericModel class is no longer necessary, and has been removed. Instead, you can now create generic BaseModel subclasses by just adding Generic as a parent class on a BaseModel subclass directly. This looks like class MyGenericModel(BaseModel, Generic\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\]): .... Mixing of V1 and V2 models is not supported which means that type parameters of such generic BaseModel (V2) cannot be V1 models. While it may not raise an error, we strongly advise against using parametrized generics in isinstance checks. For example, you should not do isinstance(my\\\\\\\\\\\\\\_model, MyGenericModel\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]). However, it is fine to do isinstance(my\\\\\\\\\\\\\\_model, MyGenericModel). (Note that for standard generics, it would raise an error to do a subclass check with a parameterized generic.) If you need to perform isinstance checks against parametrized generics, you can do this by subclassing the parametrized generic class. This looks like class MyIntModel(MyGenericModel\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]): ... and isinstance(my\\\\\\\\\\\\\\_model, MyIntModel). Find more information in the Generic models documentation. Changes to pydantic.Field¶ Field no longer supports arbitrary keyword arguments to be added to the JSON schema. Instead, any extra data you want to add to the JSON schema should be passed as a dictionary to the json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra keyword argument. In Pydantic V1, the alias property returns the field's name when no alias is set. In Pydantic V2, this behavior has changed to return None when no alias is set. The following properties have been removed from or changed in Field: const min\\\\\\\\\\\\\\_items (use min\\\\\\\\\\\\\\_length instead) max\\\\\\\\\\\\\\_items (use max\\\\\\\\\\\\\\_length instead) unique\\\\\\\\\\\\\\_items allow\\\\\\\\\\\\\\_mutation (use frozen instead) regex (use pattern instead) final (use the typing.Final type hint instead) Field constraints are no longer automatically pushed down to the parameters of generics. For example, you can no longer validate every element of a list matches a regex by providing my\\\\\\\\\\\\\\_list: list\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] = Field(pattern=\".\\\\\\\\\\\\\\*\"). Instead, use typing.Annotated to provide an annotation on the str itself: my\\\\\\\\\\\\\\_list: list\\\\\\\\\\\\\\[Annotated\\\\\\\\\\\\\\[str, Field(pattern=\".\\\\\\\\\\\\\\*\")\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] \\\\\\\\\\\\\\[TODO: Need to document any other backwards-incompatible changes to pydantic.Field\\\\\\\\\\\\\\] Changes to dataclasses¶ Pydantic dataclasses continue to be useful for enabling the data validation on standard dataclasses without having to subclass BaseModel. Pydantic V2 introduces the following changes to this dataclass behavior: When used as fields, dataclasses (Pydantic or vanilla) no longer accept tuples as validation inputs; dicts should be used instead. The \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ in Pydantic dataclasses will now be called after validation, rather than before. As a result, the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_parse\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method would have become redundant, so has been removed. Pydantic no longer supports extra='allow' for Pydantic dataclasses, where extra fields passed to the initializer would be stored as extra attributes on the dataclass. extra='ignore' is still supported for the purpose of ignoring unexpected fields while parsing data, they just won't be stored on the instance. Pydantic dataclasses no longer have an attribute \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, and no longer use an underlying BaseModel to perform validation or provide other functionality. To perform validation, generate a JSON schema, or make use of any other functionality that may have required \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ in V1, you should now wrap the dataclass with a TypeAdapter (discussed more below) and make use of its methods. In Pydantic V1, if you used a vanilla (i.e., non-Pydantic) dataclass as a field, the config of the parent type would be used as though it was the config for the dataclass itself as well. In Pydantic V2, this is no longer the case. In Pydantic V2, to override the config (like you would with model\\\\\\\\\\\\\\_config on a BaseModel), you can use the config parameter on the @dataclass decorator. See Dataclass Config for examples. Changes to config¶ In Pydantic V2, to specify config on a model, you should set a class attribute called model\\\\\\\\\\\\\\_config to be a dict with the key/value pairs you want to be used as the config. The Pydantic V1 behavior to create a class called Config in the namespace of the parent BaseModel subclass is now deprecated. The following config settings have been removed: allow\\\\\\\\\\\\\\_mutation — this has been removed. You should be able to use frozen equivalently (inverse of current use). error\\\\\\\\\\\\\\_msg\\\\\\\\\\\\\\_templates fields — this was the source of various bugs, so has been removed. You should be able to use Annotated on fields to modify them as desired. getter\\\\\\\\\\\\\\_dict — orm\\\\\\\\\\\\\\_mode has been removed, and this implementation detail is no longer necessary. smart\\\\\\\\\\\\\\_union. underscore\\\\\\\\\\\\\\_attrs\\\\\\\\\\\\\\_are\\\\\\\\\\\\\\_private — the Pydantic V2 behavior is now the same as if this was always set to True in Pydantic V1. json\\\\\\\\\\\\\\_loads json\\\\\\\\\\\\\\_dumps copy\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_validation post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_call The following config settings have been renamed: allow\\\\\\\\\\\\\\_population\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_name → populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name anystr\\\\\\\\\\\\\\_lower → str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_lower anystr\\\\\\\\\\\\\\_strip\\\\\\\\\\\\\\_whitespace → str\\\\\\\\\\\\\\_strip\\\\\\\\\\\\\\_whitespace anystr\\\\\\\\\\\\\\_upper → str\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_upper keep\\\\\\\\\\\\\\_untouched → ignored\\\\\\\\\\\\\\_types max\\\\\\\\\\\\\\_anystr\\\\\\\\\\\\\\_length → str\\\\\\\\\\\\\\_max\\\\\\\\\\\\\\_length min\\\\\\\\\\\\\\_anystr\\\\\\\\\\\\\\_length → str\\\\\\\\\\\\\\_min\\\\\\\\\\\\\\_length orm\\\\\\\\\\\\\\_mode → from\\\\\\\\\\\\\\_attributes schema\\\\\\\\\\\\\\_extra → json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_extra validate\\\\\\\\\\\\\\_all → validate\\\\\\\\\\\\\\_default See the ConfigDict API reference for more details. Changes to validators¶ @validator and @root\\\\\\\\\\\\\\_validator are deprecated¶ @validator has been deprecated, and should be replaced with @field\\\\\\\\\\\\\\_validator, which provides various new features and improvements. The new @field\\\\\\\\\\\\\\_validator decorator does not have the each\\\\\\\\\\\\\\_item keyword argument; validators you want to apply to items within a generic container should be added by annotating the type argument. See validators in Annotated metadata for details. This looks like List\\\\\\\\\\\\\\[Annotated\\\\\\\\\\\\\\[int, Field(ge=0)\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] Even if you keep using the deprecated @validator decorator, you can no longer add the field or config arguments to the signature of validator functions. If you need access to these, you'll need to migrate to @field\\\\\\\\\\\\\\_validator — see the next section for more details. If you use the always=True keyword argument to a validator function, note that standard validators for the annotated type will also be applied even to defaults, not just the custom validators. For example, despite the fact that the validator below will never error, the following code raises a ValidationError: Note To avoid this, you can use the validate\\\\\\\\\\\\\\_default argument in the Field function. When set to True, it mimics the behavior of always=True in Pydantic v1. However, the new way of using validate\\\\\\\\\\\\\\_default is encouraged as it provides more flexibility and control. from pydantic import BaseModel, validator class Model(BaseModel): x: str = 1 @validator('x', always=True) @classmethod def validate\\\\\\\\\\\\\\_x(cls, v): return v Model() @root\\\\\\\\\\\\\\_validator has been deprecated, and should be replaced with @model\\\\\\\\\\\\\\_validator, which also provides new features and improvements. Under some circumstances (such as assignment when model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['validate\\\\\\\\\\\\\\_assignment'\\\\\\\\\\\\\\] is True), the @model\\\\\\\\\\\\\\_validator decorator will receive an instance of the model, not a dict of values. You may need to be careful to handle this case. Even if you keep using the deprecated @root\\\\\\\\\\\\\\_validator decorator, due to refactors in validation logic, you can no longer run with skip\\\\\\\\\\\\\\_on\\\\\\\\\\\\\\_failure=False (which is the default value of this keyword argument, so must be set explicitly to True). Changes to @validator's allowed signatures¶ In Pydantic V1, functions wrapped by @validator could receive keyword arguments with metadata about what was being validated. Some of these arguments have been removed from @field\\\\\\\\\\\\\\_validator in Pydantic V2: config: Pydantic V2's config is now a dictionary instead of a class, which means this argument is no longer backwards compatible. If you need to access the configuration you should migrate to @field\\\\\\\\\\\\\\_validator and use info.config. field: this argument used to be a ModelField object, which was a quasi-internal class that no longer exists in Pydantic V2. Most of this information can still be accessed by using the field name from info.field\\\\\\\\\\\\\\_name to index into cls.model\\\\\\\\\\\\\\_fields from pydantic import BaseModel, ValidationInfo, field\\\\\\\\\\\\\\_validator class Model(BaseModel): x: int @field\\\\\\\\\\\\\\_validator('x') def val\\\\\\\\\\\\\\_x(cls, v: int, info: ValidationInfo) -> int: assert info.config is not None print(info.config.get('title')) #> Model print(cls.model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\[info.field\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\].is\\\\\\\\\\\\\\_required()) #> True return v Model(x=1) TypeError is no longer converted to ValidationError in validators¶ Previously, when raising a TypeError within a validator function, that error would be wrapped into a ValidationError and, in some cases (such as with FastAPI), these errors might be displayed to end users. This led to a variety of undesirable behavior — for example, calling a function with the wrong signature might produce a user-facing ValidationError. However, in Pydantic V2, when a TypeError is raised in a validator, it is no longer converted into a ValidationError: import pytest from pydantic import BaseModel, field\\\\\\\\\\\\\\_validator # or validator class Model(BaseModel): x: int @field\\\\\\\\\\\\\\_validator('x') def val\\\\\\\\\\\\\\_x(cls, v: int) -> int: return str.lower(v) # raises a TypeError with pytest.raises(TypeError): Model(x=1) This applies to all validation decorators. Validator behavior changes¶ Pydantic V2 includes some changes to type coercion. For example: coercing int, float, and Decimal values to strings is now optional and disabled by default, see Coerce Numbers to Strings. iterable of pairs is no longer coerced to a dict. See the Conversion table for details on Pydantic V2 type coercion defaults. The allow\\\\\\\\\\\\\\_reuse keyword argument is no longer necessary¶ Previously, Pydantic tracked \"reused\" functions in decorators as this was a common source of mistakes. We did this by comparing the function's fully qualified name (module name + function name), which could result in false positives. The allow\\\\\\\\\\\\\\_reuse keyword argument could be used to disable this when it was intentional. Our approach to detecting repeatedly defined functions has been overhauled to only error for redefinition within a single class, reducing false positives and bringing the behavior more in line with the errors that type checkers and linters would give for defining a method with the same name multiple times in a single class definition. In nearly all cases, if you were using allow\\\\\\\\\\\\\\_reuse=True, you should be able to simply delete that keyword argument and have things keep working as expected. @validate\\\\\\\\\\\\\\_arguments has been renamed to @validate\\\\\\\\\\\\\\_call¶ In Pydantic V2, the @validate\\\\\\\\\\\\\\_arguments decorator has been renamed to @validate\\\\\\\\\\\\\\_call. In Pydantic V1, the decorated function had various attributes added, such as raw\\\\\\\\\\\\\\_function, and validate (which could be used to validate arguments without actually calling the decorated function). Due to limited use of these attributes, and performance-oriented changes in implementation, we have not preserved this functionality in @validate\\\\\\\\\\\\\\_call. Input types are not preserved¶ In Pydantic V1 we made great efforts to preserve the types of all field inputs for generic collections when they were proper subtypes of the field annotations. For example, given the annotation Mapping\\\\\\\\\\\\\\[str, int\\\\\\\\\\\\\\] if you passed in a collection.Counter() you'd get a collection.Counter() as the value. Supporting this behavior in V2 would have negative performance implications for the general case (we'd have to check types every time) and would add a lot of complexity to validation. Further, even in V1 this behavior was inconsistent and partially broken: it did not work for many types (str, UUID, etc.), and for generic collections it's impossible to re-build the original input correctly without a lot of special casing (consider ChainMap; rebuilding the input is necessary because we need to replace values after validation, e.g. if coercing strings to ints). In Pydantic V2 we no longer attempt to preserve the input type in all cases; instead, we only promise that the output type will match the type annotations. Going back to the Mapping example, we promise the output will be a valid Mapping, and in practice it will be a plain dict: from typing import Mapping from pydantic import TypeAdapter class MyDict(dict): pass ta = TypeAdapter(Mapping\\\\\\\\\\\\\\[str, int\\\\\\\\\\\\\\]) v = ta.validate\\\\\\\\\\\\\\_python(MyDict()) print(type(v)) #> If you want the output type to be a specific type, consider annotating it as such or implementing a custom validator: from typing import Any, Mapping, TypeVar from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import ( TypeAdapter, ValidationInfo, ValidatorFunctionWrapHandler, WrapValidator, ) def restore\\\\\\\\\\\\\\_input\\\\\\\\\\\\\\_type( value: Any, handler: ValidatorFunctionWrapHandler, \\\\\\\\\\\\\\_info: ValidationInfo ) -> Any: return type(value)(handler(value)) T = TypeVar('T') PreserveType = Annotated\\\\\\\\\\\\\\[T, WrapValidator(restore\\\\\\\\\\\\\\_input\\\\\\\\\\\\\\_type)\\\\\\\\\\\\\\] ta = TypeAdapter(PreserveType\\\\\\\\\\\\\\[Mapping\\\\\\\\\\\\\\[str, int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]) class MyDict(dict): pass v = ta.validate\\\\\\\\\\\\\\_python(MyDict()) assert type(v) is MyDict While we don't promise to preserve input types everywhere, we do preserve them for subclasses of BaseModel, and for dataclasses: import pydantic.dataclasses from pydantic import BaseModel class InnerModel(BaseModel): x: int class OuterModel(BaseModel): inner: InnerModel class SubInnerModel(InnerModel): y: int m = OuterModel(inner=SubInnerModel(x=1, y=2)) print(m) #> inner=SubInnerModel(x=1, y=2) @pydantic.dataclasses.dataclass class InnerDataclass: x: int @pydantic.dataclasses.dataclass class SubInnerDataclass(InnerDataclass): y: int @pydantic.dataclasses.dataclass class OuterDataclass: inner: InnerDataclass d = OuterDataclass(inner=SubInnerDataclass(x=1, y=2)) print(d) #> OuterDataclass(inner=SubInnerDataclass(x=1, y=2)) Changes to Handling of Standard Types¶ Dicts¶ Iterables of pairs (which include empty iterables) no longer pass validation for fields of type dict. Unions¶ While union types will still attempt validation of each choice from left to right, they now preserve the type of the input whenever possible, even if the correct type is not the first choice for which the input would pass validation. As a demonstration, consider the following example: from typing import Union from pydantic import BaseModel class Model(BaseModel): x: Union\\\\\\\\\\\\\\[int, str\\\\\\\\\\\\\\] print(Model(x='1')) #> x='1' In Pydantic V1, the printed result would have been x=1, since the value would pass validation as an int. In Pydantic V2, we recognize that the value is an instance of one of the cases and short-circuit the standard union validation. To revert to the non-short-circuiting left-to-right behavior of V1, annotate the union with Field(union\\\\\\\\\\\\\\_mode='left\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_right'). See Union Mode for more details. Required, optional, and nullable fields¶ Pydantic V2 changes some of the logic for specifying whether a field annotated as Optional is required (i.e., has no default value) or not (i.e., has a default value of None or any other value of the corresponding type), and now more closely matches the behavior of dataclasses. Similarly, fields annotated as Any no longer have a default value of None. The following table describes the behavior of field annotations in V2: State Field Definition Required, cannot be None f1: str Not required, cannot be None, is 'abc' by default f2: str = 'abc' Required, can be None f3: Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] Not required, can be None, is None by default f4: Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] = None Not required, can be None, is 'abc' by default f5: Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] = 'abc' Required, can be any type (including None) f6: Any Not required, can be any type (including None) f7: Any = None Note A field annotated as typing.Optional\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\] will be required, and will allow for a value of None. It does not mean that the field has a default value of None. (This is a breaking change from V1.) Note Any default value if provided makes a field not required. Here is a code example demonstrating the above: from typing import Optional from pydantic import BaseModel, ValidationError class Foo(BaseModel): f1: str # required, cannot be None f2: Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] # required, can be None - same as str | None f3: Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] = None # not required, can be None f4: str = 'Foobar' # not required, but cannot be None try: Foo(f1=None, f2=None, f4='b') except ValidationError as e: print(e) \"\"\" 1 validation error for Foo f1 Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=None, input\\\\\\\\\\\\\\_type=NoneType\\\\\\\\\\\\\\] \"\"\" Patterns / regex on strings¶ Pydantic V1 used Python's regex library. Pydantic V2 uses the Rust regex crate. This crate is not just a \"Rust version of regular expressions\", it's a completely different approach to regular expressions. In particular, it promises linear time searching of strings in exchange for dropping a couple of features (namely look arounds and backreferences). We believe this is a tradeoff worth making, in particular because Pydantic is used to validate untrusted input where ensuring things don't accidentally run in exponential time depending on the untrusted input is important. On the flipside, for anyone not using these features complex regex validation should be orders of magnitude faster because it's done in Rust and in linear time. If you still want to use Python's regex library, you can use the regex\\\\\\\\\\\\\\_engine config setting. Introduction of TypeAdapter¶ Pydantic V1 had weak support for validating or serializing non-BaseModel types. To work with them, you had to either create a \"root\" model or use the utility functions in pydantic.tools (namely, parse\\\\\\\\\\\\\\_obj\\\\\\\\\\\\\\_as and schema\\\\\\\\\\\\\\_of). In Pydantic V2 this is a lot easier: the TypeAdapter class lets you create an object with methods for validating, serializing, and producing JSON schemas for arbitrary types. This serves as a complete replacement for parse\\\\\\\\\\\\\\_obj\\\\\\\\\\\\\\_as and schema\\\\\\\\\\\\\\_of (which are now deprecated), and also covers some of the use cases of \"root\" models. (RootModel, discussed above, covers the others.) from typing import List from pydantic import TypeAdapter adapter = TypeAdapter(List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]) assert adapter.validate\\\\\\\\\\\\\\_python(\\\\\\\\\\\\\\['1', '2', '3'\\\\\\\\\\\\\\]) == \\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\] print(adapter.json\\\\\\\\\\\\\\_schema()) #> {'items': {'type': 'integer'}, 'type': 'array'} Due to limitations of inferring generic types with common type checkers, to get proper typing in some scenarios, you may need to explicitly specify the generic parameter: from pydantic import TypeAdapter adapter: TypeAdapter\\\\\\\\\\\\\\[str | int\\\\\\\\\\\\\\] = TypeAdapter(str | int) ... \\\\\\\\\\\\\\[TODO: Add link to TypeAdapter documentation. For now, you can find example usage in tests/test\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_adapter.py.\\\\\\\\\\\\\\] Defining custom types¶ We have completely overhauled the way custom types are defined in pydantic. We have exposed hooks for generating both pydantic-core and JSON schemas, allowing you to get all the performance benefits of Pydantic V2 even when using your own custom types. We have also introduced ways to use typing.Annotated to add custom validation to your own types. The main changes are: \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ should be replaced with \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. See Custom Data Types for more information. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_modify\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ becomes \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. See JSON Schema Customization for more information. Additionally, you can use typing.Annotated to modify or provide the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_get\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ functions of a type by annotating it, rather than modifying the type itself. This provides a powerful and flexible mechanism for integrating third-party types with Pydantic, and in some cases may help you remove hacks from Pydantic V1 introduced to work around the limitations for custom types. See Custom Data Types for more information. Changes to JSON schema generation¶ We received many requests over the years to make changes to the JSON schemas that pydantic generates. In Pydantic V2, we have tried to address many of the common requests: The JSON schema for Optional fields now indicates that the value null is allowed. The Decimal type is now exposed in JSON schema (and serialized) as a string. The JSON schema no longer preserves namedtuples as namedtuples. The JSON schema we generate by default now targets draft 2020-12 (with some OpenAPI extensions). When they differ, you can now specify if you want the JSON schema representing the inputs to validation, or the outputs from serialization. However, there have been many reasonable requests over the years for changes which we have not chosen to implement. In Pydantic V1, even if you were willing to implement changes yourself, it was very difficult because the JSON schema generation process involved various recursive function calls; to override one, you'd have to copy and modify the whole implementation. In Pydantic V2, one of our design goals was to make it easier to customize JSON schema generation. To this end, we have introduced the class GenerateJsonSchema, which implements the translation of a type's pydantic-core schema into a JSON schema. By design, this class breaks the JSON schema generation process into smaller methods that can be easily overridden in subclasses to modify the \"global\" approach to generating JSON schema. The various methods that can be used to produce JSON schema (such as BaseModel.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema or TypeAdapter.json\\\\\\\\\\\\\\_schema) accept a keyword argument schema\\\\\\\\\\\\\\_generator: type\\\\\\\\\\\\\\[GenerateJsonSchema\\\\\\\\\\\\\\] = GenerateJsonSchema, and you can pass your custom subclass to these methods in order to use your own approach to generating JSON schema. Hopefully this means that if you disagree with any of the choices we've made, or if you are reliant on behaviors in Pydantic V1 that have changed in Pydantic V2, you can use a custom schema\\\\\\\\\\\\\\_generator, modifying the GenerateJsonSchema class as necessary for your application. BaseSettings has moved to pydantic-settings¶ BaseSettings, the base object for Pydantic settings management, has been moved to a separate package, pydantic-settings. Also, the parse\\\\\\\\\\\\\\_env\\\\\\\\\\\\\\_var classmethod has been removed. So, you need to customise settings sources to have your own parsing function. Color and Payment Card Numbers moved to pydantic-extra-types¶ The following special-use types have been moved to the Pydantic Extra Types package, which may be installed separately if needed. Color Types Payment Card Numbers Url and Dsn types in pydantic.networks no longer inherit from str¶ In Pydantic V1 the AnyUrl type inherited from str, and all the other Url and Dsn types inherited from these. In Pydantic V2 these types are built on two new Url and MultiHostUrl classes using Annotated. Inheriting from str had upsides and downsides, and for V2 we decided it would be better to remove this. To use these types in APIs which expect str you'll now need to convert them (with str(url)). Pydantic V2 uses Rust's Url crate for URL validation. Some of the URL validation differs slightly from the previous behavior in V1. One notable difference is that the new Url types append slashes to the validated version if no path is included, even if a slash is not specified in the argument to a Url type constructor. See the example below for this behavior: from pydantic import AnyUrl assert str(AnyUrl(url='https://google.com')) == 'https://google.com/' assert str(AnyUrl(url='https://google.com/')) == 'https://google.com/' assert str(AnyUrl(url='https://google.com/api')) == 'https://google.com/api' assert str(AnyUrl(url='https://google.com/api/')) == 'https://google.com/api/' If you still want to use the old behavior without the appended slash, take a look at this solution. Constrained types¶ The Constrained\\\\\\\\\\\\\\* classes were removed, and you should replace them by Annotated\\\\\\\\\\\\\\[, Field(...)\\\\\\\\\\\\\\], for example: from pydantic import BaseModel, ConstrainedInt class MyInt(ConstrainedInt): ge = 0 class Model(BaseModel): x: MyInt ...becomes: from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, Field MyInt = Annotated\\\\\\\\\\\\\\[int, Field(ge=0)\\\\\\\\\\\\\\] class Model(BaseModel): x: MyInt Read more about it in the Composing types via Annotated docs. For ConstrainedStr you can use StringConstraints instead. Moved in Pydantic V2¶ Pydantic V1 Pydantic V2 pydantic.BaseSettings pydantic\\\\\\\\\\\\\\_settings.BaseSettings pydantic.color pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.color pydantic.types.PaymentCardBrand pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.PaymentCardBrand pydantic.types.PaymentCardNumber pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_types.PaymentCardNumber pydantic.utils.version\\\\\\\\\\\\\\_info pydantic.version.version\\\\\\\\\\\\\\_info pydantic.error\\\\\\\\\\\\\\_wrappers.ValidationError pydantic.ValidationError pydantic.utils.to\\\\\\\\\\\\\\_camel pydantic.alias\\\\\\\\\\\\\\_generators.to\\\\\\\\\\\\\\_pascal pydantic.utils.to\\\\\\\\\\\\\\_lower\\\\\\\\\\\\\\_camel pydantic.alias\\\\\\\\\\\\\\_generators.to\\\\\\\\\\\\\\_camel pydantic.PyObject pydantic.ImportString Deprecated and moved in Pydantic V2¶ Pydantic V1 Pydantic V2 pydantic.tools.schema\\\\\\\\\\\\\\_of pydantic.deprecated.tools.schema\\\\\\\\\\\\\\_of pydantic.tools.parse\\\\\\\\\\\\\\_obj\\\\\\\\\\\\\\_as pydantic.deprecated.tools.parse\\\\\\\\\\\\\\_obj\\\\\\\\\\\\\\_as pydantic.tools.schema\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_of pydantic.deprecated.tools.schema\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_of pydantic.json.pydantic\\\\\\\\\\\\\\_encoder pydantic.deprecated.json.pydantic\\\\\\\\\\\\\\_encoder pydantic.validate\\\\\\\\\\\\\\_arguments pydantic.deprecated.decorator.validate\\\\\\\\\\\\\\_arguments pydantic.json.custom\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_encoder pydantic.deprecated.json.custom\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_encoder pydantic.json.timedelta\\\\\\\\\\\\\\_isoformat pydantic.deprecated.json.timedelta\\\\\\\\\\\\\\_isoformat pydantic.decorator.validate\\\\\\\\\\\\\\_arguments pydantic.deprecated.decorator.validate\\\\\\\\\\\\\\_arguments pydantic.class\\\\\\\\\\\\\\_validators.validator pydantic.deprecated.class\\\\\\\\\\\\\\_validators.validator pydantic.class\\\\\\\\\\\\\\_validators.root\\\\\\\\\\\\\\_validator pydantic.deprecated.class\\\\\\\\\\\\\\_validators.root\\\\\\\\\\\\\\_validator pydantic.utils.deep\\\\\\\\\\\\\\_update pydantic.v1.utils.deep\\\\\\\\\\\\\\_update pydantic.utils.GetterDict pydantic.v1.utils.GetterDict pydantic.utils.lenient\\\\\\\\\\\\\\_issubclass pydantic.v1.utils.lenient\\\\\\\\\\\\\\_issubclass pydantic.utils.lenient\\\\\\\\\\\\\\_isinstance pydantic.v1.utils.lenient\\\\\\\\\\\\\\_isinstance pydantic.utils.is\\\\\\\\\\\\\\_valid\\\\\\\\\\\\\\_field pydantic.v1.utils.is\\\\\\\\\\\\\\_valid\\\\\\\\\\\\\\_field pydantic.utils.update\\\\\\\\\\\\\\_not\\\\\\\\\\\\\\_none pydantic.v1.utils.update\\\\\\\\\\\\\\_not\\\\\\\\\\\\\\_none pydantic.utils.import\\\\\\\\\\\\\\_string pydantic.v1.utils.import\\\\\\\\\\\\\\_string pydantic.utils.Representation pydantic.v1.utils.Representation pydantic.utils.ROOT\\\\\\\\\\\\\\_KEY pydantic.v1.utils.ROOT\\\\\\\\\\\\\\_KEY pydantic.utils.smart\\\\\\\\\\\\\\_deepcopy pydantic.v1.utils.smart\\\\\\\\\\\\\\_deepcopy pydantic.utils.sequence\\\\\\\\\\\\\\_like pydantic.v1.utils.sequence\\\\\\\\\\\\\\_like Removed in Pydantic V2¶ pydantic.ConstrainedBytes pydantic.ConstrainedDate pydantic.ConstrainedDecimal pydantic.ConstrainedFloat pydantic.ConstrainedFrozenSet pydantic.ConstrainedInt pydantic.ConstrainedList pydantic.ConstrainedSet pydantic.ConstrainedStr pydantic.JsonWrapper pydantic.NoneBytes This was an alias to None | bytes. pydantic.NoneStr This was an alias to None | str. pydantic.NoneStrBytes This was an alias to None | str | bytes. pydantic.Protocol pydantic.Required pydantic.StrBytes This was an alias to str | bytes. pydantic.compiled pydantic.config.get\\\\\\\\\\\\\\_config pydantic.config.inherit\\\\\\\\\\\\\\_config pydantic.config.prepare\\\\\\\\\\\\\\_config pydantic.create\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_namedtuple pydantic.create\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_typeddict pydantic.dataclasses.create\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_from\\\\\\\\\\\\\\_dataclass pydantic.dataclasses.make\\\\\\\\\\\\\\_dataclass\\\\\\\\\\\\\\_validator pydantic.dataclasses.set\\\\\\\\\\\\\\_validation pydantic.datetime\\\\\\\\\\\\\\_parse.parse\\\\\\\\\\\\\\_date pydantic.datetime\\\\\\\\\\\\\\_parse.parse\\\\\\\\\\\\\\_time pydantic.datetime\\\\\\\\\\\\\\_parse.parse\\\\\\\\\\\\\\_datetime pydantic.datetime\\\\\\\\\\\\\\_parse.parse\\\\\\\\\\\\\\_duration pydantic.error\\\\\\\\\\\\\\_wrappers.ErrorWrapper pydantic.errors.AnyStrMaxLengthError pydantic.errors.AnyStrMinLengthError pydantic.errors.ArbitraryTypeError pydantic.errors.BoolError pydantic.errors.BytesError pydantic.errors.CallableError pydantic.errors.ClassError pydantic.errors.ColorError pydantic.errors.ConfigError pydantic.errors.DataclassTypeError pydantic.errors.DateError pydantic.errors.DateNotInTheFutureError pydantic.errors.DateNotInThePastError pydantic.errors.DateTimeError pydantic.errors.DecimalError pydantic.errors.DecimalIsNotFiniteError pydantic.errors.DecimalMaxDigitsError pydantic.errors.DecimalMaxPlacesError pydantic.errors.DecimalWholeDigitsError pydantic.errors.DictError pydantic.errors.DurationError pydantic.errors.EmailError pydantic.errors.EnumError pydantic.errors.EnumMemberError pydantic.errors.ExtraError pydantic.errors.FloatError pydantic.errors.FrozenSetError pydantic.errors.FrozenSetMaxLengthError pydantic.errors.FrozenSetMinLengthError pydantic.errors.HashableError pydantic.errors.IPv4AddressError pydantic.errors.IPv4InterfaceError pydantic.errors.IPv4NetworkError pydantic.errors.IPv6AddressError pydantic.errors.IPv6InterfaceError pydantic.errors.IPv6NetworkError pydantic.errors.IPvAnyAddressError pydantic.errors.IPvAnyInterfaceError pydantic.errors.IPvAnyNetworkError pydantic.errors.IntEnumError pydantic.errors.IntegerError pydantic.errors.InvalidByteSize pydantic.errors.InvalidByteSizeUnit pydantic.errors.InvalidDiscriminator pydantic.errors.InvalidLengthForBrand pydantic.errors.JsonError pydantic.errors.JsonTypeError pydantic.errors.ListError pydantic.errors.ListMaxLengthError pydantic.errors.ListMinLengthError pydantic.errors.ListUniqueItemsError pydantic.errors.LuhnValidationError pydantic.errors.MissingDiscriminator pydantic.errors.MissingError pydantic.errors.NoneIsAllowedError pydantic.errors.NoneIsNotAllowedError pydantic.errors.NotDigitError pydantic.errors.NotNoneError pydantic.errors.NumberNotGeError pydantic.errors.NumberNotGtError pydantic.errors.NumberNotLeError pydantic.errors.NumberNotLtError pydantic.errors.NumberNotMultipleError pydantic.errors.PathError pydantic.errors.PathNotADirectoryError pydantic.errors.PathNotAFileError pydantic.errors.PathNotExistsError pydantic.errors.PatternError pydantic.errors.PyObjectError pydantic.errors.PydanticTypeError pydantic.errors.PydanticValueError pydantic.errors.SequenceError pydantic.errors.SetError pydantic.errors.SetMaxLengthError pydantic.errors.SetMinLengthError pydantic.errors.StrError pydantic.errors.StrRegexError pydantic.errors.StrictBoolError pydantic.errors.SubclassError pydantic.errors.TimeError pydantic.errors.TupleError pydantic.errors.TupleLengthError pydantic.errors.UUIDError pydantic.errors.UUIDVersionError pydantic.errors.UrlError pydantic.errors.UrlExtraError pydantic.errors.UrlHostError pydantic.errors.UrlHostTldError pydantic.errors.UrlPortError pydantic.errors.UrlSchemeError pydantic.errors.UrlSchemePermittedError pydantic.errors.UrlUserInfoError pydantic.errors.WrongConstantError pydantic.main.validate\\\\\\\\\\\\\\_model pydantic.networks.stricturl pydantic.parse\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_as pydantic.parse\\\\\\\\\\\\\\_raw\\\\\\\\\\\\\\_as pydantic.stricturl pydantic.tools.parse\\\\\\\\\\\\\\_file\\\\\\\\\\\\\\_as pydantic.tools.parse\\\\\\\\\\\\\\_raw\\\\\\\\\\\\\\_as pydantic.types.JsonWrapper pydantic.types.NoneBytes pydantic.types.NoneStr pydantic.types.NoneStrBytes pydantic.types.PyObject pydantic.types.StrBytes pydantic.typing.evaluate\\\\\\\\\\\\\\_forwardref pydantic.typing.AbstractSetIntStr pydantic.typing.AnyCallable pydantic.typing.AnyClassMethod pydantic.typing.CallableGenerator pydantic.typing.DictAny pydantic.typing.DictIntStrAny pydantic.typing.DictStrAny pydantic.typing.IntStr pydantic.typing.ListStr pydantic.typing.MappingIntStrAny pydantic.typing.NoArgAnyCallable pydantic.typing.NoneType pydantic.typing.ReprArgs pydantic.typing.SetStr pydantic.typing.StrPath pydantic.typing.TupleGenerator pydantic.typing.WithArgsTypes pydantic.typing.all\\\\\\\\\\\\\\_literal\\\\\\\\\\\\\\_values pydantic.typing.display\\\\\\\\\\\\\\_as\\\\\\\\\\\\\\_type pydantic.typing.get\\\\\\\\\\\\\\_all\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_hints pydantic.typing.get\\\\\\\\\\\\\\_args pydantic.typing.get\\\\\\\\\\\\\\_origin pydantic.typing.get\\\\\\\\\\\\\\_sub\\\\\\\\\\\\\\_types pydantic.typing.is\\\\\\\\\\\\\\_callable\\\\\\\\\\\\\\_type pydantic.typing.is\\\\\\\\\\\\\\_classvar pydantic.typing.is\\\\\\\\\\\\\\_finalvar pydantic.typing.is\\\\\\\\\\\\\\_literal\\\\\\\\\\\\\\_type pydantic.typing.is\\\\\\\\\\\\\\_namedtuple pydantic.typing.is\\\\\\\\\\\\\\_new\\\\\\\\\\\\\\_type pydantic.typing.is\\\\\\\\\\\\\\_none\\\\\\\\\\\\\\_type pydantic.typing.is\\\\\\\\\\\\\\_typeddict pydantic.typing.is\\\\\\\\\\\\\\_typeddict\\\\\\\\\\\\\\_special pydantic.typing.is\\\\\\\\\\\\\\_union pydantic.typing.new\\\\\\\\\\\\\\_type\\\\\\\\\\\\\\_supertype pydantic.typing.resolve\\\\\\\\\\\\\\_annotations pydantic.typing.typing\\\\\\\\\\\\\\_base pydantic.typing.update\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_forward\\\\\\\\\\\\\\_refs pydantic.typing.update\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_forward\\\\\\\\\\\\\\_refs pydantic.utils.ClassAttribute pydantic.utils.DUNDER\\\\\\\\\\\\\\_ATTRIBUTES pydantic.utils.PyObjectStr pydantic.utils.ValueItems pydantic.utils.almost\\\\\\\\\\\\\\_equal\\\\\\\\\\\\\\_floats pydantic.utils.get\\\\\\\\\\\\\\_discriminator\\\\\\\\\\\\\\_alias\\\\\\\\\\\\\\_and\\\\\\\\\\\\\\_values pydantic.utils.get\\\\\\\\\\\\\\_model pydantic.utils.get\\\\\\\\\\\\\\_unique\\\\\\\\\\\\\\_discriminator\\\\\\\\\\\\\\_alias pydantic.utils.in\\\\\\\\\\\\\\_ipython pydantic.utils.is\\\\\\\\\\\\\\_valid\\\\\\\\\\\\\\_identifier pydantic.utils.path\\\\\\\\\\\\\\_type pydantic.utils.validate\\\\\\\\\\\\\\_field\\\\\\\\\\\\\\_name pydantic.validate\\\\\\\\\\\\\\_model Made with Material for MkDocs Insiders"
  },
  {
    "title": "Version Policy - Pydantic",
    "url": "https://docs.pydantic.dev/latest/version-policy/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Version Policy Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Get Started Welcome to Pydantic Why use Pydantic Help with Pydantic Installation Migration Guide Version Policy Contributing Changelog Page contents Pydantic V1 Pydantic V2 Pydantic V3 and beyond Support for Python versions Version Policy First of all, we recognize that the transitions from Pydantic V1 to V2 has been and will be painful for some users. We're sorry about this pain , it was an unfortunate but necessary step to correct design mistakes of V1. There will not be another breaking change of this magnitude! Pydantic V1¶ Active development of V1 has already stopped, however critical bug fixes and security vulnerabilities will be fixed in V1 for one year after the release of V2 (June 30, 2024). Pydantic V2¶ We will not intentionally make breaking changes in minor releases of V2. Methods marked as deprecated will not be removed until the next major release, V3. Of course some apparently safe changes and bug fixes will inevitably break some users' code — obligatory link to XKCD. The following changes will NOT be considered breaking changes, and may occur in minor releases: Changing the format of ref as used in JSON Schema. Changing the msg, ctx, and loc fields of ValidationError errors. type will not change — if you're programmatically parsing error messages, you should use type. Adding new keys to ValidationError errors — e.g. we intend to add line\\\\\\\\\\\\\\_number and column\\\\\\\\\\\\\\_number to errors when validating JSON once we migrate to a new JSON parser. Adding new ValidationError errors. Changing repr even of public classes. In all cases we will aim to minimize churn and do so only when justified by the increase of quality of pydantic for users. Pydantic V3 and beyond¶ We expect to make new major releases roughly once a year going forward, although as mentioned above, any associated breaking changes should be trivial to fix compared to the V1-to-V2 transition. Support for Python versions¶ Pydantic will drop support for a Python version when the following conditions are met: The Python version has reached EOL. <5% of downloads of the most recent minor release need to be using that version. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Installation - Pydantic",
    "url": "https://docs.pydantic.dev/latest/install/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Installation Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Get Started Welcome to Pydantic Why use Pydantic Help with Pydantic Installation Migration Guide Version Policy Contributing Changelog Page contents Optional dependencies Install from repository Installation Installation is as simple as: pip install pydantic Pydantic has a few dependencies: pydantic-core: Core validation logic for pydantic written in rust. typing-extensions: Backport of the standard library typing module. annotated-types: Reusable constraint types to use with typing.Annotated. If you've got Python 3.7+ and pip installed, you're good to go. Pydantic is also available on conda under the conda-forge channel: conda install pydantic -c conda-forge Optional dependencies¶ Pydantic has the following optional dependencies: If you require email validation, you can add email-validator. To install optional dependencies along with Pydantic: pip install pydantic\\\\\\\\\\\\\\[email\\\\\\\\\\\\\\] Of course, you can also install requirements manually with pip install email-validator. Install from repository¶ And if you prefer to install Pydantic directly from the repository: pip install git+https://github.com/pydantic/pydantic@main#egg=pydantic # or with extras pip install git+https://github.com/pydantic/pydantic@main#egg=pydantic\\\\\\\\\\\\\\[email\\\\\\\\\\\\\\] Made with Material for MkDocs Insiders"
  },
  {
    "title": "Help with Pydantic - Pydantic",
    "url": "https://docs.pydantic.dev/latest/help_with_pydantic/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Help with Pydantic Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Get Started Welcome to Pydantic Why use Pydantic Help with Pydantic Installation Migration Guide Version Policy Contributing Changelog Page contents Usage Documentation API Documentation GitHub Discussions Discord Stack Overflow YouTube Getting help with Pydantic¶ If you need help getting started with Pydantic or with advanced usage, the following sources may be useful. Usage Documentation¶ The usage documentation is the most complete guide on how to use Pydantic. API Documentation¶ The API documentation give reference docs for all public Pydantic APIs. GitHub Discussions¶ GitHub discussions are useful for asking questions, your question and the answer will help everyone. Discord¶ The Pydantic Discord server is a great place to chat about Pydantic and ask quick questions. Stack Overflow¶ Use the pydantic tag on Stack Overflow to ask questions, note this is not always monitored by the core Pydantic team. YouTube¶ Youtube as lots of useful videos on Pydantic. In particular Marcelo Trylesinski's video \"Pydantic V1 to V2 - The Migration\" has helped people a lot when migrating from Pydantic V1 to V2. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Why use Pydantic - Pydantic",
    "url": "https://docs.pydantic.dev/latest/why/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Why use Pydantic Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Get Started Welcome to Pydantic Why use Pydantic Help with Pydantic Installation Migration Guide Version Policy Contributing Changelog Page contents Type hints powering schema validation Performance Serialization JSON Schema Strict mode and data coercion Dataclasses, TypedDicts, and more Customisation Ecosystem Organisations using Pydantic Adobe Amazon and AWS Anthropic Apple ASML AstraZeneca Cisco Systems Comcast Datadog Facebook GitHub Google HSBC IBM Intel Intuit Intergovernmental Panel on Climate Change JPMorgan Jupyter Microsoft Molecular Science Software Institute NASA Netflix NSA NVIDIA OpenAI Oracle Palantir Qualcomm Red Hat Revolut Robusta Salesforce Starbucks Texas Instruments Twilio Twitter UK Home Office Why use Pydantic?¶ Today, Pydantic is downloaded many times a month and used by some of the largest and most recognisable organisations in the world. It's hard to know why so many people have adopted Pydantic since its inception six years ago, but here are a few guesses. Type hints powering schema validation¶ The schema that Pydantic validates against is generally defined by Python type hints. Type hints are great for this since, if you're writing modern Python, you already know how to use them. Using type hints also means that Pydantic integrates well with static typing tools like mypy and pyright and IDEs like pycharm and vscode. Example - just type hints (This example requires Python 3.9+) from typing import Annotated, Dict, List, Literal, Tuple from annotated\\\\\\\\\\\\\\_types import Gt from pydantic import BaseModel class Fruit(BaseModel): name: str The name field is simply annotated with str - any string is allowed. color: Literal\\\\\\\\\\\\\\['red', 'green'\\\\\\\\\\\\\\] The Literal type is used to enforce that color is either 'red' or 'green'. weight: Annotated\\\\\\\\\\\\\\[float, Gt(0)\\\\\\\\\\\\\\] Even when we want to apply constraints not encapsulated in python types, we can use Annotated and annotated-types to enforce constraints without breaking type hints. bazam: Dict\\\\\\\\\\\\\\[str, List\\\\\\\\\\\\\\[Tuple\\\\\\\\\\\\\\[int, bool, float\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] I'm not claiming \"bazam\" is really an attribute of fruit, but rather to show that arbitrarily complex types can easily be validated. print( Fruit( name='Apple', color='red', weight=4.2, bazam={'foobar': \\\\\\\\\\\\\\[(1, True, 0.1)\\\\\\\\\\\\\\]}, ) ) #> name='Apple' color='red' weight=4.2 bazam={'foobar': \\\\\\\\\\\\\\[(1, True, 0.1)\\\\\\\\\\\\\\]} Learn more See the documentation on supported types. Performance¶ Pydantic's core validation logic is implemented in separate package pydantic-core, where validation for most types is implemented in Rust. As a result Pydantic is among the fastest data validation libraries for Python. Performance Example - Pydantic vs. dedicated code Unlike other performance-centric libraries written in compiled languages, Pydantic also has excellent support for customizing validation via functional validators. Learn more Samuel Colvin's talk at PyCon 2023 explains how pydantic-core works and how it integrates with Pydantic. Serialization¶ Pydantic provides functionality to serialize model in three ways: To a Python dict made up of the associated Python objects To a Python dict made up only of \"jsonable\" types To a JSON string In all three modes, the output can be customized by excluding specific fields, excluding unset fields, excluding default values, and excluding None values Example - Serialization 3 ways Learn more See the documentation on serialization. JSON Schema¶ JSON Schema can be generated for any Pydantic schema — allowing self-documenting APIs and integration with a wide variety of tools which support JSON Schema. Example - JSON Schema Pydantic generates JSON Schema version 2020-12, the latest version of the standard which is compatible with OpenAPI 3.1. Learn more See the documentation on JSON Schema. Strict mode and data coercion¶ By default, Pydantic is tolerant to common incorrect types and coerces data to the right type — e.g. a numeric string passed to an int field will be parsed as an int. Pydantic also has strict=True mode — also known as \"Strict mode\" — where types are not coerced and a validation error is raised unless the input data exactly matches the schema or type hint. But strict mode would be pretty useless when validating JSON data since JSON doesn't have types matching many common python types like datetime, UUID or bytes. To solve this, Pydantic can parse and validate JSON in one step. This allows sensible data conversion like RFC3339 (aka ISO8601) strings to datetime objects. Since the JSON parsing is implemented in Rust, it's also very performant. Example - Strict mode that's actually useful Learn more See the documentation on strict mode. Dataclasses, TypedDicts, and more¶ Pydantic provides four ways to create schemas and perform validation and serialization: BaseModel — Pydantic's own super class with many common utilities available via instance methods. pydantic.dataclasses.dataclass — a wrapper around standard dataclasses which performs validation when a dataclass is initialized. TypeAdapter — a general way to adapt any type for validation and serialization. This allows types like TypedDict and NampedTuple to be validated as well as simple scalar values like int or timedelta — all types supported can be used with TypeAdapter. validate\\\\\\\\\\\\\\_call — a decorator to perform validation when calling a function. Example - schema based on TypedDict Customisation¶ Functional validators and serializers, as well as a powerful protocol for custom types, means the way Pydantic operates can be customized on a per-field or per-type basis. Customisation Example - wrap validators Learn more See the documentation on validators, custom serializers, and custom types. Ecosystem¶ At the time of writing there are 214,100 repositories on GitHub and 8,119 packages on PyPI that depend on Pydantic. Some notable libraries that depend on Pydantic: huggingface/transformers 107,475 stars tiangolo/fastapi 60,355 stars hwchase17/langchain 54,514 stars apache/airflow 30,955 stars microsoft/DeepSpeed 26,908 stars ray-project/ray 26,600 stars lm-sys/FastChat 24,924 stars Lightning-AI/lightning 24,034 stars OpenBB-finance/OpenBBTerminal 22,785 stars gradio-app/gradio 19,726 stars pola-rs/polars 18,587 stars mindsdb/mindsdb 17,242 stars RasaHQ/rasa 16,695 stars mlflow/mlflow 14,780 stars heartexlabs/label-studio 13,634 stars spotDL/spotify-downloader 12,124 stars Sanster/lama-cleaner 12,075 stars airbytehq/airbyte 11,174 stars openai/evals 11,110 stars matrix-org/synapse 11,071 stars ydataai/ydata-profiling 10,884 stars pyodide/pyodide 10,245 stars tiangolo/sqlmodel 10,160 stars lucidrains/DALLE2-pytorch 9,916 stars pynecone-io/reflex 9,679 stars PaddlePaddle/PaddleNLP 9,663 stars aws/serverless-application-model 9,061 stars modin-project/modin 8,808 stars great-expectations/great\\\\\\\\\\\\\\_expectations 8,613 stars dagster-io/dagster 7,908 stars NVlabs/SPADE 7,407 stars NVlabs/SPADE 7,407 stars brycedrennan/imaginAIry 7,217 stars chroma-core/chroma 7,127 stars lucidrains/imagen-pytorch 7,089 stars sqlfluff/sqlfluff 6,278 stars deeppavlov/DeepPavlov 6,278 stars autogluon/autogluon 5,966 stars bridgecrewio/checkov 5,747 stars bentoml/BentoML 5,275 stars replicate/cog 5,089 stars vitalik/django-ninja 4,623 stars apache/iceberg 4,479 stars jina-ai/discoart 3,820 stars embedchain/embedchain 3,493 stars skypilot-org/skypilot 3,052 stars PrefectHQ/marvin 2,985 stars microsoft/FLAML 2,569 stars docarray/docarray 2,353 stars aws-powertools/powertools-lambda-python 2,198 stars NVIDIA/NeMo-Guardrails 1,830 stars roman-right/beanie 1,299 stars art049/odmantic 807 stars More libraries using Pydantic can be found at Kludex/awesome-pydantic. Organisations using Pydantic¶ Some notable companies and organisations using Pydantic together with comments on why/how we know they're using Pydantic. The organisations below are included because they match one or more of the following criteria: Using pydantic as a dependency in a public repository Referring traffic to the pydantic documentation site from an organization-internal domain - specific referrers are not included since they're generally not in the public domain Direct communication between the Pydantic team and engineers employed by the organization about usage of Pydantic within the organization We've included some extra detail where appropriate and already in the public domain. Adobe¶ adobe/dy-sql uses Pydantic. Amazon and AWS¶ powertools-lambda-python awslabs/gluonts AWS sponsored Samuel Colvin $5,000 to work on Pydantic in 2022 Anthropic¶ anthropics/anthropic-sdk-python uses Pydantic. Apple¶ (Based on the criteria described above) ASML¶ (Based on the criteria described above) AstraZeneca¶ Multiple repos in the AstraZeneca GitHub org depend on Pydantic. Cisco Systems¶ Pydantic is listed in their report of Open Source Used In RADKit. cisco/webex-assistant-sdk Comcast¶ (Based on the criteria described above) Datadog¶ Extensive use of Pydantic in DataDog/integrations-core and other repos Communication with engineers from Datadog about how they use Pydantic. Facebook¶ Multiple repos in the facebookresearch GitHub org depend on Pydantic. GitHub¶ GitHub sponsored Pydantic $750 in 2022 Google¶ Extensive use of Pydantic in google/turbinia and other repos. HSBC¶ (Based on the criteria described above) IBM¶ Multiple repos in the IBM GitHub org depend on Pydantic. Intel¶ (Based on the criteria described above) Intuit¶ (Based on the criteria described above) Intergovernmental Panel on Climate Change¶ Tweet explaining how the IPCC use Pydantic. JPMorgan¶ (Based on the criteria described above) Jupyter¶ The developers of the Jupyter notebook are using Pydantic for subprojects Through the FastAPI-based Jupyter server Jupyverse FPS's configuration management. Microsoft¶ DeepSpeed deep learning optimisation library uses Pydantic extensively Multiple repos in the microsoft GitHub org depend on Pydantic, in particular their Pydantic is also used in the Azure GitHub org Comments on GitHub show Microsoft engineers using Pydantic as part of Windows and Office Molecular Science Software Institute¶ Multiple repos in the MolSSI GitHub org depend on Pydantic. NASA¶ Multiple repos in the NASA GitHub org depend on Pydantic. NASA are also using Pydantic via FastAPI in their JWST project to process images from the James Webb Space Telescope, see this tweet. Netflix¶ Multiple repos in the Netflix GitHub org depend on Pydantic. NSA¶ The nsacyber/WALKOFF repo depends on Pydantic. NVIDIA¶ Mupltiple repos in the NVIDIA GitHub org depend on Pydantic. Their \"Omniverse Services\" depends on Pydantic according to their documentation. OpenAI¶ OpenAI use Pydantic for their ChatCompletions API, as per this discussion on GitHub. Anecdotally, OpenAI use Pydantic extensively for their internal services. Oracle¶ (Based on the criteria described above) Palantir¶ (Based on the criteria described above) Qualcomm¶ (Based on the criteria described above) Red Hat¶ (Based on the criteria described above) Revolut¶ Anecdotally, all internal services at Revolut are built with FastAPI and therefore Pydantic. Robusta¶ The robusta-dev/robusta repo depends on Pydantic. Salesforce¶ Salesforce sponsored Samuel Colvin $10,000 to work on Pydantic in 2022. Starbucks¶ (Based on the criteria described above) Texas Instruments¶ (Based on the criteria described above) Twilio¶ (Based on the criteria described above) Twitter¶ Twitter's the-algorithm repo where they open sourced their recommendation engine uses Pydantic. UK Home Office¶ (Based on the criteria described above) Made with Material for MkDocs Insiders"
  },
  {
    "title": "Pydantic V2 Is Here! - Pydantic",
    "url": "https://docs.pydantic.dev/latest/blog/pydantic-v2-final/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Pydantic V2 Is Here! Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Blog Pydantic V2 Is Here! Pydantic V2 Pre Release Pydantic V2 Plan Page contents Getting started with Pydantic V2 Migration guide Pydantic V2 Is Here!¶ Terrence Dorsey & Samuel Colvin •  •  •  June 30, 2023 •  2 min read The last few months have involved a whirlwind of work, and we're finally ready to announce to official release of Pydantic V2! Getting started with Pydantic V2¶ To get started with Pydantic V2, install it from PyPI: pip install -U pydantic Pydantic V2 is compatible with Python 3.7 and above. See the docs for examples of Pydantic at work. Migration guide¶ If you are upgrading an existing project, you can use our extensive migration guide to understand what has changed. If you do encounter any issues, please create an issue in GitHub using the bug V2 label. This will help us to actively monitor and track errors, and to continue to improve the library’s performance. Thank you for your support, and we look forward to your feedback. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Mypy - Pydantic",
    "url": "https://docs.pydantic.dev/latest/integrations/mypy/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Mypy Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Integrations Mypy PyCharm Hypothesis Visual Studio Code datamodel-code-generator devtools Rich Page contents Using mypy without the plugin Strict Optional Other Pydantic interfaces Mypy Plugin Capabilities Generate a signature for Model.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ Generate a typed signature for Model.model\\\\\\\\\\\\\\_construct Respect Config.frozen Generate a signature for dataclasses Respect the type of the Field's default and default\\\\\\\\\\\\\\_factory Warn about the use of untyped fields Optional Capabilities: Prevent the use of required dynamic aliases Enabling the Plugin Configuring the Plugin Mypy Pydantic works well with mypy right out of the box. However, Pydantic also ships with a mypy plugin that adds a number of important pydantic-specific features to mypy that improve its ability to type-check your code. For example, consider the following script: from datetime import datetime from typing import List, Optional from pydantic import BaseModel class Model(BaseModel): age: int first\\\\\\\\\\\\\\_name = 'John' last\\\\\\\\\\\\\\_name: Optional\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] = None signup\\\\\\\\\\\\\\_ts: Optional\\\\\\\\\\\\\\[datetime\\\\\\\\\\\\\\] = None list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] m = Model(age=42, list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints=\\\\\\\\\\\\\\[1, '2', b'3'\\\\\\\\\\\\\\]) print(m.middle\\\\\\\\\\\\\\_name) # not a model field! Model() # will raise a validation error for age and list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints Without any special configuration, mypy catches one of the errors: 16: error: \"Model\" has no attribute \"middle\\\\\\\\\\\\\\_name\" \\\\\\\\\\\\\\[attr-defined\\\\\\\\\\\\\\] But with the plugin enabled, it catches both: 9: error: Untyped fields disallowed \\\\\\\\\\\\\\[pydantic-field\\\\\\\\\\\\\\] 16: error: \"Model\" has no attribute \"middle\\\\\\\\\\\\\\_name\" \\\\\\\\\\\\\\[attr-defined\\\\\\\\\\\\\\] 17: error: Missing named argument \"age\" for \"Model\" \\\\\\\\\\\\\\[call-arg\\\\\\\\\\\\\\] 17: error: Missing named argument \"list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints\" for \"Model\" \\\\\\\\\\\\\\[call-arg\\\\\\\\\\\\\\] With the pydantic mypy plugin, you can fearlessly refactor your models knowing mypy will catch any mistakes if your field names or types change. There are other benefits too! See below for more details. Using mypy without the plugin¶ You can run your code through mypy with: mypy \\\\\\\\\\\\\\\\ --ignore-missing-imports \\\\\\\\\\\\\\\\ --follow-imports=skip \\\\\\\\\\\\\\\\ --strict-optional \\\\\\\\\\\\\\\\ pydantic\\\\\\\\\\\\\\_mypy\\\\\\\\\\\\\\_test.py Strict Optional¶ For your code to pass with --strict-optional, you need to use Optional\\\\\\\\\\\\\\[\\\\\\\\\\\\\\] or an alias of Optional\\\\\\\\\\\\\\[\\\\\\\\\\\\\\] for all fields with None as the default. (This is standard with mypy.) Other Pydantic interfaces¶ Pydantic dataclasses and the validate\\\\\\\\\\\\\\_call decorator should also work well with mypy. Mypy Plugin Capabilities¶ Generate a signature for Model.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_¶ Any required fields that don't have dynamically-determined aliases will be included as required keyword arguments. If Config.populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name=True, the generated signature will use the field names, rather than aliases. If Config.extra='forbid' and you don't make use of dynamically-determined aliases, the generated signature will not allow unexpected inputs. Optional: If the init\\\\\\\\\\\\\\_forbid\\\\\\\\\\\\\\_extra plugin setting is set to True, unexpected inputs to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ will raise errors even if Config.extra is not 'forbid'. Optional: If the init\\\\\\\\\\\\\\_typed plugin setting is set to True, the generated signature will use the types of the model fields (otherwise they will be annotated as Any to allow parsing). Generate a typed signature for Model.model\\\\\\\\\\\\\\_construct¶ The model\\\\\\\\\\\\\\_construct method is an alternative to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ when input data is known to be valid and should not be parsed. Because this method performs no runtime validation, static checking is important to detect errors. Respect Config.frozen¶ If Config.frozen is True, you'll get a mypy error if you try to change the value of a model field; cf. faux immutability. Generate a signature for dataclasses¶ classes decorated with @pydantic.dataclasses.dataclass are type checked the same as standard Python dataclasses The @pydantic.dataclasses.dataclass decorator accepts a config keyword argument which has the same meaning as the Config sub-class. Respect the type of the Field's default and default\\\\\\\\\\\\\\_factory¶ Field with both a default and a default\\\\\\\\\\\\\\_factory will result in an error during static checking. The type of the default and default\\\\\\\\\\\\\\_factory value must be compatible with the one of the field. Warn about the use of untyped fields¶ You'll get a mypy error any time you assign a public attribute on a model without annotating its type If your goal is to set a ClassVar, you should explicitly annotate the field using typing.ClassVar Optional Capabilities:¶ Prevent the use of required dynamic aliases¶ If the warn\\\\\\\\\\\\\\_required\\\\\\\\\\\\\\_dynamic\\\\\\\\\\\\\\_aliases plugin setting is set to True, you'll get a mypy error any time you use a dynamically-determined alias or alias generator on a model with Config.populate\\\\\\\\\\\\\\_by\\\\\\\\\\\\\\_name=False. This is important because if such aliases are present, mypy cannot properly type check calls to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. In this case, it will default to treating all arguments as optional. Enabling the Plugin¶ To enable the plugin, just add pydantic.mypy to the list of plugins in your mypy config file (this could be mypy.ini, pyproject.toml, or setup.cfg). To get started, all you need to do is create a mypy.ini file with following contents: \\\\\\\\\\\\\\[mypy\\\\\\\\\\\\\\] plugins = pydantic.mypy The plugin is compatible with mypy versions >=0.930. See the plugin configuration docs for more details. Configuring the Plugin¶ To change the values of the plugin settings, create a section in your mypy config file called \\\\\\\\\\\\\\[pydantic-mypy\\\\\\\\\\\\\\], and add any key-value pairs for settings you want to override. A mypy.ini file with all plugin strictness flags enabled (and some other mypy strictness flags, too) might look like: \\\\\\\\\\\\\\[mypy\\\\\\\\\\\\\\] plugins = pydantic.mypy follow\\\\\\\\\\\\\\_imports = silent warn\\\\\\\\\\\\\\_redundant\\\\\\\\\\\\\\_casts = True warn\\\\\\\\\\\\\\_unused\\\\\\\\\\\\\\_ignores = True disallow\\\\\\\\\\\\\\_any\\\\\\\\\\\\\\_generics = True check\\\\\\\\\\\\\\_untyped\\\\\\\\\\\\\\_defs = True no\\\\\\\\\\\\\\_implicit\\\\\\\\\\\\\\_reexport = True # for strict mypy: (this is the tricky one :-)) disallow\\\\\\\\\\\\\\_untyped\\\\\\\\\\\\\\_defs = True \\\\\\\\\\\\\\[pydantic-mypy\\\\\\\\\\\\\\] init\\\\\\\\\\\\\\_forbid\\\\\\\\\\\\\\_extra = True init\\\\\\\\\\\\\\_typed = True warn\\\\\\\\\\\\\\_required\\\\\\\\\\\\\\_dynamic\\\\\\\\\\\\\\_aliases = True As of mypy>=0.900, mypy config may also be included in the pyproject.toml file rather than mypy.ini. The same configuration as above would be: \\\\\\\\\\\\\\[tool.mypy\\\\\\\\\\\\\\] plugins = \\\\\\\\\\\\\\[ \"pydantic.mypy\" \\\\\\\\\\\\\\] follow\\\\\\\\\\\\\\_imports = \"silent\" warn\\\\\\\\\\\\\\_redundant\\\\\\\\\\\\\\_casts = true warn\\\\\\\\\\\\\\_unused\\\\\\\\\\\\\\_ignores = true disallow\\\\\\\\\\\\\\_any\\\\\\\\\\\\\\_generics = true check\\\\\\\\\\\\\\_untyped\\\\\\\\\\\\\\_defs = true no\\\\\\\\\\\\\\_implicit\\\\\\\\\\\\\\_reexport = true # for strict mypy: (this is the tricky one :-)) disallow\\\\\\\\\\\\\\_untyped\\\\\\\\\\\\\\_defs = true \\\\\\\\\\\\\\[tool.pydantic-mypy\\\\\\\\\\\\\\] init\\\\\\\\\\\\\\_forbid\\\\\\\\\\\\\\_extra = true init\\\\\\\\\\\\\\_typed = true warn\\\\\\\\\\\\\\_required\\\\\\\\\\\\\\_dynamic\\\\\\\\\\\\\\_aliases = true Made with Material for MkDocs Insiders"
  },
  {
    "title": "Error Handling - Pydantic",
    "url": "https://docs.pydantic.dev/latest/errors/errors/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Error Handling Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Error Messages Error Handling Validation Errors Usage Errors Page contents Custom Errors Error messages Customize error messages Error Handling Pydantic will raise a ValidationError whenever it finds an error in the data it's validating. Note Validation code should not raise ValidationError itself, but rather raise a ValueError or AssertionError (or subclass thereof) which will be caught and used to populate ValidationError. One exception will be raised regardless of the number of errors found, that ValidationError will contain information about all the errors and how they happened. You can access these errors in several ways: Method Description e.errors() Returns a list of errors found in the input data. e.error\\\\\\\\\\\\\\_count() Returns the number of errors found in errors. e.json() Returns a JSON representation of errors. str(e) Returns a human-readable representation of the errors. Each error object contains: Property Description ctx An optional object which contains values required to render the error message. input The input provided for validation. loc The error's location as a list. msg A human-readable explanation of the error. type A computer-readable identifier of the error type. url The URL to further information about the error. The first item in the loc list will be the field where the error occurred, and if the field is a sub-model, subsequent items will be present to indicate the nested location of the error. As a demonstration: from typing import List from pydantic import BaseModel, ValidationError, conint class Location(BaseModel): lat: float = 0.1 lng: float = 10.1 class Model(BaseModel): is\\\\\\\\\\\\\\_required: float gt\\\\\\\\\\\\\\_int: conint(gt=42) list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] = None a\\\\\\\\\\\\\\_float: float = None recursive\\\\\\\\\\\\\\_model: Location = None data = dict( list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints=\\\\\\\\\\\\\\['1', 2, 'bad'\\\\\\\\\\\\\\], a\\\\\\\\\\\\\\_float='not a float', recursive\\\\\\\\\\\\\\_model={'lat': 4.2, 'lng': 'New York'}, gt\\\\\\\\\\\\\\_int=21, ) try: Model(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data) except ValidationError as e: print(e) \"\"\" 5 validation errors for Model is\\\\\\\\\\\\\\_required Field required \\\\\\\\\\\\\\[type=missing, input\\\\\\\\\\\\\\_value={'list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints': \\\\\\\\\\\\\\['1', 2,...ew York'}, 'gt\\\\\\\\\\\\\\_int': 21}, input\\\\\\\\\\\\\\_type=dict\\\\\\\\\\\\\\] gt\\\\\\\\\\\\\\_int Input should be greater than 42 \\\\\\\\\\\\\\[type=greater\\\\\\\\\\\\\\_than, input\\\\\\\\\\\\\\_value=21, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints.2 Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='bad', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] a\\\\\\\\\\\\\\_float Input should be a valid number, unable to parse string as a number \\\\\\\\\\\\\\[type=float\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='not a float', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] recursive\\\\\\\\\\\\\\_model.lng Input should be a valid number, unable to parse string as a number \\\\\\\\\\\\\\[type=float\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='New York', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" try: Model(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data) except ValidationError as e: print(e.errors()) \"\"\" \\\\\\\\\\\\\\[ { 'type': 'missing', 'loc': ('is\\\\\\\\\\\\\\_required',), 'msg': 'Field required', 'input': { 'list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints': \\\\\\\\\\\\\\['1', 2, 'bad'\\\\\\\\\\\\\\], 'a\\\\\\\\\\\\\\_float': 'not a float', 'recursive\\\\\\\\\\\\\\_model': {'lat': 4.2, 'lng': 'New York'}, 'gt\\\\\\\\\\\\\\_int': 21, }, 'url': 'https://errors.pydantic.dev/2/v/missing', }, { 'type': 'greater\\\\\\\\\\\\\\_than', 'loc': ('gt\\\\\\\\\\\\\\_int',), 'msg': 'Input should be greater than 42', 'input': 21, 'ctx': {'gt': 42}, 'url': 'https://errors.pydantic.dev/2/v/greater\\\\\\\\\\\\\\_than', }, { 'type': 'int\\\\\\\\\\\\\\_parsing', 'loc': ('list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints', 2), 'msg': 'Input should be a valid integer, unable to parse string as an integer', 'input': 'bad', 'url': 'https://errors.pydantic.dev/2/v/int\\\\\\\\\\\\\\_parsing', }, { 'type': 'float\\\\\\\\\\\\\\_parsing', 'loc': ('a\\\\\\\\\\\\\\_float',), 'msg': 'Input should be a valid number, unable to parse string as a number', 'input': 'not a float', 'url': 'https://errors.pydantic.dev/2/v/float\\\\\\\\\\\\\\_parsing', }, { 'type': 'float\\\\\\\\\\\\\\_parsing', 'loc': ('recursive\\\\\\\\\\\\\\_model', 'lng'), 'msg': 'Input should be a valid number, unable to parse string as a number', 'input': 'New York', 'url': 'https://errors.pydantic.dev/2/v/float\\\\\\\\\\\\\\_parsing', }, \\\\\\\\\\\\\\] \"\"\" Custom Errors¶ In your custom data types or validators you should use ValueError or AssertionError to raise errors. See validators for more details on use of the @validator decorator. from pydantic import BaseModel, ValidationError, field\\\\\\\\\\\\\\_validator class Model(BaseModel): foo: str @field\\\\\\\\\\\\\\_validator('foo') def value\\\\\\\\\\\\\\_must\\\\\\\\\\\\\\_equal\\\\\\\\\\\\\\_bar(cls, v): if v != 'bar': raise ValueError('value must be \"bar\"') return v try: Model(foo='ber') except ValidationError as e: print(e) \"\"\" 1 validation error for Model foo Value error, value must be \"bar\" \\\\\\\\\\\\\\[type=value\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='ber', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" print(e.errors()) \"\"\" \\\\\\\\\\\\\\[ { 'type': 'value\\\\\\\\\\\\\\_error', 'loc': ('foo',), 'msg': 'Value error, value must be \"bar\"', 'input': 'ber', 'ctx': {'error': ValueError('value must be \"bar\"')}, 'url': 'https://errors.pydantic.dev/2/v/value\\\\\\\\\\\\\\_error', } \\\\\\\\\\\\\\] \"\"\" You can also use PydanticCustomError, to fully control the error structure: from pydantic\\\\\\\\\\\\\\_core import PydanticCustomError from pydantic import BaseModel, ValidationError, field\\\\\\\\\\\\\\_validator class Model(BaseModel): foo: str @field\\\\\\\\\\\\\\_validator('foo') def value\\\\\\\\\\\\\\_must\\\\\\\\\\\\\\_equal\\\\\\\\\\\\\\_bar(cls, v): if v != 'bar': raise PydanticCustomError( 'not\\\\\\\\\\\\\\_a\\\\\\\\\\\\\\_bar', 'value is not \"bar\", got \"{wrong\\\\\\\\\\\\\\_value}\"', dict(wrong\\\\\\\\\\\\\\_value=v), ) return v try: Model(foo='ber') except ValidationError as e: print(e) \"\"\" 1 validation error for Model foo value is not \"bar\", got \"ber\" \\\\\\\\\\\\\\[type=not\\\\\\\\\\\\\\_a\\\\\\\\\\\\\\_bar, input\\\\\\\\\\\\\\_value='ber', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Error messages¶ Pydantic attempts to provide useful default error messages for validation and usage errors. We've provided documentation for default error codes in the following sections: Validation Errors Usage Errors Customize error messages¶ You can customize error messages by creating a custom error handler. from typing import Dict, List from pydantic\\\\\\\\\\\\\\_core import ErrorDetails from pydantic import BaseModel, HttpUrl, ValidationError CUSTOM\\\\\\\\\\\\\\_MESSAGES = { 'int\\\\\\\\\\\\\\_parsing': 'This is not an integer! 🤦', 'url\\\\\\\\\\\\\\_scheme': 'Hey, use the right URL scheme! I wanted {expected\\\\\\\\\\\\\\_schemes}.', } def convert\\\\\\\\\\\\\\_errors( e: ValidationError, custom\\\\\\\\\\\\\\_messages: Dict\\\\\\\\\\\\\\[str, str\\\\\\\\\\\\\\] ) -> List\\\\\\\\\\\\\\[ErrorDetails\\\\\\\\\\\\\\]: new\\\\\\\\\\\\\\_errors: List\\\\\\\\\\\\\\[ErrorDetails\\\\\\\\\\\\\\] = \\\\\\\\\\\\\\[\\\\\\\\\\\\\\] for error in e.errors(): custom\\\\\\\\\\\\\\_message = custom\\\\\\\\\\\\\\_messages.get(error\\\\\\\\\\\\\\['type'\\\\\\\\\\\\\\]) if custom\\\\\\\\\\\\\\_message: ctx = error.get('ctx') error\\\\\\\\\\\\\\['msg'\\\\\\\\\\\\\\] = ( custom\\\\\\\\\\\\\\_message.format(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*ctx) if ctx else custom\\\\\\\\\\\\\\_message ) new\\\\\\\\\\\\\\_errors.append(error) return new\\\\\\\\\\\\\\_errors class Model(BaseModel): a: int b: HttpUrl try: Model(a='wrong', b='ftp://example.com') except ValidationError as e: errors = convert\\\\\\\\\\\\\\_errors(e, CUSTOM\\\\\\\\\\\\\\_MESSAGES) print(errors) \"\"\" \\\\\\\\\\\\\\[ { 'type': 'int\\\\\\\\\\\\\\_parsing', 'loc': ('a',), 'msg': 'This is not an integer! 🤦', 'input': 'wrong', 'url': 'https://errors.pydantic.dev/2/v/int\\\\\\\\\\\\\\_parsing', }, { 'type': 'url\\\\\\\\\\\\\\_scheme', 'loc': ('b',), 'msg': \"Hey, use the right URL scheme! I wanted 'http' or 'https'.\", 'input': 'ftp://example.com', 'ctx': {'expected\\\\\\\\\\\\\\_schemes': \"'http' or 'https'\"}, 'url': 'https://errors.pydantic.dev/2/v/url\\\\\\\\\\\\\\_scheme', }, \\\\\\\\\\\\\\] \"\"\" A common use case would be to translate error messages. For example, in the above example, we could translate the error messages replacing the CUSTOM\\\\\\\\\\\\\\_MESSAGES dictionary with a dictionary of translations. Another example is customizing the way that the 'loc' value of an error is represented. from typing import Any, Dict, List, Tuple, Union from pydantic import BaseModel, ValidationError def loc\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_dot\\\\\\\\\\\\\\_sep(loc: Tuple\\\\\\\\\\\\\\[Union\\\\\\\\\\\\\\[str, int\\\\\\\\\\\\\\], ...\\\\\\\\\\\\\\]) -> str: path = '' for i, x in enumerate(loc): if isinstance(x, str): if i > 0: path += '.' path += x elif isinstance(x, int): path += f'\\\\\\\\\\\\\\[{x}\\\\\\\\\\\\\\]' else: raise TypeError('Unexpected type') return path def convert\\\\\\\\\\\\\\_errors(e: ValidationError) -> List\\\\\\\\\\\\\\[Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]: new\\\\\\\\\\\\\\_errors: List\\\\\\\\\\\\\\[Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = e.errors() for error in new\\\\\\\\\\\\\\_errors: error\\\\\\\\\\\\\\['loc'\\\\\\\\\\\\\\] = loc\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_dot\\\\\\\\\\\\\\_sep(error\\\\\\\\\\\\\\['loc'\\\\\\\\\\\\\\]) return new\\\\\\\\\\\\\\_errors class TestNestedModel(BaseModel): key: str value: str class TestModel(BaseModel): items: List\\\\\\\\\\\\\\[TestNestedModel\\\\\\\\\\\\\\] data = {'items': \\\\\\\\\\\\\\[{'key': 'foo', 'value': 'bar'}, {'key': 'baz'}\\\\\\\\\\\\\\]} try: TestModel.model\\\\\\\\\\\\\\_validate(data) except ValidationError as e: print(e.errors()) By default, e.errors() produces a List of errors with loc values that take the form of tuples. \"\"\" \\\\\\\\\\\\\\[ { 'type': 'missing', 'loc': ('items', 1, 'value'), 'msg': 'Field required', 'input': {'key': 'baz'}, 'url': 'https://errors.pydantic.dev/2/v/missing', } \\\\\\\\\\\\\\] \"\"\" pretty\\\\\\\\\\\\\\_errors = convert\\\\\\\\\\\\\\_errors(e) print(pretty\\\\\\\\\\\\\\_errors) With our custom loc\\\\\\\\\\\\\\_to\\\\\\\\\\\\\\_dot\\\\\\\\\\\\\\_sep function, we've modified the form of the loc representation. \"\"\" \\\\\\\\\\\\\\[ { 'type': 'missing', 'loc': 'items\\\\\\\\\\\\\\[1\\\\\\\\\\\\\\].value', 'msg': 'Field required', 'input': {'key': 'baz'}, 'url': 'https://errors.pydantic.dev/2/v/missing', } \\\\\\\\\\\\\\] \"\"\" Made with Material for MkDocs Insiders"
  },
  {
    "title": "Secrets - Pydantic",
    "url": "https://docs.pydantic.dev/latest/examples/secrets/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic Secrets Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Examples Secrets Page contents Serialize SecretStr and SecretBytes as plain-text Secrets 🚧 Work in Progress This page is a work in progress. Serialize SecretStr and SecretBytes as plain-text¶ By default, SecretStr and SecretBytes will be serialized as \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\* when serializing to json. You can use the field\\\\\\\\\\\\\\_serializer to dump the secret as plain-text when serializing to json. from pydantic import BaseModel, SecretBytes, SecretStr, field\\\\\\\\\\\\\\_serializer class Model(BaseModel): password: SecretStr password\\\\\\\\\\\\\\_bytes: SecretBytes @field\\\\\\\\\\\\\\_serializer('password', 'password\\\\\\\\\\\\\\_bytes', when\\\\\\\\\\\\\\_used='json') def dump\\\\\\\\\\\\\\_secret(self, v): return v.get\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_value() model = Model(password='IAmSensitive', password\\\\\\\\\\\\\\_bytes=b'IAmSensitiveBytes') print(model) #> password=SecretStr('\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*') password\\\\\\\\\\\\\\_bytes=SecretBytes(b'\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*') print(model.password) #> \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\* print(model.model\\\\\\\\\\\\\\_dump()) \"\"\" { 'password': SecretStr('\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*'), 'password\\\\\\\\\\\\\\_bytes': SecretBytes(b'\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*'), } \"\"\" print(model.model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json()) #> {\"password\":\"IAmSensitive\",\"password\\\\\\\\\\\\\\_bytes\":\"IAmSensitiveBytes\"} Made with Material for MkDocs Insiders"
  },
  {
    "title": "BaseModel - Pydantic",
    "url": "https://docs.pydantic.dev/latest/api/base_model/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 BaseModel Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog API Documentation Pydantic BaseModel RootModel Pydantic Dataclasses TypeAdapter Validate Call Fields Configuration JSON Schema Errors Functional Validators Functional Serializers Standard Library Types Pydantic Types Network Types Version Information Pydantic Plugins Annotated Handlers Pydantic Core Pydantic Settings Pydantic Extra Types Page contents BaseModel \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_() model\\\\\\\\\\\\\\_config model\\\\\\\\\\\\\\_computed\\\\\\\\\\\\\\_fields model\\\\\\\\\\\\\\_extra model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set model\\\\\\\\\\\\\\_construct() model\\\\\\\\\\\\\\_copy() model\\\\\\\\\\\\\\_dump() model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json() model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema() model\\\\\\\\\\\\\\_parametrized\\\\\\\\\\\\\\_name() model\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init() model\\\\\\\\\\\\\\_rebuild() model\\\\\\\\\\\\\\_validate() model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json() copy() create\\\\\\\\\\\\\\_model() BaseModel Pydantic models are simply classes which inherit from BaseModel and define fields as annotated attributes. pydantic.BaseModel ¶ Usage Documentation Models A base class for creating Pydantic models. Attributes: Name Type Description \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_class\\\\\\\\\\\\\\_vars\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ set\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] The names of classvars defined on the model. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_private\\\\\\\\\\\\\\_attributes\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ dict\\\\\\\\\\\\\\[str, ModelPrivateAttr\\\\\\\\\\\\\\] Metadata about the private attributes of the model. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_signature\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ Signature The signature for instantiating the model. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_complete\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ bool Whether model building is completed, or if there are still undefined fields. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_core\\\\\\\\\\\\\\_schema\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ CoreSchema The pydantic-core schema used to build the SchemaValidator and SchemaSerializer. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_custom\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ bool Whether the model has a custom \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ function. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_decorators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ \\\\\\\\\\\\\\_decorators.DecoratorInfos Metadata containing the decorators defined on the model. This replaces Model.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and Model.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ from Pydantic V1. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_generic\\\\\\\\\\\\\\_metadata\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ \\\\\\\\\\\\\\_generics.PydanticGenericMetadata Metadata for generic models; contains data used for a similar purpose to args, origin, parameters in typing-module generics. May eventually be replaced by these. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_parent\\\\\\\\\\\\\\_namespace\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None Parent namespace of the model, used for automatic rebuilding of models. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ None | Literal\\\\\\\\\\\\\\['model\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init'\\\\\\\\\\\\\\] The name of the post-init method for the model, if defined. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_root\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ bool Whether the model is a RootModel. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_serializer\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ SchemaSerializer The pydantic-core SchemaSerializer used to dump instances of the model. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_validator\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ SchemaValidator The pydantic-core SchemaValidator used to validate instances of the model. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None An instance attribute with the values of extra fields from validation when model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['extra'\\\\\\\\\\\\\\] == 'allow'. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ set\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] An instance attribute with the names of fields explicitly set. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_private\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None Instance attribute with the values of private attributes set on the model instance. Source code in pydantic/main.py \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ ¶ \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_self\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data) Raises ValidationError if the input data cannot be validated to form a valid model. \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ uses \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_self\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ instead of the more common self for the first arg to allow self as a field name. Source code in pydantic/main.py model\\\\\\\\\\\\\\_config instance-attribute class-attribute ¶ model\\\\\\\\\\\\\\_config: ConfigDict = ConfigDict() Configuration for the model, should be a dictionary conforming to ConfigDict. model\\\\\\\\\\\\\\_computed\\\\\\\\\\\\\\_fields property ¶ model\\\\\\\\\\\\\\_computed\\\\\\\\\\\\\\_fields: dict\\\\\\\\\\\\\\[str, ComputedFieldInfo\\\\\\\\\\\\\\] Get the computed fields of this model instance. Returns: Type Description dict\\\\\\\\\\\\\\[str, ComputedFieldInfo\\\\\\\\\\\\\\] A dictionary of computed field names and their corresponding ComputedFieldInfo objects. model\\\\\\\\\\\\\\_extra property ¶ model\\\\\\\\\\\\\\_extra: dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None Get extra fields set during validation. Returns: Type Description dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None A dictionary of extra fields, or None if config.extra is not set to \"allow\". model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set property ¶ model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set: set\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] Returns the set of fields that have been explicitly set on this model instance. Returns: Type Description set\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] A set of strings representing the fields that have been set, i.e. that were not filled from defaults. model\\\\\\\\\\\\\\_construct classmethod ¶ model\\\\\\\\\\\\\\_construct(\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set=None, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*values) Creates a new instance of the Model class with validated data. Creates a new model setting \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_dict\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ from trusted or pre-validated data. Default values are respected, but no other validation is performed. Behaves as if Config.extra = 'allow' was set since it adds all passed values Parameters: Name Type Description Default \\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set set\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] | None The set of field names accepted for the Model instance. None values Any Trusted or pre-validated data dictionary. {} Returns: Type Description Model A new instance of the Model class with validated data. Source code in pydantic/main.py model\\\\\\\\\\\\\\_copy ¶ model\\\\\\\\\\\\\\_copy(\\\\\\\\\\\\\\*, update=None, deep=False) Usage Documentation model\\\\\\\\\\\\\\_copy(...) Returns a copy of the model. Parameters: Name Type Description Default update dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None Values to change/add in the new model. Note: the data is not validated before creating the new model. You should trust this data. None deep bool Set to True to make a deep copy of the model. False Returns: Type Description Model New model instance. Source code in pydantic/main.py model\\\\\\\\\\\\\\_dump ¶ model\\\\\\\\\\\\\\_dump( \\\\\\\\\\\\\\*, mode=\"python\", include=None, exclude=None, by\\\\\\\\\\\\\\_alias=False, exclude\\\\\\\\\\\\\\_unset=False, exclude\\\\\\\\\\\\\\_defaults=False, exclude\\\\\\\\\\\\\\_none=False, round\\\\\\\\\\\\\\_trip=False, warnings=True ) Usage Documentation model.model\\\\\\\\\\\\\\_dump(...) Generate a dictionary representation of the model, optionally specifying which fields to include or exclude. Parameters: Name Type Description Default mode Literal\\\\\\\\\\\\\\['json', 'python'\\\\\\\\\\\\\\] | str The mode in which to\\\\\\\\\\\\\\_python should run. If mode is 'json', the dictionary will only contain JSON serializable types. If mode is 'python', the dictionary may contain any Python objects. 'python' include IncEx A list of fields to include in the output. None exclude IncEx A list of fields to exclude from the output. None by\\\\\\\\\\\\\\_alias bool Whether to use the field's alias in the dictionary key if defined. False exclude\\\\\\\\\\\\\\_unset bool Whether to exclude fields that have not been explicitly set. False exclude\\\\\\\\\\\\\\_defaults bool Whether to exclude fields that are set to their default value from the output. False exclude\\\\\\\\\\\\\\_none bool Whether to exclude fields that have a value of None from the output. False round\\\\\\\\\\\\\\_trip bool Whether to enable serialization and deserialization round-trip support. False warnings bool Whether to log warnings when invalid fields are encountered. True Returns: Type Description dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] A dictionary representation of the model. Source code in pydantic/main.py model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json ¶ model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json( \\\\\\\\\\\\\\*, indent=None, include=None, exclude=None, by\\\\\\\\\\\\\\_alias=False, exclude\\\\\\\\\\\\\\_unset=False, exclude\\\\\\\\\\\\\\_defaults=False, exclude\\\\\\\\\\\\\\_none=False, round\\\\\\\\\\\\\\_trip=False, warnings=True ) Usage Documentation model.model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json(...) Generates a JSON representation of the model using Pydantic's to\\\\\\\\\\\\\\_json method. Parameters: Name Type Description Default indent int | None Indentation to use in the JSON output. If None is passed, the output will be compact. None include IncEx Field(s) to include in the JSON output. Can take either a string or set of strings. None exclude IncEx Field(s) to exclude from the JSON output. Can take either a string or set of strings. None by\\\\\\\\\\\\\\_alias bool Whether to serialize using field aliases. False exclude\\\\\\\\\\\\\\_unset bool Whether to exclude fields that have not been explicitly set. False exclude\\\\\\\\\\\\\\_defaults bool Whether to exclude fields that have the default value. False exclude\\\\\\\\\\\\\\_none bool Whether to exclude fields that have a value of None. False round\\\\\\\\\\\\\\_trip bool Whether to use serialization/deserialization between JSON and class instance. False warnings bool Whether to show any warnings that occurred during serialization. True Returns: Type Description str A JSON string representation of the model. Source code in pydantic/main.py model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema classmethod ¶ model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema( by\\\\\\\\\\\\\\_alias=True, ref\\\\\\\\\\\\\\_template=DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE, schema\\\\\\\\\\\\\\_generator=GenerateJsonSchema, mode=\"validation\", ) Generates a JSON schema for a model class. Parameters: Name Type Description Default by\\\\\\\\\\\\\\_alias bool Whether to use attribute aliases or not. True ref\\\\\\\\\\\\\\_template str The reference template. DEFAULT\\\\\\\\\\\\\\_REF\\\\\\\\\\\\\\_TEMPLATE schema\\\\\\\\\\\\\\_generator type\\\\\\\\\\\\\\[GenerateJsonSchema\\\\\\\\\\\\\\] To override the logic used to generate the JSON schema, as a subclass of GenerateJsonSchema with your desired modifications GenerateJsonSchema mode JsonSchemaMode The mode in which to generate the schema. 'validation' Returns: Type Description dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] The JSON schema for the given model class. Source code in pydantic/main.py model\\\\\\\\\\\\\\_parametrized\\\\\\\\\\\\\\_name classmethod ¶ model\\\\\\\\\\\\\\_parametrized\\\\\\\\\\\\\\_name(params) Compute the class name for parametrizations of generic classes. This method can be overridden to achieve a custom naming scheme for generic BaseModels. Parameters: Name Type Description Default params tuple\\\\\\\\\\\\\\[type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], ...\\\\\\\\\\\\\\] Tuple of types of the class. Given a generic class Model with 2 type variables and a concrete model Model\\\\\\\\\\\\\\[str, int\\\\\\\\\\\\\\], the value (str, int) would be passed to params. required Returns: Type Description str String representing the new class where params are passed to cls as type variables. Raises: Type Description TypeError Raised when trying to generate concrete names for non-generic models. Source code in pydantic/main.py model\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init ¶ model\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init(\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_context) Override this method to perform additional initialization after \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and model\\\\\\\\\\\\\\_construct. This is useful if you want to do some validation that requires the entire model to be initialized. Source code in pydantic/main.py model\\\\\\\\\\\\\\_rebuild classmethod ¶ model\\\\\\\\\\\\\\_rebuild( \\\\\\\\\\\\\\*, force=False, raise\\\\\\\\\\\\\\_errors=True, \\\\\\\\\\\\\\_parent\\\\\\\\\\\\\\_namespace\\\\\\\\\\\\\\_depth=2, \\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_namespace=None ) Try to rebuild the pydantic-core schema for the model. This may be necessary when one of the annotations is a ForwardRef which could not be resolved during the initial attempt to build the schema, and automatic rebuilding fails. Parameters: Name Type Description Default force bool Whether to force the rebuilding of the model schema, defaults to False. False raise\\\\\\\\\\\\\\_errors bool Whether to raise errors, defaults to True. True \\\\\\\\\\\\\\_parent\\\\\\\\\\\\\\_namespace\\\\\\\\\\\\\\_depth int The depth level of the parent namespace, defaults to 2. 2 \\\\\\\\\\\\\\_types\\\\\\\\\\\\\\_namespace dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None The types namespace, defaults to None. None Returns: Type Description bool | None Returns None if the schema is already \"complete\" and rebuilding was not required. bool | None If rebuilding was required, returns True if rebuilding was successful, otherwise False. Source code in pydantic/main.py model\\\\\\\\\\\\\\_validate classmethod ¶ model\\\\\\\\\\\\\\_validate( obj, \\\\\\\\\\\\\\*, strict=None, from\\\\\\\\\\\\\\_attributes=None, context=None ) Validate a pydantic model instance. Parameters: Name Type Description Default obj Any The object to validate. required strict bool | None Whether to raise an exception on invalid fields. None from\\\\\\\\\\\\\\_attributes bool | None Whether to extract data from object attributes. None context dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None Additional context to pass to the validator. None Raises: Type Description ValidationError If the object could not be validated. Returns: Type Description Model The validated model instance. Source code in pydantic/main.py model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json classmethod ¶ model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json( json\\\\\\\\\\\\\\_data, \\\\\\\\\\\\\\*, strict=None, context=None ) Usage Documentation Json Parsing Validate the given JSON data against the Pydantic model. Parameters: Name Type Description Default json\\\\\\\\\\\\\\_data str | bytes | bytearray The JSON data to validate. required strict bool | None Whether to enforce types strictly. None context dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None Extra variables to pass to the validator. None Returns: Type Description Model The validated Pydantic model. Raises: Type Description ValueError If json\\\\\\\\\\\\\\_data is not a JSON string. Source code in pydantic/main.py copy ¶ copy( \\\\\\\\\\\\\\*, include=None, exclude=None, update=None, deep=False ) Returns a copy of the model. Deprecated This method is now deprecated; use model\\\\\\\\\\\\\\_copy instead. If you need include or exclude, use: data = self.model\\\\\\\\\\\\\\_dump(include=include, exclude=exclude, round\\\\\\\\\\\\\\_trip=True) data = {\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*(update or {})} copied = self.model\\\\\\\\\\\\\\_validate(data) Parameters: Name Type Description Default include AbstractSetIntStr | MappingIntStrAny | None Optional set or mapping specifying which fields to include in the copied model. None exclude AbstractSetIntStr | MappingIntStrAny | None Optional set or mapping specifying which fields to exclude in the copied model. None update typing.Dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None Optional dictionary of field-value pairs to override field values in the copied model. None deep bool If True, the values of fields that are Pydantic models will be deep copied. False Returns: Type Description Model A copy of the model with included, excluded and updated fields as specified. Source code in pydantic/main.py pydantic.create\\\\\\\\\\\\\\_model ¶ pydantic.create\\\\\\\\\\\\\\_model( \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_name, \\\\\\\\\\\\\\*, \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_=None, \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_doc\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_=None, \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_base\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_=None, \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_module\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_=None, \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_=None, \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_cls\\\\\\\\\\\\\\_kwargs\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_=None, \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_slots\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_=None, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*field\\\\\\\\\\\\\\_definitions ) Dynamically creates and returns a new Pydantic model, in other words, create\\\\\\\\\\\\\\_model dynamically creates a subclass of BaseModel. Parameters: Name Type Description Default \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\_name str The name of the newly created model. required \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ ConfigDict | None The configuration of the new model. None \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_doc\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ str | None The docstring of the new model. None \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_base\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ type\\\\\\\\\\\\\\[Model\\\\\\\\\\\\\\] | tuple\\\\\\\\\\\\\\[type\\\\\\\\\\\\\\[Model\\\\\\\\\\\\\\], ...\\\\\\\\\\\\\\] | None The base class for the new model. None \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_module\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ str | None The name of the module that the model belongs to, if None the value is taken from sys.\\\\\\\\\\\\\\_getframe(1) None \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ dict\\\\\\\\\\\\\\[str, classmethod\\\\\\\\\\\\\\] | None A dictionary of methods that validate fields. None \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_cls\\\\\\\\\\\\\\_kwargs\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ dict\\\\\\\\\\\\\\[str, Any\\\\\\\\\\\\\\] | None A dictionary of keyword arguments for class creation. None \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_slots\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ tuple\\\\\\\\\\\\\\[str, ...\\\\\\\\\\\\\\] | None Deprecated. Should not be passed to create\\\\\\\\\\\\\\_model. None \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*field\\\\\\\\\\\\\\_definitions Any Attributes of the new model. They should be passed in the format: \\\\\\\\=(, ) or \\\\\\\\=(, ). {} Returns: Type Description type\\\\\\\\\\\\\\[Model\\\\\\\\\\\\\\] The new model. Raises: Type Description PydanticUserError If \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_base\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ are both passed. Source code in pydantic/main.py Made with Material for MkDocs Insiders"
  },
  {
    "title": "Models - Pydantic",
    "url": "https://docs.pydantic.dev/latest/concepts/models/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Models Initializing search pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Concepts Models Fields JSON Schema JSON Types Unions Alias Configuration Serialization Validators Dataclasses Postponed Annotations Strict Mode Type Adapter Validation Decorator Conversion Table Settings Management Performance Pydantic Plugins Page contents TL;DR The long version validation Basic model usage Model methods and properties Nested models Rebuild model schema Arbitrary class instances Reserved names Nested attributes Error handling Helper functions Creating models without validation Generic models Dynamic model creation RootModel and custom root types Faux immutability Abstract base classes Field ordering Required fields Fields with non-hashable default values Fields with dynamic default values Automatically excluded attributes Class vars Private model attributes Data conversion Model signature Structural pattern matching Attribute copies Extra fields Models API Documentation One of the primary ways of defining schema in Pydantic is via models. Models are simply classes which inherit from pydantic.BaseModel and define fields as annotated attributes. You can think of models as similar to structs in languages like C, or as the requirements of a single endpoint in an API. Models share many similarities with Python's dataclasses, but have been designed with some subtle-yet-important differences that streamline certain workflows related to validation, serialization, and JSON schema generation. You can find more discussion of this in the Dataclasses section of the docs. Untrusted data can be passed to a model and, after parsing and validation, Pydantic guarantees that the fields of the resultant model instance will conform to the field types defined on the model. Validation — a deliberate misnomer TL;DR¶ We use the term \"validation\" to refer to the process of instantiating a model (or other type) that adheres to specified types and constraints. This task, which Pydantic is well known for, is most widely recognized as \"validation\" in colloquial terms, even though in other contexts the term \"validation\" may be more restrictive. The long version¶ The potential confusion around the term \"validation\" arises from the fact that, strictly speaking, Pydantic's primary focus doesn't align precisely with the dictionary definition of \"validation\": validation¶ noun the action of checking or proving the validity or accuracy of something. In Pydantic, the term \"validation\" refers to the process of instantiating a model (or other type) that adheres to specified types and constraints. Pydantic guarantees the types and constraints of the output, not the input data. This distinction becomes apparent when considering that Pydantic's ValidationError is raised when data cannot be successfully parsed into a model instance. While this distinction may initially seem subtle, it holds practical significance. In some cases, \"validation\" goes beyond just model creation, and can include the copying and coercion of data. This can involve copying arguments passed to the constructor in order to perform coercion to a new type without mutating the original input data. For a more in-depth understanding of the implications for your usage, refer to the Data Conversion and Attribute Copies sections below. In essence, Pydantic's primary goal is to assure that the resulting structure post-processing (termed \"validation\") precisely conforms to the applied type hints. Given the widespread adoption of \"validation\" as the colloquial term for this process, we will consistently use it in our documentation. While the terms \"parse\" and \"validation\" were previously used interchangeably, moving forward, we aim to exclusively employ \"validate\", with \"parse\" reserved specifically for discussions related to JSON parsing. Basic model usage¶ from pydantic import BaseModel class User(BaseModel): id: int name: str = 'Jane Doe' In this example, User is a model with two fields: id, which is an integer and is required name, which is a string and is not required (it has a default value). user = User(id='123') In this example, user is an instance of User. Initialization of the object will perform all parsing and validation. If no ValidationError is raised, you know the resulting model instance is valid. assert user.id == 123 assert isinstance(user.id, int) # Note that '123' was coerced to an int and its value is 123 More details on pydantic's coercion logic can be found in Data Conversion. Fields of a model can be accessed as normal attributes of the user object. The string '123' has been converted into an int as per the field type. assert user.name == 'Jane Doe' name wasn't set when user was initialized, so it has the default value. assert user.model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set == {'id'} The fields which were supplied when user was initialized. assert user.model\\\\\\\\\\\\\\_dump() == {'id': 123, 'name': 'Jane Doe'} Either .model\\\\\\\\\\\\\\_dump() or dict(user) will provide a dict of fields, but .model\\\\\\\\\\\\\\_dump() can take numerous other arguments. (Note that dict(user) will not recursively convert nested models into dicts, but .model\\\\\\\\\\\\\\_dump() will.) user.id = 321 assert user.id == 321 By default, models are mutable and field values can be changed through attribute assignment. Model methods and properties¶ The example above only shows the tip of the iceberg of what models can do. Models possess the following methods and attributes: model\\\\\\\\\\\\\\_computed\\\\\\\\\\\\\\_fields: a dictionary of the computed fields of this model instance. model\\\\\\\\\\\\\\_construct(): a class method for creating models without running validation. See Creating models without validation. model\\\\\\\\\\\\\\_copy(): returns a copy (by default, shallow copy) of the model. See Serialization. model\\\\\\\\\\\\\\_dump(): returns a dictionary of the model's fields and values. See Serialization. model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json(): returns a JSON string representation of model\\\\\\\\\\\\\\_dump(). See Serialization. model\\\\\\\\\\\\\\_extra: get extra fields set during validation. model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set: set of fields which were set when the model instance was initialized. model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema(): returns a jsonable dictionary representing the model as JSON Schema. See JSON Schema. model\\\\\\\\\\\\\\_parametrized\\\\\\\\\\\\\\_name(): compute the class name for parametrizations of generic classes. model\\\\\\\\\\\\\\_post\\\\\\\\\\\\\\_init(): perform additional initialization after the model is initialized. model\\\\\\\\\\\\\\_rebuild(): rebuild the model schema, which also supports building recursive generic models. See Rebuild model schema. model\\\\\\\\\\\\\\_validate(): a utility for loading any object into a model. See Helper functions. model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json(): a utility for validating the given JSON data against the Pydantic model. See Helper functions. Note See BaseModel for the class definition including a full list of methods and attributes. Tip See Changes to pydantic.BaseModel in the Migration Guide for details on changes from Pydantic V1. Nested models¶ More complex hierarchical data structures can be defined using models themselves as types in annotations. from typing import List, Optional from pydantic import BaseModel class Foo(BaseModel): count: int size: Optional\\\\\\\\\\\\\\[float\\\\\\\\\\\\\\] = None class Bar(BaseModel): apple: str = 'x' banana: str = 'y' class Spam(BaseModel): foo: Foo bars: List\\\\\\\\\\\\\\[Bar\\\\\\\\\\\\\\] m = Spam(foo={'count': 4}, bars=\\\\\\\\\\\\\\[{'apple': 'x1'}, {'apple': 'x2'}\\\\\\\\\\\\\\]) print(m) \"\"\" foo=Foo(count=4, size=None) bars=\\\\\\\\\\\\\\[Bar(apple='x1', banana='y'), Bar(apple='x2', banana='y')\\\\\\\\\\\\\\] \"\"\" print(m.model\\\\\\\\\\\\\\_dump()) \"\"\" { 'foo': {'count': 4, 'size': None}, 'bars': \\\\\\\\\\\\\\[{'apple': 'x1', 'banana': 'y'}, {'apple': 'x2', 'banana': 'y'}\\\\\\\\\\\\\\], } \"\"\" For self-referencing models, see postponed annotations. Rebuild model schema¶ The model schema can be rebuilt using model\\\\\\\\\\\\\\_rebuild(). This is useful for building recursive generic models. from pydantic import BaseModel, PydanticUserError class Foo(BaseModel): x: 'Bar' try: Foo.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema() except PydanticUserError as e: print(e) \"\"\" \\\\\\\\\\\\\\`Foo\\\\\\\\\\\\\\` is not fully defined; you should define \\\\\\\\\\\\\\`Bar\\\\\\\\\\\\\\`, then call \\\\\\\\\\\\\\`Foo.model\\\\\\\\\\\\\\_rebuild()\\\\\\\\\\\\\\`. For further information visit https://errors.pydantic.dev/2/u/class-not-fully-defined \"\"\" class Bar(BaseModel): pass Foo.model\\\\\\\\\\\\\\_rebuild() print(Foo.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema()) \"\"\" { '$defs': {'Bar': {'properties': {}, 'title': 'Bar', 'type': 'object'}}, 'properties': {'x': {'$ref': '#/$defs/Bar'}}, 'required': \\\\\\\\\\\\\\['x'\\\\\\\\\\\\\\], 'title': 'Foo', 'type': 'object', } \"\"\" Pydantic tries to determine when this is necessary automatically and error if it wasn't done, but you may want to call model\\\\\\\\\\\\\\_rebuild() proactively when dealing with recursive models or generics. In V2, model\\\\\\\\\\\\\\_rebuild() replaced update\\\\\\\\\\\\\\_forward\\\\\\\\\\\\\\_refs() from V1. There are some slight differences with the new behavior. The biggest change is that when calling model\\\\\\\\\\\\\\_rebuild() on the outermost model, it builds a core schema used for validation of the whole model (nested models and all), so all types at all levels need to be ready before model\\\\\\\\\\\\\\_rebuild() is called. Arbitrary class instances¶ (Formerly known as \"ORM Mode\"/from\\\\\\\\\\\\\\_orm.) Pydantic models can also be created from arbitrary class instances by reading the instance attributes corresponding to the model field names. One common application of this functionality is integration with object-relational mappings (ORMs). To do this, set the config attribute model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['from\\\\\\\\\\\\\\_attributes'\\\\\\\\\\\\\\] = True. See Model Config and ConfigDict for more information. The example here uses SQLAlchemy, but the same approach should work for any ORM. from typing import List from sqlalchemy import Column, Integer, String from sqlalchemy.dialects.postgresql import ARRAY from sqlalchemy.orm import declarative\\\\\\\\\\\\\\_base from typing\\\\\\\\\\\\\\_extensions import Annotated from pydantic import BaseModel, ConfigDict, StringConstraints Base = declarative\\\\\\\\\\\\\\_base() class CompanyOrm(Base): \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_tablename\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ = 'companies' id = Column(Integer, primary\\\\\\\\\\\\\\_key=True, nullable=False) public\\\\\\\\\\\\\\_key = Column(String(20), index=True, nullable=False, unique=True) name = Column(String(63), unique=True) domains = Column(ARRAY(String(255))) class CompanyModel(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(from\\\\\\\\\\\\\\_attributes=True) id: int public\\\\\\\\\\\\\\_key: Annotated\\\\\\\\\\\\\\[str, StringConstraints(max\\\\\\\\\\\\\\_length=20)\\\\\\\\\\\\\\] name: Annotated\\\\\\\\\\\\\\[str, StringConstraints(max\\\\\\\\\\\\\\_length=63)\\\\\\\\\\\\\\] domains: List\\\\\\\\\\\\\\[Annotated\\\\\\\\\\\\\\[str, StringConstraints(max\\\\\\\\\\\\\\_length=255)\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] co\\\\\\\\\\\\\\_orm = CompanyOrm( id=123, public\\\\\\\\\\\\\\_key='foobar', name='Testing', domains=\\\\\\\\\\\\\\['example.com', 'foobar.com'\\\\\\\\\\\\\\], ) print(co\\\\\\\\\\\\\\_orm) #> <\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_main\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.CompanyOrm object at 0x0123456789ab> co\\\\\\\\\\\\\\_model = CompanyModel.model\\\\\\\\\\\\\\_validate(co\\\\\\\\\\\\\\_orm) print(co\\\\\\\\\\\\\\_model) \"\"\" id=123 public\\\\\\\\\\\\\\_key='foobar' name='Testing' domains=\\\\\\\\\\\\\\['example.com', 'foobar.com'\\\\\\\\\\\\\\] \"\"\" Reserved names¶ You may want to name a Column after a reserved SQLAlchemy field. In that case, Field aliases will be convenient: import typing import sqlalchemy as sa from sqlalchemy.orm import declarative\\\\\\\\\\\\\\_base from pydantic import BaseModel, ConfigDict, Field class MyModel(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(from\\\\\\\\\\\\\\_attributes=True) metadata: typing.Dict\\\\\\\\\\\\\\[str, str\\\\\\\\\\\\\\] = Field(alias='metadata\\\\\\\\\\\\\\_') Base = declarative\\\\\\\\\\\\\\_base() class SQLModel(Base): \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_tablename\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ = 'my\\\\\\\\\\\\\\_table' id = sa.Column('id', sa.Integer, primary\\\\\\\\\\\\\\_key=True) # 'metadata' is reserved by SQLAlchemy, hence the '\\\\\\\\\\\\\\_' metadata\\\\\\\\\\\\\\_ = sa.Column('metadata', sa.JSON) sql\\\\\\\\\\\\\\_model = SQLModel(metadata\\\\\\\\\\\\\\_={'key': 'val'}, id=1) pydantic\\\\\\\\\\\\\\_model = MyModel.model\\\\\\\\\\\\\\_validate(sql\\\\\\\\\\\\\\_model) print(pydantic\\\\\\\\\\\\\\_model.model\\\\\\\\\\\\\\_dump()) #> {'metadata': {'key': 'val'}} print(pydantic\\\\\\\\\\\\\\_model.model\\\\\\\\\\\\\\_dump(by\\\\\\\\\\\\\\_alias=True)) #> {'metadata\\\\\\\\\\\\\\_': {'key': 'val'}} Note The example above works because aliases have priority over field names for field population. Accessing SQLModel's metadata attribute would lead to a ValidationError. Nested attributes¶ When using attributes to parse models, model instances will be created from both top-level attributes and deeper-nested attributes as appropriate. Here is an example demonstrating the principle: from typing import List from pydantic import BaseModel, ConfigDict class PetCls: def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, \\\\\\\\\\\\\\*, name: str, species: str): self.name = name self.species = species class PersonCls: def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, \\\\\\\\\\\\\\*, name: str, age: float = None, pets: List\\\\\\\\\\\\\\[PetCls\\\\\\\\\\\\\\]): self.name = name self.age = age self.pets = pets class Pet(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(from\\\\\\\\\\\\\\_attributes=True) name: str species: str class Person(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(from\\\\\\\\\\\\\\_attributes=True) name: str age: float = None pets: List\\\\\\\\\\\\\\[Pet\\\\\\\\\\\\\\] bones = PetCls(name='Bones', species='dog') orion = PetCls(name='Orion', species='cat') anna = PersonCls(name='Anna', age=20, pets=\\\\\\\\\\\\\\[bones, orion\\\\\\\\\\\\\\]) anna\\\\\\\\\\\\\\_model = Person.model\\\\\\\\\\\\\\_validate(anna) print(anna\\\\\\\\\\\\\\_model) \"\"\" name='Anna' age=20.0 pets=\\\\\\\\\\\\\\[Pet(name='Bones', species='dog'), Pet(name='Orion', species='cat')\\\\\\\\\\\\\\] \"\"\" Error handling¶ Pydantic will raise ValidationError whenever it finds an error in the data it's validating. A single exception of type ValidationError will be raised regardless of the number of errors found, and that ValidationError will contain information about all of the errors and how they happened. See Error Handling for details on standard and custom errors. As a demonstration: from typing import List from pydantic import BaseModel, ValidationError class Model(BaseModel): list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] a\\\\\\\\\\\\\\_float: float data = dict( list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints=\\\\\\\\\\\\\\['1', 2, 'bad'\\\\\\\\\\\\\\], a\\\\\\\\\\\\\\_float='not a float', ) try: Model(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data) except ValidationError as e: print(e) \"\"\" 2 validation errors for Model list\\\\\\\\\\\\\\_of\\\\\\\\\\\\\\_ints.2 Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='bad', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] a\\\\\\\\\\\\\\_float Input should be a valid number, unable to parse string as a number \\\\\\\\\\\\\\[type=float\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='not a float', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Helper functions¶ Pydantic provides two classmethod helper functions on models for parsing data: model\\\\\\\\\\\\\\_validate(): this is very similar to the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method of the model, except it takes a dict or an object rather than keyword arguments. If the object passed cannot be validated, or if it's not a dictionary or instance of the model in question, a ValidationError will be raised. model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json(): this takes a str or bytes and parses it as json, then passes the result to model\\\\\\\\\\\\\\_validate(). from datetime import datetime from typing import Optional from pydantic import BaseModel, ValidationError class User(BaseModel): id: int name: str = 'John Doe' signup\\\\\\\\\\\\\\_ts: Optional\\\\\\\\\\\\\\[datetime\\\\\\\\\\\\\\] = None m = User.model\\\\\\\\\\\\\\_validate({'id': 123, 'name': 'James'}) print(m) #> id=123 name='James' signup\\\\\\\\\\\\\\_ts=None try: User.model\\\\\\\\\\\\\\_validate(\\\\\\\\\\\\\\['not', 'a', 'dict'\\\\\\\\\\\\\\]) except ValidationError as e: print(e) \"\"\" 1 validation error for User Input should be a valid dictionary or instance of User \\\\\\\\\\\\\\[type=model\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=\\\\\\\\\\\\\\['not', 'a', 'dict'\\\\\\\\\\\\\\], input\\\\\\\\\\\\\\_type=list\\\\\\\\\\\\\\] \"\"\" m = User.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json('{\"id\": 123, \"name\": \"James\"}') print(m) #> id=123 name='James' signup\\\\\\\\\\\\\\_ts=None try: m = User.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json('{\"id\": 123, \"name\": 123}') except ValidationError as e: print(e) \"\"\" 1 validation error for User name Input should be a valid string \\\\\\\\\\\\\\[type=string\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=123, input\\\\\\\\\\\\\\_type=int\\\\\\\\\\\\\\] \"\"\" try: m = User.model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json('invalid JSON') except ValidationError as e: print(e) \"\"\" 1 validation error for User Invalid JSON: expected value at line 1 column 1 \\\\\\\\\\\\\\[type=json\\\\\\\\\\\\\\_invalid, input\\\\\\\\\\\\\\_value='invalid JSON', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" If you want to validate serialized data in a format other than JSON, you should load the data into a dict yourself and then pass it to model\\\\\\\\\\\\\\_validate. Note Depending on the types and model configs involved, model\\\\\\\\\\\\\\_validate and model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json may have different validation behavior. If you have data coming from a non-JSON source, but want the same validation behavior and errors you'd get from model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json, our recommendation for now is to use model\\\\\\\\\\\\\\_validate\\\\\\\\\\\\\\_json(json.dumps(data)). Note Learn more about JSON parsing in the JSON section of the docs. Note If you're passing in an instance of a model to model\\\\\\\\\\\\\\_validate, you will want to consider setting revalidate\\\\\\\\\\\\\\_instances in the model's config. If you don't set this value, then validation will be skipped on model instances. See the below example: revalidate\\\\\\\\\\\\\\_instances='never' revalidate\\\\\\\\\\\\\\_instances='always' from pydantic import BaseModel class Model(BaseModel): a: int m = Model(a=0) # note: the \\\\\\\\\\\\\\`model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\` setting validate\\\\\\\\\\\\\\_assignment=True\\\\\\\\\\\\\\` can prevent this kind of misbehavior m.a = 'not an int' # doesn't raise a validation error even though m is invalid m2 = Model.model\\\\\\\\\\\\\\_validate(m) Creating models without validation¶ Pydantic also provides the model\\\\\\\\\\\\\\_construct() method, which allows models to be created without validation. This can be useful in at least a few cases: when working with complex data that is already known to be valid (for performance reasons) when one or more of the validator functions are non-idempotent, or when one or more of the validator functions have side effects that you don't want to be triggered. Note In Pydantic V2, the performance gap between BaseModel.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and BaseModel.model\\\\\\\\\\\\\\_construct has been narrowed considerably. For simple models, calling BaseModel.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ may even be faster. If you are using model\\\\\\\\\\\\\\_construct() for performance reasons, you may want to profile your use case before assuming that model\\\\\\\\\\\\\\_construct() is faster. Warning model\\\\\\\\\\\\\\_construct() does not do any validation, meaning it can create models which are invalid. You should only ever use the model\\\\\\\\\\\\\\_construct() method with data which has already been validated, or that you definitely trust. from pydantic import BaseModel class User(BaseModel): id: int age: int name: str = 'John Doe' original\\\\\\\\\\\\\\_user = User(id=123, age=32) user\\\\\\\\\\\\\\_data = original\\\\\\\\\\\\\\_user.model\\\\\\\\\\\\\\_dump() print(user\\\\\\\\\\\\\\_data) #> {'id': 123, 'age': 32, 'name': 'John Doe'} fields\\\\\\\\\\\\\\_set = original\\\\\\\\\\\\\\_user.model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set print(fields\\\\\\\\\\\\\\_set) #> {'age', 'id'} # ... # pass user\\\\\\\\\\\\\\_data and fields\\\\\\\\\\\\\\_set to RPC or save to the database etc. # ... # you can then create a new instance of User without # re-running validation which would be unnecessary at this point: new\\\\\\\\\\\\\\_user = User.model\\\\\\\\\\\\\\_construct(\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set=fields\\\\\\\\\\\\\\_set, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*user\\\\\\\\\\\\\\_data) print(repr(new\\\\\\\\\\\\\\_user)) #> User(id=123, age=32, name='John Doe') print(new\\\\\\\\\\\\\\_user.model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set) #> {'age', 'id'} # construct can be dangerous, only use it with validated data!: bad\\\\\\\\\\\\\\_user = User.model\\\\\\\\\\\\\\_construct(id='dog') print(repr(bad\\\\\\\\\\\\\\_user)) #> User(id='dog', name='John Doe') The \\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set keyword argument to model\\\\\\\\\\\\\\_construct() is optional, but allows you to be more precise about which fields were originally set and which weren't. If it's omitted model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set will just be the keys of the data provided. For example, in the example above, if \\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set was not provided, new\\\\\\\\\\\\\\_user.model\\\\\\\\\\\\\\_fields\\\\\\\\\\\\\\_set would be {'id', 'age', 'name'}. Note that for subclasses of RootModel, the root value can be passed to model\\\\\\\\\\\\\\_construct() positionally, instead of using a keyword argument. Here are some additional notes on the behavior of model\\\\\\\\\\\\\\_construct(): When we say \"no validation is performed\" — this includes converting dicts to model instances. So if you have a field with a Model type, you will need to convert the inner dict to a model yourself before passing it to model\\\\\\\\\\\\\\_construct(). In particular, the model\\\\\\\\\\\\\\_construct() method does not support recursively constructing models from dicts. If you do not pass keyword arguments for fields with defaults, the default values will still be used. For models with model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['extra'\\\\\\\\\\\\\\] == 'allow', data not corresponding to fields will be correctly stored in the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ dict. For models with private attributes, the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_private\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ dict will be initialized the same as it would be when calling \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_. When constructing an instance using model\\\\\\\\\\\\\\_construct(), no \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method from the model or any of its parent classes will be called, even when a custom \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ method is defined. Generic models¶ Pydantic supports the creation of generic models to make it easier to reuse a common model structure. In order to declare a generic model, you perform the following steps: Declare one or more typing.TypeVar instances to use to parameterize your model. Declare a pydantic model that inherits from pydantic.BaseModel and typing.Generic, where you pass the TypeVar instances as parameters to typing.Generic. Use the TypeVar instances as annotations where you will want to replace them with other types or pydantic models. Here is an example using a generic BaseModel subclass to create an easily-reused HTTP response payload wrapper: from typing import Generic, List, Optional, TypeVar from pydantic import BaseModel, ValidationError DataT = TypeVar('DataT') class DataModel(BaseModel): numbers: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] people: List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] class Response(BaseModel, Generic\\\\\\\\\\\\\\[DataT\\\\\\\\\\\\\\]): data: Optional\\\\\\\\\\\\\\[DataT\\\\\\\\\\\\\\] = None data = DataModel(numbers=\\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\], people=\\\\\\\\\\\\\\[\\\\\\\\\\\\\\]) print(Response\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\](data=1)) #> data=1 print(Response\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\](data='value')) #> data='value' print(Response\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\](data='value').model\\\\\\\\\\\\\\_dump()) #> {'data': 'value'} print(Response\\\\\\\\\\\\\\[DataModel\\\\\\\\\\\\\\](data=data).model\\\\\\\\\\\\\\_dump()) #> {'data': {'numbers': \\\\\\\\\\\\\\[1, 2, 3\\\\\\\\\\\\\\], 'people': \\\\\\\\\\\\\\[\\\\\\\\\\\\\\]}} try: Response\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\](data='value') except ValidationError as e: print(e) \"\"\" 1 validation error for Response\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] data Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='value', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" If you set the model\\\\\\\\\\\\\\_config or make use of @field\\\\\\\\\\\\\\_validator or other Pydantic decorators in your generic model definition, they will be applied to parametrized subclasses in the same way as when inheriting from a BaseModel subclass. Any methods defined on your generic class will also be inherited. Pydantic's generics also integrate properly with type checkers, so you get all the type checking you would expect if you were to declare a distinct type for each parametrization. Note Internally, Pydantic creates subclasses of BaseModel at runtime when generic models are parametrized. These classes are cached, so there should be minimal overhead introduced by the use of generics models. To inherit from a generic model and preserve the fact that it is generic, the subclass must also inherit from typing.Generic: from typing import Generic, TypeVar from pydantic import BaseModel TypeX = TypeVar('TypeX') class BaseClass(BaseModel, Generic\\\\\\\\\\\\\\[TypeX\\\\\\\\\\\\\\]): X: TypeX class ChildClass(BaseClass\\\\\\\\\\\\\\[TypeX\\\\\\\\\\\\\\], Generic\\\\\\\\\\\\\\[TypeX\\\\\\\\\\\\\\]): # Inherit from Generic\\\\\\\\\\\\\\[TypeX\\\\\\\\\\\\\\] pass # Replace TypeX by int print(ChildClass\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\](X=1)) #> X=1 You can also create a generic subclass of a BaseModel that partially or fully replaces the type parameters in the superclass: from typing import Generic, TypeVar from pydantic import BaseModel TypeX = TypeVar('TypeX') TypeY = TypeVar('TypeY') TypeZ = TypeVar('TypeZ') class BaseClass(BaseModel, Generic\\\\\\\\\\\\\\[TypeX, TypeY\\\\\\\\\\\\\\]): x: TypeX y: TypeY class ChildClass(BaseClass\\\\\\\\\\\\\\[int, TypeY\\\\\\\\\\\\\\], Generic\\\\\\\\\\\\\\[TypeY, TypeZ\\\\\\\\\\\\\\]): z: TypeZ # Replace TypeY by str print(ChildClass\\\\\\\\\\\\\\[str, int\\\\\\\\\\\\\\](x='1', y='y', z='3')) #> x=1 y='y' z=3 If the name of the concrete subclasses is important, you can also override the default name generation: from typing import Any, Generic, Tuple, Type, TypeVar from pydantic import BaseModel DataT = TypeVar('DataT') class Response(BaseModel, Generic\\\\\\\\\\\\\\[DataT\\\\\\\\\\\\\\]): data: DataT @classmethod def model\\\\\\\\\\\\\\_parametrized\\\\\\\\\\\\\\_name(cls, params: Tuple\\\\\\\\\\\\\\[Type\\\\\\\\\\\\\\[Any\\\\\\\\\\\\\\], ...\\\\\\\\\\\\\\]) -> str: return f'{params\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\].\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_.title()}Response' print(repr(Response\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\](data=1))) #> IntResponse(data=1) print(repr(Response\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\](data='a'))) #> StrResponse(data='a') Using the same TypeVar in nested models allows you to enforce typing relationships at different points in your model: from typing import Generic, TypeVar from pydantic import BaseModel, ValidationError T = TypeVar('T') class InnerT(BaseModel, Generic\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\]): inner: T class OuterT(BaseModel, Generic\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\]): outer: T nested: InnerT\\\\\\\\\\\\\\[T\\\\\\\\\\\\\\] nested = InnerT\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\](inner=1) print(OuterT\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\](outer=1, nested=nested)) #> outer=1 nested=InnerT\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\](inner=1) try: nested = InnerT\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\](inner='a') print(OuterT\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\](outer='a', nested=nested)) except ValidationError as e: print(e) \"\"\" 2 validation errors for OuterT\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] outer Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='a', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] nested Input should be a valid dictionary or instance of InnerT\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] \\\\\\\\\\\\\\[type=model\\\\\\\\\\\\\\_type, input\\\\\\\\\\\\\\_value=InnerT\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\](inner='a'), input\\\\\\\\\\\\\\_type=InnerT\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] \"\"\" When using bound type parameters, and when leaving type parameters unspecified, Pydantic treats generic models similarly to how it treats built-in generic types like List and Dict: If you don't specify parameters before instantiating the generic model, they are validated as the bound of the TypeVar. If the TypeVars involved have no bounds, they are treated as Any. Also, like List and Dict, any parameters specified using a TypeVar can later be substituted with concrete types: from typing import Generic, TypeVar from pydantic import BaseModel, ValidationError AT = TypeVar('AT') BT = TypeVar('BT') class Model(BaseModel, Generic\\\\\\\\\\\\\\[AT, BT\\\\\\\\\\\\\\]): a: AT b: BT print(Model(a='a', b='a')) #> a='a' b='a' IntT = TypeVar('IntT', bound=int) typevar\\\\\\\\\\\\\\_model = Model\\\\\\\\\\\\\\[int, IntT\\\\\\\\\\\\\\] print(typevar\\\\\\\\\\\\\\_model(a=1, b=1)) #> a=1 b=1 try: typevar\\\\\\\\\\\\\\_model(a='a', b='a') except ValidationError as exc: print(exc) \"\"\" 2 validation errors for Model\\\\\\\\\\\\\\[int, TypeVar\\\\\\\\\\\\\\] a Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='a', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] b Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='a', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" concrete\\\\\\\\\\\\\\_model = typevar\\\\\\\\\\\\\\_model\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] print(concrete\\\\\\\\\\\\\\_model(a=1, b=1)) #> a=1 b=1 Warning While it may not raise an error, we strongly advise against using parametrized generics in isinstance checks. For example, you should not do isinstance(my\\\\\\\\\\\\\\_model, MyGenericModel\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]). However, it is fine to do isinstance(my\\\\\\\\\\\\\\_model, MyGenericModel). (Note that, for standard generics, it would raise an error to do a subclass check with a parameterized generic.) If you need to perform isinstance checks against parametrized generics, you can do this by subclassing the parametrized generic class. This looks like class MyIntModel(MyGenericModel\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\]): ... and isinstance(my\\\\\\\\\\\\\\_model, MyIntModel). If a Pydantic model is used in a TypeVar bound and the generic type is never parametrized then Pydantic will use the bound for validation but treat the value as Any in terms of serialization: from typing import Generic, Optional, TypeVar from pydantic import BaseModel class ErrorDetails(BaseModel): foo: str ErrorDataT = TypeVar('ErrorDataT', bound=ErrorDetails) class Error(BaseModel, Generic\\\\\\\\\\\\\\[ErrorDataT\\\\\\\\\\\\\\]): message: str details: Optional\\\\\\\\\\\\\\[ErrorDataT\\\\\\\\\\\\\\] class MyErrorDetails(ErrorDetails): bar: str # serialized as Any error = Error( message='We just had an error', details=MyErrorDetails(foo='var', bar='var2'), ) assert error.model\\\\\\\\\\\\\\_dump() == { 'message': 'We just had an error', 'details': { 'foo': 'var', 'bar': 'var2', }, } # serialized using the concrete parametrization # note that \\\\\\\\\\\\\\`'bar': 'var2'\\\\\\\\\\\\\\` is missing error = Error\\\\\\\\\\\\\\[ErrorDetails\\\\\\\\\\\\\\]( message='We just had an error', details=ErrorDetails(foo='var'), ) assert error.model\\\\\\\\\\\\\\_dump() == { 'message': 'We just had an error', 'details': { 'foo': 'var', }, } Here's another example of the above behavior, enumerating all permutations regarding bound specification and generic type parametrization: from typing import Generic from typing\\\\\\\\\\\\\\_extensions import TypeVar from pydantic import BaseModel TBound = TypeVar('TBound', bound=BaseModel) TNoBound = TypeVar('TNoBound') class IntValue(BaseModel): value: int class ItemBound(BaseModel, Generic\\\\\\\\\\\\\\[TBound\\\\\\\\\\\\\\]): item: TBound class ItemNoBound(BaseModel, Generic\\\\\\\\\\\\\\[TNoBound\\\\\\\\\\\\\\]): item: TNoBound item\\\\\\\\\\\\\\_bound\\\\\\\\\\\\\\_inferred = ItemBound(item=IntValue(value=3)) item\\\\\\\\\\\\\\_bound\\\\\\\\\\\\\\_explicit = ItemBound\\\\\\\\\\\\\\[IntValue\\\\\\\\\\\\\\](item=IntValue(value=3)) item\\\\\\\\\\\\\\_no\\\\\\\\\\\\\\_bound\\\\\\\\\\\\\\_inferred = ItemNoBound(item=IntValue(value=3)) item\\\\\\\\\\\\\\_no\\\\\\\\\\\\\\_bound\\\\\\\\\\\\\\_explicit = ItemNoBound\\\\\\\\\\\\\\[IntValue\\\\\\\\\\\\\\](item=IntValue(value=3)) # calling \\\\\\\\\\\\\\`print(x.model\\\\\\\\\\\\\\_dump())\\\\\\\\\\\\\\` on any of the above instances results in the following: #> {'item': {'value': 3}} If you use a default=... (available in Python >= 3.13 or via typing-extensions) or constraints (TypeVar('T', str, int); note that you rarely want to use this form of a TypeVar) then the default value or constraints will be used for both validation and serialization if the type variable is not parametrized. You can override this behavior using pydantic.SerializeAsAny: from typing import Generic, Optional from typing\\\\\\\\\\\\\\_extensions import TypeVar from pydantic import BaseModel, SerializeAsAny class ErrorDetails(BaseModel): foo: str ErrorDataT = TypeVar('ErrorDataT', default=ErrorDetails) class Error(BaseModel, Generic\\\\\\\\\\\\\\[ErrorDataT\\\\\\\\\\\\\\]): message: str details: Optional\\\\\\\\\\\\\\[ErrorDataT\\\\\\\\\\\\\\] class MyErrorDetails(ErrorDetails): bar: str # serialized using the default's serializer error = Error( message='We just had an error', details=MyErrorDetails(foo='var', bar='var2'), ) assert error.model\\\\\\\\\\\\\\_dump() == { 'message': 'We just had an error', 'details': { 'foo': 'var', }, } class SerializeAsAnyError(BaseModel, Generic\\\\\\\\\\\\\\[ErrorDataT\\\\\\\\\\\\\\]): message: str details: Optional\\\\\\\\\\\\\\[SerializeAsAny\\\\\\\\\\\\\\[ErrorDataT\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] # serialized as Any error = SerializeAsAnyError( message='We just had an error', details=MyErrorDetails(foo='var', bar='baz'), ) assert error.model\\\\\\\\\\\\\\_dump() == { 'message': 'We just had an error', 'details': { 'foo': 'var', 'bar': 'baz', }, } Note Note, you may run into a bit of trouble if you don't parametrize a generic when the case of validating against the generic's bound could cause data loss. See the example below: from typing import Generic from typing\\\\\\\\\\\\\\_extensions import TypeVar from pydantic import BaseModel TItem = TypeVar('TItem', bound='ItemBase') class ItemBase(BaseModel): ... class IntItem(ItemBase): value: int class ItemHolder(BaseModel, Generic\\\\\\\\\\\\\\[TItem\\\\\\\\\\\\\\]): item: TItem loaded\\\\\\\\\\\\\\_data = {'item': {'value': 1}} print(ItemHolder(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*loaded\\\\\\\\\\\\\\_data).model\\\\\\\\\\\\\\_dump()) When the generic isn't parametrized, the input data is validated against the generic bound. Given that ItemBase has no fields, the item field information is lost. #> {'item': {}} print(ItemHolder\\\\\\\\\\\\\\[IntItem\\\\\\\\\\\\\\](\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*loaded\\\\\\\\\\\\\\_data).model\\\\\\\\\\\\\\_dump()) In this case, the runtime type information is provided explicitly via the generic parametrization, so the input data is validated against the IntItem class and the serialization output matches what's expected. #> {'item': {'value': 1}} Dynamic model creation¶ There are some occasions where it is desirable to create a model using runtime information to specify the fields. For this Pydantic provides the create\\\\\\\\\\\\\\_model function to allow models to be created on the fly: from pydantic import BaseModel, create\\\\\\\\\\\\\\_model DynamicFoobarModel = create\\\\\\\\\\\\\\_model( 'DynamicFoobarModel', foo=(str, ...), bar=(int, 123) ) class StaticFoobarModel(BaseModel): foo: str bar: int = 123 Here StaticFoobarModel and DynamicFoobarModel are identical. Fields are defined by a tuple of the form (, ). The special keyword arguments \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_base\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ can be used to customise the new model. This includes extending a base model with extra fields. from pydantic import BaseModel, create\\\\\\\\\\\\\\_model class FooModel(BaseModel): foo: str bar: int = 123 BarModel = create\\\\\\\\\\\\\\_model( 'BarModel', apple=(str, 'russet'), banana=(str, 'yellow'), \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_base\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_=FooModel, ) print(BarModel) #> print(BarModel.model\\\\\\\\\\\\\\_fields.keys()) #> dict\\\\\\\\\\\\\\_keys(\\\\\\\\\\\\\\['foo', 'bar', 'apple', 'banana'\\\\\\\\\\\\\\]) You can also add validators by passing a dict to the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ argument. from pydantic import ValidationError, create\\\\\\\\\\\\\\_model, field\\\\\\\\\\\\\\_validator def username\\\\\\\\\\\\\\_alphanumeric(cls, v): assert v.isalnum(), 'must be alphanumeric' return v validators = { 'username\\\\\\\\\\\\\\_validator': field\\\\\\\\\\\\\\_validator('username')(username\\\\\\\\\\\\\\_alphanumeric) } UserModel = create\\\\\\\\\\\\\\_model( 'UserModel', username=(str, ...), \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_validators\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_=validators ) user = UserModel(username='scolvin') print(user) #> username='scolvin' try: UserModel(username='scolvi%n') except ValidationError as e: print(e) \"\"\" 1 validation error for UserModel username Assertion failed, must be alphanumeric \\\\\\\\\\\\\\[type=assertion\\\\\\\\\\\\\\_error, input\\\\\\\\\\\\\\_value='scolvi%n', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" Note To pickle a dynamically created model: the model must be defined globally it must provide \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_module\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ RootModel and custom root types¶ API Documentation Pydantic models can be defined with a \"custom root type\" by subclassing pydantic.RootModel. The root type can be any type supported by Pydantic, and is specified by the generic parameter to RootModel. The root value can be passed to the model \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ or model\\\\\\\\\\\\\\_validate via the first and only argument. Here's an example of how this works: from typing import Dict, List from pydantic import RootModel Pets = RootModel\\\\\\\\\\\\\\[List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] PetsByName = RootModel\\\\\\\\\\\\\\[Dict\\\\\\\\\\\\\\[str, str\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] print(Pets(\\\\\\\\\\\\\\['dog', 'cat'\\\\\\\\\\\\\\])) #> root=\\\\\\\\\\\\\\['dog', 'cat'\\\\\\\\\\\\\\] print(Pets(\\\\\\\\\\\\\\['dog', 'cat'\\\\\\\\\\\\\\]).model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json()) #> \\\\\\\\\\\\\\[\"dog\",\"cat\"\\\\\\\\\\\\\\] print(Pets.model\\\\\\\\\\\\\\_validate(\\\\\\\\\\\\\\['dog', 'cat'\\\\\\\\\\\\\\])) #> root=\\\\\\\\\\\\\\['dog', 'cat'\\\\\\\\\\\\\\] print(Pets.model\\\\\\\\\\\\\\_json\\\\\\\\\\\\\\_schema()) \"\"\" {'items': {'type': 'string'}, 'title': 'RootModel\\\\\\\\\\\\\\[List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]', 'type': 'array'} \"\"\" print(PetsByName({'Otis': 'dog', 'Milo': 'cat'})) #> root={'Otis': 'dog', 'Milo': 'cat'} print(PetsByName({'Otis': 'dog', 'Milo': 'cat'}).model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json()) #> {\"Otis\":\"dog\",\"Milo\":\"cat\"} print(PetsByName.model\\\\\\\\\\\\\\_validate({'Otis': 'dog', 'Milo': 'cat'})) #> root={'Otis': 'dog', 'Milo': 'cat'} If you want to access items in the root field directly or to iterate over the items, you can implement custom \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_iter\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ and \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_getitem\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ functions, as shown in the following example. from typing import List from pydantic import RootModel class Pets(RootModel): root: List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_iter\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self): return iter(self.root) def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_getitem\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, item): return self.root\\\\\\\\\\\\\\[item\\\\\\\\\\\\\\] pets = Pets.model\\\\\\\\\\\\\\_validate(\\\\\\\\\\\\\\['dog', 'cat'\\\\\\\\\\\\\\]) print(pets\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]) #> dog print(\\\\\\\\\\\\\\[pet for pet in pets\\\\\\\\\\\\\\]) #> \\\\\\\\\\\\\\['dog', 'cat'\\\\\\\\\\\\\\] You can also create subclasses of the parametrized root model directly: from typing import List from pydantic import RootModel class Pets(RootModel\\\\\\\\\\\\\\[List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\]\\\\\\\\\\\\\\]): root: List\\\\\\\\\\\\\\[str\\\\\\\\\\\\\\] def describe(self) -> str: return f'Pets: {\", \".join(self.root)}' my\\\\\\\\\\\\\\_pets = Pets.model\\\\\\\\\\\\\\_validate(\\\\\\\\\\\\\\['dog', 'cat'\\\\\\\\\\\\\\]) print(my\\\\\\\\\\\\\\_pets.describe()) #> Pets: dog, cat Faux immutability¶ Models can be configured to be immutable via model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['frozen'\\\\\\\\\\\\\\] = True. When this is set, attempting to change the values of instance attributes will raise errors. See the API reference for more details. Note This behavior was achieved in Pydantic V1 via the config setting allow\\\\\\\\\\\\\\_mutation = False. This config flag is deprecated in Pydantic V2, and has been replaced with frozen. Warning Immutability in Python is never strict. If developers are determined/stupid they can always modify a so-called \"immutable\" object. from pydantic import BaseModel, ConfigDict, ValidationError class FooBarModel(BaseModel): model\\\\\\\\\\\\\\_config = ConfigDict(frozen=True) a: str b: dict foobar = FooBarModel(a='hello', b={'apple': 'pear'}) try: foobar.a = 'different' except ValidationError as e: print(e) \"\"\" 1 validation error for FooBarModel a Instance is frozen \\\\\\\\\\\\\\[type=frozen\\\\\\\\\\\\\\_instance, input\\\\\\\\\\\\\\_value='different', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" print(foobar.a) #> hello print(foobar.b) #> {'apple': 'pear'} foobar.b\\\\\\\\\\\\\\['apple'\\\\\\\\\\\\\\] = 'grape' print(foobar.b) #> {'apple': 'grape'} Trying to change a caused an error, and a remains unchanged. However, the dict b is mutable, and the immutability of foobar doesn't stop b from being changed. Abstract base classes¶ Pydantic models can be used alongside Python's Abstract Base Classes (ABCs). import abc from pydantic import BaseModel class FooBarModel(BaseModel, abc.ABC): a: str b: int @abc.abstractmethod def my\\\\\\\\\\\\\\_abstract\\\\\\\\\\\\\\_method(self): pass Field ordering¶ Field order affects models in the following ways: field order is preserved in the model schema field order is preserved in validation errors field order is preserved by .model\\\\\\\\\\\\\\_dump() and .model\\\\\\\\\\\\\\_dump\\\\\\\\\\\\\\_json() etc. from pydantic import BaseModel, ValidationError class Model(BaseModel): a: int b: int = 2 c: int = 1 d: int = 0 e: float print(Model.model\\\\\\\\\\\\\\_fields.keys()) #> dict\\\\\\\\\\\\\\_keys(\\\\\\\\\\\\\\['a', 'b', 'c', 'd', 'e'\\\\\\\\\\\\\\]) m = Model(e=2, a=1) print(m.model\\\\\\\\\\\\\\_dump()) #> {'a': 1, 'b': 2, 'c': 1, 'd': 0, 'e': 2.0} try: Model(a='x', b='x', c='x', d='x', e='x') except ValidationError as err: error\\\\\\\\\\\\\\_locations = \\\\\\\\\\\\\\[e\\\\\\\\\\\\\\['loc'\\\\\\\\\\\\\\] for e in err.errors()\\\\\\\\\\\\\\] print(error\\\\\\\\\\\\\\_locations) #> \\\\\\\\\\\\\\[('a',), ('b',), ('c',), ('d',), ('e',)\\\\\\\\\\\\\\] Required fields¶ To declare a field as required, you may declare it using just an annotation, or you may use Ellipsis/... as the value: from pydantic import BaseModel, Field class Model(BaseModel): a: int b: int = ... c: int = Field(...) Where Field refers to the field function. Here a, b and c are all required. However, this use of b: int = ... does not work properly with mypy, and as of v1.0 should be avoided in most cases. Note In Pydantic V1, fields annotated with Optional or Any would be given an implicit default of None even if no default was explicitly specified. This behavior has changed in Pydantic V2, and there are no longer any type annotations that will result in a field having an implicit default value. Fields with non-hashable default values¶ A common source of bugs in python is to use a mutable object as a default value for a function or method argument, as the same instance ends up being reused in each call. The dataclasses module actually raises an error in this case, indicating that you should use the default\\\\\\\\\\\\\\_factory argument to dataclasses.field. Pydantic also supports the use of a default\\\\\\\\\\\\\\_factory for non-hashable default values, but it is not required. In the event that the default value is not hashable, Pydantic will deepcopy the default value when creating each instance of the model: from typing import Dict, List from pydantic import BaseModel class Model(BaseModel): item\\\\\\\\\\\\\\_counts: List\\\\\\\\\\\\\\[Dict\\\\\\\\\\\\\\[str, int\\\\\\\\\\\\\\]\\\\\\\\\\\\\\] = \\\\\\\\\\\\\\[{}\\\\\\\\\\\\\\] m1 = Model() m1.item\\\\\\\\\\\\\\_counts\\\\\\\\\\\\\\[0\\\\\\\\\\\\\\]\\\\\\\\\\\\\\['a'\\\\\\\\\\\\\\] = 1 print(m1.item\\\\\\\\\\\\\\_counts) #> \\\\\\\\\\\\\\[{'a': 1}\\\\\\\\\\\\\\] m2 = Model() print(m2.item\\\\\\\\\\\\\\_counts) #> \\\\\\\\\\\\\\[{}\\\\\\\\\\\\\\] Fields with dynamic default values¶ When declaring a field with a default value, you may want it to be dynamic (i.e. different for each model). To do this, you may want to use a default\\\\\\\\\\\\\\_factory. Here is an example: from datetime import datetime, timezone from uuid import UUID, uuid4 from pydantic import BaseModel, Field def datetime\\\\\\\\\\\\\\_now() -> datetime: return datetime.now(timezone.utc) class Model(BaseModel): uid: UUID = Field(default\\\\\\\\\\\\\\_factory=uuid4) updated: datetime = Field(default\\\\\\\\\\\\\\_factory=datetime\\\\\\\\\\\\\\_now) m1 = Model() m2 = Model() assert m1.uid != m2.uid You can find more information in the documentation of the Field function. Automatically excluded attributes¶ Class vars¶ Attributes annotated with typing.ClassVar are properly treated by Pydantic as class variables, and will not become fields on model instances: from typing import ClassVar from pydantic import BaseModel class Model(BaseModel): x: int = 2 y: ClassVar\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] = 1 m = Model() print(m) #> x=2 print(Model.y) #> 1 Private model attributes¶ Attributes whose name has a leading underscore are not treated as fields by Pydantic, and are not included in the model schema. Instead, these are converted into a \"private attribute\" which is not validated or even set during calls to \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_, model\\\\\\\\\\\\\\_validate, etc. Note As of Pydantic v2.1.0, you will receive a NameError if trying to use the Field function with a private attribute. Because private attributes are not treated as fields, the Field() function cannot be applied. Here is an example of usage: from datetime import datetime from random import randint from pydantic import BaseModel, PrivateAttr class TimeAwareModel(BaseModel): \\\\\\\\\\\\\\_processed\\\\\\\\\\\\\\_at: datetime = PrivateAttr(default\\\\\\\\\\\\\\_factory=datetime.now) \\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_value: str def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data): super().\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data) # this could also be done with default\\\\\\\\\\\\\\_factory self.\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_value = randint(1, 5) m = TimeAwareModel() print(m.\\\\\\\\\\\\\\_processed\\\\\\\\\\\\\\_at) #> 2032-01-02 03:04:05.000006 print(m.\\\\\\\\\\\\\\_secret\\\\\\\\\\\\\\_value) #> 3 Private attribute names must start with underscore to prevent conflicts with model fields. However, dunder names (such as \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_attr\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_) are not supported. Data conversion¶ Pydantic may cast input data to force it to conform to model field types, and in some cases this may result in a loss of information. For example: from pydantic import BaseModel class Model(BaseModel): a: int b: float c: str print(Model(a=3.000, b='2.72', c=b'binary data').model\\\\\\\\\\\\\\_dump()) #> {'a': 3, 'b': 2.72, 'c': 'binary data'} This is a deliberate decision of Pydantic, and is frequently the most useful approach. See here for a longer discussion on the subject. Nevertheless, strict type checking is also supported. Model signature¶ All Pydantic models will have their signature generated based on their fields: import inspect from pydantic import BaseModel, Field class FooModel(BaseModel): id: int name: str = None description: str = 'Foo' apple: int = Field(alias='pear') print(inspect.signature(FooModel)) #> (\\\\\\\\\\\\\\*, id: int, name: str = None, description: str = 'Foo', pear: int) -> None An accurate signature is useful for introspection purposes and libraries like FastAPI or hypothesis. The generated signature will also respect custom \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ functions: import inspect from pydantic import BaseModel class MyModel(BaseModel): id: int info: str = 'Foo' def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, id: int = 1, \\\\\\\\\\\\\\*, bar: str, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data) -> None: \"\"\"My custom init!\"\"\" super().\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(id=id, bar=bar, \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data) print(inspect.signature(MyModel)) #> (id: int = 1, \\\\\\\\\\\\\\*, bar: str, info: str = 'Foo') -> None To be included in the signature, a field's alias or name must be a valid Python identifier. Pydantic will prioritize a field's alias over its name when generating the signature, but may use the field name if the alias is not a valid Python identifier. If a field's alias and name are both not valid identifiers (which may be possible through exotic use of create\\\\\\\\\\\\\\_model), a \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data argument will be added. In addition, the \\\\\\\\\\\\\\*\\\\\\\\\\\\\\*data argument will always be present in the signature if model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['extra'\\\\\\\\\\\\\\] == 'allow'. Structural pattern matching¶ Pydantic supports structural pattern matching for models, as introduced by PEP 636 in Python 3.10. from pydantic import BaseModel class Pet(BaseModel): name: str species: str a = Pet(name='Bones', species='dog') match a: # match \\\\\\\\\\\\\\`species\\\\\\\\\\\\\\` to 'dog', declare and initialize \\\\\\\\\\\\\\`dog\\\\\\\\\\\\\\_name\\\\\\\\\\\\\\` case Pet(species='dog', name=dog\\\\\\\\\\\\\\_name): print(f'{dog\\\\\\\\\\\\\\_name} is a dog') #> Bones is a dog # default case case \\\\\\\\\\\\\\_: print('No dog matched') Note A match-case statement may seem as if it creates a new model, but don't be fooled; it is just syntactic sugar for getting an attribute and either comparing it or declaring and initializing it. Attribute copies¶ In many cases, arguments passed to the constructor will be copied in order to perform validation and, where necessary, coercion. In this example, note that the ID of the list changes after the class is constructed because it has been copied during validation: from typing import List from pydantic import BaseModel class C1: arr = \\\\\\\\\\\\\\[\\\\\\\\\\\\\\] def \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_init\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_(self, in\\\\\\\\\\\\\\_arr): self.arr = in\\\\\\\\\\\\\\_arr class C2(BaseModel): arr: List\\\\\\\\\\\\\\[int\\\\\\\\\\\\\\] arr\\\\\\\\\\\\\\_orig = \\\\\\\\\\\\\\[1, 9, 10, 3\\\\\\\\\\\\\\] c1 = C1(arr\\\\\\\\\\\\\\_orig) c2 = C2(arr=arr\\\\\\\\\\\\\\_orig) print('id(c1.arr) == id(c2.arr):', id(c1.arr) == id(c2.arr)) #> id(c1.arr) == id(c2.arr): False Note There are some situations where Pydantic does not copy attributes, such as when passing models — we use the model as is. You can override this behaviour by setting model\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\['revalidate\\\\\\\\\\\\\\_instances'\\\\\\\\\\\\\\] = 'always'. Extra fields¶ By default, Pydantic models won't error when you provide data for unrecognized fields, they will just be ignored: from pydantic import BaseModel class Model(BaseModel): x: int m = Model(x=1, y='a') assert m.model\\\\\\\\\\\\\\_dump() == {'x': 1} If you want this to raise an error, you can achieve this via model\\\\\\\\\\\\\\_config: from pydantic import BaseModel, ConfigDict, ValidationError class Model(BaseModel): x: int model\\\\\\\\\\\\\\_config = ConfigDict(extra='forbid') try: Model(x=1, y='a') except ValidationError as exc: print(exc) \"\"\" 1 validation error for Model y Extra inputs are not permitted \\\\\\\\\\\\\\[type=extra\\\\\\\\\\\\\\_forbidden, input\\\\\\\\\\\\\\_value='a', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" To instead preserve any extra data provided, you can set extra='allow'. The extra fields will then be stored in BaseModel.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_: from pydantic import BaseModel, ConfigDict class Model(BaseModel): x: int model\\\\\\\\\\\\\\_config = ConfigDict(extra='allow') m = Model(x=1, y='a') assert m.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ == {'y': 'a'} By default, no validation will be applied to these extra items, but you can set a type for the values by overriding the type annotation for \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_: from typing import Dict from pydantic import BaseModel, ConfigDict, ValidationError class Model(BaseModel): \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_: Dict\\\\\\\\\\\\\\[str, int\\\\\\\\\\\\\\] x: int model\\\\\\\\\\\\\\_config = ConfigDict(extra='allow') try: Model(x=1, y='a') except ValidationError as exc: print(exc) \"\"\" 1 validation error for Model y Input should be a valid integer, unable to parse string as an integer \\\\\\\\\\\\\\[type=int\\\\\\\\\\\\\\_parsing, input\\\\\\\\\\\\\\_value='a', input\\\\\\\\\\\\\\_type=str\\\\\\\\\\\\\\] \"\"\" m = Model(x=1, y='2') assert m.x == 1 assert m.y == 2 assert m.model\\\\\\\\\\\\\\_dump() == {'x': 1, 'y': 2} assert m.\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_extra\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ == {'y': 2} The same configurations apply to TypedDict and dataclass' except the config is controlled by setting the \\\\\\\\\\\\\\_\\\\\\\\\\\\\\_pydantic\\\\\\\\\\\\\\_config\\\\\\\\\\\\\\_\\\\\\\\\\\\\\_ attribute of the class to a valid ConfigDict. Made with Material for MkDocs Insiders"
  },
  {
    "title": "Welcome to Pydantic - Pydantic",
    "url": "https://docs.pydantic.dev/latest/",
    "html": "Skip to content Pydantic V2 is here 🚀! Upgrading an existing app? See the Migration Guide for tips on essential changes from Pydantic V1! Pydantic 2.5 dev 2.5 2.4 2.3 2.2 2.1 2.0 1.10 Welcome to Pydantic Type to start searching pydantic/pydantic v2.5.3 17k 1.6k Get Started Concepts API Documentation Examples Error Messages Integrations Blog Get Started Welcome to Pydantic Why use Pydantic Help with Pydantic Installation Migration Guide Version Policy Contributing Changelog Page contents Why use Pydantic? Pydantic examples Who is using Pydantic? Pydantic¶ Documentation for version: v2.5.2. Pydantic is the most widely used data validation library for Python. Fast and extensible, Pydantic plays nicely with your linters/IDE/brain. Define how data should be in pure, canonical Python 3.7+; validate it with Pydantic. Migrating to Pydantic V2 Using Pydantic V1? See the Migration Guide for notes on upgrading to Pydantic V2 in your applications! Pydantic Example from datetime import datetime from typing import Tuple from pydantic import BaseModel class Delivery(BaseModel): timestamp: datetime dimensions: Tuple\\\\\\\\\\\\\\[int, int\\\\\\\\\\\\\\] m = Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=\\\\\\\\\\\\\\['10', '20'\\\\\\\\\\\\\\]) print(repr(m.timestamp)) #> datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC)) print(m.dimensions) #> (10, 20) Why use Pydantic?¶ Powered by type hints — with Pydantic, schema validation and serialization are controlled by type annotations; less to learn, less code to write, and integration with your IDE and static analysis tools. Learn more… Speed — Pydantic's core validation logic is written in Rust. As a result, Pydantic is among the fastest data validation libraries for Python. Learn more… JSON Schema — Pydantic models can emit JSON Schema, allowing for easy integration with other tools. Learn more… Strict and Lax mode — Pydantic can run in either strict=True mode (where data is not converted) or strict=False mode where Pydantic tries to coerce data to the correct type where appropriate. Learn more… Dataclasses, TypedDicts and more — Pydantic supports validation of many standard library types including dataclass and TypedDict. Learn more… Customisation — Pydantic allows custom validators and serializers to alter how data is processed in many powerful ways. Learn more… Ecosystem — around 8,000 packages on PyPI use Pydantic, including massively popular libraries like FastAPI, huggingface, Django Ninja, SQLModel, & LangChain. Learn more… Battle tested — Pydantic is downloaded over 70M times/month and is used by all FAANG companies and 20 of the 25 largest companies on NASDAQ. If you're trying to do something with Pydantic, someone else has probably already done it. Learn more… Installing Pydantic is as simple as: pip install pydantic Pydantic examples¶ To see Pydantic at work, let's start with a simple example, creating a custom class that inherits from BaseModel: Validation Successful from datetime import datetime from pydantic import BaseModel, PositiveInt class User(BaseModel): id: int name: str = 'John Doe' signup\\\\\\\\\\\\\\_ts: datetime | None tastes: dict\\\\\\\\\\\\\\[str, PositiveInt\\\\\\\\\\\\\\] external\\\\\\\\\\\\\\_data = { 'id': 123, 'signup\\\\\\\\\\\\\\_ts': '2019-06-01 12:22', 'tastes': { 'wine': 9, b'cheese': 7, 'cabbage': '1', }, } user = User(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*external\\\\\\\\\\\\\\_data) print(user.id) #> 123 print(user.model\\\\\\\\\\\\\\_dump()) \"\"\" { 'id': 123, 'name': 'John Doe', 'signup\\\\\\\\\\\\\\_ts': datetime.datetime(2019, 6, 1, 12, 22), 'tastes': {'wine': 9, 'cheese': 7, 'cabbage': 1}, } \"\"\" If validation fails, Pydantic will raise an error with a breakdown of what was wrong: Validation Error # continuing the above example... from pydantic import ValidationError class User(BaseModel): id: int name: str = 'John Doe' signup\\\\\\\\\\\\\\_ts: datetime | None tastes: dict\\\\\\\\\\\\\\[str, PositiveInt\\\\\\\\\\\\\\] external\\\\\\\\\\\\\\_data = {'id': 'not an int', 'tastes': {}} try: User(\\\\\\\\\\\\\\*\\\\\\\\\\\\\\*external\\\\\\\\\\\\\\_data) except ValidationError as e: print(e.errors()) \"\"\" \\\\\\\\\\\\\\[ { 'type': 'int\\\\\\\\\\\\\\_parsing', 'loc': ('id',), 'msg': 'Input should be a valid integer, unable to parse string as an integer', 'input': 'not an int', 'url': 'https://errors.pydantic.dev/2/v/int\\\\\\\\\\\\\\_parsing', }, { 'type': 'missing', 'loc': ('signup\\\\\\\\\\\\\\_ts',), 'msg': 'Field required', 'input': {'id': 'not an int', 'tastes': {}}, 'url': 'https://errors.pydantic.dev/2/v/missing', }, \\\\\\\\\\\\\\] \"\"\" Who is using Pydantic?¶ Hundreds of organisations and packages are using Pydantic. Some of the prominent companies and organizations around the world who are using Pydantic include: For a more comprehensive list of open-source projects using Pydantic see the list of dependents on github, or you can find some awesome projects using Pydantic in awesome-pydantic. Made with Material for MkDocs Insiders"
  }
]